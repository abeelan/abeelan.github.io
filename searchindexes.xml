<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>功能测试 - 抓包工具 Charles 代理Macos请求</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7-charles-%E4%BB%A3%E7%90%86macos%E8%AF%B7%E6%B1%82/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html">准备：Charles（4.6.1）MacOS（10.15.7）
第一步：设置 Charles
1）打开 Charles，勾选 macOS Proxy，开启代理本机；
2）勾选后会弹出权限许可弹框，点击授予权限即可；
弹框内容：macOS代理自动配置；Charles 可以自动配置您的网络设置并使用，这需要你授予权限给 Charles 代理设置应用程序。
您只需要这样做一次。现在设置吗? 没有；授予权限
第二步：设置 chrome 浏览器
1）下载代理扩展插件 Proxy SwitchyOmega
地址：https://chrome.google.com/webstore/detail/proxy-switchyomega/padekgcemlokbadohgkifijomclgjgif?hl=zh-CN
2）新建情景模式
3）将代理配置为刚才创建好的 Charles
第三步：验证
打开新的浏览器窗口，百度搜索“测试”，查看 Charles 是否代理成功</content></entry><entry><title>功能测试 - 正则表达式汇总</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B1%87%E6%80%BB/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html"><![CDATA[一、校验数字的表达式 1 数字： ^[0-9]$
2 n位的数字： ^\d{n}$
3 至少n位的数字： ^\d{n,}$
4 m-n位的数字：^\d{m,n}$
5 零和非零开头的数字：^(0|[1-9][0-9]*)$
6 非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]{1,2})?$
7 带1-2位小数的正数或负数：^(-)?\d+(.\d{1,2})?$
8 正数、负数、和小数：想
9 有两位小数的正实数：^[0-9]+(.[0-9]{2})?$
10 有1~3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$
11 非零的正整数：^[1-9]\d*$ 或 ^([1-9][0-9]){1,3}$ 或 ^+?[1-9][0-9]$
12 非零的负整数：^-[1-9][]0-9&quot;$ 或 ^-[1-9]\d$
13 非负整数：^\d+$ 或 ^[1-9]\d*|0$
14 非正整数：^-[1-9]\d*|0$ 或 ^((-\d+)|(0+))$
15 非负浮点数：^\d+(.\d+)?$ 或 ^[1-9]\d*.\d*|0.\d*[1-9]\d*|0?.0+|0$
16 非正浮点数：^((-\d+(.\d+)?)|(0+(.0+)?))$ 或 ^(-([1-9]\d*.\d*|0.\d*[1-9]\d*))|0?.0+|0$
17 正浮点数：^[1-9]\d*.\d*|0.\d*[1-9]\d*$ 或 ^(([0-9]+.[0-9][1-9][0-9])|([0-9][1-9][0-9].[0-9]+)|([0-9][1-9][0-9]))$
18 负浮点数：^-([1-9]\d*.\d*|0.\d*[1-9]\d*)$ 或 ^(-(([0-9]+.[0-9][1-9][0-9])|([0-9][1-9][0-9].[0-9]+)|([0-9][1-9][0-9])))$
19 浮点数：^(-?\d+)(.\d+)?$ 或 ^-?([1-9]\d*.\d*|0.\d*[1-9]\d*|0?.0+|0)$
二、校验字符的表达式 1 汉字：^[\u4e00-\u9fa5]{0,}$
2 英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$
3 长度为3-20的所有字符：^.{3,20}$
4 由26个英文字母组成的字符串：^[A-Za-z]+$
5 由26个大写英文字母组成的字符串：^[A-Z]+$
6 由26个小写英文字母组成的字符串：^[a-z]+$
7 由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$
8 由数字、26个英文字母或者下划线组成的字符串：^\w+$ 或 ^\w{3,20}$
9 中文、英文、数字包括下划线：^[\u4E00-\u9FA5A-Za-z0-9_]+$
10 中文、英文、数字但不包括下划线等符号：^[\u4E00-\u9FA5A-Za-z0-9]+$ 或 ^[\u4E00-\u9FA5A-Za-z0-9]{2,20}$
11 可以输入含有^%&amp;',;=?$&quot;等字符：[^%&amp;',;=?$\x22]+
12 禁止输入含有~的字符：[^~\x22]+
三、特殊需求表达式 1 Email地址：^\w+([-+.]\w+)@\w+([-.]\w+).\w+([-.]\w+)*$
2 域名：[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.?
3 InternetURL：[a-zA-z]+://[^\s]* 或 ^http://([\w-]+.)+[\w-]+(/[\w-./?%&amp;=]*)?$
4 手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\d{8}$
5 电话号码(&ldquo;XXX-XXXXXXX&rdquo;、&ldquo;XXXX-XXXXXXXX&rdquo;、&ldquo;XXX-XXXXXXX&rdquo;、&ldquo;XXX-XXXXXXXX&rdquo;、&ldquo;XXXXXXX&quot;和&quot;XXXXXXXX)：^((\d{3,4}-)|\d{3.4}-)?\d{7,8}$
6 国内电话号码(0511-4405222、021-87888822)：\d{3}-\d{8}|\d{4}-\d{7}
7 身份证号(15位、18位数字)：^\d{15}|\d{18}$
8 短身份证号码(数字、字母x结尾)：^([0-9]){7,18}(x|X)?$ 或 ^\d{8,18}|[0-9x]{8,18}|[0-9X]{8,18}?$
9 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$
10 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\w{5,17}$
11 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.\d)(?=.[a-z])(?=.*[A-Z]).{8,10}$
12 日期格式：^\d{4}-\d{1,2}-\d{1,2}
13 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$
14 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$
16 1.有四种钱的表示形式我们可以接受:&ldquo;10000.00&rdquo; 和 &ldquo;10,000.00&rdquo;, 和没有 &ldquo;分&rdquo; 的 &ldquo;10000&rdquo; 和 &ldquo;10,000&rdquo;：^[1-9][0-9]*$
17 2.这表示任意一个不以0开头的数字,但是,这也意味着一个字符&quot;0&quot;不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$
18 3.一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$
19 4.这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$
20 5.必须说明的是,小数点后面至少应该有1位数,所以&quot;10.&ldquo;是不通过的,但是 &ldquo;10&rdquo; 和 &ldquo;10.2&rdquo; 是通过的：^[0-9]+(.[0-9]{2})?$
21 6.这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]{1,2})?$
22 7.这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]{1,3}(,[0-9]{3})*(.[0-9]{1,2})?$
23 8.1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]{1,3}(,[0-9]{3})*)(.[0-9]{1,2})?$
24 备注：这就是最终结果了,别忘了&rdquo;+&ldquo;可以用&rdquo;*&ldquo;替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里
25 xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\.[x|X][m|M][l|L]$
26 中文字符的正则表达式：[\u4e00-\u9fa5]
27 双字节字符：[^\x00-\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1))28 空白行的正则表达式：\n\s*\r (可以用来删除空白行)
29 HTML标记的正则表达式：&lt;(\S*?)[^&gt;]&gt;.?&lt;/\1&gt;|&lt;.? /&gt; (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力)30 首尾空白字符的正则表达式：^\s|\s*$或(^\s*)|(\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式)
31 腾讯QQ号：[1-9][0-9]{4,} (腾讯QQ号从10000开始)
32 中国邮政编码：[1-9]\d{5}(?!\d) (中国邮政编码为6位数字)
33 IP地址：\d+.\d+.\d+.\d+ (提取IP地址时有用)34 IP地址：((?:(?:25[0-5]|2[0-4]\d|[01]?\d?\d)\.){3}(?:25[0-5]|2[0-4]\d|[01]?\d?\d))
&ldquo;^\d+$&rdquo; //非负整数（正整数 + 0）
&ldquo;^[0-9][1-9][0-9]$&rdquo; //正整数
&ldquo;^((-\d+)|(0+))$&rdquo; //非正整数（负整数 + 0）
&ldquo;^-[0-9][1-9][0-9]$&rdquo; //负整数
&ldquo;^-?\d+$&rdquo; //整数
&ldquo;^\d+(.\d+)?$&rdquo; //非负浮点数（正浮点数 + 0）
&ldquo;^(([0-9]+.[0-9][1-9][0-9])|([0-9][1-9][0-9].[0-9]+)|([0-9][1-9][0-9]))$&rdquo; //正浮点数
&ldquo;^((-\d+(.\d+)?)|(0+(.0+)?))$&rdquo; //非正浮点数（负浮点数 + 0）
&ldquo;^(-(([0-9]+.[0-9][1-9][0-9])|([0-9][1-9][0-9].[0-9]+)|([0-9][1-9][0-9])))$&rdquo; //负浮点数
&ldquo;^(-?\d+)(.\d+)?$&rdquo; //浮点数
&ldquo;^[A-Za-z]+$&rdquo; //由26个英文字母组成的字符串
&ldquo;^[A-Z]+$&rdquo; //由26个英文字母的大写组成的字符串
&ldquo;^[a-z]+$&rdquo; //由26个英文字母的小写组成的字符串
&ldquo;^[A-Za-z0-9]+$&rdquo; //由数字和26个英文字母组成的字符串
&ldquo;^\w+$&rdquo; //由数字、26个英文字母或者下划线组成的字符串
&ldquo;^[\w-]+(.[\w-]+)*@[\w-]+(.[\w-]+)+$&rdquo; //email地址
&ldquo;^[a-zA-z]+://(\w+(-\w+))(.(\w+(-\w+)))(?\S)?$&rdquo; //url
整数或者小数：^[0-9]+.{0,1}[0-9]{0,2}$
只能输入数字：&quot;^[0-9]*$&quot;。
只能输入n位的数字：&quot;^\d{n}$&quot;。
只能输入至少n位的数字：&quot;^\d{n,}$&quot;。
只能输入m~n位的数字：。&quot;^\d{m,n}$&rdquo;
只能输入零和非零开头的数字：&quot;^(0|[1-9][0-9]*)$&quot;。
只能输入有两位小数的正实数：&quot;^[0-9]+(.[0-9]{2})?$&quot;。
只能输入有1~3位小数的正实数：&quot;^[0-9]+(.[0-9]{1,3})?$&quot;。
只能输入非零的正整数：&quot;^+?[1-9][0-9]*$&quot;。
只能输入非零的负整数：&quot;^-[1-9][]0-9&rdquo;*$。
只能输入长度为3的字符：&quot;^.{3}$&quot;。
只能输入由26个英文字母组成的字符串：&quot;^[A-Za-z]+$&quot;。
只能输入由26个大写英文字母组成的字符串：&quot;^[A-Z]+$&quot;。
只能输入由26个小写英文字母组成的字符串：&quot;^[a-z]+$&quot;。
只能输入由数字和26个英文字母组成的字符串：&quot;^[A-Za-z0-9]+$&quot;。
只能输入由数字、26个英文字母或者下划线组成的字符串：&quot;^\w+$&quot;。
验证用户密码：&quot;^[a-zA-Z]\w{5,17}$&ldquo;正确格式为：以字母开头，长度在6~18之间，只能包含字符、数字和下划线。
验证是否含有^%&amp;'',;=?$&quot;等字符：&quot;[^%&amp;'',;=?$\x22]+&quot;。
只能输入汉字：&quot;^[\u4e00-\u9fa5]{0,}$&rdquo;
验证Email地址：&quot;^\w+([-+.]\w+)@\w+([-.]\w+).\w+([-.]\w+)*$&quot;。
验证InternetURL：&quot;^http://([\w-]+.)+[\w-]+(/[\w-./?%&amp;=]*)?$&quot;。
验证电话号码：&quot;^((\d{3,4}-)|\d{3.4}-)?\d{7,8}$&ldquo;正确格式为：&ldquo;XXX-XXXXXXX&rdquo;、&ldquo;XXXX-XXXXXXXX&rdquo;、&ldquo;XXX-XXXXXXX&rdquo;、&ldquo;XXX-XXXXXXXX&rdquo;、&ldquo;XXXXXXX&quot;和&quot;XXXXXXXX&rdquo;。
验证身份证号（15位或18位数字）：&quot;^\d{15}|\d{18}$&quot;。
验证一年的12个月：&quot;^(0?[1-9]|1[0-2])$&ldquo;正确格式为：&ldquo;01&quot;～&quot;09&quot;和&quot;1&quot;～&quot;12&rdquo;。
验证一个月的31天：&quot;^((0?[1-9])|((1|2)[0-9])|30|31)$&ldquo;正确格式
为；&ldquo;01&quot;～&quot;09&quot;和&quot;1&quot;～&quot;31&rdquo;。
整数或者小数：^[0-9]+.{0,1}[0-9]{0,2}$
&ldquo;^\w+$&rdquo; //由数字、26个英文字母或者下划线组成的字符串
&ldquo;^[\w-]+(.[\w-]+)*@[\w-]+(.[\w-]+)+$&rdquo; //email地址
&ldquo;^[a-zA-z]+://(\w+(-\w+))(.(\w+(-\w+)))(?\S)?$&rdquo; //url
可输入形如2008、2008-9、2008-09、2008-9-9、2008-09-09. ^(\d{4}|(\d{4}-\d{1,2})|(\d{4}-\d{1,2}-\d{1,2}))$
邮箱验证正则表达式 \w+([-+.']\w+)@\w+([-.]\w+).\w+([-.]\w+)*
四、网络验证应用技巧  验证 E-mail格式  public bool IsEmail(string str_Email) { return System.Text.RegularExpressions.Regex.IsMatch(str_Email,@&quot;^([\w-.]+)@(([−9]1,3.[−9]1,3.[−9]1,3.)|(([\w−]+.)+))([a−zA−Z]2,4|[−9]1,3)(?)$&quot;); }
 验证 IP 地址  public bool IPCheck(string IP) {
string num = &ldquo;(25[0-5]|2[0-4]\d|[0-1]\d{2}|[1-9]?\d)&quot;; return Regex.IsMatch(IP,(&quot;^&rdquo; + num + &ldquo;\.&rdquo; + num + &ldquo;\.&rdquo; + num + &ldquo;\.&rdquo; + num + &ldquo;$&quot;)); }
 验证 URL  public bool IsUrl(string str_url) { return System.Text.RegularExpressions.Regex.IsMatch(str_url, @&ldquo;http(s)?://([\w-]+.)+[\w-]+(/[\w- ./?%&amp;=]*)?&quot;); }
五、 常用数字验证技巧
• 验证电话号码
public bool IsTelephone(string str_telephone) { return System.Text.RegularExpressions.Regex.IsMatch(str_telephone, @&quot;^(\d{3,4}-)?\d{6,8}$&quot;); }
 输入密码条件(字符与数据同时出现)  public bool IsPassword(string str_password) { return System.Text.RegularExpressions.Regex.IsMatch(str_password, @&quot;[A-Za-z]+[0-9]&quot;); }
 邮政编号  public bool IsPostalcode(string str_postalcode) { return System.Text.RegularExpressions.Regex.IsMatch(str_postalcode, @&quot;^\d{6}$&quot;); }
 手机号码  public bool IsHandset(string str_handset) { return System.Text.RegularExpressions.Regex.IsMatch(str_handset, @&quot;^[1]+[3,5]+\d{9}$&quot;); }
 身份证号  public bool IsIDcard(string str_idcard) { return System.Text.RegularExpressions.Regex.IsMatch(str_idcard, @&quot;(^\d{18}$)|(^\d{15}$)&quot;); }
 两位小数  public bool IsDecimal(string str_decimal) { return System.Text.RegularExpressions.Regex.IsMatch(str_decimal, @&quot;^[0-9]+(.[0-9]{2})?$&quot;); }
 一年的12个月  public bool IsMonth(string str_Month) { return System.Text.RegularExpressions.Regex.IsMatch(str_Month, @&quot;^(0?[[1-9]|1[0-2])$&quot;); }
 一个月的31天  public bool IsDay(string str_day) { return System.Text.RegularExpressions.Regex.IsMatch(str_day, @&quot;^((0?[1-9])|((1|2)[0-9])|30|31)$&quot;); }
 数字输入  public bool IsNumber(string str_number) { return System.Text.RegularExpressions.Regex.IsMatch(str_number, @&quot;^[0-9]*$&quot;); }
 密码长度 (6-18位)  public bool IsPasswLength(string str_Length) { return System.Text.RegularExpressions.Regex.IsMatch(str_Length, @&quot;^\d{6,18}$&quot;); }
 非零的正整数  public bool IsIntNumber(string str_intNumber) { return System.Text.RegularExpressions.Regex.IsMatch(str_intNumber, @&quot;^+?[1-9][0-9]*$&quot;); }
六、 常用字符验证技巧 1.大写字母
public bool IsUpChar(string str_UpChar) { return System.Text.RegularExpressions.Regex.IsMatch(str_UpChar, @&quot;^[A-Z]+$&quot;); }
2.小写字母
public bool IsLowChar(string str_UpChar) { return System.Text.RegularExpressions.Regex.IsMatch(str_UpChar, @&quot;^[a-z]+$&quot;); }
3.检查字符串重复出现的词
private void btnWord_Click(object sender, EventArgs e) { System.Text.RegularExpressions.MatchCollection matches = System.Text.RegularExpressions.Regex.Matches(label1.Text, @&quot;\b(?\w+)\s+(\k)\b&rdquo;, System.Text.RegularExpressions.RegexOptions.Compiled   | System.Text.RegularExpressions.RegexOptions.IgnoreCase); if (matches.Count != 0) {
foreach (System.Text.RegularExpressions.Match match in matches) {
string word = match.Groups[&ldquo;word&rdquo;].Value; MessageBox.Show(word.ToString(),&ldquo;英文单词&rdquo;); } } else { MessageBox.Show(&ldquo;没有重复的单词&rdquo;); } }
4.替换字符串
private void button1_Click(object sender, EventArgs e) {
string strResult = System.Text.RegularExpressions.Regex.Replace(textBox1.Text, @&quot;[A-Za-z]*?&rdquo;, textBox2.Text); MessageBox.Show(&ldquo;替换前字符:&rdquo; + &ldquo;\n&rdquo; + textBox1.Text + &ldquo;\n&rdquo; + &ldquo;替换的字符:&rdquo; + &ldquo;\n&rdquo; + textBox2.Text + &ldquo;\n&rdquo; + &ldquo;替换后的字符:&rdquo; + &ldquo;\n&rdquo; + strResult,&ldquo;替换&rdquo;); }
5·拆分字符串
private void button1_Click(object sender, EventArgs e) { //实例: 甲025-8343243乙0755-2228382丙029-32983298389289328932893289丁
foreach (string s in System.Text.RegularExpressions.Regex.Split(textBox1.Text,@&quot;\d{3,4}-\d*&quot;)) {
textBox2.Text+=s; //依次输出 &ldquo;甲乙丙丁&rdquo; } }
6.验证输入字母
public bool IsLetter(string str_Letter) { return System.Text.RegularExpressions.Regex.IsMatch(str_Letter, @&quot;^[A-Za-z]+$&quot;); }
7.验证输入汉字
public bool IsChinese(string str_chinese) { return System.Text.RegularExpressions.Regex.IsMatch(str_chinese, @&quot;^[\u4e00-\u9fa5],{0,}$&quot;); }
8.验证输入字符串 (至少8个字符)
public bool IsLength(string str_Length) { return System.Text.RegularExpressions.Regex.IsMatch(str_Length, @&quot;^.{8,}$&quot;); }
来源：https://www.zhihu.com/question/48219401/answer/1476436385
]]></content></entry><entry><title>Linux - 命令 Truncate生成大文件</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-truncate%E7%94%9F%E6%88%90%E5%A4%A7%E6%96%87%E4%BB%B6/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[生成各种类型的大文件
$ truncate -s 1G test.txt $ truncate -s 1G bigfile.xmind  docx xls xmind pdf（11G）  用法：truncate 选项&hellip; 文件&hellip; 将文件缩减或扩展至指定大小。
如果指定文件不存在则创建。
如果指定文件超出指定大小则超出的数据将丢失。 如果指定文件小于指定大小则用0 补足。
长选项必须使用的参数对于短选项时也是必需使用的。 -c, &ndash;no-create	不创建文件 -o, &ndash;io-blocks	将SIZE 视为IO 块数而不使用字节数 -r, &ndash;reference=文件 使用此文件的大小 -s, &ndash;size=大小	使用此大小 &ndash;help	显示此帮助信息并退出 &ndash;version	显示版本信息并退出
SIZE 可以是一个可选的整数，后面跟着以下单位中的一个： KB 1000，K 1024，MB 10001000，M 10241024，还有 G、T、P、E、Z、Y。
指定大小也可使用以下前缀修饰： &ldquo;+&rdquo; 增加，&quot;-&quot; 减少，&quot;&lt;&quot; 至多，&quot;&gt;&quot; 至少， &ldquo;/&rdquo; 小于等于原尺寸数字的指定数字的最小倍数，&quot;%&quot; 大于等于原尺寸数字的指定数字的最大倍数。 译者注：当输入值为m，参考值为n 时， &ldquo;/&rdquo; 运算的数学计算式为 m / n * n； &ldquo;%&rdquo; 运算的数学计算式为( m + n - 1 ) / n * n
请注意-r 和-s 是互斥的选项。
[tank@localhost test1]$ echo -n 1234567 &gt; test #生成一个test文件 [tank@localhost test1]$ cat test	#查看内容 1234567[tank@localhost test1]$ truncate -s 4 test #设置文件大小为4字节 [tank@localhost test1]$ cat test #查看文件内容 1234[tank@localhost test1]$ [tank@localhost test1]$ du -ah #查看文件大小 4.0K	./test 8.0K	. [tank@localhost test1]$ truncate -s 2M test #声明将test文件扩大到2M [tank@localhost test1]$ du -ah #大小没变 4.0K	./test 8.0K	. [tank@localhost test1]$ ll 总用量 4 -rw-rw-r-- 1 tank tank 2097152 8月 21 10:33 test #大小变了 ]]></content></entry><entry><title>Golang - 基础笔记</title><url>/tech/golang/%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[环境配置 下载 Golang  下载地址：https://go.dev/dl/ 安装一路下一步即可  $ go version go version go1.20.5 darwin/amd64 下载 Goland  下载地址：https://www.jetbrains.com/go/download/#section=mac 激活教程：https://shimo.im/docs/WY3hd8Jt8KHgvVty/read  环境验证 打开 goland，创建项目 go-basic，项目下创建主文件 main.go 文件，作为程序入口
// main.go  package main import &#34;fmt&#34; func main() { fmt.Println(&#34;hello world&#34;) } 点击左侧执行按钮，控制台出现 hello world 即可。
项目结构  pkg：存放包 src：存放项目源码 bin：可执行文件 一个项目必须有一个 main 包和 main 函数  1.11 以后，可以随意编写自己的项目结构，建议遵循官方
语法基础 声明变量  变量以字母开头，不可以是数字或特殊字符 不能用关键字  package main import &#34;fmt&#34; func main() { // 显式声明变量的关键字 var 	// 关键字 变量名 变量类型 = 变量值 	var a string = &#34;hello world !&#34; // 隐式声明，系统自动根据值判断类型 	b := &#34;hello world !!&#34; fmt.Println(a) fmt.Println(b) } 关键字 关键字不能作为变量名的单词
包管理（2 个）
 import package  程序实体声明与定义（8 个）
 chan const func interface map struct type var  程序流程控制（15 个）
 break case continue default defer else fallthrough for go goto if range return select switch  预定义标识符（36 个）
 append bool、false、true byte cap close int、int8、int16、int32、int64 float32、float64 complex、conplex64、complex128 uint、uint8、uint16、uint32、uint64 copy imag iota len make new nil panic print、println real recover string uintptr  注释  单行注释：// 我是注释 多行注释：/* 我是注释 */  包 一个文件夹下不能出现多个包，只能有一个包，但是可以有多个文件。
package foo // 包里面的变量名或方法名首字母大写表示共有，可以在其他包使用 // 首字母小写表示私有 var F string = &#34;foo package&#34; package main import ( &#34;fmt&#34; &#34;go-basic/foo&#34; ) func main() { fmt.Println(foo.F) } 上面为导包的常用方法，还有两种方法：
import ( &#34;fmt&#34; bar &#34;go-basic/foo&#34; // &lt;-- 导包 ) func main() { fmt.Println(bar.F) // &lt;-- 通过别名引入 } import ( &#34;fmt&#34; . &#34;go-basic/foo&#34; // &lt;-- 导包 ) func main() { fmt.Println(F) // &lt;-- 直接使用变量 } 数据类型 // 数据类型判断 package main import &#34;fmt&#34; func main() { var num int num = 10 // 选择 Print(format string: ...) 	fmt.Printf(&#34;%T&#34;, num) } // 这里打印的就是变量的类型  // 数据类型的转换 package main import ( &#34;fmt&#34; &#34;strconv&#34; ) func main() { str1 := &#34;123&#34; int1, _ := strconv.Atoi(str1) fmt.Println(&#34;str to int: &#34;, int1) int2 := 123 str2 := strconv.Itoa(int2) fmt.Println(&#34;int to str: &#34;, str2) } 流程控制 递增递减语句：自增、自减 package main import &#34;fmt&#34; func main() { i := 0 i++ fmt.Println(i) i-- fmt.Println(i) } // 输出 1 0 // go 没有 ++i 这种语法，就上面这一种 条件语句：if、if else、else package main import &#34;fmt&#34; func main() { a := 8 if a &lt;= 5 { fmt.Println(&#34;区间：0 - 5&#34;) } else if a &lt;= 10 { fmt.Println(&#34;区间：6 - 10&#34;) } else { fmt.Println(&#34;区间: 11+&#34;) } } 选择语句：switch package main import &#34;fmt&#34; func main() { a := 0 switch a { case 0: fmt.Println(&#34;0&#34;) fallthrough // 匹配到后穿过继续执行下一个，仅执行下一个 	case 1: fmt.Println(&#34;1&#34;) case 2: fmt.Println(&#34;2&#34;) default: fmt.Println(&#34;没匹配到！&#34;) } } // 输出： 0 1 循环语句：for package main import &#34;fmt&#34; func main() { // 死循环；没有结束条件，一直运行 	for { fmt.Println(&#34;go!&#34;) } // 直到型循环 	a := 0 for { a++ fmt.Println(a) if a &gt; 10 { break } } b := 1 for b &lt; 10 { b++ fmt.Println(b) } // 传统 for 	for a := 1; a &lt; 10; a++ { fmt.Println(a) } } 跳转语句  多层循环嵌套跳出：break、continue 调整执行位置：goto  package main import &#34;fmt&#34; func main() { a := 0 A: for a &lt; 10 { a++ fmt.Println(a) if a == 5 { break A goto B } } B: fmt.Println(&#34;我来到 B 了！&#34;) } 数组和切片 初始化数组 package main import &#34;fmt&#34; func main() { // 声明数组长度 	a := [3]int{1, 2, 3} // 自动确定数组长度 	b := [...]int{4, 5, 6} // 通过创建数组对象 	var c = new([10]int) c[5] = 8 fmt.Println(a, b, c) } 循环打印数组内容 package main import &#34;fmt&#34; func main() { zoo := [...]string{&#34;熊猫&#34;, &#34;狮子&#34;, &#34;老虎&#34;} for i := 0; i &lt; len(zoo); i++ { fmt.Println(zoo[i] + &#34;冲啊！&#34;) } /* 熊猫冲啊！ 狮子冲啊！ 老虎冲啊！ */ for i, v := range zoo { fmt.Println(i, v) } /* 0 熊猫 1 狮子 2 老虎 */ // 数组的情况下 容量和长度一般相等 	fmt.Println(cap(zoo), len(zoo)) } 初始化二维数组 package main import &#34;fmt&#34; func main() { arr2 := [3][3]int{ [3]int{0, 1, 2}, [3]int{1, 2, 3}, [3]int{2, 3, 4}, // 这里逗号不能省略 	} fmt.Println(arr2) } 数组切片 package main import &#34;fmt&#34; func main() { a := [3]int{1, 2, 3} cl := a[1:] // [2 3] 	cl1 := a[0:1] // [1] 前开后闭 	cl2 := a[:1] // [1] 从开始取到下标 1 结束，不包括下标 1 	cl3 := a[1:] // [2, 3] 从下标 1 取到最后 	fmt.Println(cl1, cl2, cl3) // 切片是原数组的一部分，修改切片后原数组也发生改变 	cl[1] = 5 fmt.Println(cl) // [2 5] 	fmt.Println(a) // [1 2 5]  // 数组容量是固定的，但是切片可以添加 	cl = append(cl, 8) fmt.Println(cl) // [2 5 8] 切片在原有的基础上增加了 8  // 切片在 append 后，再修改数据，就不会影响原数组了 	cl[0] = 6 fmt.Println(a, cl) // a[1 2 5] cl[6 5 8]  // 原数组是没有 append copy 等方法的  // 只有在切片上才有，创建一个空切片的方法如下  var cli1 []int cli2 := make([]int, 4, 6) // 这种方式可以直接放 len cap } 数组切片扩容
package main import &#34;fmt&#34; func main() { a := [3]int{1, 2, 3} cl := a[:] fmt.Println(len(cl), cap(cl)) // 3 3 	// 向切片添加数据后，到达临界值会自动扩容，避免多次申请空间 	cl = append(cl, 5) fmt.Println(len(cl), cap(cl)) // 4 6 	cl = append(cl, 5) fmt.Println(len(cl), cap(cl)) // 5 6 	cl = append(cl, 5) fmt.Println(len(cl), cap(cl)) // 6 6 	cl = append(cl, 5) fmt.Println(len(cl), cap(cl)) // 7 12 } 数组切片复制
package main import &#34;fmt&#34; func main() { a := [3]int{0, 1, 2} cl1 := a[:] // [0, 1, 2] 	cl2 := a[2:] // [2]  // 把第二个数组的内容复制到第一个数组 	copy(cl1, cl2) fmt.Println(cl1) // [2 1 2] 第一位有数据了就自动跳过了  // 复制到指定切片的地方 	copy(cl1[1:2], cl2) fmt.Println(cl1) } map 声明和使用 声明 map 是类似于字典或哈希表的键值对，key: value 形式。
package main import &#34;fmt&#34; func main() { // 声明方式一 var 	var m1 map[string]string m1 = map[string]string{} // 声明方式二 隐式声明 	m2 := map[string]string{} // 声明方式三 make 	m3 := make(map[string]string) fmt.Println(m1) // map[] 	fmt.Println(m2) // map[] 	fmt.Println(m3) // map[] } 使用方式 package main import &#34;fmt&#34; func main() { // 基础的声明和使用 	m1 := map[string]string{} // 使用 	m1[&#34;name&#34;] = &#34;tom&#34; m1[&#34;gender&#34;] = &#34;male&#34; fmt.Println(m1) // map[gender:male name:tom]  // go 的 map 键可以是任意的，不局限与字符串 	m2 := map[int]bool{} m2[1] = true m2[2] = false fmt.Println(m2) // map[1:true 2:false]  // 通过声明值为接口，可以放各种类型的数据，混合类型 	m3 := map[int]interface{}{} m3[0] = &#34;string&#34; m3[1] = 18 m3[2] = [3]int{0, 1, 2} m3[3] = false fmt.Println(m3) // map[0:string 1:18 2:[0 1 2] 3:false] } 通过循环打印 map 内容
package main import &#34;fmt&#34; func main() { m := map[string]interface{}{} m[&#34;a&#34;] = 1 m[&#34;b&#34;] = true m[&#34;c&#34;] = &#34;test&#34; m[&#34;d&#34;] = false for k, v := range m { fmt.Println(k, v) } /* 无序 d false a 1 b true c test */ } 函数 func 声明及调用 go 语言中函数内不可再声明函数，函数名首字母大写可以被别的包调用，小写为本包私有。
不带返回值
package main import &#34;fmt&#34; func main() { OutputUint(10, &#34;请输入正整数！&#34;) // 10 	OutputUint(-10, &#34;请输入正整数！&#34;) // 请输入正整数！ } func OutputUint(num int, errMsg string) { if num &gt;= 0 { fmt.Println(num) } else { fmt.Println(errMsg) } } 带返回值
package main import &#34;fmt&#34; func main() { r11, r12 := OutputUint(10, &#34;请输入正整数！&#34;) fmt.Println(r11, r12) // &lt;-- 	r21, r22 := OutputUint(-10, &#34;请输入正整数！&#34;) fmt.Println(r21, r22) // &lt;-- } func OutputUint(num int, errMsg string) (rNum int, isUint bool) { if num &gt;= 0 { fmt.Println(num) // &lt;-- 	return num, true } else { fmt.Println(errMsg) // &lt;-- 	return num, false } } /* 10 10 true 请输入正整数！ -10 false */ 带返回值的另一种写法
// 函数的返回值还有一种写法 // 函数体内给返回值变量赋值然后直接写个 retrun 就行 func OutputUint(num int, errMsg string) (rNum int, isUint bool) { rNum = num if num &gt;= 0 { isUint = true } else { isUint = false } return } /* 10 true -10 false */ 匿名函数 package main import &#34;fmt&#34; func main() { // 匿名函数可以在函数体内调用 	f := func(str string) { fmt.Println(str) } f(&#34;我是匿名函数！&#34;) } 函数参数不定长 package main import &#34;fmt&#34; func main() { demo(18, &#34;a&#34;, &#34;b&#34;, &#34;c&#34;) } // 传入不定长度的参数 func demo(num int, data ...string) { // &lt;-- 	fmt.Println(num) // 18 	fmt.Println(data) // [a b c] } 那如果本来就有一个字符串数组，想要传递给 demo 函数呢？可以这样做。
package main import &#34;fmt&#34; func main() { arr := []string{&#34;a&#34;, &#34;b&#34;, &#34;c&#34;} demo(18, arr...) // &lt;-- } func demo(num int, data ...string) { fmt.Println(num) // 这里可以通过 for 循环打印整个不定项参数的内容 	for k, v := range data { fmt.Println(k, v) } } /* 18 0 a 1 b 2 c */ 自调用函数 package main import &#34;fmt&#34; func main() { (func() { fmt.Println(&#34;我是自调用函数，声明即执行，没人能调用我！&#34;) })() } // 一对括号括起来，然后外面再来一对括号 闭包函数 函数返回一个函数
package main import &#34;fmt&#34; func main() { closureFunc() // 没有任何输出 	closureFunc()(10) // 输出：我是闭包函数最终执行的语句，给我的值是： 10 } func closureFunc() func(int) { return func(num int) { fmt.Println(&#34;我是闭包函数最终执行的语句，给我的值是:&#34;, num) } } 延迟调用函数 无论函数放在哪里，都是最后才被调用
package main import &#34;fmt&#34; func main() { defer deferFunc() // 虽然写在第一行，但是是最后执行 	fmt.Println(&#34;called.&#34;) fmt.Println(&#34;called.&#34;) fmt.Println(&#34;called.&#34;) } func deferFunc() { fmt.Println(&#34;我是 deferFunc 函数！&#34;) } /* called. called. called. called. 我是 deferFunc 函数！ */ 指针和地址 指针用 * 表示，表示这个变量本身没有存储任何值，而是拿到数据的内存地址。
地址：和指针搭配使用。
变量指针 package main import &#34;fmt&#34; func main() { var a int a = 123 fmt.Println(a) // 123  var b int b = a // a 的值赋值给 b 	fmt.Println(a, b) // 123 123  b = 456 // b 的修改不会引起 a 的变动 	fmt.Println(a, b) // 123 456  // 重点来了 使用指针修改变量 	var c *int c = &amp;a // 把 c 指针指向 a 的内存地址，通过 &amp;a 取变量的内存地址 	*c = 456 // 修改 c 指针所指向内存地址的值（也就是 a 的值） 	fmt.Println(a) // 456 	fmt.Println(c) // 0xc00010e008 指针变量输出的是内存地址 	fmt.Println(*c) // 456 通过 *c 来取该地址的值  fmt.Println(a == *c, &amp;a == c) // true true } 数组指针和指针数组 package main import &#34;fmt&#34; func main() { var arr [3]string arr = [3]string{&#34;a&#34;, &#34;b&#34;, &#34;c&#34;} fmt.Println(arr) // 数组指针：数组里面都是值，指整个数组的指针地址 	var arrP *[3]string arrP = &amp;arr fmt.Println(arrP) // &amp;[a b c] 数组地址 	fmt.Println(*arrP) // [a b c] 数组值 } package main import &#34;fmt&#34; func main() { a := &#34;a&#34; b := &#34;b&#34; c := &#34;c&#34; array := [3]string{a, b, c} array[1] = &#34;m&#34; fmt.Println(b) // b ;依然是 b，数组内的值不会改变原始变量的值  // 如果指针数组的话可以通过指针修改变量 	// 指针数组：数组里面存的都是指针 	var arr [3]*string arr = [3]*string{&amp;a, &amp;b, &amp;c} fmt.Println(arr) // [0xc000014270 0xc000014280 0xc000014290]  *arr[1] = &#34;m&#34; fmt.Println(b) // m ;通过指针更改了数组内的值 } 函数指针 package main import &#34;fmt&#34; func main() { s := &#34;我是初始值&#34; f(s) // 函数的值传递 	fmt.Println(s) // 我是初始值 ;未被修改  fPoint(&amp;s) // 函数的地址传递 	fmt.Println(s) // fPoint 函数体内重新赋值 ;被成功修改 } func f(str string) { str = &#34;f 函数体内重新赋值&#34; } func fPoint(strPoint *string) { *strPoint = &#34;fPoint 函数体内重新赋值&#34; } 结构体 struct 结构体是一个可以存储不同数据类型的数据类型，声明完成后，可以像其他数据类型一样使用，也有指针、值等等。
声明结构体 package main import &#34;fmt&#34; func main() { // 通过 var 关键字声明 	var tom UserStruct tom.Name = &#34;tom&#34; tom.Age = 18 tom.Male = true tom.Hobbies = []string{&#34;抽烟&#34;, &#34;喝酒&#34;, &#34;烫头&#34;} fmt.Println(tom) // {tom 18 true [抽烟 喝酒 烫头]}  // 隐式声明 	jerry := UserStruct{ &#34;jerry&#34;, 18, true, []string{&#34;吃饭&#34;, &#34;睡觉&#34;, &#34;打豆豆&#34;}, } fmt.Println(jerry) // {jerry 18 true [吃饭 睡觉 打豆豆]}  // 第三种写法，比较明确 	lisa := UserStruct{ Name: &#34;lisa&#34;, Age: 18, Male: false, Hobbies: []string{&#34;学习&#34;}, } fmt.Println(lisa) // {lisa 18 false [学习]}  // 第四种写法 通过 new 一个对象 	faker := new(UserStruct) faker.Name = &#34;faker&#34; fmt.Println(faker) // &amp;{faker 0 false []} 是一个地址 	// 以上所有方式不写参数都会有默认值 } type UserStruct struct { // 大写开头公有 首字母小写私有 	Name string Age uint Male bool Hobbies []string } package main import &#34;fmt&#34; func main() { tom := UserStruct{ &#34;tom&#34;, 18, true, []string{&#34;吃饭&#34;, &#34;睡觉&#34;}, } UsFunc(tom) } type UserStruct struct { // 大写开头公有 首字母小写私有 	Name string Age uint Male bool Hobbies []string } func UsFunc(us UserStruct) { fmt.Println(us) // {tom 18 true [吃饭 睡觉]} } 结构体可以有自己的方法 package main import &#34;fmt&#34; func main() { tom := UserStruct{ Name: &#34;Tom&#34;, } msg := tom.Song(&#34;Little Star&#34;) fmt.Println(msg) // Tom 唱了一首《Little Star》，大家觉得泰裤辣！ } type UserStruct struct { // 大写开头公有 首字母小写私有 	Name string Age uint Male bool Hobbies []string } func (us *UserStruct) Song(name string) (rStr string) { // 声明一个结构体函数 	rStr = fmt.Sprintf(&#34;%s 唱了一首《%s》，大家觉得泰裤辣！&#34;, us.Name, name) return } 结构体嵌套结构体 package main import &#34;fmt&#34; func main() { tom := UserStruct{ Name: &#34;Tom&#34;, } tom.Home.City = &#34;北京&#34; tom.HomeStruct.Address = &#34;昌平区回龙观&#34; fmt.Println(tom) // {Tom 0 false [] {北京 } { 昌平区回龙观}}  tom.Home.Info() // 假装打印具体的信息 	tom.HomeStruct.Info() // 假装打印具体的信息(同上) } type UserStruct struct { // 大写开头公有 首字母小写私有 	Name string Age uint Male bool Hobbies []string Home HomeStruct // 完整写法 	HomeStruct // 简写 如果没有给别名 则直接通过原名称调用 } type HomeStruct struct { City string Address string } func (home HomeStruct) Info() { // 嵌套的结构体也可以定义结构体方法 	fmt.Println(&#34;假装打印具体的信息&#34;) } 接口 interface 接口是一类规范，是一些方法的集合。
package main import &#34;fmt&#34; // Car 定义一个汽车的接口 type Car interface { AddOil() Driver() } // Audi 定义第一辆车的结构体 type Audi struct { Name string } func (audi Audi) AddOil() { fmt.Println(audi.Name, &#34; 加油中...&#34;) } func (audi Audi) Driver() { fmt.Println(audi.Name, &#34; 行驶中...&#34;) } // Volvo 定义第二辆车的结构体 type Volvo struct { Name string } func (volvo Volvo) AddOil() { fmt.Println(volvo.Name, &#34; 加油中...&#34;) } func (volvo Volvo) Driver() { fmt.Println(volvo.Name, &#34; 行驶中...&#34;) } func main() { // 使用方法一 	var car1 Car audi := Audi{ Name: &#34;Audi&#34;, } car1 = audi // car 可以接收实现该接口的数据 	car1.AddOil() // Audi 加油中... 	car1.Driver() // Audi 行驶中...  // 简写形式 	car2 := Volvo{ Name: &#34;Volvo&#34;, } car2.AddOil() // Volvo 加油中... 	car2.Driver() // Volvo 行驶中... } 接口实现泛型
package main import &#34;fmt&#34; func main() { Foo(&#34;哈哈&#34;) // 哈哈 	Foo(19) // 19 	Foo([5]int{1, 2, 3, 4, 5}) // [1 2 3 4 5] } // Foo 传参为接口时，是一个泛型函数，接收任何传参 func Foo(any interface{}) { fmt.Println(any) } 根据这个泛型的特性，声明一个函数，调用该函数就自动开始执行接口的所有函数
func main() { audi := Audi{ Name: &#34;Audi&#34;, } CalledAllFunc(audi) } func CalledAllFunc(car Car) { car.AddOil() car.Driver() } 还有一种场景，接口是在别的包定义的，导入包过来后，想使用怎么办？
// C 全局的 var C Car func main() { audi := Audi{ Name: &#34;Audi&#34;, } InitCar(audi) C.Driver() // &lt;-- 这里通过 C 也能调用 	C.AddOil() } func InitCar(car Car) { // 将数据初始化到全局变量的接口中 	C = car } 并发（goroutine&amp;channel） 协程 goroutine ⭐️ goroutine
在调用一个方法的前面加上 go 就是 goroutine，让方法异步执行，相当于 协程。
package main import &#34;fmt&#34; func main() { Run() // 正常调用 } func Run() { fmt.Println(&#34;Running...&#34;) } // 输出：Running... func main() { // 如果加上 go 	go Run() } // 没有任何输出 原因是主程序开始运行后，由于 Run 函数是异步执行的，并不会阻塞当前主程序。
所以主程序就直接结束，导致 Run 还没来得及输出。
package main import ( &#34;fmt&#34; &#34;time&#34; ) func main() { go Run() time.Sleep(1 * time.Second) // 主程序等待一秒再结束 } func Run() { fmt.Println(&#34;Running...&#34;) } // 输出：Running... 在等待的一秒钟，异步函数也在执行，所以输出结果，1 秒结束后主程序停止。
这次通过一个循环打印数字的方式，看看到底是什么时候执行的 Run 函数。
package main import &#34;fmt&#34; func main() { go Run() for i := 0; i &lt; 50; i++ { fmt.Println(i) } } func Run() { fmt.Println(&#34;Running...&#34;) } /* 25 26 Running... 27 28 */ 每次运行后，Run 函数的输出位置都是不一样的，也就是不确定异步的 Run 函数到底什么时候执行，跟当前主线程就没关系了~控制不了。
协程管理器 如果在主线程内要等待协程执行完毕，可以使用 协程管理器。
package main import ( &#34;fmt&#34; &#34;sync&#34; ) func main() { wg := sync.WaitGroup{} wg.Add(1) // 设置为 1 表示正在执行 	go Run(&amp;wg) // 这里必须传地址，否则修改无效，造成死锁 	wg.Wait() // 等待协程执行完毕 } func Run(wg *sync.WaitGroup) { fmt.Println(&#34;Running...&#34;) wg.Done() // Done 执行完毕后设置为 -1 } 协程间通讯工具 channel ⭐️ channel
channel 是 goroutine 之间的通讯桥梁。
定义 chan：
 可读可取：c:=make(chan int) 可读：var readChan &lt;- chan int = c 可取：var setChan chan &lt;- int = c 有缓冲：c:=make(chan int, 5) 无缓冲：c:=make(chan int)  有/无缓冲区 func main() { c := make(chan int, 1) // 有缓冲 	c &lt;- 1 // 存了 1，只能存 1 个 	fmt.Println(&lt;-c) // 1 读取出来 1 } func main() { c := make(chan int) // 无缓冲 	c &lt;- 1 // 没有缓冲区，存不进去 	fmt.Println(&lt;-c) // fatal error: all goroutines are asleep - deadlock! } 为啥报错？分析下程序执行逻辑
 c &lt;- 1 ，由于声明的时候，没有创建缓冲区，存不进去 fmt.Println(&lt;-c)到这里要读取的时候，会先去往容量里面存，然后再读 这里存的代码 c &lt;- 1 已经执行过了，没办法在主线程再返回去调用 所以程序卡在这里  如果创建一个 go 协程函数，里面存数据，那么主线程读数据，没有数据，就会读协程里面的数据，正常输出。
package main import &#34;fmt&#34; func main() { c := make(chan int) go func() { for i := 0; i &lt; 10; i++ { c &lt;- i } }() for i := 0; i &lt; 10; i++ { fmt.Println(&lt;-c) } } 以上无缓冲区，每次打印数据的时候都先阻塞，因为没有数据，协程数据存入后，再被读取出来。
依次读（无数据）、存（协程）、打印数据，所以结果正常打印 0-9；
如果是有缓冲区，则是在携程全部存完数据后，再被主线程一次性全部打印出来。
可读可写 package main import &#34;fmt&#34; func main() { c := make(chan int, 5) var readc &lt;-chan int = c var writec chan&lt;- int = c writec &lt;- 1 // 只能写 	fmt.Println(&lt;-readc) // 读了 1 	// &lt;-readc // 存 1 读 1，再读就报错 } 关闭 package main import &#34;fmt&#34; func main() { c := make(chan int, 5) c &lt;- 1 c &lt;- 2 c &lt;- 3 c &lt;- 4 c &lt;- 5 close(c) // 必须先关再读 	// 通过循环一次读所有 	for v := range c { fmt.Println(v) } } select 有数据才读，否则忽略。
package main import &#34;fmt&#34; func main() { c1 := make(chan int, 1) c2 := make(chan int, 1) c3 := make(chan int, 1) c2 &lt;- 1 // c2 存数据了  select { case &lt;-c1: fmt.Println(&#34;c1&#34;) case &lt;-c2: fmt.Println(&#34;c2&#34;) case &lt;-c3: fmt.Println(&#34;c3&#34;) default: fmt.Println(&#34;都没有数据！&#34;) } } // 因此最后输出 c2 // 如果删除 c2 存数据的话，那么输出 default 如果上面的三个 channel 都存数据了，那么随机执行一个 case 内的代码，谁先完成执行谁。
package main import &#34;fmt&#34; func main() { c := make(chan int) var readc &lt;-chan int = c var writec chan&lt;- int = c go SetChan(writec) GetChan(readc) } func SetChan(writec chan&lt;- int) { for i := 0; i &lt; 10; i++ { writec &lt;- i } } func GetChan(readc &lt;-chan int) { for i := 0; i &lt; 10; i++ { fmt.Println(&#34;GetChan: &#34;, &lt;-readc) } } 断言和反射 断言 Assertion 把一个接口类型指定为它原始的类型。
package main import &#34;fmt&#34; type User struct { Name string Age int } type Student struct { User } func (user User) SayName(name string) { fmt.Println(&#34;我的名字：&#34;, name) } func main() { user := User{ &#34;张三&#34;, 18, } student := Student{user} check(user) // User 	check(student) // Student  } func check(v interface{}) { // v.(User) 这种方式告诉 v 它是哪个结构体，这就叫断言是否是 User 	// v.(User).SayName(v.(User).Name)  switch v.(type) { case User: fmt.Println(&#34;User&#34;) case Student: fmt.Println(&#34;Student&#34;) } } 反射 reflect 在编译时不知道类型的情况下，可更新变量、运行时查看值、调用方法以及直接对他们的布局进行操作的机制，称为反射。
package main import ( &#34;fmt&#34; &#34;reflect&#34; ) type User struct { Name string Age int } func (user User) SayName(name string) { fmt.Println(&#34;我的名字：&#34;, name) } func main() { user := User{ &#34;张三&#34;, 18, } check(user) } func check(data interface{}) { // 通过反射 	t := reflect.TypeOf(data) // 获取类型 main.User 	v := reflect.ValueOf(data) // 获取数据 {张三 18} 	fmt.Println(t) fmt.Println(v) // 通过 for 循环 下标，取到该接口的每个值 	for i := 0; i &lt; t.NumField(); i++ { fmt.Println(v.Field(i)) } } package main import ( &#34;fmt&#34; &#34;reflect&#34; ) type User struct { Name string Age int } type Student struct { User Class string } func (user User) SayName(name string) { fmt.Println(&#34;我的名字：&#34;, name) } func main() { user := User{&#34;张三&#34;, 18} student := Student{user, &#34;三年二班&#34;} check(student) } func check(data interface{}) { t := reflect.TypeOf(data) v := reflect.ValueOf(data) fmt.Println(t, v) // 如果有名字，可以按照名称取值 	class := v.FieldByName(&#34;Class&#34;) fmt.Println(class) // 三年二班  // 如果没有名字，取 user 的值，按照下标取值 	user := v.FieldByIndex([]int{0}) fmt.Println(user) // {张三 18}  // 继续向下取值 	u1 := v.FieldByIndex([]int{0, 0}) u2 := v.FieldByIndex([]int{0, 1}) fmt.Println(u1, u2) // 张三 18 } package main import ( &#34;fmt&#34; &#34;reflect&#34; ) type User struct { Name string Age int } type Student struct { User Class string } func (user User) SayName(name string) { fmt.Println(&#34;我的名字：&#34;, name) } func main() { user := User{&#34;张三&#34;, 18} student := Student{user, &#34;三年二班&#34;} check(student) } func check(data interface{}) { t := reflect.TypeOf(data) // main.Student  ty := t.Kind() // 获取 t 是个啥类型 .kind() 	fmt.Println(ty) // struct  // 判断当前是啥类型 然后再去执行 	if ty == reflect.Struct { fmt.Println(&#34;in Struct&#34;) } if ty == reflect.String { fmt.Println(&#34;in String&#34;) } if ty == reflect.Int { fmt.Println(&#34;in Int&#34;) } } package main import ( &#34;fmt&#34; &#34;reflect&#34; ) type User struct { Name string Age int } type Student struct { User Class string } func (user User) SayName(name string) { fmt.Println(&#34;我的名字：&#34;, name) } func main() { user := User{&#34;张三&#34;, 18} student := Student{user, &#34;三年二班&#34;} check(&amp;student) // 修改原始数据必须传递指针  } func check(data interface{}) { value := reflect.ValueOf(data) fmt.Println(value) // &amp;{{张三 18} 三年二班}  valueElem := value.Elem() // 获取原始数据 	valueElem.FieldByName(&#34;Class&#34;).SetString(&#34;四年二班&#34;) fmt.Println(data) // &amp;{{张三 18} 四年二班} } 并发 sync 互斥锁（Mutex）  Lock() Unlock()  package main import ( &#34;fmt&#34; &#34;time&#34; ) func SyncClass() { // 等待一秒输出一次 	lockRun() lockRun() lockRun() } func lockRun() { fmt.Println(&#34;等一秒后，执行一次&#34;) time.Sleep(1 * time.Second) } func main() { SyncClass() } 上面程序每打印一次，然后就会等待一秒，直到三个函数都执行完毕，代码结束。
修改程序为通过异步执行。
func SyncClass() { // 等待一秒输出一次 	go lockRun() go lockRun() go lockRun() // 阻塞下主线程 可以看到异步执行的输出信息  time.Sleep(5 * time.Second) } 以上执行非常快速，几乎一瞬间同时输出三条打印信息，然后等待时间结束后，程序终止。
为了解决各异步执行程序之间的共享资源问题，防止出现数据竞争和其他并发问题，可以使用互斥锁。
互斥锁最常见的使用方式是对共享资源进行加锁和解锁操作。
当一个 goroutine 需要访问共享资源时，它首先尝试获取锁：
 如果获取到了锁，则可以进入临界区并执行相应的操作； 如果没有获取到锁，则需要等待锁被释放后再次尝试获取。  当 goroutine 完成对共享资源的访问后，它会将锁释放，以便其他 goroutine 可以继续访问该资源。
package main import ( &#34;fmt&#34; &#34;sync&#34; &#34;time&#34; ) func SyncClass() { // 创建锁 必须是通过地址操作 	lock := &amp;sync.Mutex{} go lockRun(lock) go lockRun(lock) go lockRun(lock) time.Sleep(5 * time.Second) } func lockRun(lock *sync.Mutex) { lock.Lock() // 上锁  fmt.Println(&#34;等一秒后，执行一次&#34;) time.Sleep(1 * time.Second) lock.Unlock() // 执行完成后，解锁 } func main() { SyncClass() } 以上程序执行，由于主线程设置了阻塞 5 秒，所以可以看到每打印一条信息，等待一秒，然后输出下一条信息。当第一个函数 lockRun 执行时：
 先上锁 然后输出打印信息 等待一秒 解锁  然后才是第二个函数进入执行，重复上述操作，这就是互斥锁的作用。
读写锁（RWMutex） 读锁：允许多人同时读，读的过程中不允许写
写锁：仅能一人同时写，写的过程中不允许读
package main import ( &#34;fmt&#34; &#34;sync&#34; &#34;time&#34; ) func SyncClass() { // 创建锁 必须是通过地址操作 	lock := &amp;sync.RWMutex{} go lockRun(lock) go lockRun(lock) go lockRun(lock) go readLockRun(lock) go readLockRun(lock) go readLockRun(lock) go readLockRun(lock) go readLockRun(lock) time.Sleep(5 * time.Second) } func lockRun(lock *sync.RWMutex) { // 写锁 写的时候，排斥其他的写锁和读锁 	lock.Lock() fmt.Println(&#34;等一秒后，执行一次&#34;) time.Sleep(1 * time.Second) lock.Unlock() } func readLockRun(lock *sync.RWMutex) { // 读锁；读锁间不互斥，可以同时读；但是会排斥写锁 	lock.RLock() fmt.Println(&#34;我是读锁！&#34;) time.Sleep(1 * time.Second) lock.RUnlock() } func main() { SyncClass() } /* 等一秒后，执行一次 我是读锁！ 我是读锁！ 我是读锁！ 我是读锁！ 我是读锁！ 等一秒后，执行一次 等一秒后，执行一次 */ 程序输出分析：
 先执行第一把写锁，写锁执行时，不会读，其他写锁不会执行； 当第一把写锁完成后，读锁全部同步执行，输出 5 次，虽然代码的调用顺序在全部写锁后； 后续写锁依次按个执行。  单例（Once） sync.Once 是一个用于实现单例模式的同步工具。sync.Once 可以确保某个函数只被执行一次，无论有多少个 goroutine 并发调用该函数。
sync.Once 类型有一个名为 Do() 的方法，用于执行传入的函数。该方法会检查一个内部变量（称为once）是否已经被设置为true，如果尚未设置，则调用传入的函数并将 once 设置为 true。
package main import ( &#34;fmt&#34; &#34;sync&#34; ) func SyncClass() { one := &amp;sync.Once{} for i := 0; i &lt; 10; i++ { one.Do(func() { fmt.Println(i) }) } } func main() { SyncClass() } 以上代码，输出为 0，虽然是通过 for 循环不断打印数字，但是由于 Do 函数的限制，仅执行一次。
sync.Once 是一种非常有用的同步工具，可以用于实现单例模式、初始化操作等场景，避免竞争条件和其他并发问题，并确保程序的正确性和安全性。
WaitGroup sync.WaitGroup 是一种同步工具，用于等待一组 goroutine 执行完毕。
WaitGroup 可以跟踪一组并发操作的状态，并在这些操作全部完成后再继续执行。
WaitGroup类型有三个方法：
 Add()：用于将计数器加 1，表示要等待的 goroutine 数量增加； Done()：用于将计数器减1，表示有一个 goroutine 已经完成； Wait()：阻塞当前 goroutine，直到计数器归零  package main import ( &#34;fmt&#34; &#34;sync&#34; &#34;time&#34; ) func SyncClass() { wg := &amp;sync.WaitGroup{} wg.Add(2) go func() { time.Sleep(3 * time.Second) wg.Done() fmt.Println(&#34;等待了 3 秒，然后输出 Done 1&#34;) }() go func() { time.Sleep(5 * time.Second) wg.Done() fmt.Println(&#34;继续等待了 2 秒，然后输出 Done 2&#34;) }() wg.Wait() fmt.Println(&#34;Finish&#34;) } func main() { SyncClass() } 并发字典（Map） sync.Map 是一个线程安全的、并发访问的 map 类型。与普通的 map 不同，使用 sync.Map 类型时无需加锁即可在多个 goroutine 之间安全地并发读写数据。
sync.Map 类型的方法：
 Load()：用于获取指定键的值； Store()：用于设置指定键的值； Delete()：用于删除指定键的值； Range()：用于遍历所有键值对并调用指定的回调函数 LoadOrStore()：获取键值时如果没有就自动设置  package main import ( &#34;fmt&#34; &#34;sync&#34; ) func main() { m := &amp;sync.Map{} // 存储键值对 	m.Store(&#34;name&#34;, &#34;Alice&#34;) m.Store(&#34;age&#34;, 18) m.Store(&#34;gender&#34;, &#34;female&#34;) // 获取键值对 	name, _ := m.Load(&#34;name&#34;) age, _ := m.Load(&#34;age&#34;) gender, _ := m.Load(&#34;gender&#34;) fmt.Printf(&#34;name: %s, age: %d, gender: %s\n&#34;, name, age, gender) // 删除键值对 	m.Delete(&#34;gender&#34;) // 遍历所有键值对，当 bool 为 true 时，才进行下一次循环 	m.Range(func(key, value interface{}) bool { fmt.Printf(&#34;%s: %v\n&#34;, key, value) return true }) } 注意，Load()、Store() 和 Delete() 方法都不会返回任何错误信息，因此不能通过返回值来判断操作是否成功。如果需要进行错误检查，则可以在回调函数中添加额外的参数或者使用其他同步机制（如互斥锁）来保证并发安全性。
使用 sync.Map 可以避免竞争条件和其他并发问题，并确保程序的正确性和安全性。
并发池（Pool） sync.Pool 是一种用于对象池管理的同步机制。Pool 类型可以用于缓存已经分配的临时对象，以避免频繁地创建和销毁对象，从而提高程序的性能和效率。
Pool 类型有两个方法：
 Get()：用于从对象池中获取一个对象，如果池中没有可用对象，则会调用指定的函数生成一个新的对象并返回； Put()：用于将不再使用的对象放回池中，以便下次可以被重复使用。  package main import ( &#34;fmt&#34; &#34;sync&#34; ) func main() { p := &amp;sync.Pool{} // 放入 3 个对象 	p.Put(1) p.Put(2) p.Put(3) // 取出 3 个对象 	for i := 0; i &lt; 3; i++ { fmt.Println(p.Get()) } // 当池子里的对象取完后再取就是 nil 	fmt.Println(p.Get()) } 由于 Pool 类型的实现方式不同于普通的变量和对象，在使用时需要特别小心。例如，在对于 sync.Pool 类型的对象不能进行拷贝、比较和序列化等操作，否则可能会导致程序崩溃或出现其他异常。
Cond sync.Cond 是一种条件变量，用于在多个 goroutine 之间实现等待、通知和唤醒操作。
与互斥锁不同，使用 Cond 类型时可以使某些 goroutine 进入等待状态，直到满足特定条件后再被唤醒。
Cond 类型有三个方法：
 Wait()：用于使当前 goroutine 进入等待状态，并释放与 Cond 关联的互斥锁； Signal()：用于唤醒一个处于等待状态的 goroutine； Broadcast()：用于唤醒所有处于等待状态的 goroutine。  package main import ( &#34;fmt&#34; &#34;sync&#34; &#34;time&#34; ) // 将 cond 和 互斥锁关联 var cond = sync.NewCond(&amp;sync.Mutex{}) // 定义全局切片，可增删元素 var queue []int // 模拟生产一个元素，并添加到队列 func produce() { for i := 0; i &lt; 10; i++ { time.Sleep(time.Millisecond * 500) cond.L.Lock() queue = append(queue, i) fmt.Printf(&#34;produce: %d\n&#34;, i) // 生产完成后唤醒一个等待状态的 goroutine 	cond.Signal() cond.L.Unlock() } } // 模拟消费一个元素，并将其从队列中删除 func consume() { for i := 0; i &lt; 10; i++ { cond.L.Lock() // 如果队列为空，则进入等待状态 	for len(queue) == 0 { cond.Wait() } // 被唤醒则消费一个 	item := queue[0] queue = queue[1:] fmt.Printf(&#34;consume: %d\n&#34;, item) cond.L.Unlock() } } func main() { go produce() consume() } 如果消费者大于生产者，那么当队列为空时，消费者 goroutine 会一直阻塞在 cond.Wait() 方法上，导致程序出现死锁的情况。
io 包 package main import ( &#34;fmt&#34; &#34;os&#34; ) func main() { // 创建文件 	f, err := os.OpenFile(&#34;./test.txt&#34;, os.O_CREATE|os.O_RDWR, 0777) if err != nil { fmt.Println(err) return } // 写数据 	// 读数据 	for { // 设置一个切片为任意数的缓冲区，这里代表每次读 12 字节（4 个汉字） 	buffer := make([]byte, 12) byteNums, err := f.Read(buffer) if err != nil { // 当内容读取完毕后，err 为 EOF 代表结束 	fmt.Println(err) return } fmt.Println(string(buffer), byteNums) } } net包 TCP 实现一个服务端和一个客户端，进行消息通信
package main import ( &#34;fmt&#34; &#34;net&#34; ) func main() { // 监听本地 8888 端口 	listenAddr, err := net.ResolveTCPAddr(&#34;tcp&#34;, &#34;:8888&#34;) if err != nil { fmt.Println(&#34;Error resolving TCP address:&#34;, err.Error()) return } // 创建 TCP 监听器 	listener, err := net.ListenTCP(&#34;tcp&#34;, listenAddr) if err != nil { fmt.Println(&#34;Error listening on TCP port:&#34;, err.Error()) return } defer listener.Close() fmt.Println(&#34;Server is listening on &#34;, listener.Addr().String()) // 不断接受新的连接，并处理客户端发送的数据 	for { conn, err := listener.AcceptTCP() if err != nil { fmt.Println(&#34;Error accepting new connection:&#34;, err.Error()) return } fmt.Printf(&#34;New client connected: %s\n&#34;, conn.RemoteAddr().String()) go handleConnection(conn) // 处理客户端连接 	} } func handleConnection(conn *net.TCPConn) { defer conn.Close() for { // 读取客户端发送的数据 	buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil { fmt.Println(&#34;Error reading data from client:&#34;, err.Error()) break } // 输出客户端发送的数据 	data := string(buf[:n]) fmt.Printf(&#34;[ Client %s ]: %s\n&#34;, conn.RemoteAddr().String(), data) // 返回给客户端信息 	conn.Write([]byte(&#34;收到了消息: &#34; + data)) } } package main import ( &#34;bufio&#34; &#34;fmt&#34; &#34;net&#34; &#34;os&#34; ) func main() { // 连接本地 8888 端口 	serverAddr, err := net.ResolveTCPAddr(&#34;tcp&#34;, &#34;127.0.0.1:8888&#34;) if err != nil { fmt.Println(&#34;Error resolving TCP address:&#34;, err.Error()) return } // 建立连接 	conn, err := net.DialTCP(&#34;tcp&#34;, nil, serverAddr) if err != nil { fmt.Println(&#34;error connecting to TCP port:&#34;, err.Error()) return } defer conn.Close() fmt.Println(&#34;Connected to server:&#34;, conn.RemoteAddr().String()) // 向服务器发送数据 	reader := bufio.NewReader(os.Stdin) for { bytes, _, _ := reader.ReadLine() _, err = conn.Write(bytes) if err != nil { fmt.Println(&#34;Error writing data to server:&#34;, err.Error()) return } reply := make([]byte, 1024) buf, _ := conn.Read(reply) fmt.Println(string(reply[:buf])) } } HTTP  server：服务端，包含地址、端口、处理器等等 conn：用户请求来的那个链接 response：响应 request：用户请求信息 Handle：对于接收的信息进行处理并且返回的一个处理器  package main import ( &#34;io&#34; &#34;net/http&#34; ) func handle(res http.ResponseWriter, req *http.Request) { switch req.Method { case &#34;GET&#34;: res.Write([]byte(&#34;[Get]&#34;)) break case &#34;POST&#34;: // 将请求体返回去 	b, _ := io.ReadAll(req.Body) res.Write(b) // 设置 headers 	header := res.Header() header[&#34;test&#34;] = []string{&#34;test1&#34;, &#34;test2&#34;} // 设置状态码 	res.WriteHeader(http.StatusBadRequest) // 设置返回状态码为 400 	break } } func main() { http.HandleFunc(&#34;/test&#34;, handle) http.ListenAndServe(&#34;:8080&#34;, nil) } package main import ( &#34;fmt&#34; &#34;io&#34; &#34;net/http&#34; ) func main() { client := new(http.Client) req, _ := http.NewRequest(&#34;GET&#34;, &#34;http://localhost:8080/test&#34;, nil) res, _ := client.Do(req) body := res.Body b, _ := io.ReadAll(body) fmt.Println(string(b)) } RPC 远程过程调用，GO RPC 函数有特殊要求：
 函数首字母必须大写 必须只有两个参数，第一个参数是接收的参数，第二个参数是返回给客户端的参数 第二个参数必须是指针类型的 函数还要有一个返回值 ERROR  泛型 ]]></content></entry><entry><title>Golang - 根据系统平台执行对应代码</title><url>/tech/golang/%E6%A0%B9%E6%8D%AE%E7%B3%BB%E7%BB%9F%E5%B9%B3%E5%8F%B0%E6%89%A7%E8%A1%8C%E5%AF%B9%E5%BA%94%E4%BB%A3%E7%A0%81/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[看源码的时候发现这样一段代码
log.Info().Msgf(&#34;%s https://httprunner.com&#34;, openCmd) main 里面的 openCmd 是个常量，在如下三个文件中都分别定义了。
. ├── main.go ├── open_darwin.go -&gt; const openCmd = &#34;open&#34; ├── open_linux.go -&gt; const openCmd = &#34;xdg-open&#34; └── open_windows.go -&gt; const openCmd = &#34;explorer&#34; 当我追进去 openCmd 的时候，自动进入了 open_darwin.go文件，跟我的系统自动匹配。
查看文档：https://pkg.go.dev/cmd/go#hdr-Build_constraints
 If a file&rsquo;s name, after stripping the extension and a possible _test suffix, matches any of the following patterns:
*_GOOS *_GOARCH *_GOOS_GOARCH
(example: source_windows_amd64.go) where GOOS and GOARCH represent any known operating system and architecture values respectively, then the file is considered to have an implicit build constraint requiring those terms (in addition to any explicit constraints in the file).
 它会自动构建文件名后缀与当前系统名或系统架构匹配的 go 文件，这点就非常方便。
当使用 goland 时，在 设置 - Go - Build Tag &amp; Vendoring 中，会自动设置当前系统为默认。
因此，就算没有进行构建，通过常量名也可以追到对应的系统文件内。
]]></content></entry><entry><title>功能测试 - 抓包工具 Charles 界面说明</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7-charles-%E7%95%8C%E9%9D%A2%E8%AF%B4%E6%98%8E/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html">主菜单 这是主菜单栏的内容
About Charles Preferences Services Hide Charles Hide Others Show All Quit Charles Aboult Charles 显示当前版本号、激活信息
Preferences Service 一些开发者服务
Hide Charles 隐藏 Charles 窗口，展示其他，相当于最小化，但不缩放到程序坞内
Other Charles 仅展示 Charles 窗口，隐藏其他窗口
Show All 全部窗口都展示
Quit Charles 退出 Charles
File 会话就是相当于新建一个录制窗口，可以理解为 Excel 下的 sheet 页。
Edit View 分为四个区域（按图示分线）：
视图展示区域 请求/响应 展示区域 请求/响应 展示类型设置 其他设置 视图展示区域 推荐使用结构化视图，测试过程中只看自己相关业务的 host 请求即可
还可以在 Charles - Preferences - user Interface 内设置横向 或 纵向布局。
推荐纵向，即上图侧边栏的方式展示。
请求/响应 展示区域 overview：概述，请求的基本信息展示 request：请求详情 response：响应详情 summary：总览，选中多请求后会有汇总信息展示 chart：请求耗时图形化展示 请求-发送（上传）请求所花费的时间（深蓝色） 延迟-等待网络延迟或服务器上的处理时间所花费的时间（蓝色） 响应-接收（下载）响应所花费的时间（浅蓝色） notes：来源信息、错误信息、映射信息、Rewrite 等 求/响应 展示类型设置 View Request As View Response As 有很多可选类型，比如：HTML、CSS、JSON等，根据具体的业务返回数据类型来选择。
其他设置 Focused Hosts 描述：「聚焦」功能，将自己关注的域名与其他域名分开展示。
使用：点击该选项，弹出的会话框内，点击 Add，填入常用的/关注的域名，点击确定。
示例：右图，设置的域名会单独展示出来，其他域名会收录到 Other Hosts 内
Viewer Mappings 描述：「查看器映射」，将指定域名下的请求返回值，映射为固定格式 xml（举例，json 也行）。
使用：右图，点击该选项，弹出的会话框内，点击 Add，填入需要映射的域名，点击确定。
该域名下所有请求返回的响应值，最终都会以 XML 格式展示。
Protobuf Settings ProtoBuf （Google Protocol Buffer）是由 google 公司用于数据交换的序列结构化数据格式，具有跨平台、跨语言、可扩展特性，类型于常用的 XML 及 JSON，但具有更小的传输体积、更高的编码、解码能力，特别适合于数据存储、网络数据传输等对存储体积、实时性要求高的领域。以 .proto为后缀，有自己的编译器 protoc, protoc2 和 protoc3 版本.
这个是我没接触过的数据格式，下面列了几个文档共参考：
Language Guide | Protocol Buffers | Google Developers
Protobuf 有没有比 JSON 快 5 倍？-InfoQ
ProtoBuf试用与JSON的比较
这是 Charle Protocol Buffers 使用文档，供参考： Charles
Proxy Proxy Stop Recording Start Throttling Enable Breakpoints Recording Settings Throttle Settings Breakpoint Settings Reverse Proxies Port Forwarding macOS Proxy Proxy Settings SSL Proxying Settings Access Control Settings External Proxy Settings Web Interface Settings Start/Stop Recording 开启/关闭 录制，开启后才会开始代理请求，正常抓包&amp;hellip;
开启录制后，状态变更为：Stop Recording
停止录制后，状态变更为：Start Recording
工具栏样式如图
Start/Stop Throttling 开启/关闭 弱网状态
开启弱网后，状态变更为：Stop Throttling
停止弱网后，状态变更为：Start Throttling
工具栏样式如图:
Enable/Disable Breakpoints 启用/禁用 断点
允许断点后，状态变更为：disable Throttling
停止弱网后，状态变更为：enable Throttling
Recording Settings 点弹出设置弹框，包含：
Options Include Exclude Tab - 1 ：Options
1️⃣ Recording size limit（MB） 这个选项是限制请求及响应大小，如果超出 100 MB，则过滤掉，不会录制在 Charles 工具内；
100 这个数字可以随意设置
2️⃣ Limit recording history 这个选项是设置同一请求最大展示数量，如果开启选项，同一请求再次请求，会自动删除第一次请求的数据，所以为了避免数据丢失，建议不开启此功能或数字设置大一点
3️⃣ Limit WebSocket transaction history 这个选项类似 2⃣️，是针对 WebSocket 的限制
Tab - 2 ：Include
仅录制当前列表内添加的域名请求，如果不填或全部取消选中，则将所有的请求录制到 Charles 内
添加方法：
点击 Add → 弹出 Edit Location → 域名粘贴在 host 内，点击任意区域自动填充 → 点击确定
Tab - 3 ：Exclude
与 Include 相反，仅录制当前列表外的其他域名请求
如果不填或全部取消选中，则不排除任何域名的请求
添加方法与 Include 一致
Throttle Settings Breakpoints Settings Reverse Proxies 💡 正向代理隐藏真实客户端，反向代理隐藏真实服务端 ![image-20230822150055836](https://cdn.jsdelivr.net/gh/abeelan/image-hosting-service/img/image-20230822150055836.png) 官方教程: Charles
反向代理使用案例: Charles录制反向代理
Port Forwarding charles 端口转发丨阿西河
Charles
macOS/Windows Proxy 点击 勾选/取消勾选；
是否代理 PC 浏览器的请求
Proxy Settings Tab - Proxies HTTP Proxy：
Port：设置端口号，默认 8888，手机连接代理时填写的端口号需要与此处保持一致，如果设置了固定端口，其他服务就不能再使用这个端口号，否则冲突； Use a dynamic port：是否设置动态端口，如果勾选则监听动态端口，可以避免与计算机上运行的其他网络服务冲突，如果开的端口很多且不清楚端口号，可以勾选使用这个功能； Enable transparent HTTP proxying：是否启动透明代理，可以先百度了解下什么是透明代理，在Charles 上具体有什么用处，我没搞懂。 SOCKS Proxy：
Socks 服务器通常是作为一个代理服务器，充当一个中间代理的角色，与客户端以及真正的服务端建立 TCP 连接，然后负责对客户端与服务端之间的流量进行路由和转发。一个 socks 代理服务器能够与任何一种网络协议进行工作
具体如何使用，我没搞懂。
Tab - Options Tab - macOS/Windows SSL Proxying Settings Access Control Settings 访问控制设置
External Proxy Settings 外部代理设置：可能在网络上有一个代理服务器，必须使用该代理服务器才能访问 Internet。在这种情况下，需要将 Charles 配置为在尝试访问 Internet 时使用现有代理。
Web Interface Settings web 界面设置：Charles 具有 Web 界面，使您可以从浏览器或将 Web 界面用作 Web 服务的外部程序来控制Charles。使用“Proxy”菜单中的“Web Interface Settings”选项启用 Web 界面。您可以允许匿名访问，也可以配置用户名和密码。您可以通过配置为使用 Charles 作为其代理的 Web 浏览器访问 http://control.charles/ 来访问 Web 界面。
Tools 禁用设置 No Caching Settings：禁用缓存设置 Block Cookies Settings：禁用 Cookie设置 功能设置 Map Remote Settings：远程映射设置 Map Local Settings：本地映射设置 Rewrite Settings：重写设置 Black List Settings：黑名单设置 White List Settings：白名单设置 DNS Spoofing Settings：DNS 欺骗设置 其他设置 Mirror Settings：镜像设置 Auto Save Settings：自动保存设置 Client Process Settings：客户端进程设置 请求设置 Compose：编辑修改 Repeat：重复发包 Repeat Advanced：高级重复发包 Validate：验证 Publish Gist：发布要点。 配置设置 Import/Export Settings：导入/导出设置 Profiles：配置文件 Publish Gist Settings：发布要点设置 No Caching Settings No Caching 工具可防止客户端应用程序（如 Web 浏览器）缓存任何资源。因此，始终向远程网站发出请求，您始终可以看到最新版本。
**适用范围：**该工具可以作用于每个请求(选中 Enable No Caching 即可)，也可以仅对你配置的请求启用(启用 No Caching 的同时，请选中 Only for selected locations)。当用于选定的请求时，可以使用简单但功能强大的模式匹配将工具的效果限制为指定的主机和路径。
**工作原理：**No Caching 工具通过操纵控制响应缓存的 HTTP 请求头来防止缓存。从请求中删除 If-Modified-Since 和 If-None-Match 请求头，添加 Pragma：no-cache 和 Cache-control：no-cache。从响应中删除 Expires，Last-Modified 和 ETag 请求头，添加 Expires：0 和 Cache-Control：no-cache。
Block Cookies Settings Block Cookies 工具阻止了 Cookie 的发送和接收。它可用于测试网站，就像在浏览器中禁用了 Cookie 一样。 请注意，网络爬虫（例如 Google）通常不支持 Cookie，因此该工具还可用于模拟网络爬虫网站的视图。
**适用范围：**该工具可以作用于每个请求(选中 Enable Block Cookies 即可)，也可以仅对你配置的请求启用(启用 Block Cookies 的同时，请选中 Only for selected locations)。当用于选定的请求时，可以使用简单但功能强大的模式匹配将工具的效果限制为指定的主机和路径。
**工作原理：**Block Cookies 工具通过操纵控制响应 Cookies 的 HTTP 请求头来禁用 Cookies。从请求中移除 Cookie 请求头，防止 Cookie 值从客户端应用程序（例如 Web 浏览器）发送到远程服务器。从响应中删除 Set-Cookie 请求头，防止请求设置客户端应用程序从远程服务器接收的 Cookie。
Map Remote Settings **Map Remote：**将请求的主机或者域名重定向到配置的主机或域名。
**HTTPS：**Map Remote 工具可以将 HTTP 请求映射到 HTTPS 目标，反之亦然。 **站点匹配：**每个站点匹配可能包含协议、主机、端口和路径模式，以匹配特定的 URL，站点可能包括通配符。 Map Local Settings **Map Local：映射本地文件，**将本地文件的内容返回给客户端。
比如要修改服务的某个数值或者字段，正常情况下需要操作数据库或者后端服务去修改
通过 map local 可以直接修改本地文件，映射到客户端。
**动态文件：**动态文件（例如包含服务器端脚本的文件）不会由 Map Local 执行，因此如果文件中有任何脚本，脚本将按原样返回到浏览器，这可能不是预期的结果。如果您想使用动态文件，就好像它们是远程网站的一部分一样，请参阅 Map Remote 工具。
**工作原理：**当请求与 Map Local 映射匹配时，它会检查与路径匹配的本地文件。它不包括查询字符串（如果有）。如果在本地找到所请求的文件，则将其作为响应返回，就好像它是从远程站点加载的一样，因此它对客户端是透明的。如果在本地找不到所请求的文件，那么该请求会像平常一样由网站提供，返回由真正的服务器提供的数据。
**站点匹配：**每个站点匹配可能包含协议、主机、端口和路径模式，以匹配特定的 URL。站点可能包括通配符。当您向此工具添加新站点时，可能会找到有关创建站点匹配的更多帮助。</content></entry><entry><title>禅道 - 服务迁移指南</title><url>/tech/%E7%A6%85%E9%81%93/%E6%9C%8D%E5%8A%A1%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97/</url><categories><category>禅道</category></categories><tags><tag>禅道</tag></tags><content type="html"> 禅道从云服务器迁移至本地服务器，基于 Docker 启动。
原服务器 使用管理员账号登录禅道； 访问：后台 - 系统设置 - 备份 - 开始备份，备份期间确保不会有增量数据； 备份完成后登录该服务器，将三个备份文件同步至新服务器上。 新服务器 使用 docker 先启动一个新的禅道服务，配置好挂载目录； name=zentao zentaoDir=/data/docker/$name if docker ps -aqf name=$name | grep -q .; then docker rm -f $name fi docker run -d \ --name $name \ -p 8183:80 \ -v $zentaoDir/zentaopms:/www/zentaopms \ -v $zentaoDir/mysqldata:/var/lib/mysql \ -e MYSQL_ROOT_PASSWORD=xxxxxx \ --restart always \ easysoft/zentao:18.2 将同步过来的备份数据放在新服务器的如下目录 $ cp xxxxx.* /path/to/zentaopms/tmp/backup/ 使用管理员登录新创建的服务，进入备份页面，看到同步过来的备份文件，点击「还原」等待完成。 访问 通过 nginx 做虚拟主机（vhost）配置，以便通过原域名可以访问新服务。
Nginx 中的虚拟主机（Virtual Host，通常缩写为vhost）是一种服务器配置方法，允许在单个物理服务器上托管多个不同的网站或应用程序，每个都可以使用不同的域名或主机名进行访问。
虚拟主机的主要目的是将请求根据域名或主机名分发到不同的网站或应用程序，以实现多个网站共享同一个服务器的资源。
编辑 nginx 配置文件：
server { listen 80; server_name yourdomain.com; client_max_body_size 50M; # 设置请求体最大不能超过 50M，默认 1M 太小 location / { proxy_pass http://localhost:3000; # 新服务的端口号 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } } 启动容器
NAME=nginx if docker ps -aqf name=$NAME | grep -q .; then docker rm -f $NAME fi docker run -d --name $NAME -p 80:80 \ -v path/to/your-vhost.conf:/etc/nginx/conf.d/my-vhost.conf:ro \ --net=host \ # 必须主机网络模式 否则 localhost 访问不到新服务 nginx 最后就是把原域名的解析地址切到新服务器上，完成迁移。</content></entry><entry><title>Python - Gdb 查看程序调试信息</title><url>/tech/python/gdb-%E6%9F%A5%E7%9C%8B%E7%A8%8B%E5%BA%8F%E8%B0%83%E8%AF%95%E4%BF%A1%E6%81%AF/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ Mac
Python 3.7
  https://www.modb.pro/db/454999  
安装 # 搜索仓库 $ brew search gdb # 安装 $ brew install gdb Error: python@3.10: the bottle needs the Apple Command Line Tools to be installed. You can install them, if desired, with: xcode-select --install # 出现报错，根据报错提示安装命令行工具 $ xcode-select --install # 重新安装后查看 $ which gdb /usr/local/bin/gdb $ gdb -v GNU gdb (GDB) 12.1 创建证书 打开钥匙串应用，菜单栏点击：钥匙串访问 - 证书助理 - 创建证书
一路下一步，直到指定证书位置，选择 系统。
创建完成后，还需要修改权限，钥匙串 - 系统 - 打开刚创建的证书 - 信任 - 始终信任。
# 证书授权，执行命令后输入管理员账号密码 $ codesign -fs {上面创建的证书名称} /usr/local/bin/gdb # 关闭 MacOS 系统的 SIP 安全验证  $ echo &#34;set startup-with-shell off&#34; &gt;&gt; ~/.gdbinit $ security find-certificate -c gdb keychain: &#34;/Library/Keychains/System.keychain&#34; version: 256 class: 0x80001000 attributes: ... # 确保证书未过期 $ security find-certificate -p -c gdb | openssl x509 -checkend 0 Certificate will not expire # 里面应该包括 Code Signing $ security dump-trust-settings -d $ codesign --entitlements ~/Downloads/gdb-entitlement.xml -fs gdb $(which gdb) /usr/local/bin/gdb: replacing existing signature 重启电脑生效。
重启电脑后 python 环境不见了 $ python dyld: Library not loaded: /usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/Python Referenced from: /usr/local/bin/python3.10 Reason: image not found # 查看python所在的位置 $ which python /usr/local/bin/python # 查看 /usr/local/bin/python 的依赖 $ otool -L /usr/local/bin/python /usr/local/bin/python: /usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/Python (compatibility version 3.7.0, current version 3.7.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.250.1) # 3.7 环境已经被干掉了，修改环境为最新的 3.10 # install_name_tool -change {old_path} {new_path} {env_path} $ install_name_tool -change /usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/Python /usr/local/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/Python /usr/local/bin/python # 正常使用 $ python # 更新 pip 软链 $ rm -f /usr/local/bin/pip $ pip3 -V pip 22.2.2 from /usr/local/lib/python3.10/site-packages/pip (python 3.10) $ ln -s /usr/local/Cellar/python@3.10/3.10.8/bin/pip3 /usr/local/bin/pip $ pip -V pip 22.2.2 from /usr/local/lib/python3.10/site-packages/pip (python 3.10) 查看 python 进程信息 重新执行程序
# 获取 python 程序进程 ID $ ps -ef | grep python | grep -v grep | awk &#39;{print $2}&#39; # 进入 gdb 交互命令 # bt 查看堆栈信息 $ gdb python 5048 (gdb) bt # 当前C调用栈 py-bt # 当前Py调用栈 py-list # 当前py代码位置 py-up # 上一帧（py级别的帧） py-down # 下一帧（py级别的帧） info thread # 线程信息 thread &lt;id&gt; # 切换到某个线程 thread apply all py-list # 查看所有线程的py代码位置 ctrl-c # 中断 上面是从网上看的，不生效
$ cd Desktop $ gdb python (gdb) run test.py continue bt ]]></content></entry><entry><title>Python - Pandas 数据处理</title><url>/tech/python/pandas-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"> 数据处理
pandas 数据读取 pd.read_csv：csv/tsv/txt 用逗号、tab 分隔的纯文本文件
pd.read_excel:：微软 xls 或者 xlsx 文件
pd.read_sql：mysql 关系型数据库
pd.read_csv 读取纯文本文件
userId,movieId,rating,timestamp 1,1,4.0,123456 1,3,5.0,123456 文章丢了，待补充&amp;hellip;</content></entry><entry><title>Linux - Ubuntu 粉色窗口</title><url>/tech/linux/ubuntu-%E7%B2%89%E8%89%B2%E7%AA%97%E5%8F%A3/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> Ubuntu 22.0 当我使用 apt 安装一些软件包时，总是弹出一个粉色窗口，询问是否重启服务？
原因是系统默认安装了 needrestart，在每个 apt 安装完成后都会检查是否有更新，如果有就建议重启。
不想重启就直接 ESC 掉。
参考： 官网：Needrestart for Servers</content></entry><entry><title>Linux - 命令 后台挂起(Nohup)</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-%E5%90%8E%E5%8F%B0%E6%8C%82%E8%B5%B7nohup/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> nohup 英文全称 no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行。
nohup 命令，在默认情况下（非重定向时），会输出一个名叫 nohup.out 的文件到当前目录下，如果当前目录该文件不可写，输出重定向到 $HOME/nohup.out 文件中。
后台执行 # 等待 100 秒 # &amp;amp; 让命令在后台执行，终端退出后命令仍旧执行 $ nohup sleep 100 &amp;amp; appending output to nohup.out 杀死后台程序 $ ps -ef | grep sleep # 找到进程号并杀死 $ kill -9 {pid}</content></entry><entry><title>Linux - 设置环境变量</title><url>/tech/linux/%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> PATH 变量是一个路径列表，以 : 隔开； 如果可执行程序所在的目录在 PATH 变量路径列表里，那么输入命令时可以省略路径 路径列表前面的路径为优先匹配路径，匹配到即停止，可以用来实现新老版本程序的命令更换 $ echo $PATH /usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin # /usr/local/bin 里面的 python version = 2.7 # /usr/bin 里面的 python version = 3.6 # 会先使用路径列表前面的 python 版本 $ which python /usr/local/bin/python # 2.7 设置环境变量，并使其立马生效；修改后如果不 source 该配置文件，则每次用户重新登录时才会自动生效。
$ vim ~/.bash_profile $ source ~/.bash_profile</content></entry><entry><title>Linux - 删除文件名乱码文件</title><url>/tech/linux/%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E5%90%8D%E4%B9%B1%E7%A0%81%E6%96%87%E4%BB%B6/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">问题 出现了乱码的文件名：??iA?，没办法通过文件名删除（复制文件名然后 rm 无效）。
解决 # 获取该文件的节点号 $ ls -i 167557 ??iA? # 通过 find delete 参数删除该文件 $ find -inum 167557 -delete 问题解决。</content></entry><entry><title>Linux - 包管理工具</title><url>/tech/linux/%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">包管理工具 yum: centos/redhat $ yum search $package $ yum install $package $ yum remove $package apt-get: ubuntu debian $ apt-cache search $package $ apt-get install $package $ apt-get uninstall $package 源码编译安装：make; make install 开源镜像站 华为镜像： https://mirrors.huaweicloud.com 阿里云： https://developer.aliyun.com/mirror 豆瓣： https://developer.aliyun.com/mirror</content></entry><entry><title>Linux - 命令 复制(Cp)</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-%E5%A4%8D%E5%88%B6cp/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">问题 在 Linux 中使用 cp 命令时，发现将目录中文件复制到另一个目录具有相同文件名称时,同名文件强制覆盖参数 $ cp -rf 不生效，依然需要手工填写 y 确认覆盖。
原因 cp 命令被系统设置了别名，相当于 cp=‘cp -i’
解决 # 方法一：使用原生 cp 命令 $ /bin/cp -rf xxxx # 方法二 # 先取消 cp 命令的别名： $ unalias cp # 覆盖完成后，再恢复别名 $ alias cp=&amp;#39;cp -i&amp;#39;</content></entry><entry><title>Docker - Docker 执行命令提示权限不足</title><url>/tech/docker/docker-%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E6%8F%90%E7%A4%BA%E6%9D%83%E9%99%90%E4%B8%8D%E8%B6%B3/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html">登录 Ubuntu 服务器上使用 docker 命令报错：
permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get &amp;ldquo; http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/json": dial unix /var/run/docker.sock: connect: permission denied
根据 官方文档：以非 root 用户身份管理 Docker 进行操作。
# 1. 创建 docker 用户组 $ sudo groupadd docker # 2. 将当前用户添加到 docker 组中 $ sudo usermod -aG docker $USER # 3. 激活组更新 $ newgrp docker # 4. 验证 $ docker ps</content></entry><entry><title>Andorid - Uiautomator冲突问题解决</title><url>/tech/andorid/uiautomator%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">启动 appium server 后，再次启动 weditor 连接设备报错
[E 221216 18:20:07 web:2162] 500 GET /api/v1/devices/android%3Aemulator-5554/screenshot (::1) 2133.77ms 解决办法：
停掉 appium 服务 执行命令：python3 -m uiautomator2 init 重装手机上的 agent 服务 目前已知调用 android uiautomator 会冲突的项目：
appium uiautomator2 weditor maxim fastbot andorid 遇到问题后，检查下是否同时开启两种服务及以上，手动解决冲突。</content></entry><entry><title>Jmeter&Ms - Ms 前置更新请求体中的数据</title><url>/tech/jmeterms/ms-%E5%89%8D%E7%BD%AE%E6%9B%B4%E6%96%B0%E8%AF%B7%E6%B1%82%E4%BD%93%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html"><![CDATA[修改请求体中部分字段的值（dict-&gt;str），然后用更新后的请求体发起请求。
需求 metersphere 接口平台，需求如下：
 设置请求前置脚本，修改 「请求体」 内容，然后用更新后的请求体发起请求 将 address 的值(jsonObject)，转为字符串，其他字段保持不变  // url ：https://httpbin.org/post // method：post // body : { &#34;name&#34;: &#34;John&#34;, &#34;age&#34;: 30, &#34;address&#34;: { &#34;street&#34;: &#34;123 Main St&#34;, &#34;city&#34;: &#34;Anytown&#34;, &#34;state&#34;: &#34;CA&#34;, &#34;zip&#34;: &#34;12345&#34; } } 实现 新增 beanshell 脚本
import org.json.JSONObject; log.info(&#34;Output &gt;&gt;&gt;&gt;&gt;&#34;); // 获取请求体内容，数组的第一个元素就是请求体 String request = sampler.getArguments().getArgument(0).getValue(); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; requests body type: &#34; + request.getClass().getName()); // 将请求体转为 json 对象 JSONObject json = new JSONObject(request); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; 初始请求体: {}&#34;, json); // 提取 json 内的字段值 JSONObject data = json.getJSONObject(&#34;address&#34;); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; address: {}&#34;, data); // 将 address 的 json 对象转为字符串 String dataString = data.toString(); // 重新填充到请求体内 json.put(&#34;address&#34;, dataString); String updatedRequest = json.toString(); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; requests body type（update）: &#34; + updatedRequest.getClass().getName()); // 重新添加更新后的请求体 sampler.getArguments().removeAllArguments(); // sampler.addArgument(&#34;updateRequest&#34;, updatedRequest); # 会自动 urlencode，导致编码问题 sampler.addNonEncodedArgument(&#34;&#34;, updatedRequest, &#34;&#34;); // 打印当前的请求体 String request = sampler.getArguments().getArgument(0).getValue(); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; 最终请求体: {}&#34;, request); 遇到的问题 调用该前置脚本后，控制台输出的请求体是正常编码，但是在请求内容中，请求体的编码格式为 urlencode，导致请求出错。 后来在 jmeter 官方找到 addNonEncodedArgument 函数，问题解决，已更新到上面的脚本中。
参考：https://jmeter.apache.org/api/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.html#addNonEncodedArgument(java.lang.String,java.lang.String,java.lang.String)
]]></content></entry><entry><title>Httprunner - Golang 源码分析</title><url>/tech/httprunner/golang-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url><categories><category>Httprunner</category></categories><tags><tag>Httprunner</tag></tags><content type="html">先上图，debug 按步骤查看的代码逻辑。</content></entry><entry><title>随笔 - 通过Api实现移动自动打卡签到</title><url>/tech/%E9%9A%8F%E7%AC%94/%E9%80%9A%E8%BF%87api%E5%AE%9E%E7%8E%B0%E7%A7%BB%E5%8A%A8%E8%87%AA%E5%8A%A8%E6%89%93%E5%8D%A1%E7%AD%BE%E5%88%B0/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html"> 移动自动化签到；
签到送流量，连续签到赢 6 GB。
移动经常会送一些流量卡券到个人账户上，可以登录 APP 进入卡券页面使用。
最近推出连续签到赠送流量活动，最高 6GB，这也算是大额券了，哈哈，毕竟平时每月才固定160M，券到手后留着备用它不香吗？
参与方法 每天登录 APP，点击我的 -&amp;gt; 签到，完成签到即可。没啥难度，坚持就行。作为互联网小工，重复性强的工作必然要总结规律，自动化来实现。
本文通过接口实现每日自动签到，文中附源码地址，仅供学习参考，不得用于其他用途，如侵联删。
使用脚本 下载源码 github.com/abeelan/ha-ha 抓包 1、手机连接代理工具，使用账号密码登录，抓包请求websitepwdLogin参数列表：
ef：用户登录信息的加密字符串，粘贴到脚本的全局变量上； ver：应用版本信息，这个可以忽略。 2、进入签到页面，抓包SignInH5请求：
复制cookies信息填写到脚本内（不填也可以正常运行，最好保持与正常发送请求一致）； 复制参数列表内的 token 值，填写到脚本的全局变量上。 运行 # 环境准备 $ pip install requests $ pip install loguru # 运行脚本 $ python mobile_sign.py 定时任务 (mac) $ crontab -e 10 15 * * * python mobile_sign.py 查看每日执行结果有两种方式：
通过 mail 命令，查看每日新邮件，包含详细日志； 在脚本内指定 log 的输出路径。 完。</content></entry><entry><title>随笔 - 通过Api实现微博清理及关注清理</title><url>/tech/%E9%9A%8F%E7%AC%94/%E9%80%9A%E8%BF%87api%E5%AE%9E%E7%8E%B0%E5%BE%AE%E5%8D%9A%E6%B8%85%E7%90%86%E5%8F%8A%E5%85%B3%E6%B3%A8%E6%B8%85%E7%90%86/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html"><![CDATA[ 通过 API 删除微博、取消关注用户。
 五一假期在家呆着无聊，收拾卫生，屋子里弄得是干干净净，一尘不染，躺在床上，打开微博刷起热搜。
这是我的微博账号。
等等&hellip; 点了这么多关注，发了这么多微博！？
原来我的账号一直被媳妇当作测试账号来用，几年下来增加了很多测试微博和无效关注，手动删除太痛苦了，利用一个下午的时间编写自动化脚本，清扫账号。
技术栈
 Requests：发送 API 请求 Requests-html：解析网页，提取值 CSS 定位、XPath 定位或正则，都可 Chrome Network 抓包  都是一些基础用法，没啥难度，算是一个小练习吧。
准备工作 第一步是获取登录凭证。
打开谷歌浏览器，进入微博网页移动版(weibo.cn)，登录自己的账号。按 F12 进入开发者工具，点击 Network 开启抓包，刷新页面，在 API 请求头内，把 cookie 内容复制下来。
第二步抓取参数 st 的值。
首页 -&gt; 关注，到达关注列表页面，用箭头定位到【取消关注】元素，该元素的 href 属性链接内就包含 st 的值，记录一下。
流程分析  以取消关注为例，删除微博同理。
 开启抓包，手动取消关注一个用户，得到请求如下：
https://weibo.cn/attention/del?rl=1&amp;act=delc&amp;uid=5623715908&amp;st=e08ff9  rl：代表什么意思暂时不知道，当取消关注其他用户时，该值不变，证明可复用； act：按字面意思，应该是操作类型，表示删除的动作，该值不变； uid：要取消关注的用户的 ID，定位到该元素，发现在 href 元素内包含该参数，可以通过脚本实时获取； st：与上面我们抓到的是一样的，当取消关注其他用户时，该值不变，证明可复用。  初步分析完成后，程序的大致流程也就出来了：
 进入网页，登录 进入关注列表页面，获取分页总数 遍历分页总数次，获取每页用户信息 遍历每个用户，提取到 uid 执行取消关注请求  脚本编写 首先做一些初始化工作，比如请求链接拼装、实例变量初始化、获取当前登录用户信息。
class WeiBo: HOST = &#34;https://weibo.cn&#34; USER_AGENT = &#34;&#34; def __init__(self, uid, flag=1): self.headers = { &#39;user-agent&#39;: self.USER_AGENT, &#39;cookie&#39;: COOKIES } self.session = HTMLSession() self.session.headers = self.headers self.uid = str(uid) self.flag = int(flag) # 1 删除全部微博；2 取消全部关注 self.total_weibo_pages = 0 # 已发表微博总页数，每页 10 条 self.total_follow_pages = 0 # 已关注用户总页数，每页 10 个 # URL self.url_info = f&#34;{self.HOST}/{self.uid}/info&#34; self.url_profile = f&#34;{self.HOST}/{self.uid}/profile&#34; # Default page=1 self.url_del_weibo = f&#34;{self.HOST}/mblog/del&#34; self.url_follow = f&#34;{self.HOST}/{self.uid}/follow&#34; self.url_del_follow = f&#34;{self.HOST}/attention/del&#34; # 用户信息，从 profile 获取 self.post = 0 # 发表微博数 self.follow = 0 # 关注人数 self.fans = 0 # 粉丝人数 # 初始化 self.get_weibo_list_page() self.get_user_info() 实现方法：需包含两个功能，获取关注总页数、根据页数获取该页所有用户信息。
def get_follow_list_page(self, page=1): &#34;&#34;&#34; 根据页数获取我的关注页面的内容 [&lt;Element&gt;, ...] &#34;&#34;&#34; r = self.session.get(self.url_follow, params={&#34;page&#34;: page}) html = r.html # 获取总页数 if self.total_follow_pages == 0: page_nums_str: str = html.find(&#34;div.pa&#34;, first=True).text self.total_follow_pages = int(page_nums_str.split(&#34;/&#34;)[-1].replace(&#34;页&#34;, &#34;&#34;)) # 获取被关注人对象（每页最多 10 个） follow_objs = html.find(&#34;table tr&#34;) return follow_objs 实现方法：根据单个用户，提取到UID。
def get_single_uid(self, user_obj: Element): &#34;&#34;&#34;获取被关注用户 ID&#34;&#34;&#34; uid = None elements = user_obj.find(&#34;a&#34;) name = elements[1].text for e in elements: link = e.attrs[&#34;href&#34;] if &#34;uid&#34; in link: params = link.split(&#34;?&#34;)[-1].split(&#34;&amp;&#34;) for p in params: if &#34;uid&#34; in p: uid = p.split(&#34;=&#34;)[-1] break logger.info(f&#34;当前被关注用户为: {name}({uid})&#34;) return uid 实现方法：根据UID，取消关注。
def del_single_follow(self, uid): &#34;&#34;&#34;取消关注, uid 为被关注用户的 ID&#34;&#34;&#34; headers = { **self.headers, **{&#34;referer&#34;: self.url_del_follow + f&#34;?uid={uid}&amp;rl=1&amp;st={ST}&#34;} } params = { &#34;rl&#34;: &#34;1&#34;, &#34;act&#34;: &#34;delc&#34;, &#34;uid&#34;: uid, &#34;st&#34;: ST } r = requests.get(self.url_del_follow, params=params, headers=headers) # logger.debug(r.url) # logger.debug(r.text) if r.status_code == 200 and &#34;首页&#34; not in r.text: logger.success(f&#34;取消关注成功: {uid}&#34;) return True return False 将上面实现的方法，组装一下，通过遍历完成取消全部关注的功能。
def del_all_follow(self): &#34;&#34;&#34;取消全部关注&#34;&#34;&#34; self.get_follow_list_page() # 获取关注总页数 del_nums = 0 # 取消关注数统计 for i in range(1, self.total_follow_pages): logger.info(f&#34;******* 取消关注，第 {i}页 *******&#34;) objs = self.get_follow_list_page(page=i) for obj in objs: uid = self.get_single_uid(obj) if self.del_single_follow(uid): del_nums += 1 logger.info(f&#34;取消关注总人数为: {del_nums}.\n&#34;) sleep(sec) 运行程序，会输出基本信息。
此时，访问网页版，关注人数会实时减少，证明程序功能正常。
实际运行过程中， 当请求100+次后，会被限制访问一段时间。
最无语的是，还剩最后 20 个关注，触发了风控策略，关注列表不返回内容。不过还好，总体上达到预期，给我省了不少功夫。
使用微博客户端过程中，还发现了一些体验不好的情况，比如微博手机客户端我的页面，不支持下拉刷新；已经取关的用户，依然在微博-关注里面展示动态；还有大半屏的消息通知开关&hellip;好复杂。
只是一个普通用户，了解的不多，吐槽太片面，哈哈。
最后，源码地址： https://github.com/abeelan/ha-ha  
]]></content></entry><entry><title>Python - Pycharm Jetbrains全家桶无法打开</title><url>/tech/python/pycharm-jetbrains%E5%85%A8%E5%AE%B6%E6%A1%B6%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html">点击程序坞上面的应用程序，跳动两下就没有然后了，无法打开程序；附上解决办法。
前几天改了电脑的用户名称，导致一部分软件都没办法启动；原因是软件的配置文件依然保存原用户名的路径，启动时未获取到目录地址，所以报错了。
以 Pycharm 为例
找到命令行执行程序：「应用程序」- 右键「显示包内容」- Contents - MacOS - pycharm；
/Applications/PyCharm.app/Contents/MacOS/pycharm ; exit; # lan @ tester in ~ [14:58:15] $ /Applications/PyCharm.app/Contents/MacOS/pycharm ; exit; 2021-04-07 14:58:15.785 pycharm[55629:2464832] allVms required 1.8*,1.8+ 2021-04-07 14:58:15.787 pycharm[55629:2464835] Current Directory: /Users/lan 2021-04-07 14:58:15.787 pycharm[55629:2464835] Value of PYCHARM_VM_OPTIONS is (null) 2021-04-07 14:58:15.787 pycharm[55629:2464835] Processing VMOptions file at /Users/lan/Library/Application Support/JetBrains/PyCharm2020.1/pycharm.vmoptions 2021-04-07 14:58:15.788 pycharm[55629:2464835] Done Error: could not find libjava.dylib Failed to GetJREPath() OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. Error opening zip file or JAR manifest missing : /Users/lanzy/.jetbrains/jetbrains-agent-v3.2.1.4255.9c8 Error occurred during initialization of VM agent library failed to init: instrument [进程已完成] 日志显示获取 jre 环境失败，关键信息就是这句，这个路径是老用户名，需要修改为最新：
Error opening zip file or JAR manifest missing : /Users/lanzy/.jetbrains/jetbrains-agent-v3.2.1.4255.9c8 $ cd /Users/lan/Library/Application Support/JetBrains/PyCharm2020.1/ $ subl pycharm.vmoptions # 将 `javaagent` 这一项改为新用户名即可 ... -javaagent:/Users/lan/.jetbrains/jetbrains-agent-v3.2.1.4255.9c8=51aaea47 再次启动 Pycharm，正常使用～
idea 也是同样的问题，修改 idea.vmoptions 文件下的 javaagent 配置即可。</content></entry><entry><title>Python - Python 运行报错记录</title><url>/tech/python/%E8%BF%90%E8%A1%8C%E6%8A%A5%E9%94%99%E8%AE%B0%E5%BD%95/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[遇到的问题 报错一 【Python】Library not loaded: /usr/local/opt/openssl/lib/libssl.1.0.0.dylib
 Mac Big Sur 11.5.1
 运行 python 程序出现报错：
import ssl File &#34;/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py&#34;, line 98, in &lt;module&gt; import _ssl # if we can&#39;t import it, let the error propagate ImportError: dlopen(/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_ssl.cpython-37m-darwin.so, 2): Library not loaded: /usr/local/opt/openssl/lib/libssl.1.0.0.dylib Referenced from: /usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload/_ssl.cpython-37m-darwin.so Reason: image not found 原因是升级了 OpenSSL，重新下载低版本软链即可。
$ brew install rbenv/tap/openssl@1.0 $ ln -sfn /usr/local/Cellar/openssl@1.0/1.0.2t /usr/local/opt/openssl  参考：https://stackoverflow.com/questions/59006602/dyld-library-not-loaded-usr-local-opt-openssl-lib-libssl-1-0-0-dylib
 ]]></content></entry><entry><title>Python - Pytest Hook插件</title><url>/tech/python/pytest-hook%E6%8F%92%E4%BB%B6/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[插件分类  外部插件：pip install 安装的 本地插件：pytest 自动模块发现机制（ conftest.py   存放的） 内置插件：代码内部的 _pytest 目录加载的  常用外部插件
$ pip install pytest-ordering # 控制用例执行顺序 $ pip install pytest-xdist # 分布式并发执行测试用例 $ pip install pytest-dependency # 控制用例的依赖关系 $ pip install pytest-rerunfailures # 失败重跑 $ pip install pytest-assume # 多重校验，同一用例遇到断言失败会继续执行后续断言 $ pip install pytest-random-order # 用例随机执行 $ pip install pytest-html # 测试报告 pytest hook 特性：
 是个函数，在系统消息触发时被系统调用 自动触发机制 Hook 函数的名称是确定的 pytest 有非常多的 hook 函数 使用时直接编写函数体  pytest 有很多不同的 hook 函数，在不同的阶段做不同的事情
# site-package/_pytest/hookspec.py &#34;&#34;&#34; pytest_addoption: 添加命令行参数 pytest_collection_modifuitems: 收集测试用例后（改编码、改执行顺序） pytest_collection_finish: 收集之后的操作 pytest_runtest_setup: 在调用 pytest_runtest_call 之前调用 pytest_runtest_call: 调用执行测试的用例 pytest_runtest_makereport: 运行测试用例，返回 setup、call、teardown 的执行结果 &#34;&#34;&#34; pytest hook 执行顺序
root └── pytest_cmdline_main ├── pytest_plugin_registered ├── pytest_configure │ └── pytest_plugin_registered ├── pytest_sessionstart │ ├── pytest_plugin_registered │ └── pytest_report_header ├── pytest_collection │ ├── pytest_collectstart │ ├── pytest_make_collect_report │ │ ├── pytest_collect_file │ │ │ └── pytest_pycollect_makemodule │ │ └── pytest_pycollect_makeitem │ │ └── pytest_generate_tests │ │ └── pytest_make_parametrize_id │ ├── pytest_collectreport │ ├── pytest_itemcollected │ ├── pytest_collection_modifyitems │ └── pytest_collection_finish │ └── pytest_report_collectionfinish ├── pytest_runtestloop │ └── pytest_runtest_protocol │ ├── pytest_runtest_logstart │ ├── pytest_runtest_setup │ │ └── pytest_fixture_setup │ ├── pytest_runtest_makereport │ ├── pytest_runtest_logreport │ │ └── pytest_report_teststatus │ ├── pytest_runtest_call │ │ └── pytest_pyfunc_call │ ├── pytest_runtest_teardown │ │ └── pytest_fixture_post_finalizer │ └── pytest_runtest_logfinish ├── pytest_sessionfinish │ └── pytest_terminal_summary └── pytest_unconfigure Hook - 修改默认编码 pytest_collection_modifyitems 收集上来的测试用例实现定制化功能
解决问题：
 自定义用例的执行顺序 解决编码问题（中文的测试名称显示乱码） 自动添加标签  def pytest_collection_modifyitems(items: list): &#34;&#34;&#34;The default encoding format is Unicode, which is changed to UTF-8 for Chinese display. &#34;&#34;&#34; for item in items: item.name = item.name.encode(&#34;utf-8&#34;).decode(&#34;unicode-escape&#34;) item._nodeid = item.nodeid.encode(&#34;utf-8&#34;).decode(&#34;unicode-escape&#34;) Hook - 添加命令行参数 def pytest_addoption(parser): mygroup = parser.getgroup(&#34;abee&#34;) # 给 option 分组 mygroup.addoption( &#34;--env&#34;, # 注册一个命令行选项 action=&#34;store&#34;, default=&#34;ol&#34;, # 设置参数的默认值 help=&#34;Change the script running environment.&#34;, # 帮助提示，参数的描述信息 ) @pytest.fixture(scope=&#34;session&#34;) def env(request): return request.config.getoption(&#34;--env&#34;) Hook - 插件打包发布 打包发布到 www.pypi.org  
代码上传到 github
打包项目构成：
 源码包  setup.py   测试包  # setup.py from setuptools import setup,find_packages setup( name=&#39;pytest_encode&#39;, url=&#39;https://github.com/xxx/pytest-encode&#39;, version=&#39;1.0&#39;, author=&#34;xixi&#34;, author_email=&#39;418974188@qq.com&#39;, description=&#39;set your encoding and logger&#39;, long_description=&#39;Show Chinese for your mark.parametrize(). Define logger variable for getting your log&#39;, classifiers=[# 分类索引 ，pip 对所属包的分类 &#39;Framework :: Pytest&#39;, &#39;Programming Language :: Python&#39;, &#39;Topic :: Software Development :: Testing&#39;, &#39;Programming Language :: Python :: 3.8&#39;, ], license=&#39;proprietary&#39;, packages = find_packages(), #[&#39;pytest_encode&#39;], keywords=[ &#39;pytest&#39;, &#39;py.test&#39;, &#39;pytest_encode&#39;, ], # 需要安装的依赖 install_requires=[ &#39;pytest&#39; ], # 入口模块 或者入口函数 pytest11 不能更改 entry_points={ &#39;pytest11&#39;: [ &#39;pytest_encode = pytest_encode.main&#39;, ] }, zip_safe=False ) 打包命令
$ pip install setuptools # 包管理工具，负责安装和发布，尤其是安装拥有信赖关系的包 $ pip install wheel # 生成 *.whl 格式的安装包，本质上是一个压缩包 # 打包命令 $ python setup.py sdist bdist_wheel 发布
  https://packaging.python.org/en/latest/tutorials/packaging-projects/   Uploading the distribution archives  ]]></content></entry><entry><title>Python - Pytest Ini配置文件</title><url>/tech/python/pytest-ini%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html">pytest.ini 是 pytest 的默认配置文件，名称不可更改。
可以修改 pytest 的默认行为，不能使用任何中文符号，包括汉字、空格、引号、冒号等等
作用：
修改用例的命名规则 设置默认命令行参数 配置日志格式，比代码配置更方便 添加标签，防止代码警告错误 指定执行目录 排除搜索目录 [pytest] # https://docs.pytest.org/en/6.2.x/reference.html#ini-options-ref ;修改用例的命名规则 ;执行 check_ 开头 和 test_ 开头的所有文件 python_files = check_* test_* ;执行 Check 和 Test 开头的类 python_classes = Check* Test* ;执行 check_ 开头 和 test_ 开头的方法 python_functions = check_* test_* # 设置默认命令行参数 # Add the specified OPTS to the set of command line arguments as # if they had been specified by the user. addopts = -s -v -q # 设置执行路径 # 指定路径 # testpaths = dir1 dir2 # 设置忽略指定路径 norecursedirs = test api ci data log reports utils # 日志配置 log_cli = true log_cli_level = info log_cli_format = %(asctime)s [%(levelname)s] %(message)s (%(filename)s:%(lineno)s) log_cli_date_format = %Y-%m-%d %H:%M:%S log_file = ./log/test.log log_file_level = info log_file_format = %(asctime)s [%(levelname)s] %(message)s (%(filename)s:%(lineno)s) log_file_date_format = %Y-%m-%d %H:%M:%S # 添加用例标签 markers =flaky: 用例失败重试插件 smoke: 冒烟测试 ios: IOS 设备测试用例</content></entry><entry><title>Python - Pytest 异常处理</title><url>/tech/python/pytest-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[try&hellip;except&hellip; 同 python 用法
pytest.raises() def test_raise(): # 当捕获到预期的异常，且异常信息也匹配时，就忽略该异常，认为用例执行通过，match 可以不写 with pytest.raises(ZeroDivisionError, match=&#34;除数不能为0&#34;): raise ZeroDivisionError(&#34;除数不能为0&#34;) ]]></content></entry><entry><title>Python - Pytest Mark作用</title><url>/tech/python/pytest-mark%E4%BD%9C%E7%94%A8/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[参数化用例 单参数 import pytest search_list = [&#34;a&#34;, &#34;b&#34;] @pytest.mark.parametrize(&#34;name&#34;, search_list) def test_search(name): assert name in search_list 多参数 @pytest.mark.parametrize( &#34;input_num, expect&#34;, [(&#34;3+5&#34;, 8), (&#34;2+3&#34;, 5), (&#34;6+3&#34;, 9)], # 多参数传递需要通过列表或元组嵌套的方式传递 ids=[&#34;add1&#34;, &#34;add2&#34;, &#34;add3&#34;] # 用例标识，个数与前面的参数对应 ) def add(input_num, expect): assert eval(input_num) == expect 笛卡尔积 @pytest.mark.parametrize(&#34;letter&#34;, [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]) @pytest.mark.parametrize(&#34;number&#34;, [1, 2, 3]) def test_search(letter, number): print(f&#34;{letter}- {number}&#34;) PASSED [ 11%]a - 1 PASSED [ 22%]b - 1 PASSED [ 33%]c - 1 PASSED [ 44%]a - 2 PASSED [ 55%]b - 2 PASSED [ 66%]c - 2 PASSED [ 77%]a - 3 PASSED [ 88%]b - 3 PASSED [100%]c - 3 标记测试用例 通过标记对测试用例进行分类
# test_demo.py @pytest.mark.num def test_num1(): ... @pytest.mark.num def test_num2(): ... @pytest.mark.str def test_str1(): ... @pytest.mark.str def test_str2(): ... # -vs 打印详细日志 $ pytest test_demo.py -vs -m &#34;str&#34; # 仅执行 str 标记的测试用例 如果标签识别不到，需要在项目路径下新建 pytest.ini 文件，值有多个时，不要写在一行。
[pytest] markers = str num 跳过（skip）及预期失败（xFail） skip 始终跳过这条测试用例
import pytest # 直接跳过 无任何输出信息 @pytest.mark.skip def func(): ... # 直接跳过 说明原因  @pytest.mark.skip(reason=&#34;代码未开发完&#34;) def func(): ... skipif 遇到特定情况跳过该条测试用例
# 代码判断 def check(): return True def test_func(): print(&#34;start&#34;) if check(): pytest.skip(&#34;oh skip!&#34;) # 如果用例被跳过，后续的 print 代码不会被执行 print(&#34;end&#34;) # 装饰器判断 @pytest.mark.skipif(sys.platform==&#34;darwin&#34;, reason=&#34;not run on mac&#34;) def test_demo(): ... xfail 如果用例被标记为 xfail，那么：
 用例执行失败，被标记为 XFAIL，不会报错 如果用例执行成功，会被标记为 XPASS  @pytest.mark.xfail(reason=&#34;bug not fixed&#34;) def test_demo(): ... ]]></content></entry><entry><title>Python - Mitmproxy</title><url>/tech/python/mitmproxy/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[&#34;&#34;&#34; @Time : 2021/6/28 6:44 下午 @Author : lan @Mail : lanzy.nice@gmail.com @Desc : HTTP-specific events. 针对http，常用的API http.HTTPFlow 实例 flow flow.request.headers #获取所有头信息，包含Host、User-Agent、Content-type等字段 flow.request.url #完整的请求地址，包含域名及请求参数，但是不包含放在body里面的请求参数 flow.request.pretty_url #同flow.request.url目前没看出什么差别 flow.request.host #域名 flow.request.method #请求方式。POST、GET等 flow.request.scheme #什么请求 ，如https flow.request.path # 请求的路径，url除域名之外的内容 flow.request.get_text() #请求中body内容，有一些http会把请求参数放在body里面，那么可通过此方法获取，返回字典类型 flow.request.query #返回MultiDictView类型的数据，url直接带的键值参数 flow.request.get_content()#bytes,结果如flow.request.get_text() flow.request.raw_content #bytes,结果如flow.request.get_content() flow.request.urlencoded_form #MultiDictView，content-type：application/x-www-form-urlencoded时的请求参数，不包含url直接带的键值参数 flow.request.multipart_form #MultiDictView，content-type：multipart/form-data 时的请求参数，不包含url直接带的键值参数 以上均为获取request信息的一些常用方法，对于response，同理 flow.response.status_code #状态码 flow.response.text#返回内容，已解码 flow.response.content #返回内容，二进制 flow.response.setText()#修改返回内容，不需要转码 &#34;&#34;&#34; import mitmproxy.http class Events: def http_connect(self, flow: mitmproxy.http.HTTPFlow): &#34;&#34;&#34; An HTTP CONNECT request was received. Setting a non 2xx response on the flow will return the response to the client abort the connection. CONNECT requests and responses do not generate the usual HTTP handler events. CONNECT requests are only valid in regular and upstream proxy modes. &#34;&#34;&#34; pass def requestheaders(self, flow: mitmproxy.http.HTTPFlow): &#34;&#34;&#34; HTTP request headers were successfully read. At this point, the body is empty. &#34;&#34;&#34; pass def request(self, flow: mitmproxy.http.HTTPFlow): &#34;&#34;&#34; The full HTTP request has been read. &#34;&#34;&#34; pass def responseheaders(self, flow: mitmproxy.http.HTTPFlow): &#34;&#34;&#34; HTTP response headers were successfully read. At this point, the body is empty. &#34;&#34;&#34; pass def response(self, flow: mitmproxy.http.HTTPFlow): &#34;&#34;&#34; The full HTTP response has been read. &#34;&#34;&#34; pass def error(self, flow: mitmproxy.http.HTTPFlow): &#34;&#34;&#34; An HTTP error has occurred, e.g. invalid server responses, or interrupted connections. This is distinct from a valid server HTTP error response, which is simply a response with an HTTP error code. &#34;&#34;&#34; pass addons = [ Events() ] if __name__ == &#39;__main__&#39;: from mitmproxy.tools.main import mitmdump # 使用 debug 模式启动 mitmdump # 端口需要使用字符串 mitmdump([&#39;-p&#39;, &#39;8080&#39;, &#39;-s&#39;, __file__]) ]]></content></entry><entry><title>Python - Requests 异常类</title><url>/tech/python/requests-%E5%BC%82%E5%B8%B8%E7%B1%BB/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html">所有异常类型 requests. exceptions .HTTPError：HTTP错误 requests.exceptions.ConnectionError：连接错误 requests.exceptions.ProxyError：代理错误 requests.exceptions.SSLError：SSL错误 requests.exceptions.Timeout：请求超时错误，包含requests.exceptions.ConnectTimeout和requests.exceptions.ReadTimeout requests.exceptions.ConnectTimeout：尝试连接到远程服务器时错误 requests.exceptions.ReadTimeout：服务器未在分配的时间内发送任何数据 requests.exceptions.URLRequired：url格式错误 requests.exceptions.TooManyRedirects：过多的重定向 requests.exceptions.MissingSchema：网址架构（例如http或https）丢失 requests.exceptions.InvalidSchema：无效的架构 requests.exceptions.InvalidURL：无效的url requests.exceptions.InvalidHeader：无效的请求头 requests.exceptions.InvalidProxyURL：无效的代理链接 requests.exceptions.ChunkedEncodingError：服务器声明了分块编码，但发送了无效的分块 requests.exceptions.ContentDecodingError：解码响应内容失败 requests.exceptions.StreamConsumedError：该响应的内容已被占用 requests.exceptions.RetryError：自定义重试逻辑失败 requests.exceptions.UnrewindableBodyError：尝试快退正文时，请求遇到错误</content></entry><entry><title>Python - Threading 多线程处理</title><url>/tech/python/threading-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%84%E7%90%86/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[模拟马戏团小丑扔一个苹果。
def main(): print(&#34;扔第一个苹果&#34;) main() # 扔第一个苹果 模拟扔多个苹果。
import threading def task2(): print(&#34;扔第二个苹果&#34;) def task3(): print(&#34;扔第三个苹果&#34;) def main(): t2 = threading.Thread(target=task2) t2.start() t3 = threading.Thread(target=task3) t3.start() print(&#34;扔第一个苹果&#34;) main() # 扔第二个苹果 # 扔第三个苹果 # 扔第一个苹果 再看一个例子。
import threading import time def task(): time.sleep(3) def main(): start = time.time() t1 = threading.Thread(target=task) t2 = threading.Thread(target=task) t1.start() t2.start() end = time.time() print(start - end) -0.001416921615600586 # 线程 1 2 还没有执行完成的时候，直接就打印了时间 # 证明线程是轮询执行的，三个线程同时执行，不会等线程12执行完再执行主线程 如何让主线程等待两个线程跑完再打印结束时间呢，答案是通过 join() 方法
def main(): start = time.time() t1 = threading.Thread(target=task) t2 = threading.Thread(target=task) t1.start() t2.start() t1.join() # 让其他线程等待自己执行完成 t2.join() end = time.time() print(start - end) -3.0032341480255127 Python 天生的特性会附带一个 GIL 锁，保证线程安全。当电脑有多核 CPU 时，只有一个 CPU 在跑多线程，多个 CPU同时跑叫做多进程。所以在同一时刻，python 只有一个线程在跑。
# 通过 2 个线程分别执行 9999*9999 次加法循环 def task(): time.sleep(3) def main(): start = time.time() t1 = threading.Thread(target=task) t2 = threading.Thread(target=task) t1.start() t2.start() t1.join() # 让其他线程等待自己执行完成 t2.join() end = time.time() print(start - end) -11.349119901657104 # 通过 1 个线程执行两次 9999*9999 def main(): start = time.time() a = 0 while a != 9999 * 9999 * 2: a += 1 end = time.time() print(start - end) -11.488781213760376 从上面的例子可以看出，当执行特别耗费计算的代码时，python 的多线程其实也差不多类似于单线程。如果代码中存在 sleep 这种等待操作，那么才会在等待过程中轮询执行其他线程，这是 GIL锁的机制。
]]></content></entry><entry><title>Python - Mypy 静态类型检查</title><url>/tech/python/mypy-%E9%9D%99%E6%80%81%E7%B1%BB%E5%9E%8B%E6%A3%80%E6%9F%A5/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[$ pip install mypy 文件类型符合预期
# demo.py from typing import List a: List[int] = [] a = [1, 2] $ mypy demo.py Success: no issues found in 1 source file 文件类型出现错误
# demo.py from typing import List a: List[int] = [] a = [1, 2, 3.4] # 增加了一个小数，不符合定义的数据结构 $ mypy demo.py demo.py:10: error: List item 2 has incompatible type &#34;float&#34;; expected &#34;int&#34; Found 1 error in 1 file (checked 1 source file) ]]></content></entry><entry><title>Python - Prestool 随机数据、Mysql、加密等</title><url>/tech/python/prestool-%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AEmysql%E5%8A%A0%E5%AF%86%E7%AD%89/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html">prestool 封装了一些常用的工具，官网和 testerhome 的帖子里介绍的都很详细。
https://pypi.org/project/prestool/ https://testerhome.com/topics/32438 https://gitee.com/prestest/pres-pip-prestool</content></entry><entry><title>Python - Pipreqs 统计当前项目依赖库</title><url>/tech/python/pipreqs-%E7%BB%9F%E8%AE%A1%E5%BD%93%E5%89%8D%E9%A1%B9%E7%9B%AE%E4%BE%9D%E8%B5%96%E5%BA%93/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html">python 项目中的依赖库，可以创建一个requirements.txt文件来管理。
生成依赖文件
# 当本地的 python 环境混用时 $ pip install pipreqs # 进入到项目路径下，即可生成该项目的依赖包文件 $ pipreqs ./ $ pipreqs ./ --encoding=utf-8 # 或者 # 获取当前 python 环境安装包并写入文件 $ pip freeze &amp;gt;requirements.txt 得到如下文件
allure-pytest=2.12.0 pytest=7.2.0 pytest-rerunfailures=10.3 pytest-sugar=0.9.6 安装所有依赖
$ pip install -r requirement.txt</content></entry><entry><title>Python - Pycharm 基础使用</title><url>/tech/python/pycharm-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[专业版激活 地址：https://www.bilibili.com/read/cv17139870
  网盘地址(2022/8/8更新)：
  链接：https://pan.baidu.com/s/1DrrbDYljx5oYVMdnbhSMqQ
  提取码：jvka
  文件解压密码：jsfvg
  文件头模版设置 PyCharm → Preferences&hellip; → Editor → File and Code Templates → Python Script
&#34;&#34;&#34; @Time : ${DATE}${TIME}@Author : ${USER}@Mail : lanzy.nice@gmail.com @Desc : &#34;&#34;&#34; 常用快捷键 格式化代码：Cmd + Option + L
翻译插件：Cmd + Ctr + U
设置类型检查报错级别 当传参不符合类型的时候，可以设置编辑器提示的级别。
]]></content></entry><entry><title>Python - Typing 类型提示</title><url>/tech/python/typing-%E7%B1%BB%E5%9E%8B%E6%8F%90%E7%A4%BA/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[# 形参 food: str 代表 food 是字符串类型的 # -&gt; str 代表函数的返回值类型 def eat(food: str) -&gt; str: print(f&#34;eat {food}&#34;) return &#34;Good&#34; 类型提示的好处：
 增强代码可读性 Pycharm 中代码提示 静态代码检查  类型别名 from typing import List vector = List[float] # 定义一个数组内全部都是小数的数据类型 def scale(s: float, v: vector) -&gt; vector: return [s * i for i in v] print(scale(1.0, [2.0, 3.0])) # [2.0, 3.0] print(scale(&#34;abc&#34;, [2.0, 3.0])) # 出现类型不符合的提示 由于 python 是动态解释型语言，出现类型不符合的提示，也依然是可以进行参数传递并运行的。只不过运行后报错，原因是字符串类型不能与 float 数字相乘。编辑器可以设置类型检查报错级别。
自定义类型 class Student: name: str age: int def get_stu(name: str) -&gt; Student: return Student() get_stu(). # 输入点后就会出现 Student 的属性 name age 提示 ]]></content></entry><entry><title>Python - 装饰器</title><url>/tech/python/%E8%A3%85%E9%A5%B0%E5%99%A8/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[内置装饰器 @classmethod 类方法 # 有如下格式化日期的类 接收 年月日 三个参数 class DateFmt: def __init__(self, year, month, day): self.year = year self.month = month self.day = day def output(self): print(f&#34;{self.year}年 {self.month}月 {self.day}日&#34;) d = DateFmt(2022, 10, 28) d.output() 当接收日期的参数变更为字典时，以上类就不支持了。但是该类已经在使用中，为不影响其他调用该类的代码，需要设置一个类方法，来实现接收字典类型的参数，完成输出日期的功能，实现如下。
class DateFmt: def __init__(self, year, month, day): self.year = year self.month = month self.day = day def output(self): print(f&#34;{self.year}年 {self.month}月 {self.day}日&#34;) @classmethod def json_fmt(cls, d: dict): year, month, day = d.values() return cls(year, month, day) # 返回该类的普通调用实例 json_date = {&#34;year&#34;: 2022, &#34;month&#34;: 10, &#34;day&#34;: 28} DateFmt.json_fmt(json_date).output() 类不需要初始化就可以调用类方法。需要注意的是，类方法内只能调用类变量和类方法，不能调用实例变量和实例方法。
只有在加载类时，类方法才会被加载到内存中。
@staticmethod 静态方法 此方法没有用到任何实例方法或变量、类方法或变量，可以作为一个单独的函数来使用。
这种情况下，编译器会出现波浪线提示，则可以使用该装饰器取消提示。
class Demo: @staticmethod def start(): # 这里的 self 就可以不写了 print(&#34;game start&#34;) 程序运行开始，就会把静态方法加载到内存中。
闭包函数 函数引用 def demo(): print(&#34;haha&#34;) # 函数可以被赋值给一个变量 haha = demo haha() # haha 闭包函数  闭包的内部函数中，可以对外部作用域的变量进行引用 闭包无法修改外部函数的变量值 闭包可以保存当前的运行环境  # 实现 def stu_grade(grade): def output(name, gender): # grade 读取的是上层函数的形参 print(f&#34;name={name}, gender={gender}, grade={grade}&#34;) return output grade1 = stu_grade(1) # 保存 1 年级，grade 无需重复声明 # print(grade1) # &lt;function stu_grade.&lt;locals&gt;.output at 0x10b9b1ea0&gt; grade1(&#34;tom&#34;, &#34;M&#34;) # name=tom, gender=M, grade=1 可以看到，stu_grade 传入为 1 年级后，grade1 其实就是 output 函数的引用，可以直接添加括号，传入 name 和 gender 打印出信息。
装饰器 增强代码可读性，可维护性
def timer(func): # 装饰器会有一个默认参数，参数就是被装饰函数的引用 def inner(): print(&#34;setup&#34;) func() print(&#34;teardown&#34;) return inner @timer def output(): print(&#34;hello world!&#34;) output() 实现一个装饰器，计算函数的执行时间。
from datetime import datetime def timer(func): def inner(): start = datetime.now() func() end = datetime.now() print(f&#34;函数执行时间为：{end-start}&#34;) return inner @timer def output(): print(&#34;hello world!&#34;) 带参数装饰器 from datetime import datetime def timer(func): # func 的形参在 inner 方法接收 因为不确定传参个数及类型，所以使用不定长形参 def inner(*args, **kwargs): start = datetime.now() func(*args, **kwargs) end = datetime.now() print(f&#34;函数执行时间为：{end - start}&#34;) return inner @timer def hello(name): print(f&#34;hello {name}!&#34;) ]]></content></entry><entry><title>算法 - 代理模式</title><url>/tech/%E7%AE%97%E6%B3%95/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/</url><categories><category>算法</category></categories><tags><tag>算法</tag></tags><content type="html">为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。
代理模式应用：
远程代理：在代码中加入 web 应用 虚拟代理：存放实体化需要很久的对象，比如加载网页，先展示文字，大的图片资源通过代理请求 安全代理：控制真实对象访问权限 智能指引：调用真实对象时，额外处理一些事情，比如计算真实对象的引用次数 参考：https://blog.csdn.net/weixin_42660118/article/details/125616447</content></entry><entry><title>算法 - 工厂设计模式</title><url>/tech/%E7%AE%97%E6%B3%95/%E5%B7%A5%E5%8E%82%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url><categories><category>算法</category></categories><tags><tag>算法</tag></tags><content type="html"><![CDATA[当创建对象的代码多而杂时，可以用工厂模式将对象的创建和使用分离，让代码更清晰。
简单工厂 把创建大量实例的代码放到工厂类中。
# 普通实现 # 这种情况如果再增加 excel csv md yml 等等，对象代码过多 # 解决：使用简单工厂，把对象创建类移动到其他类中，使 load 方法更简洁 class Demo: &#34;&#34;&#34;用于加载不同的文件，对不同的文件做不同的处理&#34;&#34;&#34; def load(self, rule): if rule == &#34;xml&#34;: parse = XmlParse() elif rule == &#34;json&#34;: parse = JsonParse() else: parse = OtherParse() parse.parse() # 调用对象的方法进行操作 class BaseParse: def parse(self): # 相当于接口，用于规范各个子类 # 子类必须实现 parse() 方法，否则调用报错 raise ValueError() class XmlParse(BaseParse): def parse(self): print(&#34;XmlParse&#34;) class JsonParse(BaseParse): def parse(self): print(&#34;JsonParse&#34;) class OtherParse(BaseParse): def parse(self): print(&#34;OtherParse&#34;) 使用简单工厂方法代码如下
class Demo: &#34;&#34;&#34;用于加载不同的文件，对不同的文件做不同的处理&#34;&#34;&#34; def load(self, rule): parse = ParseRuleFactory().create_parse(rule) parse.parse() # 调用对象的方法进行操作 class ParseRuleFactory: &#34;&#34;&#34;简单工厂类：把创建实例的代码放到新的类中&#34;&#34;&#34; def create_parse(self, rule): if rule == &#34;xml&#34;: parse = XmlParse() elif rule == &#34;json&#34;: parse = JsonParse() elif rule == &#34;excel&#34;: parse = ExcelParse() elif rule == &#34;csv&#34;: parse = CsvParse() else: parse = OtherParse() return parse 工厂方法 如果创建实例的代码非常复杂，就可以把创建实例的代码单独放入一个类。
def load(self, rule): if rule == &#34;xml&#34;: parse = XmlParse() elif rule == &#34;json&#34;: # 假设这里很复杂有 1000 行代码 # parse = JsonParse() # 把 1000 行代码放到工厂类中，这里就变成这样调用 parse = JsonParseRuleFactory().create_parse() else: parse = OtherParse() parse.parse() # 调用对象的方法进行操作 class BaseParseRuleFactory: def create_parse(self): # 基类定义该方法，子类未实现调用就会报错 raise ValueError() class JsonParseRuleFactory(BaseParseRuleFactory): &#34;&#34;&#34; json parse 工厂，把复杂的代码都放在该类中&#34;&#34;&#34; def create_parse(self): # 省略 1000 行代码 return JsonParse() 抽象工厂 分类是多级的，需要创建多个工厂时，工厂类可以实现多个方法。
# 问题：通过工厂方法没办法做到，一个工厂类创建多个不同的解析实例 # 比如，JsonParseRuleFactory，想要支持 jsonpath库 和 jmespath库都能解析 # 解决：通过抽象工厂 class BaseParseRuleFactory: &#34;&#34;&#34;一个工厂类，可以实现多个不同的解析实例&#34;&#34;&#34; def a_create_parse(self): raise ValueError() def b_create_parse(self): raise ValueError() class JsonParseRuleFactory(BaseParseRuleFactory): &#34;&#34;&#34;比如解析 json，可以通过不同的 json 解析类库实现&#34;&#34;&#34; def a_create_parse(self): &#34;&#34;&#34;jsonpath&#34;&#34;&#34; def b_create_parse(self): &#34;&#34;&#34;jmespath&#34;&#34;&#34; ]]></content></entry><entry><title>算法 - 单例模式</title><url>/tech/%E7%AE%97%E6%B3%95/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</url><categories><category>算法</category></categories><tags><tag>算法</tag></tags><content type="html"><![CDATA[只允许类进行一次实例化。
饿汉式单例 类加载时就创建好实例。
class IdMaker: # 类变量 多个实例共享 __instance = None __id = 0 def __new__(cls): # python 在类加载阶段，通过父类的 __new__ 创建实例 # 重写 __new__ 会在类加载阶段调用我们定义的 __new__ # __new__ 需要返回一个实例 if cls.__instance == None: # 这里如果初始化 IdMaker 会陷入递归 # 直接赋值父类的 __new__，返回一个实例 cls.__instance = super().__new__(cls) return cls.__instance def get_id(self): self.__id += 1 return self.__id def test(): id1 = IdMaker().get_id() id2 = IdMaker().get_id() id3 = IdMaker().get_id() print(id1, id2, id3) # 1 2 3 if __name__ == &#34;__main__&#34;: test() 懒汉式单例 使用实例时才创建，避免初始化阶段卡慢。
from threading import Lock class IdMaker: # 申请线程锁避免多线程情况下重复操作 __instance_lock = Lock() # 类变量 多个实例共享 __instance = None __id = 0 def __new__(cls): raise ImportError(&#34;Instantition not allowed&#34;) # 因为不允许实例化，所以使用类方法 @classmethod def get_instance(cls): # with 会自动上锁和释放 with cls.__instance_lock: if cls.__instance is None: # 因为本类不允许实例化，借用父类的实例化 cls.__instance = super().__new__(cls) return cls.__instance def get_id(self): self.__id += 1 return self.__id def test(): id1 = IdMaker.get_instance().get_id() # 调用就不用实例化了 id2 = IdMaker.get_instance().get_id() id3 = IdMaker.get_instance().get_id() print(id1, id2, id3) # 1 2 3 if __name__ == &#34;__main__&#34;: test() ]]></content></entry><entry><title>算法 - 递归算法</title><url>/tech/%E7%AE%97%E6%B3%95/%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95/</url><categories><category>算法</category></categories><tags><tag>算法</tag></tags><content type="html">假设在排队，你不知道自己是第多少位。当你问前面一个人的时候，他也不知道自己是多少位，就会一直向前面问下去，因为是从自己这里开始问的，所以函数是从自己这里开始的，问的这一步叫做递。
前面的人一直问下去，直到第一个人，因为他前面没有人，所以他肯定是第一个，问题终止。第一个人向后面的人转达，后面再依次加一，回到自己这里，得到答案，这就是归。
递归在数学上的公示就为：f(n) = f(n-1)+1
// c 语言实现 int f(int n) { if (n == 1) return 1; return f(n-1) + 1; } 什么情况下可以使用递归？
一个问题可以拆分成若干个同样的问题 问题求解思路相同，只是数据规模不同 拥有终止条件 实践：假如有 n 个台阶（n≥3），每次可以走 1 个或 2 个台阶，走完 n 个台阶有多少种走法？
比如有 3 个台阶，可以 1，2 或者 2，1
f(n)=f(n-1)+f(n-2)，其中f(1)=1，f(2)=2
int f(n) { if (n == 1) return 1; if (n == 2) return 2; return f(n-1) + f(n-2); } 重复计算的问题（可以通过存储数据解决）
内存开销问题，空间复杂度 O(n)</content></entry><entry><title>算法 - 算法性能评估</title><url>/tech/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/</url><categories><category>算法</category></categories><tags><tag>算法</tag></tags><content type="html">评估算法好坏的两个指标：
时间复杂度 空间复杂度 影响时间复杂度的因素：
规模：测试数据的规模大小 环境：运行环境速度的快慢 大O 表示法 def tmp(n): add = 0 # 1 for i in range(n): # n add += i # n return 0 总共运行次数为 1+n+n 次，也就是 T(n)=(2n+1)*unit
通常，当 n 足够大时，低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。因此，用 O 表示渐近时间复杂度，表示代码执行时间随数据规模增长的变化趋势。上面代码时间复杂度记为：T(n)=O(n)
时间复杂度 1、只关注循环次数多的代码 回到上例，在整体代码中可以把循环次数（n）作为时间复杂度，即 O(n)
2、选大量级 def tmp(n): for i in range(999): # n print(1) for i in range(n): # n for j in range(n): # n print(2) 存在多个循环次数的时候，选择最大量级的循环，如上例，两层循环。时间复杂度为 O(n*n)
3、嵌套循环要乘积 def tmp(n): for i in range(n): # n a(i) # n def a(n): for i in range(n): print(1) 类似双层循环，时间复杂度为 O(n*n)
空间复杂度 表示算法存储空间与数据规模之间的增长关系。
def tmp(n): a = [1] * n # n 越大，a 所占用的空间越大 for i in a: # n print(i) 空间复杂度为 O(n)
数组数组与列表 数组是线性表数据结构。用连续的内存空间存储相同类型的数据。
线性表：线性表是数据排成一条线的结构，数据只有前后两个方向，包括：数组、链表、队列、栈 非线性表：数据之间不是简单的前后关系，包括：二叉树、堆、图等
连续的内存空间和相同的数据类型，使数组支持“随机访问”，通过下标就可以访问，访问速度很快。但是在数组中删除、插入数据时，需要做大量的迁移工作。
插入操作 在数组末尾插入元素，不需要移动数据，最好情况时间复杂度为 O(1) 在数组开头插入元素，所有数据需要后移一位，最坏情况时间复杂度为 O(n) 在数组中间随机位置插入元素，平均时间复杂为 O(n) 删除操作 删除末尾元素，最好情况时间复杂度为 O(1) 删除首个元素，最坏情况时间复杂度为 O(n) 删除中间元素，平均时间复杂为 O(n)</content></entry><entry><title>Jenkins - Jenkins 安卓Ui自动化流程</title><url>/tech/jenkins/%E5%AE%89%E5%8D%93ui%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%81%E7%A8%8B/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[Docker 使用容器执行 UI 自动化脚本 FROMpython:3.10-alpineLABEL description=&#34;AutoTest By: pytest &amp;&amp; uiautomator2&#34;WORKDIR/usr/src/COPY requirements.txt ./# 安装 adbRUN apk updateRUN apk --update-cache --repository http://dl-3.alpinelinux.org/alpine/edge/testing/ add android-tools# 安装 python 依赖库RUN pip install --upgrade pip -i https://pypi.douban.com/simpleRUN pip install --no-cache-dir -r requirements.txt -i https://pypi.douban.com/simple# 修改系统时区为上海RUN rm -rf /etc/localtime &amp;&amp; ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeCOPY . .CMD [&#34;python3&#34;]构建镜像
$ docker build -t python:3.10-uiautomator2 . 通过镜像执行用例
$ docker run -it --rm --name duban-u2 \  --privileged \  -v &#34;$PWD&#34;:/usr/src/ \  -v /dev/bus/usb:/dev/bus/usb \  -v /root/.android:/root/.android \  python:3.10-uiautomator2 \  python3 -m pytest testcase/login/test_welcome.py # 启动容器，进入 python 命令行模式 $ docker run -it --rm --name duban-u2 \  --privileged \  -v &#34;$PWD&#34;:/usr/src/ \  -v /dev/bus/usb:/dev/bus/usb \  -v /root/.android:/root/.android \  python:3.10-uiautomator2 # 用另一个窗口进入容器内 $ docker exec -it duban-u2 \bin\sh ]]></content></entry><entry><title>Jenkins - Jenkins 脚本命令行</title><url>/tech/jenkins/%E8%84%9A%E6%9C%AC%E5%91%BD%E4%BB%A4%E8%A1%8C/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[系统管理 - 脚本命令行，执行下面代码
// 更新时间 System.setProperty(&#39;org.apache.commons.jelly.tags.fmt.timeZone&#39;, &#39;Asia/Shanghai&#39;) // 清除项目所有构建历史 item = Jenkins.instance.getItemByFullName(&#34;job_name&#34;) item.builds.each() { build -&gt; build.delete() } item.updateNextBuildNumber(1) ]]></content></entry><entry><title>Docker - Docker 使用容器运行Python脚本</title><url>/tech/docker/docker-%E4%BD%BF%E7%94%A8%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8Cpython%E8%84%9A%E6%9C%AC/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[使用容器运行 python 脚本 使用 dockerfile 构建镜像执行 # 编写 dockerfileFROMpython:3WORKDIR/usr/src/appCOPY requirements.txt ./RUN pip install --no-cache-dir -r requirements.txtCOPY . .CMD [ &#34;python&#34;, &#34;./your-daemon-or-script.py&#34; ]然后构建镜像，通过镜像执行脚本
$ docker build -t my-python-app . $ docker run -it --rm --name my-running-app my-python-app 直接使用容器执行脚本 $ docker run -it --rm --name my-running-script \  -v &#34;$PWD&#34;:/usr/src/myapp \  -w /usr/src/myapp \  python:3 \  python your-daemon-or-script.py ]]></content></entry><entry><title>Jmeter&Ms - Jmeter 遇到的问题</title><url>/tech/jmeterms/jmeter-%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html">Jmeter 发起请求遇到报错：Address already in use: connect
网络请求发起的时候，服务器需要一个固定的端口接收数据，客户端向服务端发起请求，需要占用一个客户端的端口
当发起高并发请求的时候，客户端的端口号最多到6w，如果端口号出现不够用的情况，就会出现抢占的情况。
这种情况是客户端的问题，如何解决？
单台机器发起的请求数量是有限的，需要使用到 Jmeter 集群压测。采用分布式架构，构建一个 jmeter 集群。</content></entry><entry><title>性能测试 - 性能分析案例</title><url>/tech/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/</url><categories><category>性能测试</category></categories><tags><tag>性能测试</tag></tags><content type="html">需求：负载测试，模拟 1000请求/s
分析 获取基准响应时间 首先获取接口的基准响应时间，1 个线程 120 秒，比如得到的接口响应时间是 10ms
根据公式：
单线程并发数 = 1000ms（1秒） / 接口响应时间（ms）= 1000ms / 10ms = 100 线程数量 = 总的并发数 / 单线程并发能力 = 1000 / 100 = 10 理论线程 10 个，那么就可以模拟出需求的 1000 请求 1 秒并发。
梯度压测 因为理论线程数和实际线程数量可能存在却别，所以需要使用梯度压测手法：逐步增加线程数量。
原生的线程组不能模拟，需要安装插件来实现，jp@gc - stepping Thread Group（梯度加压）
得到测试数据 &amp;amp;&amp;amp; 分析 分析：系统能否满足 1000请求/s
并发量：系统每秒收到的请求数；梯度完成请求。
吞吐量指标：每秒系统处理的请求数。
分析：如图，平均每秒处理请求数为 537.
响应时间指标
分析：如图，虽然吞吐量为537，并发量为 1000请求，但是系统并不会直接崩溃，而是随着请求数量的增加，且吞吐量达到拐点的时候，响应时间就会增加。因为上面需求没有要求响应时间，且50ms 在可接受范围之内，所以也认为是达标的。
响应时间也是性能瓶颈的一个需求点，就看需求有没有要求响应时间。
错误率指标
分析：当出现请求错误的时候，这是不可忍受的，认为已经到达了性能瓶颈。
结合所有趋势图来看，出现错误时间节点：
并发量线程数为 12 吞吐量为 540 响应时间为 33ms 最好状态下，系统的处理请求数为 540，超过后，就可能出现错误。
高压情况下，系统的处理请求数为：1000ms / 33ms * 12 = 363 个请求
因此认为当前服务器并不能满足 1000请求/s 的并发。
定位系统瓶颈 程序为什么会有性能瓶颈？ - 本质是因为资源不够用。
CPU 内存 磁盘 网络 查看性能测试期间，服务器的性能数据
观察 CPU和内存使用率峰值都是 30+，网络正常
就要分析是不是程序出现问题，比如：服务器内存为4G，JVM 申请内存是否过小（512k）导致服务器性能过剩，就需要调整代码。
性能分析包含很多方面：
CPU 资源瓶颈分析 内存资源瓶颈分析 磁盘资源瓶颈分析 网络资源瓶颈分析 JVM 性能调优 JVM 是什么? JAVA 运行原理 JVM 运行内存 JVM 垃圾回收机制 GC 对性能的影响 GC 垃圾分代回收机制与优化方向 垃圾回收器的分类与回收 多线程机制与运行原理 多线程检测与瓶颈分析 Tomcat 性能调优与分析 Tomcat原理+核心配置项</content></entry><entry><title>性能测试 - Prometheus</title><url>/tech/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/prometheus/</url><categories><category>性能测试</category></categories><tags><tag>性能测试</tag></tags><content type="html">go 语言编写，开源系统监控和警报工具，用各种 exporter 收集服务器性能数据。
监控主机性能 1、docker - prometheus
2、主机安装 node_exporter：https://github.com/prometheus/node_exporter/releases
下载 amd-64 的包，解压缩
# 后台运行 $ nohup ./node_exporter --web.listen-address=&amp;#34;:9102&amp;#34; &amp;amp; 配置 grafana 读取 prometheus 的数据，即可展示。</content></entry><entry><title>性能测试 - 性能监控系统搭建</title><url>/tech/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA/</url><categories><category>性能测试</category></categories><tags><tag>性能测试</tag></tags><content type="html"><![CDATA[简介 性能监控系统（influxdb+grafana）
InfluxDB 存储压力测试结果，go 语言开发，8086 端口
# 新建容器网络 $ docker network create grafana # 运行容器 $ cd ~/volumes $ docker run -d --name=influxdb --network grafana -p 8086:8086 -v ${PWD}/influxdb/:/var/lib/influxdb/ influxdb:1.7.10 # 创建数据库 # 方式一 $ curl -i -XPOST http://localhost:8086/query --data-urlencode &#34;q=CREATE DATABASE jmeter&#34; # 方式二 $ docker exec -it infulxdb influx &gt; create database jmeter; &gt; show databases; &gt; use jmeter; &gt; show measurements; &gt; select * from jmeter limit 3; Grafana 读取数据以图形化方式展示测试结果
$ docker run -d --name grafana --network grafana -p 3000:3000 grafana/grafana:6.6.2 # 默认账号和密码都是 admin 配置收集 jmeter 测试数据 配置数据源：设置 -&gt; Data Sources -&gt; Add data source -&gt; influxdb
 URL：http://influxdb:8086，通过容器名加端口号可以访问 InfluxBD Details: Database -&gt; jmeter Min time interval: 配置为 5s，因为 jmeter 每 5s 写入一次，同步一下  测试，出现绿色提示即为成功。
URL 如果不使用容器名的话，可以进入 influxdb 容器内，cat /etc/hosts 找到 IP 地址，填入也行，就是会比较麻烦。
接下来，需要导入一个 dashboard
 Dashboards -&gt; Manage -&gt; Import -&gt; https://grafana.com/grafana/dashboards/5496   -&gt; Load 名称可以随意更改 DB nam 选择 InfluxDB Measurement name 填写 jmeter 刷新时间为 5 秒，跟前面配置一样 点击 Import  配置收集 服务器性能数据 配置数据源：设置 -&gt; Data Sources -&gt; Add data source -&gt; prometheus
 URL： http://prometheus:9090  ，通过容器名加端口号可以访问 Scrape interval: 配置为 15s，与配置文件内一致  导入 dashboard： https://grafana.com/grafana/dashboards/8919  
Jmeter 运行测试生成测试数据，存储到 InfluxDB 内
打开界面
 创建线程组，添加 http 请求 添加监听器 - 后端监听器 后端监听器实现修改为 influxdbBackendListener InfulxdbUrl 修改为：http://localhost:8086/write?db=jmeter application 自定义修改，区分与其他人的数据 measurement 需要与 jmeter 保持一致 summaryOnly 修改为 false，会在页面展示错误信息  http 请求内填入本机地址，或者 localhost，发起请求，刷新 grafana 页面，可以看到请求数据。
]]></content></entry><entry><title>Jmeter&Ms - Jmeter 分布式压测</title><url>/tech/jmeterms/jmeter-%E5%88%86%E5%B8%83%E5%BC%8F%E5%8E%8B%E6%B5%8B/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html">分布式简介 单机性能瓶颈，CPU、内存、IO等
大型系统， 单机无法模拟，所以需要多台机器对一台服务器施压。
工作节点 - slave 部署 负载机（slaves）：端口 tcp 1099
jmeter/bin 目录下修改配置文件：
jmeter.properties: 关闭 SSL server.rmi.ssl.disable=true system.properties: java.rmi.server.hostname=192.xxx.xxx.xx（本机地址） 运行 jmeter-server 等待出现 created remote object&amp;hellip; 即可，节点配置完毕，等待控制机连接。
控制节点 - Master 部署 控制端（Master）：端口 udp 4445
jmeter/bin/jmeter.properties 修改配置文件：
添加负载机 IP：remote_host = slave 节点的 hostname，多个用逗号隔开 关闭 SSL：server.rmi.ssl.disable=true 运行测试 windows 注意关闭防火墙
启动 jmeter 界面程序，运行菜单内，可控制所有远程机器。
远程退出所有：节点远程服务直接关闭，远程机器退出命令行 如果有多台机器的话，线程数设置为 10，那么就是每台机器上都起 10 个线程。</content></entry><entry><title>Jmeter&Ms - Jmeter 用户自定义环境变量</title><url>/tech/jmeterms/jmeter-%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html">用户自定义环境变量 添加 - 配置元件 - 用户自定义的变量
变量的作用域取决于放在什么层级目录下。
通过 key-value 定义好变量后，其他地方可以使用 $(var) 的方式使用。
使用场景一：定义环境变量 定义环境的域名和端口，在其他接口内直接引用该变量的值。
使用场景二：将接口的返回值赋值给变量，作为下个接口的请求参数 通过 Json 提取器 赋值给变量，在其他接口内就可以引用该变量的值。</content></entry><entry><title>Jmeter&Ms - Jmeter 循环控制器</title><url>/tech/jmeterms/jmeter-%E5%BE%AA%E7%8E%AF%E6%8E%A7%E5%88%B6%E5%99%A8/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html">通过循环操作 HTTP 请求，使用方法：添加 - 逻辑控制器 - 循环控制器
自定义名称，自定义名称内也可以引用变量 设置循环次数 使用场景 测试多种账号密码组合进行登录，可以将账号密码保存在一个 csv 文件内，循环调用登录接口去请求
创建 account.csv 文件如下：
username,pwd zhangsan,12345 lisi,4566 admin,admin 在循环控制器内添加 CSV Data Set Config 元件，循环次数设置为数据行数 3，请求内通过 $(var) 的方式引用变量， 就完成了参数化请求登录接口的测试需求。</content></entry><entry><title>Jmeter&Ms - Jmeter 梯度加压</title><url>/tech/jmeterms/jmeter-%E6%A2%AF%E5%BA%A6%E5%8A%A0%E5%8E%8B/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html">jp@gc - stepping Thread Group（梯度加压） 如果新接入一个性能测试需求，如何确定系统的性能如何？该使用多少线程数去进行压测呢？
刚开始是确定不了的，只能去慢慢增加 - 梯度加压
梯度加压线程组（插件）：添加 - 线程（用户） - jp@gc - stepping Thread Group
通过执行测试，收集程序性能指标</content></entry><entry><title>Jmeter&Ms - Jmeter 通过代理服务器录制脚本</title><url>/tech/jmeterms/jmeter-%E9%80%9A%E8%BF%87%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BD%95%E5%88%B6%E8%84%9A%E6%9C%AC/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html"><![CDATA[Jmeter 配置代理  Test plan -&gt; Add -&gt; Thread Group Thread Group -&gt; Add -&gt; Logic Controller -&gt; Recording Controller Test plan -&gt; Add -&gt; Non-Test Elements -&gt; HTTP(S) Test Script Recorder  信任后，点击 start。 在 jmeter/bin 目录下，会自动生成证书。Mac 系统双击证书，钥匙串内选择 登录 - 证书，找到 jmeter 证书，设置为始终信任，关闭弹窗，输入电脑密码即可。
浏览器配置代理 Chrome 浏览器，安装 SwitchOmega 插件，创建 jmeter 情景模式，端口号设置为 8888
录制与回放 开始录制后，访问网页，就会把请求都记录在 Recording Controller 内。
录制的请求比较多，可以通过 HTTP(S) Test Script Recorder 设置过滤：
 URL Patterns to Include 仅录制配置内的域名 URL Patterns to Exclude 排除配置内的域名（.*\.(png|gif|js|ttf|woof|css).*）  录制完成后，关闭录制。添加 View Result Tree，重新 start 录制的请求，即可看到响应信息。
]]></content></entry><entry><title>Jmeter&Ms - Jmeter 快速入门</title><url>/tech/jmeterms/jmeter-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html"> 官网地址：https://jmeter.apache.org/
多线程框架，支持多并发操作 用于对服务器模拟负载 支持 web、数据库、FTP服务器系统的性能测试 开源、纯 JAVA，可二次定制 快速入门 先进行环境搭建，完成后通过自带的脚本启动，脚本在 ../jmeter-5.4.3/bin/ 目录。
Windows → jmeter.bat MacOS → jmeter.sh 分布式 → jmeter-server 启动日志堆信息（HEAP）是写死的，实际是以设置的堆内存大小为准。
性能测试脚本开发的流程 业务需要测试的场景 业务功能测试通过 将功能测试步骤转换为脚本（从 1 到 N，先确保一个用户功能正常） 性能测试脚本的要求 准确：脚本可正常运行 快速：借助工具完成脚本开发 漂亮：脚本逻辑、维护性高 脚本开发方式 手工编写 抓包工具抓到请求，导入后进行调整 通过代理服务器录制脚本（TODO 软链） 功能介绍 菜单项： 文件 → 模版，可以选择请求类型，自动生成对应的脚本。 编辑 → 启动/禁用，调试是临时关闭步骤。 运行，执行脚本的菜单项，可以通过远程机器运行脚本。 项，基础配置，外观 UI，语言等。 Tools，工具集，生成报告（结果文件，配置文件，输出路径） 帮助，文档相关 命令行参数 -n：以非 GUI 方式运行 -t：指定 jmx 脚本文件路径 -l：指定 jtl 结果文件路径，如果已存在则不生成 -e：结果生成 html 报告 -o：html 报告输出路径 测试片段 将项目按模块分割，即插即用 通过模块控制器，导入模块运行。
线程组 setUp 线程组 → 初始化操作，最先运行，与位置无关 tearDown 线程组 → 后置清理操作，最后运行，与位置无关 插件： jp@gc - stepping Thread Group（梯度加压）
取样器 OS 进程取样器：执行命令行，拿到返回值
逻辑控制器 循环控制器
beanshell 前置处理器
beanshell 后置处理器
配置元件 用户自定义环境变量：添加 - 配置元件 - 用户自定义的变量
变量的作用域取决于放在什么层级目录下。
通过 key-value 定义好变量后，其他地方可以使用 $(var) 的方式使用
使用场景一：定义环境变量：定义环境的域名和端口，在其他接口内直接引用该变量的值。
使用场景二：将接口的返回值赋值给变量，作为下个接口的请求参数，通过 Json 提取器 赋值给变量，在其他接口内就可以引用该变量的值。
CSV Data Set Config：读取 csv 配置文件
自定义名称
添加文件，选择文件存储路径
文件编码：UTF-8
变量名称（用逗号分隔）：通常就是文件第一行数据的变量名称
忽略首行：如果文件内写了变量名称就设置为 True，否则为 False
分隔符：默认为逗号
后置处理器 Json 提取器：添加 - 后置处理器 - Json 提取器 自定义名称 names of created variables：为变量命名 Json path expressions：填写 jsonpath 表达式提取值 Match NO：提取第几个值或者随机提取 设置默认值 正则表达式提取器：(.*) 提取所有 断言与监听器 添加断言：线程组 - 添加 - 断言 - json 断言
参数化与关联 调试 &amp;amp; 执行 虚拟用户并发模拟：Test Group 设置
查看压测结果：
Listener View Result Tree：查看结果树，直接在当前界面显示请求结果 Aggregate Report：聚合报告，显示请求时间、tps 等百分比 Backend Listener：将测试数据转入到数据库内 分布式压测
服务器监控 性能监控系统（influxdb+grafana）
prometheus
性能分析 案例分析
性能调优 后续结果依赖前面接口的返回值
聚合报告 遇到的问题 Jmeter 发起请求遇到报错：Address already in use: connect
网络请求发起的时候，服务器需要一个固定的端口接收数据，客户端向服务端发起请求，需要占用一个客户端的端口
当发起高并发请求的时候，客户端的端口号最多到6w，如果端口号出现不够用的情况，就会出现抢占的情况。
这种情况是客户端的问题，如何解决？
单台机器发起的请求数量是有限的，需要使用到 Jmeter 集群压测。采用分布式架构，构建一个 jmeter 集群。
实际压测</content></entry><entry><title>性能测试 - 性能测试指标</title><url>/tech/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E6%A0%87/</url><categories><category>性能测试</category></categories><tags><tag>性能测试</tag></tags><content type="html"><![CDATA[常用的性能测试术语 事务（Transaction） 在 web 性能测试中，一个事务过程如下，一般的响应时间都是针对事务而言的。
 从用户发送请求 web server接受到请求，进行处理 web server向DB获取数据 生成用户的object(页面) 返回给用户  请求响应时间 请求响应时间指的是从客户端发起的一个请求开始，到客户端接收到从服务器端返回的响应结束，这个过程所耗费的时间。
在某些工具中，响应通常会称为“TTLB”，即&quot;time to last byte&quot;，意思是从发起一个请求开始，到客户端接收到最后一个字节的响应所耗费的时间，响应时间的单位一般为“秒”或者“毫秒”。
一个公式可以表示：响应时间＝网络响应时间+应用程序响应时间。标准可参考国外的3/5/10原则：
（1）在3秒钟之内，页面给予用户响应并有所显示，可认为是“很不错的”；
（2）在3~5秒钟内，页面给予用户响应并有所显示，可认为是“好的”；
（3）在5~10秒钟内，页面给予用户响应并有所显示，可认为是“勉强接受的”；
（4）超过10秒就让人有点不耐烦了，用户很可能不会继续等待下去；
事务响应时间 事务可能由一系列请求组成,事务的响应时间主要是针对用户而言,属于宏观上的概念，是为了向用户说明业务响应时间而提出的.例如:跨行取款事务的响应时间就是由一系列的请求组成的.事务响应时间是直接衡量系统性能的参数.
并发用户数 并发一般分为2种情况。
  一种是严格意义上的并发，即所有的用户在同一时刻做同一件事情或者操作，这种操作一般指做同一类型的业务。比如在信用卡审批业务中，一定数目的拥护在同一时刻对已经完成的审批业务进行提交；还有一种特例，即所有用户进行完全一样的操作，例如在信用卡审批业务中，所有的用户可以一起申请业务，或者修改同一条记录。
  另外一种并发是广义范围的并发。这种并发与前一种并发的区别是，尽管多个用户对系统发出了请求或者进行了操作，但是这些请求或者操作可以是相同的，也可以是不同的。对整个系统而言，仍然是有很多用户同时对系统进行操作，因此也属于并发的范畴。
  可以看出，后一种并发是包含前一种并发的。
而且后一种并发更接近用户的实际使用情况，因此对于大多数的系统，只有数量很少的用户进行“严格意义上的并发”。对于WEB性能测试而言，这2种并发情况一般都需要进行测试，通常做法是先进行严格意义上的并发测试。严格意义上的用户并发一般发生在使用比较频繁的模块中，尽管发生的概率不是很大，但是一旦发生性能问题，后果很可能是致命的。严格意义上的并发测试往往和功能测试关联起来，因为并发功能遇到异常通常都是程序问题，这种测试也是健壮性和稳定性测试的一部分。
用户并发数量：关于用户并发的数量，有2种常见的错误观点。 一种错误观点是把并发用户数量理解为使用系统的全部用户的数量，理由是这些用户可能同时使用系统；还有一种比较接近正确的观点是把在线用户数量理解为并发用户数量。实际上在线用户也不一定会和其他用户发生并发，例如正在浏览网页的用户，对服务器没有任何影响，但是，在线用户数量是计算并发用户数量的主要依据之一。
吞吐量 指的是在一次性能测试过程中网络上传输的数据量的总和.吞吐量/传输时间,就是吞吐率.
TPS（transactionper second） 每秒钟系统能够处理的交易或者事务的数量.它是衡量系统处理能力的重要指标.
点击率 每秒钟用户向WEB服务器提交的HTTP请求数.这个指标是WEB应用特有的一个指标:WEB应用是&quot;请求-响应&quot;模式,用户发出一次申请,服务器就要处理一次,所以点击是WEB应用能够处理的交易的最小单位.如果把每次点击定义为一个交易,点击率和TPS就是一个概念.容易看出,点击率越大,对服务器的压力越大.点击率只是一个性能参考指标,重要的是分析点击时产生的影响。需要注意的是,这里的点击并非指鼠标的一次单击操作,因为在一次单击操作中,客户端可能向服务器发出多个HTTP请求.
资源利用率 指的是对不同的系统资源的使用程度,例如服务器的CPU利用率,磁盘利用率等.资源利用率是分析系统性能指标进而改善性能的主要依据,因此是WEB性能测试工作的重点.
资源利用率主要针对WEB服务器,操作系统,数据库服务器,网络等,是测试和分析瓶颈的主要参考.在WEB性能测试中,更根据需要采集相应的参数进行分析。
性能测试行业指标维度  响应时间（RT） 每秒事物处理能力（TPS） 并发用户数 吞吐量 系统资源使用率 思考时间  响应时间 RT(Response Time)，对请求做出响应所需要的时间，是用户感知软件性能的主要指标。
响应时间包括：
 客户端页面渲染时间 请求/响应数据网络传输时间 服务器处理时间 数据库处理时间  对于 WEB 系统，很多年前的非官方标准是 2/5/8 秒，现在 5 秒应该是极限了。
随着并发数量的增加，响应时间也会增加。
比如银行 10 个柜台，每给用户办理一个业务的时间是 10 分钟
 并发 1 个人办理业务 - 平均响应时间 10 分钟 并发10 个人办理业务 - 平均响应时间 10 分钟 并发20 个人办理业务 - 平均响应时间 15 分钟 并发 30 个人办理业务 - 平均响应时间 20 分钟 &hellip;  并发用户数 用户数的三个概念
 系统用户数：总注册用户数，数据库存储用户数 在线用户数：总在线用户数，只是同时在线 并发用户数（两个都需要做，根据业务）  广义：同一时间做不同的事，但是都对服务器进行了请求（网购浏览） 狭义：用户同一时间做同一件事（秒杀）    系统用户数对服务性能产生的影响很小，因为用户注册后会保存在数据库的磁盘上，存储用户数量受磁盘空间大小影响。当服务端查询数据库的时候，用户数量大则寻址时间长，用户数量小则寻址时间短。
进行测试前，需要初始化环境：
 warm up（热机），磁盘 → 内存 → CPU，让数据先跑一会儿，更接近生产环境后再开始统计数据。 构造测试数据 网络环境或场景接近  平均并发用户数的计算：
C=nL/TC = nL / T C=nL/T
 C → 平均并发用户数 n → 平均每天访问用户数（login session） L → 一天内用户从登录到退出的平均时间 T → 一天内多长时间有用户在使用系统  并发用户数峰值计算：
C≈c+3∗3C \approx c + 3 * \sqrt3 C≈c+3∗√3
性能拐点：当用户数到达一定数量后，响应时间明显增加的点。
并发  绝对并发：同一时间服务器处理的请求数  比如：实时聊天室，同时在线人数 — 长连接 websocket   相对并发：一段时间内，服务器处理的请求数（通常是1 秒）  web 应用基本都是 http 请求，短连接：请求/响应 → 结束 约等于并发吞吐量    吞吐量（TPS → 每秒事务数） 指单位时间内系统处理用户的请求数，吞吐量指标反应的是服务器承受的压力，体现负载能力。
从业务角度看：吞吐量可以是请求数/秒、页面数/秒、处理业务数/小时，等等
从网络角度看：字节/秒
 T PS — transaction — 事务 — 多个操作（涉及数据库变更操作）— 淘宝下单 Q PS — Query — 查询 — 不涉及数据变动的操作 — 淘宝查询商品  计算公式
F = VU∗R/tF = VU*R/tF = VU∗R/t
 F → 吞吐量 VU → 表示虚拟用户个数 R → 表示每个用户发出的请求数 T → 表示性能测试所用的时间  随着用户请求的增加，吞吐量会上升，当达到最大值时，吞吐量保持在一个区间，达到性能瓶颈。
 如果该线震荡，表示可能是内存原因 如果该线平整，表示可能是网络原因  如何知道系统的最大吞吐量？
初期阶段，吞吐量会随着并发量（线程）增加而增加。
吞吐量达到一定值后，趋于平稳，这个点看作系统的瓶颈。
 不断增加并发量， 直至吞吐量不再增加【性能拐点】
 思考时间（Think Time） 用户进行操作时每个请求之间的时间间隔，模拟真实用户的操作。
成功率 在高并发的情况下，程序是否会出现处理失败的情况。
10000/s 请求，失败了 100，成功率为 99%
部分场景对于成功率要求很高，否则很影响用户体验，比如支付。
常见性能压力测试工具  Apache Jmeter：Java 语言开发，开源 LoadRunner：C 语言开发，商业 Locust：python 语言开发，开源  ]]></content></entry><entry><title>Selenium - 基础5：Form表单</title><url>/tech/selenium/%E5%9F%BA%E7%A1%805form%E8%A1%A8%E5%8D%95/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[表单 什么是表单？
 表单是一个包含表元素的区域 表单元素是允许用户在表单中（比如：文本域、下拉列表、单选框、复选框等等）输入信息的元素 表单使用表单标签  定义。  操作表单元素步骤
 首先定位到表单元素 然后操作表单元素（点击、清空、输入等）  &#34;&#34;&#34; @Time : 2021/5/9 12:23 上午 @Author : lan @Mail : lanzy.nice@gmail.com @Desc : &#34;&#34;&#34; import time from selenium import webdriver class TestForm: def setup(self): self.driver = webdriver.Chrome() self.driver.implicitly_wait(3) self.driver.maximize_window() def teardown(self): time.sleep(2) self.driver.quit() def test_form(self): self.driver.get(&#34;https://testerhome.com/account/sign_in&#34;) self.driver.find_element_by_id(&#34;user_login&#34;).send_keys(&#34;test&#34;) self.driver.find_element_by_id(&#34;user_password&#34;).send_keys(&#34;password&#34;) self.driver.find_element_by_xpath(&#34;//*[@class=&#39;custom-control-label&#39;]&#34;).click() self.driver.find_element_by_name(&#34;commit&#34;).click() ]]></content></entry><entry><title>Selenium - 报错 W3C</title><url>/tech/selenium/%E6%8A%A5%E9%94%99-w3c/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html">def setup_class(self): # Fixed # selenium.common.exceptions.WebDriverException: Message: unknown command: # Cannot call non W3C standard command while in W3C mode option = webdriver.ChromeOptions() option.add_experimental_option(&amp;#34;w3c&amp;#34;, False) driver = webdriver.Chrome(options=option) driver.maximize_window() driver.implicitly_wait(5) action = TouchActions(self.driver)</content></entry><entry><title>Andorid - 安卓应用性能测试</title><url>/tech/andorid/%E5%AE%89%E5%8D%93%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">安卓应用的性能测试，通常包括六个指标：
启动时间 内存 CPU 耗电量 流量 流畅度 启动时间 Ref：https://www.cnblogs.com/liushengchieh/p/10418279.html
APP 启动方式
COLD（冷启动）：杀死应用进程后启动 WARM（暖启动）：BACK 退出应用后启动 HOT（热启动）：应用置为后台再启动 冷启动流程
第一阶段
加载并启动 APP 启动后立即显示一个空白的窗口 创建 APP 进程 第二阶段
创建 APP 对象 启动主进程 创建 Activity 加载布局，绘制 APP 启动时间
安卓应用在启动时都会先出现一个欢迎页，它其实就是一个Activity。应用从被点击到出现欢迎页的这段时间，被定义为启动时间。在知道应用欢迎页的 Activity Name 后，就可以通过上面这条命令来获取启动时间。APP 启动首屏基本上都是以颜色来标识，而不是图片，目的是为了适配更多分辨率不同的机型。
获取启动时间的方法有三种，以下均为冷启动。
1、代码打印日志获取
这种方式需要开发自行添加代码。
attachBaseContext onCreate 2、系统日志
$ adb logcat | grep -i displayed ActivityTaskManager: Displayed com.esbook.reader/.activity.ActLoading: +932ms 3、adb 启动
# -S 杀死应用后启动 $ adb shell am start -S -W com.esbook.reader/com.esbook.reader.activity.ActLoading Stopping: com.esbook.reader Starting: Intent { act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] cmp=com.esbook.reader/.activity.ActLoading } Status: ok LaunchState: COLD Activity: com.esbook.reader/.activity.ActLoading TotalTime: 932 WaitTime: 935 Complete # Status：命令执行状态 # LaunchState：应用启动状态，分为冷、暖、热启动，还有一种 `UNKNOWN (0)` 的状态，测试当前应用在前台，执行启动命令会出现。 # TotalTime：代表所有 Activity 启动时间，应用启动到出现欢迎页的时间 # WaitTime：当前应用进程的创建过程 + TotalTime # ThisTime：代表最后一个 Activity 启动时间（Android 10 上面没有这个时间）</content></entry><entry><title>Andorid - App存储目录解释</title><url>/tech/andorid/android%E5%BA%94%E7%94%A8%E5%AD%98%E5%82%A8%E7%9B%AE%E5%BD%95%E8%A7%A3%E9%87%8A/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">/data/data 目录解释 该文件夹存放存储包私有数据，对于设备中每一个安装的 App，系统都会在内部存储空间的 data/data 目录下以应用包名为名字自动创建与之对应的文件夹。
用户卸载 App 时，系统自动删除 data/data 目录下对应包名的文件夹及其内容。
该目录下又把存储内容进行了分类：
data/data/包名/cache： 存放的 APP 的缓存信息 data/data/包名/databases： 存放 APP 的数据库信息 data/data/包名/files： 存放 APP 的文件信息 data/data/包名/shared_prefs： 存放 APP 内的 SharedPreferences 必须root或者debug情况下才可以查看该文件目录。
宜搜小说目前APP缓存做了内外缓存：
内缓存：/data/data/com.esbook.reader
外缓存(sd卡缓存)：/sdcard/Android/data/com.esbook.reader
由于需要下载一些插件及其他apk包内容等大文件，所以做了sd 卡缓存，目前已经调整为内缓存。
如果首次启动安装 APP，权限全部禁止掉，则不会创建 esbook 文件夹，APP 的使用缓存及下载的听书插件会自动下载到外缓存文件内。
清除APP缓存：相当于同时删除了内缓存和外缓存
删除文件夹：相当于删除掉APP额外创建的文件夹，比如 esbook
注意听书插件放在内缓存 cache 文件内会被系统清理垃圾清理掉，遇到过这种问题，后来放在内缓存的 file 文件夹。
不 Root 查看 App/data/data/目录文件 条件：首先必须是 Android Debug 签名的应用才可以
方法一：
sagit:/ $ adb shell sagit:/ $ run-as 应用包名 sagit:/ $ cd /data/data/应用包名 方法二：
打开 Android studio，新建一个项目，连接设备，点击右下角 DeviceFileExplorer，进入 /data/data/ 包名，即可查看。</content></entry><entry><title>Andorid - Adb命令封装为自动化测试脚本</title><url>/tech/andorid/adb-%E5%91%BD%E4%BB%A4%E5%B0%81%E8%A3%85%E4%B8%BA%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E8%84%9A%E6%9C%AC/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"><![CDATA[ 转载文章，出处不详细。
 Android SDK   https://developer.android.com/studio   Command line tools only 命令行工具  添加到环境变量
export ANDROID_HOME=/Users/username/Library/Android/sdk/ export PATH=$ANDROID_HOME/platform-tools:$ANDROID_HOME/tools:$ANDROID_HOME/tools/bin Adb  客户端 服务端 android 后台服务  服务器 server 的参数
adb -L tcp:5037 fork-server server --reply-fd 4 adb client（客户端）
adb devices adb kill-server daemon(守护进程)
adb shell ps -ef | grep adbd shell 13883 1 2 20:27:48 ? 00:01:10 adbd --root_seclable=u:r:su:s0 运行原理
adb client -&gt; adb server - adbd
性能测试  dumpsys https://developer.android.com/studio/command-line/dumpsys    dumpsys --help dumpsys -l # 列举出所有功能 adb shell dumpsys procstats --hours 3 adb shell dumpsys meminfo package_name|pid [-d] adb shell dumpsys batterystats --charged package-name adb shell dumpsys netstats detail adb shell dumpsys gfxinfo package-name 自动化测试 常用命令 获取当前页面组织结构，得到 xml 文件
adb shell uiautomator --help sagit:/ $ uiautomator dump UI hierchary dumped to: /sdcard/window_dump.xml # --compressed 压缩文件，相比上面文件小点 sagit:/ $ uiautomator dump --compressd UI hierchary dumped to: /sdcard/window_dump.xml adb shell &#34;uiautomator dump --compressed &amp;&amp; cat /sdcard/window_dump.xml HWKNT:/ $input text abc HWKNT:/ $input text 123 HWKNT:/ $input tap 1000 600 HWKNT:/ $input text 123 HWKNT:/ $input tap 1000 600 HWKNT:/ $input swipe 100 1500 800 500 HWKNT:/ $input swipe 100 1500 800 500 HWKNT:/ $input swipe 100 1500 800 500 HWKNT:/ $input swipe 100 1500 800 500 localhost:~ seveniruby$adb shell &#34;uiautomator dump --compressed &amp;&amp; cat /sdcard/window_dump.xml&#34; UI hierchary dumped to: /sdcard/window_dump.xml &lt;?xml version=&#39;1.0&#39; encoding=&#39;UTF-8&#39; standalone=&#39;yes&#39; ?&gt;&lt;hierarchy rotation=&#34;0&#34;&gt;&lt;node index=&#34;0&#34; text=&#34;&#34; resource-id=&#34;&#34; class=&#34;android.widget.FrameLayout&#34; package=&#34;com.android.incallui&#34; content-desc=&#34;&#34; checkable=&#34;false&#34; checked=&#34;false&#34; clickable=&#34;false&#34; enabled=&#34;true&#34; focusable=&#34;false&#34; focused=&#34;false&#34; scrollable=&#34;false&#34; long-clickable=&#34;false&#34; password=&#34;false&#34; selected=&#34;false&#34; bounds=&#34;[0,0][1080,1812]&#34;&gt;&lt;node index=&#34;0&#34; text=&#34;&#34; resource-id=&#34;com.android.settings:id/drawer_layout&#34; class=&#34;android.support.v4.widget.DrawerLayout&#34; package=&#34;com.android.incallui&#34; content-desc=&#34;&#34; checkable=&#34;false&#34; checked=&#34;false&#34; clickable=&#34;false&#34; enabled=&#34;true&#34; focusable=&#34;false&#34; focused=&#34;false&#34; scrollable=&#34;false&#34; long-clickable=&#34;false&#34; password=&#34;false&#34; selected=&#34;false&#34; bounds=&#34;[0,0][1080,1812]&#34;&gt;&lt;node index=&#34;0&#34; text=&#34;&#34; resource-id=&#34;com.android.settings:id/content_parent&#34; class=&#34;android.widget.LinearLayout&#34; package=&#34;com.android.incallui&#34; content-desc=&#34;&#34; checkable=&#34;false&#34; checked=&#34;false&#34; clickable=&#34;false&#34; enabled=&#34;true&#34; focusable=&#34;false&#34; focused=&#34;false&#34; scrollable=&#34;false&#34; long-clickable=&#34;false&#34; password=&#34;false&#34; selected=&#34;false&#34; bounds=&#34;[0,0][1080,1812]&#34;&gt;&lt;node index=&#34;0&#34; text=&#34;&#34; 。。。 package=&#34;com.android.incallui&#34; content-desc=&#34;状态消息：&#34; checkable=&#34;false&#34; checked=&#34;false&#34; clickable=&#34;true&#34; enabled=&#34;true&#34; focusable=&#34;true&#34; focused=&#34;false&#34; scrollable=&#34;false&#34; long-clickable=&#34;false&#34; password=&#34;false&#34; selected=&#34;false&#34; bounds=&#34;[0,72][1080,216]&#34;&gt;&lt;node index=&#34;0&#34; text=&#34;&#34; resource-id=&#34;&#34; class=&#34;android.widget.FrameLayout&#34; package=&#34;com.android.incallui&#34; content-desc=&#34;向上导航&#34; checkable=&#34;false&#34; checked=&#34;false&#34; clickable=&#34;true&#34; enabled=&#34;true&#34; focusable=&#34;true&#34; focused=&#34;false&#34; scrollable=&#34;false&#34; long-clickable=&#34;false&#34; password=&#34;false&#34; selected=&#34;false&#34; bounds=&#34;[0,72][156,216]&#34; /&gt;&lt;node index=&#34;1&#34; text=&#34;状态消息&#34; resource-id=&#34;android:id/action_bar_title&#34; class=&#34;android.widget.TextView&#34; package=&#34;com.android.incallui&#34; content-desc=&#34;&#34; checkable=&#34;false&#34; checked=&#34;false&#34; clickable=&#34;false&#34; enabled=&#34;true&#34; focusable=&#34;false&#34; focused=&#34;false&#34; scrollable=&#34;false&#34; long-clickable=&#34;false&#34; password=&#34;false&#34; selected=&#34;false&#34; bounds=&#34;[168,107][384,180]&#34; /&gt;&lt;/node&gt;&lt;/node&gt;&lt;/node&gt;&lt;/hierarchy&gt; 封装 click(){ adb shell input tap $(adb shell &#34;uiautomator dump --compressed &amp;&amp; cat /sdcard/window_dump.xml&#34; | sed &#39;s#&lt;node #^&lt;node #g&#39; | tr ^ &#39;\n&#39; | grep &#34;$@&#34; | awk -F &#39;\\[|\\]|,&#39; &#39;{print ($(NF-2)+$(NF-5))/2, ($(NF-1)+$(NF-4))/2}&#39;) } send_keys(){ adb shell input text &#34;$@&#34; } swipe(){ size=$(adn shell wm size) start=$(echo &#34;$size&#34;| awk -v x=$1 -v y=$2 -F &#39; |x&#39; &#39;{print $(NF-1)*x, $NF*y}&#39;) end=$(echo &#34;$size&#34;| awk -v x=$1 -v y=$2 -F &#39; |x&#39; &#39;{print $(NF-1)*x, $NF*y}&#39;) adb shell input swipe $start $end } 执行脚本示例 #摩拜的登录自动化 localhost:~ seveniruby$ click 摩拜单车 localhost:~ seveniruby$ click 请输入手机号 localhost:~ seveniruby$ send send_keys sendmail localhost:~ seveniruby$ send_keys 11111111 localhost:~ seveniruby$ click 请输入验证码 localhost:~ seveniruby$ send_keys 1234 localhost:~ seveniruby$ click &#39;&#34;确定&#34; #滑动摩拜的地图 localhost:~ seveniruby$ swipe 0.1 0.8 0.9 0.3 localhost:~ seveniruby$ swipe 0.1 0.8 0.9 0.3 localhost:~ seveniruby$ swipe 0.9 0.8 0.1 0.3 localhost:~ seveniruby$ swipe 0.9 0.8 0.1 0.3 完成的自动化测试框架需要具备的能力  自动化测试能力 用例组织管理能力 断言  维护公司的回归测试集合，推荐使用的是标准的编程框架。比如 appium
]]></content></entry><entry><title>Andorid - Adb模拟磁盘填满（需Root）</title><url>/tech/andorid/adb-%E6%A8%A1%E6%8B%9F%E7%A3%81%E7%9B%98%E5%A1%AB%E6%BB%A1%E9%9C%80root/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">通过如下 adb 命令在 /mnt/sdcard/ 目录下产生一个名为 bigfile 的文件，让其自动增长到磁盘剩余空间大小。
操作前提：
获取手机的 root 权限 USB 设置不能设为 U盘功能 $ adb shell dd if=/dev/zero of=/mnt/sdcard/bigfile** /mnt/sdcard/bigfile: write error: No space left on device 3036001+0 records in 3036000+0 records out 1554432000 bytes transferred in 163.839 secs (9487557 bytes/sec)</content></entry><entry><title>Andorid - Adb端口被占用解决</title><url>/tech/andorid/adb-%E7%AB%AF%E5%8F%A3%E8%A2%AB%E5%8D%A0%E7%94%A8%E8%A7%A3%E5%86%B3/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">adb nodaemon server 可查看server报错日志
方法一： 5037 为 adb 默认端口，若 5037 端口被占用，查看占用端口的进程 PID
$ netstat -aon | findstr 5037 TCP 127.0.0.1:5037 0.0.0.0:0 LISTENING 3676 通过PID查看所有进程
$ tasklist /fi &amp;#34;PID eq 3676&amp;#34; 映像名称 PID 会话名 会话# 内存使用 ==================================================== svchost.exe 3676 Services 0 13,800 K 杀死占用端口的进程
$ taskkill /pid 3676 /f 成功: 已终止 PID 为 3676 的进程。
方法二： 自己配置 adb server 端口，使用一个生僻的值。
在系统环境变量中定义 ANDROID_ADB_SERVER_PORT 的值即可。
最好选择一个5位数的端口号（10000 ~ 65535），不易重复。
win下只要在环境变量中增加一个ANDROID_ADB_SERVER_PORT ，值填你自己定义的端口。
linux下只要 export $ANDROID_ADB_SERVER_PORT = 自定义端口，即可。</content></entry><entry><title>Andorid - Adb Shell命令</title><url>/tech/andorid/adb-shell%E5%91%BD%E4%BB%A4/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">adb # 获取 app 入口 $ adb logcat | grep -i displayed shell # 查看当前 activity $ adb shell | grep -i display # 获取当前页面的元素 $ adb shell dumpsys activity top # 获取任务列表 $ adb shell dumpsys activity activities $ aapt dump badging *.apk | grep launchable-activity $ apkanalyzer 最新版本的 sdk 中才有 shell am（Activity Manager - 活动管理） 通过它可以启动App、启动Activity以及启动广播和服务等等。
$ adb shell am start -W com.esbook.reader/com.esbook.reader.activity.ActLoading Starting: Intent { act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] cmp=com.esbook.reader/.activity.ActLoading } Status: ok LaunchState: WARM Activity: com.esbook.reader/.activity.ActLoading TotalTime: 163 WaitTime: 164 Complete 参数介绍：
-S: 杀死应用后重新启动，相当于冷启动 pm</content></entry><entry><title>Andorid - Adb命令汇总</title><url>/tech/andorid/adb-%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"> TODO：有时间把代码里的命令抽离出来放这里
https://github.com/abeelan/mobileTestToolkit/blob/main/utils/adbkit.py
adb # 获取 app 入口 $ adb logcat | grep -i displayed aapt
# 查看 apk 信息 $ aapt dump badging &amp;lt;apk文件路径&amp;gt;（将apk拖放到此处即可） $ aapt dump badging *.apk | grep launchable-activity $ apkanalyzer 最新版本的 sdk 中才有 shell # 查看当前 activity $ adb shell | grep -i display # 获取当前页面的元素 $ adb shell dumpsys activity top # 获取任务列表 $ adb shell dumpsys activity activities shell settings # 关闭手机的状态栏 $ adb shell settings put global policy_control immersive.full=* # 开启手机状态栏 $ adb shell settings put global policy_control null shell am（Activity Manager - 活动管理） 通过它可以启动App、启动Activity以及启动广播和服务等等。
$ adb shell am start -W com.esbook.reader/com.esbook.reader.activity.ActLoading Starting: Intent { act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] cmp=com.esbook.reader/.activity.ActLoading } Status: ok LaunchState: WARM Activity: com.esbook.reader/.activity.ActLoading TotalTime: 163 WaitTime: 164 Complete 参数介绍：
-S: 杀死应用后重新启动，相当于冷启动 pm</content></entry><entry><title>Andorid - Adb模拟按键映射表</title><url>/tech/andorid/adb-%E6%A8%A1%E6%8B%9F%E6%8C%89%E9%94%AE%E6%98%A0%E5%B0%84%E8%A1%A8/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"><![CDATA[使用方式 $ adb shell input keyevent &lt;KEYCODE&gt; # 举个例子 $ adb shell input keyevent 4 # 这条命令相当于按了设备的 Backkey 键 $ adb shell input keyevent 82 # 可以解锁屏幕 KEYCODE列表 0 &ndash;&gt; &ldquo;KEYCODE_UNKNOWN&rdquo;
1 &ndash;&gt; &ldquo;KEYCODE_MENU&rdquo;
2 &ndash;&gt; &ldquo;KEYCODE_SOFT_RIGHT&rdquo;
3 &ndash;&gt; &ldquo;KEYCODE_HOME&rdquo;
4 &ndash;&gt; &ldquo;KEYCODE_BACK&rdquo;
5 &ndash;&gt; &ldquo;KEYCODE_CALL&rdquo;
6 &ndash;&gt; &ldquo;KEYCODE_ENDCALL&rdquo;
7 &ndash;&gt; &ldquo;KEYCODE_0&rdquo;
8 &ndash;&gt; &ldquo;KEYCODE_1&rdquo;
9 &ndash;&gt; &ldquo;KEYCODE_2&rdquo;
10 &ndash;&gt; &ldquo;KEYCODE_3&rdquo;
11 &ndash;&gt; &ldquo;KEYCODE_4&rdquo;
12 &ndash;&gt; &ldquo;KEYCODE_5&rdquo;
13 &ndash;&gt; &ldquo;KEYCODE_6&rdquo;
14 &ndash;&gt; &ldquo;KEYCODE_7&rdquo;
15 &ndash;&gt; &ldquo;KEYCODE_8&rdquo;
16 &ndash;&gt; &ldquo;KEYCODE_9&rdquo;
17 &ndash;&gt; &ldquo;KEYCODE_STAR&rdquo;
18 &ndash;&gt; &ldquo;KEYCODE_POUND&rdquo;
19 &ndash;&gt; &ldquo;KEYCODE_DPAD_UP&rdquo;
20 &ndash;&gt; &ldquo;KEYCODE_DPAD_DOWN&rdquo;
21 &ndash;&gt; &ldquo;KEYCODE_DPAD_LEFT&rdquo;
22 &ndash;&gt; &ldquo;KEYCODE_DPAD_RIGHT&rdquo;
23 &ndash;&gt; &ldquo;KEYCODE_DPAD_CENTER&rdquo;
24 &ndash;&gt; &ldquo;KEYCODE_VOLUME_UP&rdquo;
25 &ndash;&gt; &ldquo;KEYCODE_VOLUME_DOWN&rdquo;
26 &ndash;&gt; &ldquo;KEYCODE_POWER&rdquo;
27 &ndash;&gt; &ldquo;KEYCODE_CAMERA&rdquo;
28 &ndash;&gt; &ldquo;KEYCODE_CLEAR&rdquo;
29 &ndash;&gt; &ldquo;KEYCODE_A&rdquo;
30 &ndash;&gt; &ldquo;KEYCODE_B&rdquo;
31 &ndash;&gt; &ldquo;KEYCODE_C&rdquo;
32 &ndash;&gt; &ldquo;KEYCODE_D&rdquo;
33 &ndash;&gt; &ldquo;KEYCODE_E&rdquo;
34 &ndash;&gt; &ldquo;KEYCODE_F&rdquo;
35 &ndash;&gt; &ldquo;KEYCODE_G&rdquo;
36 &ndash;&gt; &ldquo;KEYCODE_H&rdquo;
37 &ndash;&gt; &ldquo;KEYCODE_I&rdquo;
38 &ndash;&gt; &ldquo;KEYCODE_J&rdquo;
39 &ndash;&gt; &ldquo;KEYCODE_K&rdquo;
40 &ndash;&gt; &ldquo;KEYCODE_L&rdquo;
41 &ndash;&gt; &ldquo;KEYCODE_M&rdquo;
42 &ndash;&gt; &ldquo;KEYCODE_N&rdquo;
43 &ndash;&gt; &ldquo;KEYCODE_O&rdquo;
44 &ndash;&gt; &ldquo;KEYCODE_P&rdquo;
45 &ndash;&gt; &ldquo;KEYCODE_Q&rdquo;
46 &ndash;&gt; &ldquo;KEYCODE_R&rdquo;
47 &ndash;&gt; &ldquo;KEYCODE_S&rdquo;
48 &ndash;&gt; &ldquo;KEYCODE_T&rdquo;
49 &ndash;&gt; &ldquo;KEYCODE_U&rdquo;
50 &ndash;&gt; &ldquo;KEYCODE_V&rdquo;
51 &ndash;&gt; &ldquo;KEYCODE_W&rdquo;
52 &ndash;&gt; &ldquo;KEYCODE_X&rdquo;
53 &ndash;&gt; &ldquo;KEYCODE_Y&rdquo;
54 &ndash;&gt; &ldquo;KEYCODE_Z&rdquo;
55 &ndash;&gt; &ldquo;KEYCODE_COMMA&rdquo;
56 &ndash;&gt; &ldquo;KEYCODE_PERIOD&rdquo;
57 &ndash;&gt; &ldquo;KEYCODE_ALT_LEFT&rdquo;
58 &ndash;&gt; &ldquo;KEYCODE_ALT_RIGHT&rdquo;
59 &ndash;&gt; &ldquo;KEYCODE_SHIFT_LEFT&rdquo;
60 &ndash;&gt; &ldquo;KEYCODE_SHIFT_RIGHT&rdquo;
61 &ndash;&gt; &ldquo;KEYCODE_TAB&rdquo;
62 &ndash;&gt; &ldquo;KEYCODE_SPACE&rdquo;
63 &ndash;&gt; &ldquo;KEYCODE_SYM&rdquo;
64 &ndash;&gt; &ldquo;KEYCODE_EXPLORER&rdquo;
65 &ndash;&gt; &ldquo;KEYCODE_ENVELOPE&rdquo;
66 &ndash;&gt; &ldquo;KEYCODE_ENTER&rdquo;
67 &ndash;&gt; &ldquo;KEYCODE_DEL&rdquo;
68 &ndash;&gt; &ldquo;KEYCODE_GRAVE&rdquo;
69 &ndash;&gt; &ldquo;KEYCODE_MINUS&rdquo;
70 &ndash;&gt; &ldquo;KEYCODE_EQUALS&rdquo;
71 &ndash;&gt; &ldquo;KEYCODE_LEFT_BRACKET&rdquo;
72 &ndash;&gt; &ldquo;KEYCODE_RIGHT_BRACKET&rdquo;
73 &ndash;&gt; &ldquo;KEYCODE_BACKSLASH&rdquo;
74 &ndash;&gt; &ldquo;KEYCODE_SEMICOLON&rdquo;
75 &ndash;&gt; &ldquo;KEYCODE_APOSTROPHE&rdquo;
76 &ndash;&gt; &ldquo;KEYCODE_SLASH&rdquo;
77 &ndash;&gt; &ldquo;KEYCODE_AT&rdquo;
78 &ndash;&gt; &ldquo;KEYCODE_NUM&rdquo;
79 &ndash;&gt; &ldquo;KEYCODE_HEADSETHOOK&rdquo;
80 &ndash;&gt; &ldquo;KEYCODE_FOCUS&rdquo;
81 &ndash;&gt; &ldquo;KEYCODE_PLUS&rdquo;
82 &ndash;&gt; &ldquo;KEYCODE_MENU&rdquo;
83 &ndash;&gt; &ldquo;KEYCODE_NOTIFICATION&rdquo;
84 &ndash;&gt; &ldquo;KEYCODE_SEARCH&rdquo;
85 &ndash;&gt; &ldquo;TAG_LAST_KEYCODE&rdquo;
电话键    KEYCODE_CALL 拨号键 5     KEYCODE_ENDCALL 挂机键 6   KEYCODE_HOME 按键Home 3   KEYCODE_MENU  菜单  键 82   KEYCODE_BACK 返回键 4   KEYCODE_S EA  RCH  搜索  键 84   KEYCODE_CAMERA 拍照键 27   KEYCODE_FOCUS 拍照对焦键 80   KEYCODE_POWER 电源键 26   KEYCODE_NOTIFICATION 通知键 83   KEYCODE_MUTE 话筒静音键 91   KEYCODE_VOLUME_MUTE 扬声器静音键 164   KEYCODE_VOLUME_UP 音量增加键 24   KEYCODE_VOLUME_DOWN 音量减小键 25       KEYCODE_NUM 按键Number modifier     KEYCODE_INFO 按键Info   KEYCODE_ APP  _SW IT  CH 按键App switch   KEYCODE_BOOKMARK 按键Bookmark   KEYCODE_AVR_INPUT 按键A/V Receiver input   KEYCODE_AVR_POWER 按键A/V Receiver power   KEYCODE_CAPTIONS 按键Toggle captions   KEYCODE_CHANNEL_DOWN 按键Channel down   KEYCODE_CHANNEL_UP 按键Channel up   KEYCODE_CLEAR 按键Clear   KEYCODE_DVR 按键DVR   KEYCODE_ENVELOPE 按键Envelope special function   KEYCODE_E XP  LORER 按键Explorer special function   KEYCODE_FORWARD 按键Forward   KEYCODE_FORWARD_DEL 按键Forward Delete   KEYCODE_FUNCTION 按键Function modifier   KEYCODE_G UI  DE 按键Guide   KEYCODE_HEADSETHOOK 按键Headset Hook   KEYCODE_META_LEFT 按键Left Meta modifier   KEYCODE_META_RIGHT 按键Right Meta modifier   KEYCODE_PICTSYMBOLS 按键Picture Symbols modifier   KEYCODE_PROG_BL UE   按键Blue “programmable”   KEYCODE_PROG_GREEN 按键Green “programmable”   KEYCODE_PROG_RED 按键Red “programmable”   KEYCODE_PROG_YELLOW 按键Yellow “programmable”   KEYCODE_SETTINGS 按键Settings   KEYCODE_SOFT_LEFT 按键Soft Left   KEYCODE_SOFT_RIGHT 按键Soft Right   KEYCODE_STB_INPUT 按键Set-top-box input   KEYCODE_STB_POWER 按键Set-top-box power   KEYCODE_SWITCH_CHARSET 按键Switch Charset modifier   KEYCODE_SYM 按键Symbol modifier   KEYCODE_SYSRQ 按键System Request / Print Screen   KEYCODE_TV 按键TV   KEYCODE_TV_INPUT 按键TV input   KEYCODE_TV_POWER 按键TV power   KEYCODE_WINDOW 按键Window   KEYCODE_UNKNOWN 未知按键    控制键
   KEYCODE_ENTER 回车键 66     KEYCODE_ESCAPE ESC键 111   KEYCODE_DPAD_CENTER  导航  键 确定键 23   KEYCODE_DPAD_UP 导航键 向上 19   KEYCODE_DPAD_DOWN 导航键 向下 20   KEYCODE_DPAD_LEFT 导航键 向左 21   KEYCODE_DPAD_RIGHT 导航键 向右 22   KEYCODE_MOVE_HOME 光标 移动  到开始键 122   KEYCODE_MOVE_END 光标移动到末尾键 123   KEYCODE_PAGE_UP 向上翻页键 92   KEYCODE_PAGE_DOWN 向下翻页键 93   KEYCODE_DEL 退格键 67   KEYCODE_FORWARD_DEL 删除键 112   KEYCODE_ IN  SERT 插入键 124   KEYCODE_TAB Tab键 61   KEYCODE_NUM_LOCK 小键盘锁 143   KEYCODE_CAPS_LOCK 大写锁定键 115   KEYCODE_BREAK Break/Pause键 121   KEYCODE_SCROLL_LOCK 滚动锁定键 116   KEYCODE_ZOOM_IN 放大键 168   KEYCODE_ZOOM_OUT 缩小键 169    组合键    KEYCODE_ALT_LEFT Alt+Left     KEYCODE_ALT_RIGHT Alt+Right   KEYCODE_CTRL_LEFT Control+Left   KEYCODE_CTRL_RIGHT Control+Right   KEYCODE_SHIFT_LEFT Shift+Left   KEYCODE_SHIFT_RIGHT Shift+Right    基本
   KEYCODE_0 按键'0' 7     KEYCODE_1 按键'1' 8   KEYCODE_2 按键'2' 9   KEYCODE_3 按键'3' 10   KEYCODE_4 按键'4' 11   KEYCODE_5 按键'5' 12   KEYCODE_6 按键'6' 13   KEYCODE_7 按键'7' 14   KEYCODE_8 按键'8' 15   KEYCODE_9 按键'9' 16   KEYCODE_A 按键&rsquo;A' 29   KEYCODE_B 按键&rsquo;B' 30   KEYCODE_C 按键&rsquo;C' 31   KEYCODE_D 按键&rsquo;D' 32   KEYCODE_E 按键&rsquo;E' 33   KEYCODE_F 按键&rsquo;F' 34   KEYCODE_G 按键&rsquo;G' 35   KEYCODE_H 按键&rsquo;H' 36   KEYCODE_I 按键&rsquo;I' 37   KEYCODE_J 按键&rsquo;J' 38   KEYCODE_K 按键&rsquo;K' 39   KEYCODE_L 按键&rsquo;L' 40   KEYCODE_M 按键&rsquo;M' 41   KEYCODE_N 按键&rsquo;N' 42   KEYCODE_O 按键&rsquo;O' 43   KEYCODE_P 按键&rsquo;P' 44   KEYCODE_Q 按键&rsquo;Q' 45   KEYCODE_R 按键&rsquo;R' 46   KEYCODE_S 按键&rsquo;S' 47   KEYCODE_T 按键&rsquo;T' 48   KEYCODE_U 按键&rsquo;U' 49   KEYCODE_V 按键&rsquo;V' 50   KEYCODE_W 按键&rsquo;W' 51   KEYCODE_X 按键&rsquo;X' 52   KEYCODE_Y 按键&rsquo;Y' 53   KEYCODE_Z 按键&rsquo;Z' 54    符号
   KEYCODE_PLUS 按键'+'     KEYCODE_MINUS 按键'-'   KEYCODE_STAR 按键'*'   KEYCODE_SLASH 按键'/'   KEYCODE_EQUALS 按键'='   KEYCODE_AT 按键'@'   KEYCODE_POUND 按键'#'   KEYCODE_AP OS  TROPHE 按键''' (单引号)   KEYCODE_BACKSLASH 按键''   KEYCODE_COMMA 按键','   KEYCODE_PERIOD 按键'.'   KEYCODE_LEFT_BRACKET 按键'['   KEYCODE_RIGHT_BRACKET 按键']'   KEYCODE_ SEM  ICOLON 按键';'   KEYCODE_GRAVE 按键'`'   KEYCODE_SPACE 空格键    小键盘
   KEYCODE_NUMPAD_0 小键盘按键'0'     KEYCODE_NUMPAD_1 小键盘按键'1'   KEYCODE_NUMPAD_2 小键盘按键'2'   KEYCODE_NUMPAD_3 小键盘按键'3'   KEYCODE_NUMPAD_4 小键盘按键'4'   KEYCODE_NUMPAD_5 小键盘按键'5'   KEYCODE_NUMPAD_6 小键盘按键'6'   KEYCODE_NUMPAD_7 小键盘按键'7'   KEYCODE_NUMPAD_8 小键盘按键'8'   KEYCODE_NUMPAD_9 小键盘按键'9'   KEYCODE_NUMPAD_ADD 小键盘按键'+'   KEYCODE_NUMPAD_SUBTRACT 小键盘按键'-'   KEYCODE_NUMPAD_MULT IP  LY 小键盘按键'*'   KEYCODE_NUMPAD_DIV IDE   小键盘按键'/'   KEYCODE_NUMPAD_EQUALS 小键盘按键'='   KEYCODE_NUMPAD_COMMA 小键盘按键','   KEYCODE_NUMPAD_DOT 小键盘按键'.'   KEYCODE_NUMPAD_LEFT_PAREN 小键盘按键'('   KEYCODE_NUMPAD_RIGHT_PAREN 小键盘按键')'   KEYCODE_NUMPAD_ENTER 小键盘按键回车    功能键
   KEYCODE_F1 按键F1     KEYCODE_F2 按键F2   KEYCODE_F3 按键F3   KEYCODE_F4 按键F4   KEYCODE_F5 按键F5   KEYCODE_F6 按键F6   KEYCODE_F7 按键F7   KEYCODE_F8 按键F8   KEYCODE_F9 按键F9   KEYCODE_F10 按键F10   KEYCODE_F11 按键F11   KEYCODE_F12 按键F12    多媒体键
   KEYCODE_ MED  IA_PLAY 多媒体键 播放     KEYCODE_MEDIA_STOP 多媒体键 停止   KEYCODE_MEDIA_PAUSE 多媒体键 暂停   KEYCODE_MEDIA_PLAY_PAUSE 多媒体键 播放/暂停   KEYCODE_MEDIA_FAST_FORWARD 多媒体键 快进   KEYCODE_MEDIA_REWIND 多媒体键 快退   KEYCODE_MEDIA_NEXT 多媒体键 下一首   KEYCODE_MEDIA_ PR  EVIOUS 多媒体键 上一首   KEYCODE_MEDIA_CLOSE 多媒体键 关闭   KEYCODE_MEDIA_EJECT 多媒体键 弹出   KEYCODE_MEDIA_RECORD 多媒体键 录音    手柄按键
   KEYCODE_BUTTON_1 通用 游戏  手柄按钮#1     KEYCODE_BUTTON_2 通用游戏手柄按钮 #2   KEYCODE_BUTTON_3 通用游戏手柄按钮 #3   KEYCODE_BUTTON_4 通用游戏手柄按钮 #4   KEYCODE_BUTTON_5 通用游戏手柄按钮 #5   KEYCODE_BUTTON_6 通用游戏手柄按钮 #6   KEYCODE_BUTTON_7 通用游戏手柄按钮 #7   KEYCODE_BUTTON_8 通用游戏手柄按钮 #8   KEYCODE_BUTTON_9 通用游戏手柄按钮 #9   KEYCODE_BUTTON_10 通用游戏手柄按钮 #10   KEYCODE_BUTTON_11 通用游戏手柄按钮 #11   KEYCODE_BUTTON_12 通用游戏手柄按钮 #12   KEYCODE_BUTTON_13 通用游戏手柄按钮 #13   KEYCODE_BUTTON_14 通用游戏手柄按钮 #14   KEYCODE_BUTTON_15 通用游戏手柄按钮 #15   KEYCODE_BUTTON_16 通用游戏手柄按钮 #16   KEYCODE_BUTTON_A 游戏手柄按钮 A   KEYCODE_BUTTON_B 游戏手柄按钮 B   KEYCODE_BUTTON_C 游戏手柄按钮 C   KEYCODE_BUTTON_X 游戏手柄按钮 X   KEYCODE_BUTTON_Y 游戏手柄按钮 Y   KEYCODE_BUTTON_Z 游戏手柄按钮 Z   KEYCODE_BUTTON_L1 游戏手柄按钮 L1   KEYCODE_BUTTON_L2 游戏手柄按钮 L2   KEYCODE_BUTTON_R1 游戏手柄按钮 R1   KEYCODE_BUTTON_R2 游戏手柄按钮 R2   KEYCODE_BUTTON_MODE 游戏手柄按钮 Mode   KEYCODE_BUTTON_SELECT 游戏手柄按钮 Select   KEYCODE_BUTTON_START 游戏手柄按钮 Start   KEYCODE_BUTTON_THUMBL Left Thumb Button   KEYCODE_BUTTON_THUMBR Right Thumb Button    ]]></content></entry><entry><title>Linux - Ubuntu安装软件汇总</title><url>/tech/linux/ubuntu-%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%B1%87%E6%80%BB/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[基础命令 重启 $ reboot 查看 ip 地址 $ ip addr show 安装包 # 安装 ssh，已安装则忽略 $ sudo apt-get install ssh # 输入密码 $ apt install net-tools # ifconfig 命令 显示磁盘大小 # 查看硬盘剩余空间 -H $ df -hl # 查看硬盘的分区 $ sudo fdisk -l # 查看 IDE硬盘信息 $ sudo hdparm -i /dev/hda # 查看STAT硬盘信息 $ sudo hdparm -I /dev/sda # 或  $ sudo apt-get install blktool $ sudo blktool /dev/sda id # 查看目录占用空间 $ du -hs 目录名 # 优盘没法卸载 $ sync fuser -km /media/usbdisk 安装 adb # 通过apt-get安装adb $ sudo add-apt-repository ppa:nilarimogard/webupd8 $ sudo apt-get update $ sudo apt-get install android-tools-adb $ adb devices * daemon not running; starting now at tcp:5037 * daemon started successfully List of devices attached 1a34c478 unauthorized # 未许可设备连接 # 重新开启「开发者选项 - USB 调试」，重启 adb server # 在手机弹框中选择允许，即可成功连接 &#34;注意：如果是未找到设备，那么继续向下看，以下内容未经实践，来源网络&#34; # 将 Android 设备连接至电脑，查看设备连接详情 $ lsusb Bus 002 Device 002: ID 8087:8000 Intel Corp. Integrated Rate Matching Hub Bus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 001 Device 002: ID 8087:8008 Intel Corp. Integrated Rate Matching Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 004 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub Bus 003 Device 004: ID 1a2c:2c27 China Resource Semico Co., Ltd USB Keyboard Bus 003 Device 003: ID 046d:c077 Logitech, Inc. M105 Optical Mouse &#34;Bus 003 Device 002: ID 18d1:4ee9 Google Inc. Nexus/Pixel Device (MIDI + debug)&#34; Bus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub # 创建 adb_usb.ini 文件并写入 id $ echo 0x18d1 &gt; ~/.android/adb_usb.ini # 添加权限 $ sudo vim /etc/udev/rules.d/70-android.rules # 加入以下内容，注意红色部分对应的就是lsusb得到的id SUBSYSTEM==&#34;usb&#34;, ATTRS{idVendor}==&#34;18d1&#34;, ATTRS{idProduct}==&#34;1002&#34;, MODE=&#34;0666&#34; # 重启 USB 服务 $ sudo chmod a+rx /etc/udev/rules.d/70-android.rules $ sudo service udev restart # 重启adb服务 $ adb kill-server $ sudo adbstart-server $ adb devices Listof devices attached 1a34c478 device 安装 SVN 要在 Ubuntu 上安装 SVN，请按照以下步骤进行操作：
$ sudo apt-get install subversion $ svn --version $ svn co --username your_username --password your_password https://svn.example.com/svn/myproject 设置静态 IP 地址 # 修改静态 IP 地址 $ vim /etc/netplan/00-installer-config.yaml # This is the network config written by &#39;subiquity&#39; network: ethernets: enp2s0: dhcp4: no optional: true addresses: [192.168.1.222/24] # 配置的静态ip地址和掩码 routes: - to: default via: 192.168.1.1 # 网关地址 nameservers: addresses: [114.114.114.114,8.8.8.8] version: 2 # 查看网络服务状态 $ sudo networkctl status # 重启网卡，加载配置 $ sudo netplan apply 安装 docker 卸载自带的 docker 旧版本
# 卸载 docker # 该版本 docker 遇到问题，所以重装一下 # 挂载目录只能放在用户目录下 $ sudo snap remove --purge docker 使用 apt-get 安装：https://docs.docker.com/engine/install/ubuntu/?spm=wolai.workspace.0.0.144bcbd9dmCyVL
]]></content></entry><entry><title>Linux - 脚本 语法基础</title><url>/tech/linux/%E8%84%9A%E6%9C%AC-%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[Shell Shell 是一种应用程序，提供用户通过界面访问操作系统内核的服务。shell 脚本是为 shell 编写的脚本程序，Linux 的 shell 编程种类较多，比如：
 /bin/sh /bin/bash /bin/zsh  通常情况下，sh 和 bash 是不区分的，下文以 bash 为例。
命名规则  命名只能使用英文字母、数字和下划线，首字符不能以数字开头 不能包含空格 不能使用标点符号 不能使用 bash 内的关键字（可用 help 命令查看保留关键字）  定义与使用变量 # 定义变量 $ name=&#34;shell&#34; # 使用变量 $ echo hello $name hello shell # 定义只读变量 $ a=1 $ readonly a $ echo $a 1 # 重新赋值就会报错 $ a=2 bash: a: readonly variable # 删除变量 $ b=2 $ echo $b 2 $ unset b # 删除 $ echo $b # 无法删除只读变量 $ unset a bash: unset: a: cannot unset: readonly variable 变量只作用于当前窗口，关掉窗口重新打开，变量就失效了，对只读变量同样有效。
变量类型   字符串: a=&quot;123&quot;
  拼接字符串: b=&quot;$a, 456&quot;
  数组:
values=(v1 v2 v3)  取单个值: v2=${values[1]} 取全部值: echo ${values[*]} 添加元素: values[3]=4    基本运算 $ a=10 $ b=20 # 严格遵守空格 $ expr $a + $b # 30 $ expr $a - $b # -10 $ expr $a \* $b # 200; 乘号需要转义 $ expr $b / $a # 2；取商 $ expr $a % $b # 10；取余 # 两数相加其他写法 $ echo `expr $a + $b` $ echo $(($a+$b)) $ echo $[$a+$b] $ if [ $a == $b ]; then echo true; else echo flase; fi # false $ if [ $a != $b ]; then echo true; else echo flase; fi # true  -eq：相等 -ne：不等 -gt：大于 -lt：小于 -ge：大于等于 -le：小于等于  控制语句 $ if condition; &gt; then &gt; commands; &gt; elif condition; &gt; then &gt; commands; &gt; else &gt; commands; &gt; fi 示例：两数比较大小
$ a=1 $ b=2 $ if [ $a -eq $b ]; &gt; then &gt; echo &#34;equal&#34;; &gt; elif [ $a -lt $b ]; &gt; then &gt; echo &#34;less than&#34;; &gt; else &gt; echo &#34;greater than&#34;; &gt; fi less than for 循环 # 方式一 $ for var in var1 var2 var3 &gt; do &gt; commands &gt; done # 方式二 $ for ((i=1; i&lt;j; i++)) &gt; do &gt; commands &gt; done 示例：逐行打印文件内容
$ for i in ${cat hotWords}; &gt; do &gt; echo $i; &gt; done while 循环 $ while condition &gt; do &gt; commands; &gt; done 示例：递减 &amp; 循环读取并打印内容
# 例 1: 递减 $ while (($a&gt;=0)); &gt; do &gt; echo $a; &gt; let &#34;a--&#34;; # let 计算表达式 &gt; done # 例 2: 循环读取文件内容并打印 # read 命令用于从终端或者文件中读取输入指令 $ while read line; &gt; do &gt; echo $line; &gt; done &lt; hotWords 以脚本方式运行程序 $ echo &#34;echo demo&#34; &gt; demo # 运行 sh 脚本方式一 $ sh demo demo # 运行方式二; 需要先添加可执行权限 $ chmod +x demo $ ./demo demo 脚本参数传递  $0 脚本名称 $1~$n 获取参数 $# 传递到脚本的参数个数 $$ 脚本运行的进程 ID $* 以一个单字符串显示所有向脚本传递的参数 $? 显示最后命令的退出状态，非 0 都表示有错误  $ cat demo echo &#34;脚本名称：$0&#34; echo &#34;参数一值：$1&#34; echo &#34;参数个数：$#&#34; echo &#34;进程ID： $$&#34; echo &#34;整串参数：$*&#34; echo &#34;退出状态：$?&#34; $ sh demo 1 2 3 4 5 6 脚本名称：demo 参数一值：1 参数个数：6 进程ID： 22173 整串参数：1 2 3 4 5 6 退出状态：0 PATH 变量  PATH 变量是一个路径列表，以 : 隔开； 如果可执行程序所在的目录在 PATH 变量路径列表里，那么输入命令时可以省略路径 路径列表前面的路径为优先匹配路径，匹配到即停止，可以用来实现新老版本程序的命令更换  $ echo $PATH /usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin # /usr/local/bin 里面的 python version = 2.7 # /usr/bin 里面的 python version = 3.6 # 会先使用路径列表前面的 python 版本 $ which python /usr/local/bin/python # 2.7  设置环境变量，并使其立马生效；修改后如果不 source 该配置文件，则每次用户重新登录时才会自动生效。
$ vim ~/.bash_profile $ source ~/.bash_profile 应用安装 # 1. yum: centos/redhat $ yum search $package $ yum install $package $ yum remove $package # 2. apt-get: ubuntu debian $ apt-cache search $package $ apt-get install $package $ apt-get uninstall $package # 3. 源码编译安装：make; make install 开源镜像站   华为镜像    阿里云    豆瓣    ]]></content></entry><entry><title>Linux - 命令 远程同步（Rsync）</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-%E8%BF%9C%E7%A8%8B%E5%90%8C%E6%AD%A5rsync/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[安装
$ yum -y install rsync 同机器同步
# 增量同步 $ rsync -avz folder1/ folder2/ 远程同步
# 服务端 $ rsync -avz /root/hello root@{远程IP}:/root/ # 从远程同步文件到本地,远程服务 需要 安装 rsync 服务 $ rsync -avz -e &#39;ssh -p 22&#39; root@{远程IP}:/root/hello /root motd file -&gt; motd文件位置 log file -&gt; 日志文件位置 path -&gt; 默认路径位置 use chroot -&gt; 是否限定在该目录下，默认为true，当有软连接时，需要改为fasle,如果为true就限定为模块默认目录 read only -&gt; 只读配置（yes or no） list=true -&gt; 是否可以列出模块名 uid = root -&gt; 传输使用的用户名 gid = root -&gt; 传输使用的用户组 auth users -&gt; 认证用户名 secrets file=/etc/rsyncd.passwd -&gt; 指定密码文件，如果设定验证用户，这一项必须设置，设定密码权限为400,密码文件/etc/rsyncd.passwd的内容格式为：username:password hosts allow=192.168.0.101 -&gt; 设置可以允许访问的主机，可以是网段，多个Ip地址用空格隔开 hosts deny 禁止的主机，host的两项可以使用*表任意。 ]]></content></entry><entry><title>Linux - 命令 性能监控</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-%E6%80%A7%E8%83%BD%E7%BB%9F%E8%AE%A1%E5%91%BD%E4%BB%A4/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[ 监测服务器性能的基本命令
 通过 CPU、内存、I/O 这三方面，回顾 Linux 系统下，服务器性能监测命令以及问题排查思路。
CPU 查看 CPU 软硬件信息 $ cat /proc/cpuinfo processor : 系统核编号，从 0 开始排序 vendor_id : 制造商 cpu family : 产品系列号 model : 产品系列中的哪一代，代号 model name : CPU 名称和编号，标称主频 stepping : 更新版本 microcode : 0x1d cpu MHz : 实际使用主频 cache size : 二级缓存大小 physical id : 单个 CPU 标号 siblings : 单个 CPU 逻辑物理核数 core id : 当前物理核在其所处 CPU 中的编号，不一定连续 cpu cores : 该逻辑核所处 CPU 的物理核数 apicid : 区分不同逻辑核的编号，每个逻辑核编号必然不同 initial apicid : 初始化逻辑核编号 fpu : 是否具有浮点运算单元（Floating Point Unit） fpu_exception : 是否支持浮点计算异常 cpuid level : 执行 cpuid 指令前，eax 寄存器中的值，根据不同的值 cpuid 指令会返回不同的内容 wp : 表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection） flags : 当前CPU支持的功能 bogomips : 在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second） clflush size : 每次刷新缓存的大小单位 cache_alignment : 缓存地址对齐单位 address sizes : 可访问地址空间位数 power management: 对能源管理的支持 常用过滤查找命令
# 查询系统CPU的个数 $ cat /proc/cpuinfo | grep &#34;physical id&#34; | sort | uniq | wc -l 2 # 查询系统具有多少个逻辑核 $ cat /proc/cpuinfo | grep &#34;processor&#34; | wc -l 8 # 查询系统CPU的物理核数 $ cat /proc/cpuinfo | grep &#34;cpu cores&#34; | uniq cpu cores : 4 # 查询系统CPU是否启用超线程; 输出二者一致，没有启用超线程，否则被启用 $ cat /proc/cpuinfo | grep -e &#34;cpu cores&#34; -e &#34;siblings&#34; | sort | uniq cpu cores : 4 siblings : 4 查看进程运行信息 $ top # -d：设置刷新间隔秒数 # -n：设置更新次数，到达指定次数后自动退出 top 视图 # -p：获取指定端口的进程信息 # 当前时间，系统运行天数；当前系统在线用户数；负载 1 分钟、5 分钟、15 分钟 top - 10:07:34 up 262 days, 16:41, 1 user, load average: 0.02, 0.04, 0.05 # 共运行进程数，2 个正在运行，829 在休眠状态；0 个停止状态； 0 个僵尸进程 Tasks: 831 total, 2 running, 829 sleeping, 0 stopped, 0 zombie # cup 占用百分比：us 用户使用；sy 系统使用；ni ；id 空闲/等待；wa 等待写入 %Cpu(s): 0.1 us, 0.1 sy, 0.0 ni, 99.8 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st # 内存占用：总内存；空闲内存；已经使用内存；缓存 KiB Mem : 16252328 total, 690012 free, 6821492 used, 8740824 buff/cache KiB Swap: 8290300 total, 8290300 free, 0 used. 8294140 avail Mem # 进程详情  PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 22166 root 20 0 162784 3056 1588 R 1.0 0.0 0:00.70 top 733 polkitd 20 0 1697352 142076 21752 S 0.7 0.9 709:12.65 mongod # S 代表进程运行状态 # TIME+ 代表进程使用的总时间 更详细的参数介绍，这篇 top 命令   写的非常详细，可以参考。
注意：僵尸进程会占用系统资源，影响正常程序运行，所以要及时处理掉僵尸进程。
# 使用 ps 过滤查找 stat 状态为 Z/z 的进程 $ ps -A -ostat,ppid,pid,cmd | grep -e &#39;^[Zz]&#39; # 使用 kill 杀掉进程 $ kill -HUP 1234 系统负载测试 新建两个服务器窗口
 窗口 1：运行 top 命令，实时观察系统负载数据 窗口 2：运行测试命令  # yes 命令的作用是输出指定字符串，直到 yes 进程被杀死 # 运行 30 秒后获取到 yes 进程并杀死 $ { yes &gt; /dev/null &amp; } &amp;&amp; sleep 30 &amp;&amp; ps -ef | grep yes | awk &#39;{print $2}&#39; | xargs kill 切换到 top 命令窗口，发现 yes 命令启动的进程已经开始工作，用户态 CPU 使用率提升，系统负载增加，30 秒后 yes 进程被自动杀死，各项数据恢复。
再做一次更直观的测试，通过 for 循环启动与 CPU 核数相同的进程数运行 yes 命令。
$ for i in $(seq 0 $(($(cat /proc/cpuinfo | grep processor | wc -l) -l))); do taskset -c $i yes &gt; /dev/null &amp; done &amp;&amp; sleep 30 &amp;&amp; ps -ef | grep yes | awk &#39;{print $2}&#39; | xargs kill 这次发现 CPU 占用率已经接近百分百了，此时再访问该机器下的其他服务，响应就会相对变慢。说回工作，在测试过程中发现业务响应很慢，除了排查网络原因外，还可以登录服务器，通过 top 命令查看是否有其他进程导致 CPU 占用率过高。
内存 $ free -h total used free shared buff/cache available Mem: 15G 6.5G 674M 724M 8.3G 7.9G Swap: 7.9G 0B 7.9G  total：总物理内存 used：已经使用的内存 free：空闲可用内存 shared：多进程共享内存 buff/cache：读写缓存内存，当 free 不足时，内核会讲该部分内存释放  buffer：即将要被写入磁盘的 cache：即将从磁盘中读出来的   available：还能被应用程序使用的物理内存  IO Input / Output
硬盘 IO 通过 iostat 工具可以对系统的磁盘操作活动进行监视。
# 安装 $ yum install sysstat # 使用 # 参数 1 代表每秒刷新一次 # 后面可以再跟一个数字，表示共刷新几次 $ iostat 1 avg-cpu: %user %nice %system %iowait %steal %idle 0.00 0.00 0.00 0.00 0.00 100.00 # 机器硬盘信息 # tps：数据每秒传输次数；每秒从设备读写的数据量（读写速度）；读写的总数据量 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 0.00 0.00 0.00 0 0 sdb 0.00 0.00 0.00 0 0 sdc 0.00 0.00 0.00 0 0 参数说明：
 %user：CPU 处在用户模式下的时间百分比 %nice：CPU 处在带 NICE 值的用户模式下的时间百分比 %system：CPU 处在系统模式下的时间百分比 %iowait：CPU 等待输入输出完成时间的百分比，如果该值过高，表示硬盘存在 I/O 瓶颈 %steal：管理程序维护另一个虚拟处理器时，虚拟 CPU 的无意识等待时间百分比 %idle：CPU 空闲时间百分比，如果该值过高，表示 CPU 较空闲  备注：
如果 %idle 值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量；%idle 值如果持续低于 10，那么系统的 CPU 处理能力较低，表明系统中最需要解决的资源是 CPU。
重新启动一个窗口，通过两条命令模拟 IO 操作：
# 写 $ dd if =/dev/zero bs=1024 count=4096000 of=test.iso # 读 $ dd if=test.iso bs=64k | dd of=/dev/null  bs：设置读/写缓冲区的字节数 /dev/null：空设备，特殊的设备文件，丢弃一切写入其中的数据 /dev/zero：特殊文件，当被读取时，提供无限的空字符  观察 iostat 数据情况，通过 dd 命令写入，由于是系统操作，所以用户态占用并不是很高，system 的 CPU 占用率升高。
网络 IO 使用 iftop 工具进行实时流量监控。
# 安装 $ yum install iftop # 使用 $ iftop # 测试向服务器发送大文件下载请求  TX：发送流量 RX：接收流量 TOTAL：总流量 cum：运行 iftop 到目前时间的总流量 peak：流量峰值 rates：分别表示过去 2s、10s、40s 的平均流量  总结 当请求服务器时无响应，首先检查本地网络、服务器网络是否正常，其次检查服务是否部署成功并正常运行。
当请求服务器返回响应过慢时，除了检查网络问题外，还需要关注一下服务器性能问题，通过性能统计命令来初步排查原因：
1、查看 CPU 占用率是否过高；
2、查看内存空间是否充足；
3、检查硬盘读写是否过慢过多；
4、检查网络流量传输，是否存在大流量堆积，导致超时响应请求。
]]></content></entry><entry><title>Linux - 命令 Io重定向及管道符</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-io%E9%87%8D%E5%AE%9A%E5%90%91%E5%8F%8A%E7%AE%A1%E9%81%93%E7%AC%A6/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[输入输出重定向  标准输入（0） 标准输出（1） 错误输出（2）  程序接收用户标准输入，根据输入的指令执行程序，执行完成后进行标准输出，当程序异常时，会有错误输出。
输入重定向：把文件导入到命令中
输出重定向：把命令输出的信息导入到文件中
 标准输出重定向 错误输出重定向 清空写入模式 追加写入模式  # 将标准输出重定向到文件内 $ echo 111 &gt; log # 将标准输入重定向到指定文件 # 控制台就不会接收键盘指令了，直接从文件读取输入 $ read a &lt; log # 将内容标准输出 $ echo $a 111 # 错误输出；123 为不存在的目录 # 错误信息并没有重定向到文件内，而是在控制台输出了 $ ls 123 &gt; error ls: 123: No such file or directory # 默认为标准输出，不需要添加文件描述符 1 # 错误输出需要添加文件描述符 2 才可以重定向到文件 $ ls 123 2&gt; error $ cat error ls: 123: No such file or directory # 将错误输出与标准输出共同写入到文件 $ (echo 123; ls 456) &gt; error 2&gt;&amp;1 $ cat error 123 ls: 456: No such file or directory 以上都为清空写入模式，将输出重定向到一个新的文件，下面是追加写入模式的例子。
$ echo &#34;add test 1&#34; &gt;&gt; test $ echo &#34;add test 2&#34; &gt;&gt; test $ cat test add test 1 add test 2 管道 重定向的作用就是将命令与文件连接，Linux 还有一种功能将命令与命令连接，也就是把前一个命令的输出作为后一个命令的输入，以这种方式连接形成了 管道，管道符为 ｜。
# 将第一个命令的标准输出作为第二个命令的标准输入 # {} 代表代码块 $ echo world | { read line; echo hello $line!; } hello world! 管道执行的上下文控制
$ echo hello world | read x; echo $x $ echo $x 通过这个方式无法直接输出变量 x，因为通过管道符连接 echo hello world | read x; 两个命令后，后者是通过子进程的方式运行的，执行完后就销毁，所以是打印不到变量 x 的。
 通过代码块连接方式执行； 使用逻辑控制 while read 组合；  $ echo hello world | { read x; echo $x;} hello world $ echo hello world | while read x; do echo $x; done hello world Linux 三剑客演示
 通过 grep awk sed 演示管道的作用
  https://mp.weixin.qq.com/s/DUB7k7jw_wP-nwL7mxUe_w  
示例：获取到用户搜索的热词后，根据分数进行排序，查找到最热门的 3 个搜索词。
// 测试数据; filename =&gt; hotWords { &#34;hotWords&#34;: [ {&#34;gid&#34;: 0,&#34;score&#34;: 5562,&#34;word&#34;: &#34;现代都市&#34;,&#34;type&#34;: 1}, {&#34;gid&#34;: 0,&#34;score&#34;: 5401,&#34;word&#34;: &#34;玄幻奇幻&#34;,&#34;type&#34;: 1}, {&#34;gid&#34;: 0,&#34;score&#34;: 5025,&#34;word&#34;: &#34;宅小说&#34;,&#34;type&#34;: 1}, {&#34;gid&#34;: 0,&#34;score&#34;: 4091,&#34;word&#34;: &#34;历史军事&#34;,&#34;type&#34;: 1}, {&#34;gid&#34;: 0,&#34;score&#34;: 2666,&#34;word&#34;: &#34;科幻小说&#34;,&#34;type&#34;: 1} } 组合命令如下：
$ cat hotWords \ | grep -o &#39;gid[^}]*}&#39; \ | awk -F &#39;&#34;&#39; &#39;{print $4, $7}&#39; \ | awk &#39;BEGIN{RS=&#34;:&#34;; FS=&#34;,&#34;; OFS=&#34;:&#34;}{$1=$1; print $0}&#39; \ | sed &#39;s/ *//&#39; \ | grep -v &#39;^$&#39; \ | sort -t &#39;:&#39; -k2 -nr \ | head -n 3 5562: 现代都市 5401: 玄幻奇幻 5025: 宅小说  grep -o：过滤出数据行 awk -F：过滤出数据列 awk BEGIN：格式化数据 sed：去除首行空格 grep -v：获取除空行外的数据 sort：按照数字列进行排序，反序 head -n 3：取前三列数据  正则表达式 基础正则：
 ^ 开头 $ 结尾 [] 表示区间，[^}] 表示除大括号之外的数据，到大括号就停止查找 * 表示 0 个或多个 . 表示任意字符  扩展正则：
 ? 非贪婪匹配 + 一个或者多个 () 分组 {} 范围约束 | 匹配多个表达式中的任何一个，1|3  ]]></content></entry><entry><title>Linux - 三剑客命令练习</title><url>/tech/linux/%E4%B8%89%E5%89%91%E5%AE%A2%E5%91%BD%E4%BB%A4%E7%BB%83%E4%B9%A0/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[ 三剑客实战练习
 统计：查出日志中包含 404、500 的报错行数 # 关键字前后加空格会更佳精准过滤 $ cat tmp.log \ &gt; | grep -E &#39; 404 | 500 &#39; \ &gt; | wc -l 4 # ~ 与 !~ 代表是否匹配正则 $ awk &#39;$9~/404|500/&#39; tmp.log \ &gt; | wc -l 4 找出 500 错误行的上下文请求 # A=after B=before；上下各两行 $ cat tmp.log \ &gt; | grep -E &#39;500&#39; -B2 -A2 统计：找出访问量前三高的 IP 地址 # 请求方 IP 地址在第一列 $ awk &#39;{print $1}&#39; tmp.log \ &gt; | sort | uniq -c | sort -nr \ &gt; | head -3 统计：根据路径匹配获取请求数并排行 # tmp.log (简化日志) &#34;POST /demo/123?do=1 HTTP/2.0&#34; 200 367 &#34;-&#34; &#34;Android 10.0;&#34; 127.0.0.1:8000 &#34;POST /demo/456?do=2 HTTP/2.0&#34; 200 367 &#34;-&#34; &#34;Android 10.0;&#34; 127.0.0.1:8000 &#34;POST /demo/123/test/456?go=1 HTTP/2.0&#34; 200 367 &#34;-&#34; &#34;Android 10.0;&#34; 127.0.0.1:8000 $ grep -E &#39; /demo/[0-9]{1,}&#39; tmp1.log \ &gt; | awk &#39;{print $2}&#39; &gt; | sed -E &#39;s#/demo/[0-9]*[?].*#/demo/:int:#&#39; \ &gt; | sed -E &#39;s#/demo/[0-9]*/test/[0-9]*[?].*#/demo/:int:/test#&#39; \ &gt; | sort | uniq -c | sort -nr | head -2 2 /demo/:int: 1 /demo/:int:/test 查看当前开放的端口号和进程 $ netstat -ntpl | sed 1,2d | awk &#39;{print $1, $4, $7}&#39; tcp 127.0.0.1:199 1002/snmpd tcp 0.0.0.0:20755 26345/sshd 统计当前机器连接数 $ netstat -tnp \ | sed 1,2d \ | awk &#39;{print $5}&#39; \ | awk -F &#39;:&#39; &#39;{print $1}&#39; \ | sort | uniq -c | sort -nr 统计一个进程的 CPU 和内存信息 # 使用 PS 命令统计并不准，占用内存 / 进程运行总时间 # 所以运行时间越久，CPU 占用更小，无法统计当前的真实使用率占比 $ for i in {1..20}; \ &gt; do &gt; sleep 1; &gt; ps -o %cpu %mem -p {pid}; &gt; done # 使用 top 命令；更准确也更耗内存 # 统计 20 次，并在统计完成后打印出平均值 $ top -b -p {pid} -n 20 -d 1 \ &gt; | grep --line-buffered {pid} \  # 逐行显示 &gt; | awk &#39;BEGIN{print &#34;cpu mem&#34;}{print $9, $10; c+=$9; m+=$10}END{print &#34;--------&#34;; print c/NR, m/NR}&#39; # top 命令实时统计平均值; 并绘制图表 $ top -b -p {pid} -n 20 -d 1 \ &gt; | grep --line-buffered {pid} \ &gt; | awk &#39;BEGIN{OFS=&#34;\t&#34;; print &#34;cpu&#34;, &#34;mem&#34;, &#34;avgc&#34;, &#34;avgm&#34;}{c+=$9; m+=$10; print $9, $10, c/NR, m/NR}&#39; \ &gt; | gnuplot -e &#34;set term du; plot &#39;&lt;cat&#39; using 1 with lines&#34; # 直接在窗口展示 $ gnuplot -e &#34;set term du; plot &#39;&lt;cat&#39; using 1 with lines&#34; # 生成为图片 $ gnuplot -e &#34;set term png; plot &#39;&lt;cat&#39; using 1 with lines&#34; &gt;tmp/top.png ]]></content></entry><entry><title>Linux - 命令 文件编辑（Sort、Uniq、Wc、Awk、Sed、Grep）</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-%E6%96%87%E4%BB%B6%E7%BC%96%E8%BE%91sortuniqwcawksedgrep/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[ Linux 常用文本编辑命令
 sort 对文本内容进行排序。
常用参数：
 -b：忽略每行左侧的空白字符 -n：按数字大小排序 -V：按照数字版本排序 -h：根据存储容量排序（KB、MB、GB） -r：倒序 -t：指定排序后的分隔符，默认为空格 -k：按指定的列排序 -o：把结果保存到文件  $ sort testfile -n $ cat testfile | sort -o test.log uniq 检查和删除文件中重复的行或列，只检查相邻行，一般与 sort 配合使用。
常用参数：
 -c：统计重复次数 -f：跳过前 N 列 -s：跳过前 N 个字符 -w：仅对前 N 个字符进行比较  # 构造测试数据 $ cat testfile tom male 18 alex male 19 ali womale 15 jerry male 18 kd male 18 # 根据同岁人口的数量排行 $ cat testfile | sort -k 3 -n | uniq -c -f 2 | sort -nr 3 jerry male 18 1 ali womale 15 1 alex male 19 wc 字符统计。
常用参数：
 -c：统计字节数 -l：统计行数 -w：统计单词数  $ cat testfile hello world tester gogogo! \n \n # 行数、单词数、字符数（换行符、空格也算字符） $ cat testfile | wc 5 4 29 grep 基于正则表达式查找满足条件的行或者字符串。
内容检索：
 -o：根据正则仅提取内容 -A1：取匹配到内容的后一行 -B2：取匹配到内容的前两行  $ grep go testfile gogogo! $ grep &#34;[a-z]*er &#34; testfile tester lan $ grep -o &#34;[a-z]*er &#34; -A1 testfile tester gogogo! 文件检索：
 -r：递归查找目录 -h：仅展示匹配的内容，不展示匹配的文件名，默认是展示的（-H） -l：仅展示匹配的文件名，不展示匹配的内容  $ grep -r hello tmp tmp/testfile:hello world $ grep -r -h hello tmp hello world $ grep -r -l hello tmp tmp/testfile 范围约束：
 -i：忽略大小写 -v：不显示匹配的行 -E：使用扩展正则表达式 &ndash;include：文件/目录范围约束，仅在匹配的文件内查找内容  # 默认区分大小写 $ grep HELLO testfile # -i 忽略大小写 $ grep -i HELLO testfile hello world # -v 除匹配的行外都显示，空行也显示 $ grep -v -r hello testfile testfile:tester lan testfile:gogogo! testfile: testfile: # -E 写正则表达式可以不使用转义符 # ^$ 代表空行，所以这里输出了两个空行 $ grep -E &#34;^$&#34; testfile $ grep -r test tmp --include &#34;test*&#34; tmp/testfile:tester lan 通过 grep 过滤进程时，由于 grep 本身会开启新进程，所以通过 -v 参数过滤匹配行，才是真正想要的内容。
$ ps -ef | grep ssh 501 35036 1 0 301121 ?? 0:00.19 /usr/bin/ssh-agent -l 501 57090 49928 0 12:20上午 ttys000 0:00.00 grep ssh $ ps -ef | grep ssh | grep -v grep 501 35036 1 0 301121 ?? 0:00.19 /usr/bin/ssh-agent -l awk 根据定位到的数据处理其中的分段。
awk 具备完整的编程特性，比如执行命令，网络请求等。核心语法：
# 匹配表达式 + 行为表达式 $ awk &#39;pattern{action}&#39; 上下文变量
 开始 BEGIN 结束 END 行数 NR 字段与字段数 $1 $2 .. $N $NF 整行 $0 字段分隔符 FS，简写 -F 输出数据的字段分隔符 OFS 记录分隔符 RS 输出字段的行分隔符 ORS  # 通过逗号分隔取第一二列 $ echo &#39;1, 2, 3&#39; | awk -F , &#39;{print $1, $2}&#39; 1 2 字段变量用法
 -F：参数指定字段分隔符，可以用 ｜ 指定多个分隔符，例：-F '&lt;|&gt;' BEGIN{FS=&quot;_&quot;} 也可以表示分隔符 $0 表示当前的记录 $1 表示第一个字段 $N 表示第 N 个字段 $NF 表示最后一个字段 $(NF-1) 表示倒数第二个字段  pattern 表达式
 正则匹配  根据字段匹配：$1~/pattern/ 整行匹配简写：/pattern/   比较表达式  $2&gt;2 $1==&ldquo;b&rdquo;    # 获取第三行的内容 $ echo &#39;1 &gt; 2 &gt; 3&#39; | awk &#34;NR==3&#34; 3 # 正则匹配 3 # 默认 action 为 {print $0} # 下面的 awk 等价于 awk &#39;$1~/3/{print $0}&#39; $ echo &#39;1 &gt; 2 &gt; 3&#39; | awk &#39;$1~/3/&#39; 匹配表达式案例
# 开始和结束 $ awk &#39;BEGIN{}END{}&#39; # 正则：整行匹配 $ awk &#39;/test/&#39; # 正则：字段匹配 $ awk &#39;$2~/test/&#39; # 取第二行 $ awk &#39;NR==2&#39; # 去掉第一行 $ awk &#39;NR&gt;1&#39; # 区间选则，包含开始和结束行，中间以逗号隔开 $ awk &#39;/aa/, /bb/&#39; $ awk &#39;/1/, NR==2&#39; action 表达式
如果行为表达式前面没有 pattern 表达式，则代表对所有数据生效。
 打印：{print $2} 赋值：{$1=&ldquo;abc&rdquo;} 处理函数 原始内容：$0 更新后内容：{$1=$1;print $0}  # 单行转多行 $ echo 1:2:3 | awk &#39;BEGIN{RS=&#34;:&#34;}{print $0}&#39; 1 2 3 # 多行转单行 $ echo &#39;1 &gt; 2 &gt; 3&#39; | awk &#39;BEGIN{RS=&#34;&#34;;FS=&#34;\n&#34;;OFS=&#34;:&#34;}{$1=$1;print $0}&#39; 1:2:3 # 多行转多行方法二 $ echo &#39;1 &gt; 2 &gt; 3&#39; | awk &#39;BEGIN{RS=&#34;&#34;;FS=&#34;\n&#34;;OFS=&#34;:&#34;}{$1=$1;print $0}&#39; 1:2:3 # 求第二列平均数 $ echo &#39;1,10 &gt; 2,20 &gt; 3,30&#39; | awk &#39;BEGIN{total=0;FS=&#34;,&#34;}{total+=$2}END{print total/NR}&#39; 20 词典/array 结构
# 求第三列总数 $ echo &#39;a, 1, 10 &gt; a, 2, 20 &gt; b, 1, 30 &gt; b, 2, 40&#39; | awk &#39;{data[$1]+=$3} END{for(k in data) print k, data[k]}&#39; a, 30 b, 70 # 求第三列平均数 $ echo &#39;a, 1, 10 a, 2, 20 b, 1, 30 b, 2, 40&#39; | awk &#39;{data[$1]+=$3; count[$1]+=1} END{for(k in data) print k, data[k]/count[k]}&#39; a, 15 b, 35 sed 流式编译器，定位并修改数据。
基本语法：sed [addr]X[options]
常用参数：
 -e：根据表达式处理文本 -n：仅展示处理后的结果 -i：直接修改源文件 -E：扩展表达式 -debug：调试模式  pattern 表达式
 行数 20 行数范围 20,40 正则匹配 /pattern/ 区间匹配 //,//  $ sed -n &#39;1p&#39; testfile hello world $ sed -n &#39;2,3p&#39; testfile tester lan gogogo! $ sed -n &#39;/world/p&#39; testfile hello world action 表达式
 p 打印，结合 -n 参数使用 s 查找替换 d 删除 a 在内容匹配行之后追加 c 取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行 i 插入内容到匹配行之前 e 执行命令 分组匹配与字段提取  # 删除最后一行, $ 在这里不是正则，代表最后一行 $ sed &#39;$d&#39; testfile # 删除多行 $ sed &#39;1,3d&#39; testfile s 表达式
# 替换 $ echo &#39;good night&#39; | sed &#39;s/night/evening/&#39; good evening # / 可以用任意符号代替，只要三个符号是一致的就行 $ echo &#39;good night&#39; | sed &#39;s#night#evening!#&#39; good evening! # 默认只会替换第一个符合表达式的内容 $ echo &#39;good night&#39; | sed &#39;s#o#_#&#39; g_od night # 通过 g 参数替换全局 $ echo &#39;good night&#39; | sed &#39;s#o#_#g&#39; g__d night # 通过 &amp; 匹配内容，n 前面添加 123 $ echo &#39;good night&#39; | sed &#39;s/n/123&amp;/&#39; good 123night # n 后面添加 123 $ echo &#39;good night&#39; | sed &#39;s/n/&amp;123/&#39; good n123ight 反向引用
 使用 () 对数据进行分组 使用 \3 \2 \1 反向引用分组  # 将 123 倒序替换 $ echo 0 1 2 3 4 5 | sed -E &#39;s#([1-3]) ([1-3]) ([1-3])#\3 \2 \1#&#39; 0 3 2 1 4 5 ]]></content></entry><entry><title>Linux - 命令 Ssh</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-ssh/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[基础使用 # 登录服务器，输入密码，密码不可见 # 默认端口号为 22，可不写 $ ssh -p 22 username@host # e.g. $ ssh test@192.168.1.222 password: test # 切换到 root 用户 # 因为 docker 用 root 起的，如果是正式服务器需要将该用户添加到 docker 组，避免使用 root $ sudo su - root@test:~# 登录成功后，前缀：
 $ 代表普通用户 # 代表管理员用户  其他命令：
 sudo：以预设身份执行命令，默认为 root 用户 exit：退出系统  利用 ssh 传输文件
# 从服务器下载文件到本地 $ scp username@servername:/dir/filename /path $ scp -r username@servername:/dir/ /path # 上传本地文件到服务器 $ scp /path/filename username@servername:/path $ scp -r /path username@servername:dir/ # -r 代表递归整个目录 # 服务器目录要开启写入权限 ssh 工具 如果需要连接多个服务器，每次输入 ssh 命令稍显麻烦。
以下是两个小工具，可列表展示服务器信息，箭头上下选择服务器回车连接。
sshmenu  GitHub: sshmenu  
安装
# python 项目，直接 pip 安装 $ pip3 install sshmenu $ sshmenu 配置需要连接的服务器
# Mac $ vim ~/Library/Application\ Support/sshmenu/config.json # Linux $ vim ~/.config/sshmenu/config.json # 模板配置文件 { &#34;targets&#34;: [ { &#34;host&#34;: &#34;username@ip地址&#34;, &#34;friendly&#34;: &#34;我是备注信息&#34;, &#34;options&#34;: [] } ] } 通过创建软链来自定义命令（非必须）
# 默认命令为 sshmenu # 为了少输入三个字母 改为 sshm $ alias sshm=&#34;sshmenu&#34; # 如果自定义了配置文件路径，则需要通过 -c 指定 $ alias sshm=&#34;sshmenu -c /root/sshmenu.json&#34; 免密访问服务器
# 查看本机密钥 $ ls -a ~/.ssh # 如果没有的话就生成密钥对 $ ssh-keygen -t rsa # 传到服务器上； -i 代表指定公钥 $ ssh-copy-id {username}@{ip} $ ssh-copy-id -i ~/.ssh/username.pub {username}@{ip} sshgo 上面的 sshmenu 是 python 实现，因此依赖 python 环境，对于这种小工具本身来说有点笨重。
sshgo 是 sshmenu 的 golang 版本，仅一个可执行文件即可。项目地址： abeelan/sshgo  
这是一个自用简单版本。
# 查看帮助信息 $ sshgo version # 增加一个 ssh 连接配置 $ sshgo add # 删除一个 ssh 连接配置 $ sshgo del # 查看当前 ssh 连接列表 $ sshgo list # 展示服务器列表信息，箭头上下选择，回车连接 $ sshgo ]]></content></entry><entry><title>Mac - 安全模式</title><url>/tech/mac/%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html"><![CDATA[如何进入 在 Mac 上，选取苹果菜单 &gt; “关机”。
Mac 关机后，等待 10 秒，然后按下电源按钮。
Mac 启动后（部分 Mac 电脑会播放启动声音），立即按住 Shift 键。
当您看到灰色的 Apple 标志和进程指示器时，请松开 Shift 键。
会出现两次输入密码的页面
如何验证 选取苹果菜单 &gt; 关于本机 &gt; 系统报告 &gt; 选中 “软件” &gt; 查看启动模式为 “安全”，即为进入安全模式。
我的 mbp 18款，进入安全模式会有闪屏的情况～
如何退出 重新关机 开机，开机时不做任何操作。
]]></content></entry><entry><title>Mac - 系统升级至Mojave</title><url>/tech/mac/%E7%B3%BB%E7%BB%9F%E5%8D%87%E7%BA%A7%E8%87%B3mojave/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html"><![CDATA[本机为 10.13.6 系统，升级至 mojove（10.14.5）版本出现各种错误，此处记录升级过程。
升级记录 1、在 AppStore 下载 mojave 更新包，如果之前已经下载过更新包，需要在应用程序内删除该安装包，使用 cleanmymac 清理掉系统缓存。
2、如果下载安装包期间，科学上网挂掉，在国内网络继续下载安装包，最后安装会出现提示：
 “验证安装器数据时发生错误。下载项已损坏或不完整。 重新下载安装器并再试一次。”
 所以一定要保证网络稳定，解决办法就是删除该安装包重新下载。
3、按步骤进行安装，如果出现类似”互联网络错误“的提示，则
系统偏好设置 -&gt; 网络 -&gt; 高级 -&gt; 代理 -&gt; 取消勾选“自动代理配置”。
至此，我就安装成功了。 一直想体验下暗黑模式，断断续续更新了2个月了快，期间一直报错～ 不容易呀。
如果你还是不能更新成功的话，试试在安全模式下进行更新。
升级至 Mojave 后 SVN 不能正常使用 Mac OS 从 Sierra 升级到 Mojave 后 svn不能使用，提示：
解决办法
$ xcode-select --install 安装完成后，SVN 可正常使用
]]></content></entry><entry><title>Mac - 无法打开文件 因为找不到原身</title><url>/tech/mac/%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6-%E5%9B%A0%E4%B8%BA%E6%89%BE%E4%B8%8D%E5%88%B0%E5%8E%9F%E8%BA%AB/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">问题： Fiddler 侧边栏文件点击打开文稿和桌面，提示：无法打开文件，因为找不到原身
解决： 打开控制台，在根目录下输入 open ./
打开用户文件夹，将这个目录下的文稿和桌面文件重新拖到侧边栏，覆盖之前的，问题解决。
出现找不到原身的提示，就是快捷方式的链接失效？ 问题解决就好。</content></entry><entry><title>Mac - 修改用户名称导致丢失管理员权限</title><url>/tech/mac/%E4%BF%AE%E6%94%B9%E7%94%A8%E6%88%B7%E5%90%8D%E7%A7%B0%E5%AF%BC%E8%87%B4%E4%B8%A2%E5%A4%B1%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">「 使用Mac的同学千万不要修改用户名称，因为管理员权限会丢失 」
使用shell工作时，看着前缀有点不舒服，闲的蛋疼，于是在用户管理内修改了账户名称。
点击确定后，发现当前用户管理员权限变为了普通用户，心里那个谎呀，各种查资料查解决办法。
最后重新添加管理员后解决了这个问题，数据资料等全部都在，虚惊一场。
我的机型为 MBP 2018，记录下恢复过程。
关机重启，启动时长按 command+s，选择用户，输入密码后进入到一个类似shell的黑窗页面； 输入命令 /sbin/mount -uaw ，回车； 输入命令 rm var/db/.AppleSetupDone，回车； 输入命令 reboot，回车； 接下来像刚买来新电脑一样，重新设置用户信息，登录进入用户； 进入系统偏好设置-&amp;gt;用户与群组，解锁当前页面，选择之前的账户，勾选上允许用户管理这台电脑，此时之前的用户也变更为管理员用户。 退出重新登录之前的账户，发现所有信息都已经恢复，大功告成。 提示：恢复之后可以保留新创建的账户，也可以删除。（我自己就删除啦～）</content></entry><entry><title>Mac - 修改终端计算机名</title><url>/tech/mac/%E4%BF%AE%E6%94%B9%E7%BB%88%E7%AB%AF%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%90%8D/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">打开终端，在输入命令之前，会显示计算机名，如下：
Last login: Thu Apr 1 14:36:03 on ttys001 $ xxMacbookPro:~ abee$ 这个前缀过长或想展示为自己名字，如何自定义？
获取命令 # 计算机名 $ scutil --get ComputerName xxMacbookPro # host $ scutil --get HostName abee 修改命令 $ sudo scutil --set HostName xxx $ sudo scutil --set ComputerName xxx 修改命令没有实测，网上搜索到的，先备份在这里；
我是根据官方给的建议修改的，新增管理员，然后切换新管理员账号修改的当前用户名称。</content></entry><entry><title>Andorid - 命令行启动模拟器命令</title><url>/tech/andorid/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%90%AF%E5%8A%A8%E6%A8%A1%E6%8B%9F%E5%99%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"> https://developer.android.com/studio/run/emulator-commandline?hl=zh-cn
查看模拟器列表 $ emulator -list-avds 启动模拟器 方法一
$ emulator @device_name $ emulator @Pixel_3_API_28 方法二
$ emulator -avd device_name $ emulator -avd Pixel_3_API_28</content></entry><entry><title>Mac - 安装Adb</title><url>/tech/mac/%E5%AE%89%E8%A3%85adb/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html"><![CDATA[Homebrew安装 $ brew cask install android-platform-tools 等待安装完成，验证：
$ adb devices 手动安装 1、如果你以前安装过，请先删除老的文件
rm -rf ~/.android-sdk-macosx/ 2、下载 android-sdk-macosx，下载地址： developer.android.com  
3、将下载的文件解压并移动到 ~/.android-sdk-macosx
cd ~/Downloads(你的下载目录)/ unzip android-sdk*.zip mv android-sdk-macosx/ ~/.android-sdk-macosx 4、运行 SDK Manager
sh ~/.android-sdk-macosx/tools/android 5、根据你的需要选择，（我只需要Android SDK Platform-tools）［可选步骤］
6、选好后 Install
7、环境变量设置
echo &#39;export PATH=$PATH:~/.android-sdk-macosx/platform-tools/&#39; &gt;&gt; ~/.bash_profile 8、更新配置文件
source ~/.bash_profile 9、测试是否正常安装
adb devices ]]></content></entry><entry><title>Mac - 解决终端提示：You Have Mail</title><url>/tech/mac/%E8%A7%A3%E5%86%B3%E7%BB%88%E7%AB%AF%E6%8F%90%E7%A4%BAyou-have-mail/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">使用终端时，总会有一行提示信息：
You have mail. 从回答可以看出来，由于配置了crontab，会下发一些任务通知邮件，因为邮件是未阅读状态，所以每次进入终端都会有这个提示。
解决办法 找到问题后，解决办法也简单，就是将邮件变为已阅读或直接删除。
进入终端，输入 mail 命令； 前两行是帮助信息，以及消息状态汇总 中间部分是各消息的标题行 最后一行以问号开头，可供输入参数 删除所有的邮件，使用命令 **d *** 即可: &amp;gt; ? d * &amp;gt; ? t No applicable messages 验证，重新打开一个窗口，未显示新邮件提醒。 根据帮助信息将其他参数整理为表格：
消息信息展示如下，输入q退出，会显示剩余未读消息数。</content></entry><entry><title>Mac - Ssh报错：Connection—Refused</title><url>/tech/mac/ssh%E6%8A%A5%E9%94%99connectionrefused/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">$ ssh localhost ssh: connect to host localhost port 22: Connection refused 提示拒绝连接，一般出现这种情况有两种原因：
本机没有安装 ssh server； 本机 ssh server 服务没有开启。 Mac 系统自带 ssh server，默认不会开机自启动；尝试手动开启。
启动 sshd 服务 $ sudo launchctl load -w /System/Library/LaunchDaemons/ssh.plist 验证是否启动成功
$ sudo launchctl list | grep ssh - 0 com.openssh.sshd 停止 sshd 服务 $ sudo launchctl unload -w /System/Library/LaunchDaemons/ssh.plist 手动开启后，ssh 连接成功，问题解决。</content></entry><entry><title>Mac - 输入法卡顿</title><url>/tech/mac/%E8%BE%93%E5%85%A5%E6%B3%95%E5%8D%A1%E9%A1%BF/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html"><![CDATA[使用自带输入法， 出现卡顿现象，键盘输入与输入法文本显示框不同步，非常难受。
解决办法 菜单栏苹果 LOGO -&gt; 系统偏好设置 -&gt; 键盘 -&gt; 文本 -&gt; 关闭「触控栏键入建议」
另外，可能电脑长期未关机，重启下试试。
]]></content></entry><entry><title>Andorid - 华为手机取消安装密码</title><url>/tech/andorid/%E5%8D%8E%E4%B8%BA%E6%89%8B%E6%9C%BA%E5%8F%96%E6%B6%88%E5%AE%89%E8%A3%85%E5%AF%86%E7%A0%81/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">关闭纯净模式即可
设置 - 系统和更新 - 纯净模式</content></entry><entry><title>Python - Pycharm Java_Error_In_Pycahrm.Hprof文件可放心删除</title><url>/tech/python/pycharm-java_error_in_pycahrm.hprof%E6%96%87%E4%BB%B6%E5%8F%AF%E6%94%BE%E5%BF%83%E5%88%A0%E9%99%A4/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"> 今天整理电脑大文件时，发现了这个名为 java_error_in_pycharm.hprof 的日志文件。 这是软件遇到性能问题时自动保存的日志信息，方便开发者定位问题，删除掉并不会有什么影响。
Hi all. I saw that my file - java_error_in_phpstorm.hprof weighs more than 1.5Gb can I delete thim from disk C, or transfer it to another disk, like disk D? How is it important ? Hi there, Yes, you may delete that file. Such files are created automatically when IDE experience performance issues &amp;ndash; can be used by devs to investigate the reasons etc. - 原问题链接</content></entry><entry><title>Mac - 通过Pd安装Win10虚拟机</title><url>/tech/mac/%E9%80%9A%E8%BF%87pd%E5%AE%89%E8%A3%85win10%E8%99%9A%E6%8B%9F%E6%9C%BA/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html"><![CDATA[ Parallels Desktop 安装 win10 虚拟机
 安装过程 下载 Parallels Desktop  点击跳转下载页面  
下载 win10 操作系统  点击跳转下载页面  
安装系统 如果需要共享 mac 文件，选择生产力，下载 pdtools 即可实现共享文件夹。 遇到的问题 错误弹窗一  网络初始化失败 您的虚拟机将继续正常运作，但将无法连接网络。
 解决办法：完全退出 Parallels Desktop，打开访达，按快捷键 Command + Shift + G 调起前往文件夹，输入 /资源库/Preferences/Parallels ，点击前往。 打开 network.desktop.xml 文件，将 &lt;UseKextless&gt;-1&lt;/UseKextless&gt; 中的 -1 修改为 0，点击保存，输入电脑密码。
重启 Parallels Desktop，提示需要安装扩展，允许即可。需要在安全性与隐私里面信任下开发者。
该问题解决后，从头安装系统。 错误弹窗二 点击创建会遇到如下弹窗。 解决办法： 设置完毕后，点击下一步，创建成功。
Win10 安装过程 等待安装完毕后，自动重启，开始使用吧！
 参考资料： https://zhuanlan.zhihu.com/p/130783640   https://baijiahao.baidu.com/s?id=1730697027055407768   https://zhuanlan.zhihu.com/p/510963674  
 ]]></content></entry><entry><title>Andorid - Adb执行命令无权限</title><url>/tech/andorid/adb-%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E6%8F%90%E7%A4%BA%E6%97%A0%E6%9D%83%E9%99%90/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">使用 OPPO 手机执行 adb 命令，出现提示：
$ adb shell pm clear com.package.name 出现如下错误提示：
Error: java.lang.SecurityException: PID 24747 does not have permission android.permission.CLEAR_APP_USER_DATA to clear data of package com.package.name
原因是部分厂商默认禁掉了相关权限。
**解决办法：**开发者模式，开启「 禁止权限监控 」开关。</content></entry><entry><title>Python - Pytest Fixture</title><url>/tech/python/pytest-fixture/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[fixture 作用域  function 函数级，每个函数或方法都会调用 class 类级，每个测试类只运行一次 module 模块级 每个 .py 文件调用一次 package 包级 每个 python 包只调用一次 session 会话级 每次会话只需要运行一次，会话内所有方法及类，模块都共享这个方法  数据返回yield fixture 的方法可以前置的构造测试数据，数据的清理操作需要用到 yield。
通过在 fixture 函数中加入 yeild 关键字，yield 调用第一次返回的结果，第二步执行它下面的语句返回。
@pytest.fixture(scope=&#34;session&#34;) def token(): # setup print(&#34;setup over&#34;) token = &#34;I am token&#34; # 返回登录后的值 yield token # teardown print(&#34;teardown over&#34;) def test_yield(token): # 获取到该 fixture 的返回值, 也就是 token print(f&#34;test case token: {token}&#34;) &#34;&#34;&#34; setup over test case token: I am token teardown over &#34;&#34;&#34; 参数化 @pytest.fixture( params=[[&#34;tom&#34;, 123], [&#34;jerry&#34;, 456], [&#34;linda&#34;, 789]], ids=[&#34;tom&#34;, &#34;jerry&#34;, &#34;linda&#34;] ) def login(request): &#34;&#34;&#34;这个 request 是固定的，内置的 fixture&#34;&#34;&#34; print(&#34;login success ==&gt; &#34;, request.param) return request.param def test_login(login): print(login) &#34;&#34;&#34; login success ==&gt; [&#39;tom&#39;, 123] [&#39;tom&#39;, 123] login success ==&gt; [&#39;jerry&#39;, 456] [&#39;jerry&#39;, 456] login success ==&gt; [&#39;linda&#39;, 789] [&#39;linda&#39;, 789] &#34;&#34;&#34; 传参 pytestoy 拿登录场景举例。
执行自动化测试时，一般是随机从配置文件内拿账号进行登录。遇到需要指定用户登录的，就需要添加参数化装饰器。实现如下：
# conftest.py @pytest.fixture(scope=&#34;session&#34;) def user(request): try: username = request.param except AttributeError: username = &#34;random user&#34; return username &#34;&#34;&#34;使用默认用户登录&#34;&#34;&#34; def test_login(user): print(f&#34;获取用户信息：{user}&#34;) --&gt; 获取用户信息：random user &#34;&#34;&#34;使用指定用户登录&#34;&#34;&#34; @pytest.mark.parametrize(&#34;user&#34;, [&#34;lan&#34;], indirect=True) def test_login(user): print(f&#34;获取用户信息：{user}&#34;) --&gt; 获取用户信息：lan 更复杂一点，登录一般有好几个步骤，那么把登录封装函数封装为 fixture，传递一个用户名和密码进去，在用例里面直接进行登录。
@pytest.fixture def auto_login(user): print(f&#34;Fixture 内进行登录操作: {user}&#34;) return user &#34;&#34;&#34;未指定用户，选取随机用户&#34;&#34;&#34; def test_fixture(auto_login, user): print(f&#34;用例内登录的用户是: {auto_login}&#34;) --&gt; Fixture 内进行登录操作: random user --&gt; 用例内登录的用户是: random user &#34;&#34;&#34;已指定用户&#34;&#34;&#34; @pytest.mark.parametrize(&#34;user&#34;, [&#34;lan&#34;], indirect=True) def test_fixture(auto_login, user): print(f&#34;用例内登录的用户是: {auto_login}&#34;) --&gt; Fixture 内进行登录操作: lan --&gt; 用例内登录的用户是: lan ]]></content></entry><entry><title>Python - Pytest 根据Mark标签控制Autouse Fixture</title><url>/tech/python/pytest-%E6%A0%B9%E6%8D%AEmark%E6%A0%87%E7%AD%BE%E6%8E%A7%E5%88%B6autouse-fixture/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[@pytest.fixture(autouse=True) def auto_restart(app, request): &#34;&#34;&#34; 每条用例执行完成后自动重启应用，默认不清除应用数据 若需要清除数据，则在用例上添加装饰器 @pytest.mark.clear 即可 &#34;&#34;&#34; if &#39;clear&#39; in request.keywords: app.restart(clear=True) else: app.restart() 定义好以上的 autouse fixture 后
@pytest.mark.clear def test_demo(): &#34;&#34;&#34;用例加上该标签就会自动清空数据后重启&#34;&#34;&#34; pass def test_demo2(): &#34;&#34;&#34;如果不加该标签，则自动杀死应用重启，不清空数据&#34;&#34;&#34; pass &#34;&#34;&#34;如果该装饰器用在类上，则该类的所有用例都会清空数据后重启&#34;&#34;&#34; @pytest.mark.clear class TestDemo: def test_01(self): pass def test_02(self): pass ]]></content></entry><entry><title>Jenkins - Jenkins Pipline 发送邮件</title><url>/tech/jenkins/pipline-%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E9%85%8D%E7%BD%AE/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[配置普通邮件通知：系统管理 - 系统配置 配置普通邮件通知 stage(&#34;send mail test&#34;) { steps{ script { mail to: &#39;xxx@xx.com&#39;, cc: &#39;xxx@xx.com&#39;, // 抄送 	charset:&#39;UTF-8&#39;, // or GBK/GB18030 	mimeType:&#39;text/plain&#39;, // or text/html 	subject: &#34;Test_${env.JOB_NAME} - Build #${env.BUILD_NUMBER}&#34;, body: &#34;测试报告: ${env.BUILD_URL}/allure&#34; } } } 使用邮箱扩展插件 插件市场下载：Extended E-mail Notification
配置路径：系统管理 - 系统配置 - Extended E-mail Notification
配置必填项：
 SMTP server：邮件发送服务，可以去邮箱设置里面找或者问邮件服务管理员 SMTP port：一般 默认 25，需要跟邮件服务管理员确认 Credentials：添加一个 Jenkins 的全局密码项，里面输入邮箱账号和密码 Use SSL / TLS：这个跟邮件服务管理员确认 Default user e-mail suffix：邮箱后缀，格式为 @xxx.com Charset：默认就是 UTF-8 Default Content Type：邮件内容类型，选择 HTML，可以自定义格式  系统配置页面向上拉，有个 Jenkins Location，这里填写上管理员的邮件地址，跟发送邮件的邮箱地址保持一致。
在 pipeline 内定义邮件内容
post { always { emailext ( subject: &#34;【测试项目】 ${env.JOB_NAME} - Build #${env.BUILD_NUMBER} - By pipeline!&#34;, to: &#34;xxx@xxx.com&#34;, from: &#34;admin@xxx.com&#34;, body: &#39;&#39;&#39;&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&#34;UTF-8&#34;&gt; &lt;/head&gt; &lt;body leftmargin=&#34;8&#34; marginwidth=&#34;0&#34; topmargin=&#34;8&#34; marginheight=&#34;4&#34; offset=&#34;0&#34;&gt; &lt;table width=&#34;95%&#34; cellpadding=&#34;20&#34; cellspacing=&#34;0&#34; style=&#34;font-size: 1pt; font-family: Tahoma, Arial, Helvetica, sans-serif&#34;&gt; &lt;tr&gt; &lt;td&gt;&lt;br /&gt; &lt;b&gt;&lt;font color=&#34;#0B610B&#34;&gt;&lt;font size=&#34;6&#34;&gt;构建信息&lt;/font&gt;&lt;/font&gt;&lt;/b&gt; &lt;hr size=&#34;2&#34; width=&#34;100%&#34; align=&#34;center&#34; /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;ul&gt; &lt;div style=&#34;font-size:15px&#34;&gt; &lt;li&gt;构建项目：${PROJECT_NAME}&lt;/li&gt; &lt;li&gt;构建结果：&lt;span style=&#34;color:red&#34;&gt;${BUILD_STATUS} &lt;/span&gt;&lt;/li&gt; &lt;li&gt;构建编号：${BUILD_NUMBER}&lt;/li&gt; &lt;li&gt;触发用户：${CAUSE}&lt;/li&gt; &lt;li&gt;变更概要：${CHANGES}&lt;/li&gt; &lt;li&gt;构建地址：&lt;a href=${BUILD_URL}&gt;${BUILD_URL}&lt;/a&gt;&lt;/li&gt; &lt;li&gt;构建日志：&lt;a href=${BUILD_URL}console&gt;${BUILD_URL}console&lt;/a&gt;&lt;/li&gt; &lt;li&gt;报告地址：&lt;a href=${BUILD_URL}allure&gt;${BUILD_URL}allure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;变更集：${JELLY_SCRIPT}&lt;/li&gt; &lt;/div&gt; &lt;/ul&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/font&gt; &lt;/body&gt; &lt;/html&gt;&#39;&#39;&#39;, to: &#34;xxx@xx.com&#34;, from: &#34;xxx@xx.com&#34; ) } } ]]></content></entry><entry><title>Python - Requests 重定向</title><url>/tech/python/requests-%E9%87%8D%E5%AE%9A%E5%90%91/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ python requests &ndash;&gt; Redirection and History  
 默认情况下，请求将对除 HEAD 之外的所有动作执行位置重定向。使用 historyResponse 方法来跟踪重定向。
该 Response.history 列表包含 Response为完成请求而创建的对象。该列表按从最早到最近的响应排序。
例如，GitHub 将所有 HTTP 请求重定向到 HTTPS：
r = requests.get(&#39;http://github.com/&#39;) r.url &#39;https://github.com/&#39; r.status_code 200 r.history [&lt;Response [301]&gt;] 如果您使用 GET、OPTIONS、POST、PUT、PATCH 或 DELETE，您可以使用以下参数禁用重定向处理 allow_redirects：
r = requests.get(&#39;http://github.com/&#39;, allow_redirects=False) r.status_code 301 r.history [] 如果您使用的是 HEAD，您也可以启用重定向：
r = requests.head(&#39;http://github.com/&#39;, allow_redirects=True) r.url &#39;https://github.com/&#39; r.history [&lt;Response [301]&gt;] ]]></content></entry><entry><title>Python - Eval和Ast.Literal_Eval的区别</title><url>/tech/python/eval%E5%92%8Cast.literal_eval%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[eval 用来执行一个字符串表达式，并返回表达式的值。
input_ = eval(input(&#39;Provide some data here: &#39;)) # 如果输入下面的字符串且被执行，非常危险 __import__(&#39;os&#39;).system(&#39;rm -rf /a-path-you-really-care-about&#39;) ast.literal_eval 安全地评估表达式节点或包含 Python 文字或容器显示的字符串。提供的字符串或节点只能由以下 Python 文字结构组成：字符串、字节、数字、元组、列表、字典、集合、布尔值、无、字节和集合。
 ref:
  Using python&rsquo;s eval() vs. ast.literal_eval()    Eval really is dangerous     ]]></content></entry><entry><title>Jmeter&Ms - 接口签名实现及Json库缺失报错解决</title><url>/tech/jmeterms/ms-%E6%8E%A5%E5%8F%A3%E7%AD%BE%E5%90%8D%E5%AE%9E%E7%8E%B0%E5%8F%8Ajson%E5%BA%93%E7%BC%BA%E5%A4%B1%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html"><![CDATA[ 接口包含参数（post）：
 timestamp id sign  需要根据前两个参数，通过 md5 的方式得到 sign，再进行请求，才能得到正确的响应结果。
 接口调试 通过 metersphere 完成该接口请求。
 id：根据上一个接口的返回值进行后置提取，在场景内导入，就可以再当前接口引用该 id 变量。 timestamp：可以使用内置函数 ${__time} 获取到。 sign：通过增加前置脚本，获取 id 跟 timestamp 参数值，使用 md5 算法加密后，将值填充会请求体中。  前置脚本如下：
import org.apache.commons.codec.digest.DigestUtils; import org.json.JSONObject; import java.net.URLEncoder; log.info(&#34;========= 请求体前置处理 =========&#34;); // 获取请求体 type jsonObject String request = sampler.getArguments().getArgument(0).getValue(); JSONObject json = new JSONObject(request); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; 初始请求体: {}&#34;, json); // 获取键的值 String timestamp = json.getString(&#34;timestamp&#34;); String id = json.getString(&#34;id&#34;); // 根据参数计算签名 &amp;&amp; 更新 sign String sign_reg = &#34;id=&#34; + id + &#34;&amp;timestamp=&#34; + timestamp; String sign = DigestUtils.md5Hex(sign_reg).toUpperCase(); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; sign: {}&#34;, sign); json.put(&#34;sign&#34;, sign); // JSON 对象转换为字符串 &amp;&amp; 替换原始请求体 String modifiedRequest = json.toString(); sampler.getArguments().getArgument(0).setValue(modifiedRequest); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; 最终请求体: {}&#34;, modifiedRequest); log.info(&#34;========= 请求体前置处理 =========&#34;); 输出结果可在『响应结果 - 控制台』查看。
性能测试 将该接口场景转为性能测试：
 接口 A 获取 id，并提取； 接口 B 根据 id 及时间戳计算 sign 并请求得到结果。  点击场景用例的更多按钮，转为性能测试用例。
发现报错
 Typed variable declaration : Class: JSONObject not found in namespace
  在 MS 平台执行报错 将该 jmx 脚本导入到 jmeter 中，依然报相同的错误  解决办法
  下载 json.jar 包，导入 jmeter/lib 目录中，再次执行，成功。
  同理，在 MS 执行性能测试时，测试文件上传 json.jar 包，执行成功。
  下载地址
  jar-download  (待测试)  阿里云盘    最大并发数默认最多 50，可在：设置 - 测试资源池 - 节点设置 - 最大并发数，调整。
]]></content></entry><entry><title>Booknotes - 《操作系统概论》</title><url>/tech/booknotes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html">1、操作系统简介 操作系统的功能 管理计算机资源 内存管理 内存分配：静态分配（大小数量不再变化）；动态分配（大小数量动态变化） 内存保护：内核空间不会被用户随意访问，保证系统安全和稳定；确保用户程序在自己的内存空间运行，互不干扰 地址映射：逻辑地址与物理地址映射 内存扩充：从逻辑上扩充内存容量，使系统能够向用户提供比物理内存大的存储容量 进程管理 设备管理：完成用户的 I/O 请求，为用户分配 I/O 设备 文件管理： 提供用户接口 命令接口： 图形用户接口 程序接口</content></entry><entry><title>Golang - 协程与通道</title><url>/tech/golang/%E5%8D%8F%E7%A8%8B%E4%B8%8E%E9%80%9A%E9%81%93/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[gorountine go 中应用程序并发处理的部分称为 协程 goroutine
 协程间的同步通过 通道 chanel 协程比线程更轻量，协程退出后自动释放  存在两种并发方式：
 确定性的（明确定义排序） 非确定性的（加锁/互斥 从而未定义排序）  func main() { fmt.Println(&#34;In main&#34;) go longWait() go shortWait() fmt.Println(&#34;About to sleep in main()&#34;) // 主线程设置为 10 s，会同时执行两个等待函数，最终耗时 10s 多点 	for i := 1; i &lt; 11; i++ { time.Sleep(1 * time.Second) fmt.Printf(&#34;main: sleep %ds\n&#34;, i) } // 当主线程设置为等待 4 秒时，longWait 还没有到结束时间，主线程就结束，那么 longWait 就不会输出，随着主程序结束而消亡 	// 主程序不会等待非 main 协程的结束，因此 serve 服务中必须保证主函数运行状态，每个请求都启动协程去处理  fmt.Println(&#34;End of main()&#34;) } func shortWait() { fmt.Println(&#34;Beginning shortWait()&#34;) time.Sleep(2 * time.Second) // 2s 	fmt.Println(&#34;End of shortWait()&#34;) } func longWait() { fmt.Println(&#34;Beginning longWait()&#34;) time.Sleep(5 * time.Second) // 5s 	fmt.Println(&#34;End of longWait()&#34;) } channel  Go 有一种特殊的类型，通道（channel），就像一个可以用于发送类型化数据的管道，由其负责协程之间的通信，从而避开所有由共享内存导致的陷阱；这种通过通道进行通信的方式保证了同步性。数据在通道中进行传递：在任何给定时间，一个数据被设计为只有一个协程可以对其访问，所以不会发生数据竞争。 数据的所有权（可以读写数据的能力）也因此被传递。
 通道的声明方式 func main() { var ch1 chan int s := make(chan string) i1 := make(chan int) // 整数类型的通道 	i2 := make(chan chan int) // 通道 的元素类型是 chan int 	funcChan := make(chan func()) // 函数类型的通道 } 通信操作符的使用 // 向通道发送数据 var ch chan int ch &lt;- int1 // 用通道 ch 发送变量 int1  // 从通道中接收、获取数据 var int2 int int2 = &lt;- ch // 方式一 int2 已声明 直接用等号  int3 := &lt;- ch // 方式二 未声明，用 冒等  // 方式三 直接使用 不赋值给变量 if &lt;- ch != 100 { ... } 示例
package main import ( &#34;fmt&#34; &#34;time&#34; ) func main() { ch := make(chan string) go sendData(ch) // 通过通道发送了 5 个字符串 	go getData(ch) // 接收并打印，打印状态和通道实际读写时间延迟可能会导致顺序不同  time.Sleep(2 * time.Second) // 防止主线程直接结束 } func sendData(ch chan string) { ch &lt;- &#34;a&#34; ch &lt;- &#34;b&#34; ch &lt;- &#34;c&#34; ch &lt;- &#34;d&#34; ch &lt;- &#34;e&#34; } func getData(ch chan string) { var input string for { input = &lt;-ch fmt.Println(input) } } 通道阻塞 通道的发送/接收操作在对方准备好之前是阻塞的：
  对于同一个通道，发送操作（协程或者函数中的），在接收者准备好之前是阻塞的：
 如果 ch 中的数据无人接收，就无法再给通道传入其他数据：新的输入无法在通道非空的情况下传入 发送操作会等待 ch 再次变为可用状态：就是通道值被接收时（可以传入变量）    对于同一个通道，接收操作是阻塞的（协程或函数中的），直到发送者可用：如果通道中没有数据，接收者就阻塞了。
  package main import &#34;fmt&#34; func main() { ch := make(chan int) // 无限循环向通道发送值 	go pump(ch) // 由于无人接收，只有输出这一次获取值，所以只输出一个 0 	fmt.Println(&lt;-ch) // 如果加上该方法，无限读取通道的值 这一秒输出了 5w+  go suck(ch) time.Sleep(1 * time.Second) } func pump(ch chan int) { for i := 0; ; i++ { ch &lt;- i } } func suck(ch chan int) { for { fmt.Println(&lt;-ch) } } 死锁 package main import ( &#34;fmt&#34; ) func f1(in chan int) { fmt.Println(&lt;-in) } func main() { out := make(chan int) out &lt;- 2 // 发送之前没有接收者 死锁 	go f1(out) // 与上面交换顺序 先创建接收者 再发送数据 才正常运行 } 信号量模式 ]]></content></entry><entry><title>Golang - Gva实践</title><url>/tech/golang/gva%E5%AE%9E%E8%B7%B5/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[项目运行 # 下载项目源代码 $ git clone https://github.com/flipped-aurora/gin-vue-admin.git 后端  使用 goland 打开 /server 目录 编辑器内打开终端，运行初始化项目包命令：$ go mod tidy 找到 main.go 文件运行，出现喝可乐则代表运行成功  该目录下的 config.yaml 内配置数据库：
 如果配置数据库名称为空，则可以从前端进行初始化数据库； 如果数据库名不为空，则前端不可以初始化，代表之前已经初始化过有数据了。  前端  使用 vscode 打开 /web 目录 编辑器内打开终端，运行初始化项目包命令：$ npm i  运行项目：$ npm run serve，出现喝可乐则代表运行成功   需要安装 nodejs 环境 $ node -v v18.16.0 # cnpm 也可以 $ npm -v 9.5.1  进入页面，如果没有配置数据库，则进行数据库初始化。
简单修改 修改平台名称：core/config.js 内修改常量 config 中的值。
 appName appLogo  修改网站图标：替换 web 目录下的 favicon.ico 即可。
删除掉页面下方的团队信息和图标链接，前端项目中全局搜索，注释掉即可。
创建一个菜单  进入 web 代码项目，view 下新增一个页面 apitest.vue ，写入代码：  &lt;template&gt; &lt;div&gt; test &lt;/div&gt; &lt;/template&gt; 超级管理员 - 菜单管理 - 新增根菜单，根据页面设置后，填入上面 vue 文件的路径，点击保存。 超级管理员 - 角色管理 - 当前角色设置权限，勾选新增菜单的权限，刷新页面。  如果当前菜单想做为一个主菜单的话，路径就直接「点我设置」用默认的就行。
创建二级菜单 新增一个菜单，编辑，父节点选择一个根菜单就行。
 参考：
  官网地址    源码仓库    ]]></content></entry><entry><title>随笔 - 北戴河202307</title><url>/tech/%E9%9A%8F%E7%AC%94/%E5%8C%97%E6%88%B4%E6%B2%B3202307/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html">自从上次青岛回来后，小兰就一直吵着要去海边玩水。虽然给他报了个游泳班，但依然不抵他去海边的热情，总时不时的说一句：啥时候再去青岛呀~哈哈，小小年纪，也有一颗爱浪的心哇（冲浪的浪）…
本周末（0708-0709），老丈人也抽空，拉着全家，青春没有售价，高速直达秦皇岛。
我们俩到现在都还不会开车…这有点丢人吧，不过没关系，我还是更爱摩托车！🏍 启程 早上出发，高速三个小时，一路上看到的大部分都是京津车牌，夏天了，还得是玩水啊。
路上发生事故，有点堵车。发现高德地图有个很好的功能，发生事故后，点击查看事故，会自动添加到一个实时聊天室内，大家可以看到前面发生了什么事故，堵车程度，还可以拍照…这就太方便了，也不用干等着着急了。
有意思的是，警车来处理事故，结果警车也撞了，车多速度快不起来，没啥大事。最后又来个警车 + 拖车…高速行驶，安全第一。
北戴河下高速会有安检，把车开到规定的区域会有机器人进行拍照，然后放行，不知道是检查啥，但是看着好高级哇。
周六 入住的一家离海边稍近的民宿，免费停车，环境还不错。老板非常热心，介绍着周边景点。
简单收拾下东西，到了中午饭点。就近找了家海鲜餐馆，三菜一汤一份水饺 200+，价格还行，不算太坑，但是味道一言难尽。
午休完换上泳装，拿上沙滩玩具泳圈，步行 10 分钟到海边浴场。位置在老虎石附近，叫平水桥浴场，免费进入。
普通泳圈不让带进去，必须得是那种厚橡胶的，门口周边租了两个泳圈，一个 10 块。
带着孩子在水里找浪大的地方拍，他玩的非常开心，也喝了不少咸水。
一下午就在这里度过了，晚上下起了小雨，人明显少了很多。在周边点了一些海鲜烧烤，不出意外，味道不咋滴，下料太狠了。
周日 早起吃了超时买的桶装泡面+泡粉，真香。
开车去南戴河国际娱乐中心，门票是 120/人，抖音团购 199 两人。
玩的项目：
双层旋转木马 水上坐个小飞机转圈 大部分好玩的项目，孩子老人都玩不了。老两口带着孩子玩挖土、抓零食、摇摇车、人力过山车，额外买了个 88 的套票。
我跟媳妇去体验了两个刺激的项目：
跳楼机：失重感很强，刺激。 过山车，是那种车开到最上面然后速降的，来回转了两个圈，一般。 午餐园区内解决，吃完饭在儿童游玩区休息会儿。儿子是真不累，什么都想玩一遍。
又热又累，不想走路，就直接购买园内小火车票，10块/人，直接去滑沙项目区，这是丈母娘每次必点项目，哈哈。
我带儿子去海边泳池区域，今天没带泳装，他直接脱光了跳进池子，太尴尬了… 赶紧追上他去商店买了泳裤。</content></entry><entry><title>Blog - Typora 历史版本查看及恢复</title><url>/tech/blog/typora-%E5%8E%86%E5%8F%B2%E7%89%88%E6%9C%AC%E6%9F%A5%E7%9C%8B%E5%8F%8A%E6%81%A2%E5%A4%8D/</url><categories><category>Blog</category></categories><tags><tag>Blog</tag></tags><content type="html">Mac 打开文本文件 -&amp;gt; 顶部菜单栏：文件 -&amp;gt; 复原到… -&amp;gt; 浏览所有版本。
这时就会出现一个时间机器的界面，可以查看之前该文件的所有历史版本内容。</content></entry><entry><title>Jmeter&Ms - 使用方法汇总</title><url>/tech/jmeterms/ms-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html"><![CDATA[内置函数使用 请求参数栏或请求体转为 JSON-SCHEMA 后，参数值输入框中有个编辑按钮，点击后可以在函数页面进行使用，支持预览结果以及函数配合使用。
时间函数：
 时间戳(13位)：${__time}  时间格式化函数：
  当前时间：${__timeShift(,,,,)}
  当前时间增加一天： ${__timeShift(,,P1d,,)}
  当前时间减小一小时： ${__timeShift(,,PT-1H,,)}
  当前时间格式化展示：${__timeShift(yyyy-MM-dd HH:mm,,,,)} ==&gt; 2023-07-26 18:53
  当前时间仅显示年月：${__timeShift(yyyy-MM,,,,)}==&gt; 2023-08
  当前时间格式化加一分钟：${__timeShift(yyyy-MM-dd HH:mm,,PT1M,,)} ==&gt; 2023-07-26 18:54
  整型相加函数（intSum）：
 ${__intSum(${user_total},1)}，其中 ${user_total} 是从接口提取出来的值  随机字符串
 生成一个拼接的字符串：超级管理员${__RandomString(5,abcdefghijklmnopqrstuvwxyz,)}，得到超级管理员abcde随机五位字符  ms 内置函数：
 @cname：自动生成中文名字 @ctitle：自动生成中文标题  请求体中字符转义问题 当 json 带转义转为字符串后，通过 ms 请求，\\\n 会被转义为 \n，注意检查下请求内容中的格式，否则接口数据提交时后端再次 json parse 时可能出错。如上，ms 中写请求体的时候，json 字符串中应修改换行为 \\\\\n。
断言 正则  判断不为空：^.*(数字开头 /d，字符开头 /s) 日期：2023-04-23 17:00:16 -&gt; ^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$ 匹配四位及四位以上数字：\d{4,}  jsonpath  判断条件：$.data.list[?(@.type==&quot;公积金险种&quot;)].id  场景 条件控制器 变量引用格式为 ${salary} 后面跟判断条件。
循环控制器 - ForEach  pk 为自定义的变量，表示每次循环的值，类似于 for i in range(10) 中的 i pks 为从上一个接口中提取出的值（通过 jsonpath，匹配多个值），这里不需要 ${} ，也不需要在后面添加 _ALL 后缀，直接使用变量名即可。 可设置循环间隔时间  使用 csv 文件参数化 创建场景 - 场景变量 - 添加左侧下拉框选择 CSV - 点击添加
输入变量名，多个以 分隔符 分开。
添加文件，文件第一行为变量名，后续行为数据，点击确定。
在后续的接口中使用 ${var_name} 使用变量。
自定义脚本 场景特别长的时候，可以用作分割线，更清楚的表示接口集的作用。
使用方法如下：脚本名称可用作注释，但是注意里面需要忽略脚本状态（500），不然 500 报错影响场景结果。
]]></content></entry><entry><title>Bookmarks - 好用的在线工具</title><url>/tech/bookmarks/%E5%A5%BD%E7%94%A8%E7%9A%84%E5%9C%A8%E7%BA%BF%E5%B7%A5%E5%85%B7/</url><categories><category>Bookmarks</category></categories><tags><tag>Bookmarks</tag></tags><content type="html">以下是一些好用的在线工具。
画图工具
excalidraw ：界面优美，不需要登录，使用方便 ⭐️ handraw : 同上，是支持中文手写版本 processon ：流程图、思维导图等等，支持各种图 翻译工具
deepl ：中文翻译，准确度高，但是慢且收费 欧路词典，我用的 mac 客户端，相当于 deepl 的平替 Json
json.cn ：json 格式化检查，在线工具集（在线代码编译运行、单位换算、教程等等）</content></entry><entry><title>Booknotes - 《Go入门指南》</title><url>/tech/booknotes/go%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html"><![CDATA[书籍地址：https://github.com/unknwon/the-way-to-go_ZH_CN/blob/master/TOC.md
持续阅读中…
书中练习题 数组和切片 问题 7.3
给定 s := make([]byte, 5)，len(s) 和 cap(s) 分别是多少？s = s[2:4]，len(s) 和 cap(s) 又分别是多少？
 当执行 s = s[2:4] 后，len(s) 和 cap(s) 分别变为 2 切片操作 s[2:4] 创建了一个新的切片 s，从原始切片 s 的索引 2 开始（包含）到索引 4 结束（不包含），因此新切片的长度为 2 由于新切片是从原始切片的一部分创建的，所以其容量也是从原始切片的索引 2 开始（包含）到原始切片的末尾（索引 5）结束，即容量为 3  问题 7.4
假设 s1 := []byte{'p', 'o', 'e', 'm'} 且 s2 := s1[2:]，s2 的值是多少？如果我们执行 s2[1] = 't'，s1 和 s2 现在的值又分别是多少？
 s2 的值为 []byte{'e', 'm'}，它包含了从原始切片 s1 的索引 2 开始（包含）到末尾的所有元素 执行 s2[1] = 't'，则会修改 s2 切片的第二个元素（索引为 1），将其值改为字母 &lsquo;t’  s1 = []byte{'p', 'o', 'e', 't'} s2 = []byte{'e', 't'}   切片是引用类型，修改 s2 的元素会影响到底层数组，因此也会反映在 s1 上。  如何理解 new、make、slice、map、channel 的关系
1.slice、map 以及 channel 都是 golang 内建的一种引用类型，三者在内存中存在多个组成部分，需要对内存组成部分初始化后才能使用，而 make 就是对三者进行初始化的一种操作方式
2. new 获取的是存储指定变量内存地址的一个变量，对于变量内部结构并不会执行相应的初始化操作， 所以 slice、map、channel 需要 make 进行初始化并获取对应的内存地址，而非 new 简单的获取内存地址。
练习 7.5
给定切片 sl，将一个 []byte 数组追加到 sl 后面。写一个函数 Append(slice, data []byte) []byte，该函数在 sl 不能存储更多数据的时候自动扩容。
package main import &#34;fmt&#34; func main() { slice := []byte{1, 2, 3} data := []byte{4, 5, 6} slice = Append(slice, data) fmt.Println(slice) } func Append(slice, data []byte) []byte { // 计算新切片的长度 	newLen := len(slice) + len(data) // 如果容量不够 则进行倍增扩容 	if newLen &lt; cap(slice) { newCap := cap(slice) * 2 if newCap &lt; newLen { newCap = newLen } // 创建新切片 复制原始切片进来 	newSlice := make([]byte, newLen, newCap) copy(newSlice, slice) // 追加新数据至末尾 	newSlice = append(newSlice, data...) return newSlice } // 如果容量足够 则直接增加 	slice = append(slice, data...) return slice } 练习 7.6
把一个缓存 buf 分片成两个切片：第一个是前 n 个 bytes，后一个是剩余的，用一行代码实现。
slice1, slice2 := buf[:n], buf[n:] 问题 7.5
假设我们有如下数组：items := [...]int{10, 20, 30, 40, 50}
a) 如果我们写了如下的 for 循环，那么执行完 for 循环后的 items 的值是多少？如果你不确定的话可以测试一下:)
for _, item := range items { item *= 2 } // item 是取出的切片中的元素的副本 // 因此，在循环体内对 item 进行修改不会影响原始的数组 items // items 的值仍然是 [10, 20, 30, 40, 50] b) 如果 a) 无法正常工作，写一个 for 循环让值可以变成自身的两倍。
for i := range items { items[i] *= 2 } // 使用索引 i 来访问数组元素，并将其乘以 2 问题 7.6
通过使用省略号操作符 ... 来实现累加方法。
func sum(nums ...int) int { total := 0 for _, num := range nums { total += num } return total } func main() { result := Sum(1, 2, 3) // 结果为 6  result = Sum(10, 20, 30, 40) // 结果为 100  result = Sum(5) // 结果为 5  result = Sum() // 结果为 0，没有参数时返回初始值 } 练习 7.16
编写一个程序，使用冒泡排序的方法排序一个包含整数的切片。
package main import &#34;fmt&#34; func main() { sla := []int{2, 6, 4, -10, 8, 89, 12, 68, -45, 37} fmt.Println(&#34;before sort: &#34;, sla) BubbleSort(sla) // 引用传递 	fmt.Println(&#34;after sort: &#34;, sla) } func BubbleSort(slice []int) { // 确定总共需要排序的个数 	for pass := 1; pass &lt; len(slice); pass++ { // 每轮将最大数换到最后 	for i := 0; i &lt; len(slice)-pass; i++ { if slice[i] &gt; slice[i+1] { slice[i], slice[i+1] = slice[i+1], slice[i] } } } } 包 问题 9.1
a）一个包能分成多个源文件么？
一个包可以分成多个源文件。在 Go 中，一个包可以由多个以 .go 扩展名结尾的源文件组成。这种方式可以帮助将相关的代码组织在一起，提高代码的可维护性和可读性。这些源文件可以包含包级别的声明，如常量、变量、函数和结构体等，并共享同一个包名。
b）一个源文件是否能包含多个包？
一个源文件只能属于一个包。每个源文件的开头需要通过 package 声明来指定它所属的包。一个包通常对应一个目录，而每个目录下只能包含一个包。这是 Go 语言的约定，用于管理代码结构和避免命名冲突。因此，一个源文件只能包含一个包的定义。如果需要创建多个包，就需要分别放置在不同的源文件中。
]]></content></entry><entry><title>Golang - Go 学习资料汇总</title><url>/tech/golang/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[Go 语言学习资料与社区索引 鉴于之前有人做的 索引资料   已经过期超过 ~2~3 年，所以特开此坑。各位同学可以通过发起 Fork + Pull Request 的方式进行补充和更新。
最后更新时间：2022 年 01 月 10 日
更新地址：https://github.com/unknwon/go-study-index
交流社区 中文社区   Golang 中国  ：国内较早的 Go 社区，汇聚各类信息与服务  Study Golang  ：国内 Go 社区先驱，同样汇聚各类信息与服务  Revel 交流论坛  ： Revel   框架的中文社区  GoCN Forum  ：Go 语言爱好者中文交流论坛  IGO.PUB Go社区  ：Go语言技术社区（新），完美主义者社区  Go 技术论坛  : Golang / Go 语言中国知识社区 QQ 群：  Go Web 交流群：259316004 Golang 中国：211938256 Go 内部实现与标准库：192706294 Go 编程语言：102319854 Martini&amp;Macaron 交流群：371440803 Golang 新手群：369793160    英文社区   Go Forum  ：Go 语言爱好者英文交流论坛  golang-nuts 邮件列表  ：Go 语言官方指定邮件列表讨论区  知识图谱   Go Knowledge Graph  ：Go 知识图谱  网址导航  官方：   Go 中国站点  : Go 语言中国官方站点(无需翻墙)  Playground  ：Go 语言代码在线运行   国内镜像：   Go 指南国内镜像    Go 语言国内下载镜像    Go 官方网站国内镜像     Web 框架：   Macaron  ：模块化 Web 框架  Beego  ：重量级 Web 框架  Revel  ：较早成熟的重量级 Web 框架  Martini（停止维护）  : 一个强大为了编写模块化 Web 应用而生的 Go 语言框架  Echo  : 功能模块齐全, 上手容易, 文档示例齐全  Gin  ：轻量级 HTTP Web 框架  Iris  ：Iris 是基于 Go 编写的一个快速，简单但功能齐全且非常高效的 Web 框架   ORM 以及数据库驱动：   xorm  ：支持 MySQL、PostgreSQL、SQLite3 以及 MsSQL  mgo  ：MongoDB 官方推荐驱动  gorm  : 全功能 ORM (无限接近) 支持 MySQL、PostgreSQL、SQLite3 以及 MsSQL  gosql  : gosql 一款全新ORM go-style风格、轻量、简单、强大 支持 MySQL   辅助站点：   Go Walker  ：Go 语言在线 API 文档  gobuild.io  ：Go 语言在线二进制编译与下载  Rego  ：Go 语言正则在线测试  gopm.io  ：科学下载第三方包  Json To Go struct  :Convert JSON to Go struct在线工具   开发工具：   Emacs24  ： 配置脚本   / (中文社区)    LiteIDE    Sublime Text 2/3  ： 配置教程    GoLand    Atom  ： 配置插件  （感觉还不错，类似 Sublime，配置比较简单）  VIM  ： 配置插件  （嫌 vim 配置麻烦的童鞋可以直接用这个）   学习站点：   Go by Example    Go database/sql tutorial     支持 Go 的云平台：   Koding    Nitrous.IO    Get up and running with Go on Google Cloud Platform    AWS SDK for Go - Developer Preview  :=&gt; github    azure sdk for go  :=&gt; github     How to Use CoreOS on Azure    Create Azure Web app with GoLang extension      Qiniu     Qiniu SDK for Go  :=&gt; github       其它站点：   Golang 杂志  ： 订阅说明    Reddit    Newspaper.IO  ：Golang 新闻订阅  Go Newsletter  ：Golang 新闻订阅    资料汇总 中文资料  书籍：   《深入解析Go》    《Go实战开发》    《Go入门指南》    《Go语言标准库》    《Go Web 编程》    《Go语言博客实践》    《Go语言学习笔记》    《Go语言高级编程》    《实效Go编程》     翻译：   Effective Go   英文版  The Way to Go   中文版  《Learning Go》  英文版:=&gt; 《Learning Go》   中文版   教程：   《Go编程基础》    《Go Web基础》    《Go名库讲解》    Go 命令教程    Gin中文文档    Gorm中文文档      英文资料  文档：   Go Code Review Comments  ：Go 语言代码风格指导  Go Code Convention  ：无闻的 Go 语言编码规范  Uber Go Guide  : Uber Go 语言编码规范  GopherCon 2014    GopherCon 2015    GopherCon 2016    GopherCon 2017     书籍：   Network programming with Go  ： 中文版    Practical Cryptography With Go    An Introduction to Programming in Go    Go Bootcamp    Mastering Concurrency in Go(July 2014)Nathan Kozyra    Go Programming Blueprints(January 23,2015)    The Go Programming Language(Published Oct 30, 2015,Not Yet Published)    Practical Go: Real world advice for writing maintainable Go programs      视频资料   基础：
 Go Slices and Bytes - Shakeel Mahate： 优酷视频   - Youtube      COSCUP 2013:
 Golang &amp; ORM - 林佑安： 优酷视频   - Youtube      GopherCon：
 2014： Youtube   2015： Youtube   2016： Youtube   2017： Youtube   2018： Youtube   2019： Youtube      Golang UK Conference：
 2015： Youtube   2016： Youtube   2017： Youtube   2018： Youtube   2019： Youtube      GopherCon India 2015: Youtube  
  职业信息  Go/Golang jobs：  官方网站：http://www.golangprojects.com/ Twitter: @golangprojects      ]]></content></entry><entry><title>Docker - Docker使用代理</title><url>/tech/docker/docker-%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[创建或编辑 Docker 服务的配置文件
$ vim /etc/systemd/system/docker.service.d/http-proxy.conf 在文件中添加以下内容来指定代理设置
[Service] Environment=&#34;HTTP_PROXY=http://192.168.101.30:1082/&#34; Environment=&#34;HTTPS_PROXY=http://192.168.101.30:1082/&#34; Environment=&#34;NO_PROXY=localhost,127.0.0.1,docker-registry.example.com,.corp&#34; # :wq  这里假设你的代理地址是 192.168.101.30:1082，根据你的实际情况进行替换。
重新加载 systemd 配置
$ sudo systemctl daemon-reload 重启 Docker 服务
$ sudo systemctl restart docker ]]></content></entry><entry><title>Nodejs - 命令使用</title><url>/tech/nodejs/%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/</url><categories><category>Nodejs</category></categories><tags><tag>Nodejs</tag></tags><content type="html"><![CDATA[要在Mac上删除本地node版本及环境，可以采取以下步骤：
 确认您已安装nvm（Node Version Manager）。如果您没有安装，请打开终端并运行以下命令来安装nvm：  复制代码curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | bash  在终端中运行以下命令以查看当前已安装的node版本：  复制代码nvm ls  选择要删除的node版本，并使用以下命令卸载它：  复制代码nvm uninstall &lt;version&gt;  重复步骤3，直到您删除了所有不需要的node版本。 最后，您可以通过以下命令检查是否还有任何node版本存在于系统中：  复制代码which node 如果你看到输出，则可能是其他应用程序所依赖的node版本。如果您确信您已经删除了所有不需要的版本，则可以手动删除这些文件或者忽略它们。
 如果您还需要删除全局的npm模块，请运行以下命令：  复制代码npm list -g --depth=0 | awk -F/ &#39;/node_modules/ &amp;&amp; !/\/npm$/ {print $NF}&#39; | xargs npm -g rm 这将列出全局node_modules目录中安装的所有模块，并删除它们。
 最后，在终端中运行以下命令以确定已成功删除所有node.js版本和相关环境：  复制代码nvm ls 这将输出已安装的node.js版本列表。如果您看不到任何输出，则没有任何node.js版本存在于系统中。
注意：在执行此操作之前，请确保您了解自己在做什么，并且备份重要数据以避免意外删除。
]]></content></entry><entry><title>Golang - 测试平台搭建</title><url>/tech/golang/%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[数据库 # 扬帆测试平台部署 $ docker run -d -host --name yangfan-mysql \ 	-p 13306:3306 \ 	-v $volume/yangfan/mysql:/var/lib/mysql \ 	-e MYSQL_ROOT_HOST=% \ 	-e MYSQL_ROOT_PASSWORD=12345 \ 	mysql:8.0 # --character-set-server=utf8mb4 报错 # --collation-server=utf8mb4_unicode_ci  # 1.拷贝SQL文件到mysql容器中 $ docker cp docs/sql/yangfan.sql yangfan-mysql:/yangfan.sql Successfully copied 270.8kB to mysql:/yangfan.sql # 2. 创建数据库 $ docker exec -it yangfan-mysql bash $ mysql -u root -p 12345 mysql&gt; create database yangfan; mysql&gt; use yangfan; # 3.登陆控制台执行source 命令 mysql&gt; source yangfan.sql # 修改配置文件 # server mysql $ vim config.yaml # vite base path 本机 ip $ vim web/.env.production $ vim web/.env.development # 修改 nginx 端口 $ vim web/.docker-compose/nginx/conf.d/my.conf # 修改冲突端口 $ vim deploy/docker-compose/docker-compose.yaml # redis $ docker run -d --name redis \ 	-p 6379:6379 \ 	-v $volume/yangfan/redis_data:/data \ 	redis:latest \ 	redis-server --appendonly yes --requirepass 123456 部署后端 使用 goland 打开项目，执行命令
go mod tidy 将配置文件 config.yaml 放到 server 目录下，并修改
# config.yaml # 阿里云 OSS 没有可忽略 aliyun-oss: endpoint: yourEndpoint access-key-id: yourAccessKeyId access-key-secret: yourAccessKeySecret bucket-name: yourBucketName bucket-url: yourBucketUrl base-path: yourBasePath autocode: transfer-restart: true root: C:\gva\taylor-test-platform-server\taylor-test-platform server: /server server-api: /api/v1/%s server-plug: /plugin/%s server-initialize: /initialize server-model: /model/%s server-request: /model/%s/request/ server-router: /router/%s server-service: /service/%s web: /web/src web-api: /api web-form: /view web-table: /view aws-s3: bucket: xxxxx-10005608 region: ap-shanghai endpoint: &#34;&#34; s3-force-path-style: false disable-ssl: false secret-id: xxxxxxxx secret-key: xxxxxxxx base-url: https://gin.vue.admin path-prefix: github.com/flipped-aurora/gin-vue-admin/server captcha: key-long: 1 img-width: 240 img-height: 80 cors: mode: whitelist whitelist: - allow-origin: example1.com allow-methods: GET, POST allow-headers: content-type expose-headers: Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-Headers, Content-Type allow-credentials: true - allow-origin: example2.com allow-methods: GET, POST allow-headers: content-type expose-headers: Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-Headers, Content-Type allow-credentials: true db-list: - disable: false type: &#34;&#34; alias-name: &#34;&#34; path: &#34;&#34; port: &#34;&#34; config: &#34;&#34; db-name: &#34;&#34; username: &#34;&#34; password: &#34;&#34; max-idle-conns: 10 max-open-conns: 100 log-mode: &#34;&#34; log-zap: false email: to: xxx@qq.com port: 465 from: xxx@163.com host: smtp.163.com is-ssl: true secret: xxx nickname: test excel: dir: ./resource/excel/ # 飞书登录配置项 fs: appID: appSecret: redirectUri: http://127.0.0.1:8080/api/fsLogin/login authorityID: 666 projectID: 1 # 华为 OBS 没有可忽略 hua-wei-obs: path: you-path bucket: you-bucket endpoint: you-endpoint access-key: you-access-key secret-key: you-secret-key # JWT 认证 jwt: signing-key: 6c8c168a-d00b-4929-a4cd-75ede0ad8cce expires-time: 604800 buffer-time: 86400 issuer: lan # 文件上传目录配置 local: path: uploads/file store-path: uploads/file # 数据库配置 mysql: path: 127.0.0.1 port: &#34;3306&#34; config: charset=utf8mb4&amp;parseTime=True&amp;loc=Local db-name: yangfan username: root password: root max-idle-conns: 10 max-open-conns: 100 log-mode: debug log-zap: false redis: db: 0 addr: 127.0.0.1:6378 password: &#34;123456&#34; pgsql: path: &#34;&#34; port: &#34;&#34; config: &#34;&#34; db-name: &#34;&#34; username: &#34;&#34; password: &#34;&#34; max-idle-conns: 10 max-open-conns: 100 log-mode: &#34;&#34; log-zap: false qiniu: zone: ZoneHuaDong bucket: &#34;&#34; img-path: &#34;&#34; use-https: false access-key: &#34;&#34; secret-key: &#34;&#34; use-cdn-domains: false system: env: public addr: 8888 db-type: mysql oss-type: local use-multipoint: false use-redis: false iplimit-count: 15000 iplimit-time: 3600 tencent-cos: bucket: xxxxx-10005608 region: ap-shanghai secret-id: xxxxxxxx secret-key: xxxxxxxx base-url: https://gin.vue.admin path-prefix: github.com/flipped-aurora/gin-vue-admin/server timer: start: true spec: &#39;@daily&#39; with_seconds: false detail: - tableName: sys_operation_records compareField: created_at interval: 2160h - tableName: jwt_blacklists compareField: created_at interval: 168h zap: level: debug prefix: &#39;[yangfan]&#39; format: console director: log encode-level: LowercaseColorLevelEncoder stacktrace-key: stacktrace max-age: 30 show-line: true log-in-console: true # 平台其他服务配置 yang-fan: background: &#34;127.0.0.1&#34; background-grpc-port: 7967 master: &#34;127.0.0.1&#34; master-boomer-prot: 9093 master-server-prot: 7966 prometheus-pushgateway-url: http://localhost:9091/ grafana-host: http://localhost:3000/ grafana-dashboard: ERv3OaBPYe6A grafana-dashboard-name: yangfan-for-distributed-load-testing grafana-dashboard-stats: WLVhzvOg56Mg grafana-dashboard-stats-name: yangfan-for-node-status run-server: localhost run-server-grpc-port: 7968 然后运行 main.go 文件。
部署前端 使用 vscode 打开项目的 web 目录
$ brew install node@18 $ npm i # 出现了报错 npm ERR! code ERESOLVE npm ERR! ERESOLVE unable to resolve dependency tree npm ERR! npm ERR! While resolving: gin-vue-admin@1.0.0 npm ERR! Found: eslint@6.8.0 npm ERR! node_modules/eslint npm ERR! dev eslint@&#34;^6.7.2&#34; from the root project npm ERR! npm ERR! Could not resolve dependency: npm ERR! peer eslint@&#34;&gt;=7.5.0&#34; from @vue/cli-plugin-eslint@5.0.8 npm ERR! node_modules/@vue/cli-plugin-eslint npm ERR! dev @vue/cli-plugin-eslint@&#34;^5.0.7&#34; from the root project # 通过提示的参数先忽略依赖冲突 $ npm i --force or --legacy-peer-deps 启动服务
$ npm run serve &gt; gin-vue-admin@1.0.0 serve &gt; vite --host --mode development &gt; 欢迎使用 yangfan &gt; 当前版本:v1.2.0 &gt; 加群方式:微信号：test-instructor QQ群：873175584 &gt; 默认自动化文档地址:http://127.0.0.1:8888/swagger/index.html &gt; 默认前端文件运行地址:http://127.0.0.1:8080 vite v2.9.16 dev server running at: &gt; Local: http://localhost:8080/ &gt; Network: http://192.168.101.31:8080/ 使用 docker 部署 拉项目
修改配置文件
$ cd angfan/deploy/yangfan/ $ vim config/docker.config.yaml # 里面修改数据库的配置 # grafana-url 要改成 grafana-host $ vim docker-compose.yaml # 修改端口号，防止冲突 $ docker-compose up --force-recreate -d ]]></content></entry><entry><title>Golang - Gorm 介绍及使用</title><url>/tech/golang/gorm-%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[ 中文文档：https://learnku.com/docs/gorm/v2/index/9728
 简介 orm
 是一种数据库操作辅助工具 在 go 的结构体和数据库之间产生映射，可以对数据的关系、表的内容，直观得体现在结构体上 使用结构体即可完成增删改查操作  orm 如何连接数据库？
 导入 gorm 导入 mysql 驱动器 使用 open 连接 得到 数据库操作对象（以 mysql 为例）  使用 数据库配置 使用 docker 启动 mysql 服务，创建数据库 db_gorm
连接 创建表 package main import ( &#34;gorm.io/driver/mysql&#34; &#34;gorm.io/gorm&#34; ) type UserModel struct { gorm.Model // 自动复用 base 模型 	Name string Sex bool Age int } func (user UserModel) TableName() string { // 自定义表名 	return &#34;tb_users&#34; } func main() { // 参考 https://github.com/go-sql-driver/mysql#dsn-data-source-name 获取详情 	dsn := &#34;root:root@tcp(127.0.0.1:3306)/db_gorm?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&#34; db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{}) if err != nil { panic(err) } // 数据库有该表则跳过，没有则默认创建 	db.AutoMigrate(&amp;UserModel{}) } 添加数据 db.Create(&amp;UserModel{ Name: &#34;张三&#34;, Sex: true, Age: 19, }) 查询数据 查询第一条数据
// 查询第一条数据 var user UserModel db.First(&amp;user) fmt.Println(user) // 增加查询条件 var user UserModel db.First(&amp;user, &#34;name = &#39;李四&#39;&#34;) fmt.Println(user) {{2 2023-06-13 18:36:57.157 +0800 CST 2023-06-13 18:36:57.157 +0800 CST {0001-01-01 00:00:00 +0000 UTC false}} 李四 true 20} 查询多条数据
var user []UserModel db.Find(&amp;user) fmt.Println(user) [ {{1 2023-06-13 18:36:55.413 +0800 CST 2023-06-13 18:36:55.413 +0800 CST {0001-01-01 00:00:00 +0000 UTC false}} 张三 true 19} {{2 2023-06-13 18:36:57.157 +0800 CST 2023-06-13 18:36:57.157 +0800 CST {01-01-01 00:00:00 +0000 UTC false}} 李四 true 20} ] // 增加查询条件 var user []UserModel db.Find(&amp;user, &#34;age &lt; ?&#34;, 20) // 写法一 db.Where(&#34;age &lt; ?&#34;, 20).Find(&amp;user) // 写法二 常用 fmt.Println(user) [{{1 2023-06-13 18:36:55.413 +0800 CST 2023-06-13 18:36:55.413 +0800 CST {0001-01-01 00:00:00 +0000 UTC false}} 张三 true 19}] 更改数据 var user []UserModel // 更改单列数据 db.Where(&#34;id = ?&#34;, 1).Find(&amp;UserModel{}).Update(&#34;age&#34;, 30) // 更改多列数据 db.Where(&#34;id = ?&#34;, 1).Find(&amp;UserModel{}).Updates(UserModel{ // 这里没有包含 sex 则不会被修改  Name: &#34;王五&#34;, Age: 31, }) // 更改多行多列数据 db.Where(&#34;id in (?)&#34;, []int{1, 2}).Find(&amp;[]UserModel{}).Updates(UserModel{ Name: &#34;王五&#34;, Age: 31, }) 删除数据 var user []UserModel // 软删除 数据依然存在，只是更新了 delete_at 字段 db.Where(&#34;id in (?)&#34;, []int{1, 2}).Delete(&amp;UserModel{}) // 硬删除 物理删除 db.Where(&#34;id in (?)&#34;, []int{1, 2}).Unscoped().Delete(&amp;UserModel{}) ]]></content></entry><entry><title>Golang - Gin Restful请求方式</title><url>/tech/golang/gin-restful%E8%AF%B7%E6%B1%82%E6%96%B9%E5%BC%8F/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[四大请求方式 package main import ( &#34;encoding/json&#34; &#34;fmt&#34; &#34;github.com/gin-gonic/gin&#34; ) /* 实现文章接口的增删改查 */ type ArticleModel struct { Title string `json:&#34;title&#34;` Content string `json:&#34;content&#34;` } type ResponseModel struct { Code int `json:&#34;code&#34;` Data any `json:&#34;data&#34;` Msg string `json:&#34;msg&#34;` } func getList(ctx *gin.Context) { // 需要搜索、分页 	articles := []ArticleModel{ {&#34;文章一&#34;, &#34;go 语言入门&#34;}, {&#34;文章二&#34;, &#34;python 语言入门&#34;}, {&#34;文章三&#34;, &#34;javascript 语言入门&#34;}, } ctx.JSON(200, ResponseModel{0, articles, &#34;获取文章列表成功&#34;}) } func getDetail(ctx *gin.Context) { fmt.Println(ctx.Param(&#34;id&#34;)) article := ArticleModel{&#34;文章一&#34;, &#34;go 语言入门&#34;} ctx.JSON(200, ResponseModel{0, article, &#34;查看文章详情成功&#34;}) } func create(ctx *gin.Context) { // 接收前端传递的 json 数据 	var article ArticleModel err := parserJson(ctx, &amp;article) if err != nil { fmt.Println(err.Error()) return } ctx.JSON(200, ResponseModel{0, article, &#34;文章创建成功&#34;}) } func update(ctx *gin.Context) { fmt.Println(ctx.Param(&#34;id&#34;)) var article ArticleModel err := parserJson(ctx, &amp;article) if err != nil { fmt.Println(err.Error()) return } ctx.JSON(200, ResponseModel{0, article, &#34;文章修改成功&#34;}) } func delete(ctx *gin.Context) { fmt.Println(ctx.Param(&#34;id&#34;)) ctx.JSON(200, ResponseModel{0, map[string]string{}, &#34;删除文章成功&#34;}) } func main() { router := gin.Default() router.GET(&#34;/articles&#34;, getList) // 文章列表 	router.GET(&#34;/articles/:id&#34;, getDetail) // 文章详情 	router.POST(&#34;/articles/&#34;, create) // 创建文章 	router.PUT(&#34;/articles/:id&#34;, update) // 编辑文章 	router.DELETE(&#34;/articles/:id&#34;, delete) // 删除文章  router.Run(&#34;:80&#34;) } func parserJson(ctx *gin.Context, obj any) (err error) { // 根据不同的数据类型 解析数据 	body, _ := ctx.GetRawData() contentType := ctx.GetHeader(&#34;Content-Type&#34;) switch contentType { case &#34;application/json&#34;: err := json.Unmarshal(body, &amp;obj) if err != nil { fmt.Println(err.Error()) return err } fmt.Println(obj) } return nil } 请求头相关 请求头参数获取 // 请求头的各种方式 router.GET(&#34;/&#34;, func(context *gin.Context) { // 请求头： 首字母大小写不区分，单词与单词之间用 - 连接  // 获取单独一个请求头，首字母不区分大小写  fmt.Println(context.GetHeader(&#34;User-Agent&#34;)) // 获取全部请求头，是一个普通的 map[string]string  fmt.Println(context.Request.Header) // 那么获取单个请求头的其他写法，首字母不区分大小写  fmt.Println(context.Request.Header.Get(&#34;Content-Type&#34;)) // 如果使用 map 的取值方式，那么需要注意大小写问题  fmt.Println(context.Request.Header[&#34;Content-Type&#34;]) context.JSON(200, gin.H{&#34;msg&#34;: &#34;成功&#34;}) }) 响应头参数获取 // 设置响应头 router.GET(&#34;/header&#34;, func(c *gin.Context) { c.Header(&#34;Token&#34;, &#34;test&#34;) c.JSON(0, gin.H{&#34;data&#34;: &#34;设置相应头&#34;}) }) ]]></content></entry><entry><title>Httprunner - 命令行使用</title><url>/tech/httprunner/%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BD%BF%E7%94%A8/</url><categories><category>Httprunner</category></categories><tags><tag>Httprunner</tag></tags><content type="html">curl 文件转 yaml 文件
$ hrp convert har/demo.curl --from-curl --to-yaml 在 debugtalk 里面定义了公共 headers，如何在 yml 用例文件内引用？</content></entry><entry><title>Chrome - 网络请求右键失效问题</title><url>/tech/chrome/%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%8F%B3%E9%94%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/</url><categories><category>Chrome</category></categories><tags><tag>Chrome</tag></tags><content type="html">桌面应用测试中，通过配置谷歌开发者工具，可以在测试过程中很方便的看到抓包请求及控制台信息。
再通过配置命令行软链，实现短命令启动的效果。
$ alias duban=&amp;#34;open /Applications/嘟伴.app --args --enable-work-devTools --enable-app-devTools&amp;#34; 今天在使用过程中，发现右键请求，不能弹出菜单，点击无效的现象。
经过一系列折腾（重装版本、升级 Chrome 等等），发现原因是：
我连接了一块副屏，如果应用界面 跟 开发者工具框（我在应用外显示的）不在同一屏幕，那么就会出现右键请求不弹菜单的情况。
在同一块屏幕的时候，正常使用。
王德发！！！</content></entry><entry><title>Python - Dynaconf 动态配置管理</title><url>/tech/python/dynaconf-%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ Dynaconf   旨在成为在 Python 中管理配置的最佳选择。它可以从各种来源读取设置，包括环境变量、文件、服务器配置等，它适用于任何类型的 Python 程序。
安装 $ pip install dynaconf # 或者 $ poetry add dynaconf 项目初始化 # 进入项目路径 $ cd project-demo # 初始化配置文件，支持 toml|yaml|json|ini|py # 默认是 toml 也是最推荐的，这里先用熟悉的 yml 哈 $ dynaconf init -f yaml ⚙️ Configuring your Dynaconf environment 🐍 The file `config.py` was generated. on your code now use `from config import settings`. (you must have `config` importable in your PYTHONPATH). 🎛️ settings.yaml created to hold your settings. 🔑 .secrets.yaml created to hold your secrets. 🙈 the .secrets.yaml is also included in `.gitignore` beware to not push your secrets to a public repo or use dynaconf builtin support for Vault Servers. 🎉 Dynaconf is configured! read more on https://dynaconf.com Use `dynaconf -i config.settings list` to see your settings (package-demo-py3.10) 生成的文件如下，默认只生成 setting.yml 和 config.py，其他是也支持的且常用的。
$ tree . ├── config.py	# 需要被导入的配置脚本 ├── settings.local.yaml # 开发时本地配置 ├── settings.yaml	# 应用配置 └── .secrets.yaml # 像密码等敏感信息配置 编写配置文件 编辑配置文件如下：
# setting.yml debug: false # 线上数据库 database: host: product-env.com  port: 3306 name: mydatabase username: myuser password: mypassword api_key: myapikey 加载配置 # config.py from pathlib import Path from dynaconf import Dynaconf # 根目录 ROOT_DIR = Path(__file__).parent # 加载配置 settings = Dynaconf( # 设置环境变量前缀 # 比如：settings.FOO = &#34;bar&#34; 在环境变量中就是 DEMO_FOO=&#34;bar&#34; envvar_prefix=&#34;DEMO&#34;, # 指定根目录 base_dir=ROOT_DIR, # 通过列表方式加载多个配置文件 settings_files=[&#34;settings.yml&#34;, ], # 加载 .env 文件 load_dotenv=True, ) 验证配置是否生效
# test_dynaconf.py from config import settings def test_settings(): &#34;&#34;&#34;正常执行完成，没有报错&#34;&#34;&#34; assert settings.debug is False assert settings.database.host == &#34;product-env.com&#34; assert settings.database.port == 3306 assert settings.database.name == &#34;mydatabase&#34; assert settings.database.username == &#34;myuser&#34; assert settings.database.password == &#34;mypassword&#34; assert settings.api_key == &#34;myapikey&#34; 项目开发过程中，通常需要在开发环境中调试，可以通过修改 settings.yml 中的配置项来完成，但是这样在提交测试或生产环境时还得记着修改，比较麻烦。
所以可以通过 settings.local.yml ，增加本地开发配置，它的优先级比较低，会在后面加载，覆盖掉之前的 settings.yml 配置。
 ⚠️ 注意
本地配置内字段需要与 settings.yml 文件内的配置项一致，否则报错：'DynaBox' object has no attribute 'HOST'
为了实现仅修改特定参数，需要在 settings.local.yml 文件内增加配置项：dynaconf_merge: true，表示自动合并到 settings.yml，达到相同配置复用的目的。
 # settings.local.yml # 开发环境配置文件 # 开启自动合并相同配置项  dynaconf_merge: true debug: true # 本机数据库 database: host: localhost 以上我打开了 debug 开关，且数据库的地址为本地，其他配置都不用改，验证配置是否生效。
# test_dynaconf.py # 再次执行之前的用例，发现报错了 # AssertionError: assert settings.debug is False def test_dev_settings(): assert settings.debug is True # &lt;-- assert settings.database.host == &#34;localhost&#34; # &lt;-- assert settings.database.port == 3306 assert settings.database.name == &#34;mydatabase&#34; assert settings.database.username == &#34;myuser&#34; assert settings.database.password == &#34;mypassword&#34; assert settings.api_key == &#34;myapikey&#34; 以上用例正确执行，证明本地配置修改成功。又来了一个问题，上面配置中密码都是明文放在配置文件中的，通常情况下，我们需要避免把敏感信息放入仓库，因此，Dynaconf 还支持通过 .secrets.yaml 配置敏感信息，默认不提交到仓库中。
# .secrets.yml # 存放敏感信息 # 记得添加自动合并配置项 dynaconf_merge: true database: username: myuser password: mypassword api_key: myapikey 删除 settings.yml 中的 username、password、api_key 配置项，再次执行测试用例，依然正常执行，配置生效。
]]></content></entry><entry><title>Fastapi - 博客项目案例</title><url>/tech/fastapi/%E5%8D%9A%E5%AE%A2%E9%A1%B9%E7%9B%AE%E6%A1%88%E4%BE%8B/</url><categories><category>Fastapi</category></categories><tags><tag>Fastapi</tag></tags><content type="html"><![CDATA[  本项目  是基于 Fastapi 异步 Web 框架搭建的博客系统，业务功能比较简单，但体现了从环境搭建到开发到测试发布的完整流程。
 项目初始化 项目结构采用 src 目录结构，是 python 项目的基础模板，详见 pypa/sampleproject  
目录结构为：
. ├── README.md ├── src │ └── example_blog │ └── __init__.py └── tests └── __init__.py 它指定 src 为包的顶级目录，不包括 src。如果导包目录为 src/a/b，则可以直接导入 from a import something 或 from a.b import something。
这里通过 poetry 管理项目
# 创建项目 $ poetry new fastapi-blog --src --name blog # 创建虚拟环境 $ poetry shell 命令行工具 click # 直接使用：在 cmdline 文件下加上 main 入口 # 直接执行 # 命令行执行 $ python cmdline.py -V # 打包后通过包执行 $ pip install -e . $ python -m blog.cmdline -V 引入 alembic 做数据库迁移 将包添加到依赖并安装
$ poetry add alembic 初始化
$ alembic init migration $ mv alembic.ini src/blog/migration 创建空白数据库迁移版本
$ python src/blog/cmdline.py migrate -- revision -m &#34;init&#34; 执行迁移
$ python src/blog/cmdline.py migrate -- upgrade head 创建第一个数据库迁移版本
$ python src/blog/cmdline.py migrate -- revision --autogenerate -m &#34;init_table&#34; 执行迁移
$ python src/blog/cmdline.py migrate -- upgrade head 安装 pytest 进行单元测试 $ poetry add -D pytest ]]></content></entry><entry><title>Python - 虚拟环境 Venv</title><url>/tech/python/%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83-venv/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ 原文请访问 小菠萝测试笔记(已授权)  ，本文在此基础上进行部分修改，用于个人知识整理。
 什么是虚拟环境 Python 虚拟环境主要是为不同 Python 项目创建一个隔离的环境，每个项目都可以拥有独立的依赖包环境，而项目间的依赖包互不影响。
 这是 Python 3.3   的新特性 每个系统环境下可以创建多个虚拟环境 默认情况下，虚拟环境和系统环境是完全隔离的 每个虚拟环境都有自己的 Python 二进制文件及单独的包安装目录，与其他环境完全隔绝  为什么要使用虚拟环境 背景:
 假设需要开发多个 Python 项目 每个项目所需的 Python 版本不一致，比如：Python 2.X、Python 3.X 每个项目所需的依赖包不一致，比如 A 项目只要 Selenium 相关依赖包，B 项目只要 Appium 相关依赖包 不同项目用同一个依赖包，但依赖包版本并不一致  如果不适用虚拟环境：
 Python 第三方库默认都是装在系统固定目录的 电脑上所有项目都会从这个目录去存储、查找第三方库（站点库）  # 以 Mac 为例 &gt;&gt;&gt; import site &gt;&gt;&gt; site.getsitepackages() [&#39;/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages&#39;] 带来的问题：
1、不同项目使用同一个依赖包，但版本不同时：
 当开发 A 项目时，要装一次依赖包 A 版本 转开发 B 项目时，先要卸载依赖包 A 版本，再重装 B 版本  2、一个项目开发完成后，需要生成当前项目的所有依赖包 requirement.txt 时：
 会附加当前环境上包，但该包可能在项目里用不上 需要人工检查，还得手工一个个删  通过 venv 操作虚拟环境 Python 3.5 后推荐使用 venv 来创建虚拟环境。
# 创建虚拟环境 $ python3 -m venv &lt;环境名称&gt; # 激活虚拟环境 $ source &lt;环境名称&gt;/bin/activate $ source venv/bin/activate (venv) # 确认已经切换到虚拟环境 $ which python $ pip list # 可以看到虚拟环境中的 Package 只有最基础的 pip、setuptools # 在虚拟环境生成依赖包目录 $ pip freeze &gt; requirements.txt # 当完成工作并退出虚拟环境时，关闭虚拟环境 $ deactivate 更强的环境管理工具 - Poetry TODO
]]></content></entry><entry><title>Python - 代码静态检查</title><url>/tech/python/%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E6%A3%80%E6%9F%A5/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"> isort 是一个自动格式化导入的工具。
安装依赖：
$ poetry add -D isort 格式化代码：
$ isort . 此时可以不用先急着提交，在后面对代码风格检测的时候可能还会再次格式化代码。
flake8 是一个遵循 PEP8 规范检测代码的工具。使用该工具，可以检测出哪些代码不符合 PEP8 规范。
安装依赖：
$ poetry add -D flake8 检测代码：
$ flake8 根据输出提示，参照 flake8 规则 进行调整，直至完全符合为止。</content></entry><entry><title>Python - Pytest Mock</title><url>/tech/python/pytest-mock/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[安装 $ pip install pytest $ pip install pytest pytest-mock 在测试模块中导入 mocker fixture
import pytest def test_example(mocker): ... 示例 def test_run(cli, mocker): mock_run = mocker.patch.object(uvicorn, &#39;run&#39;) result = cli.invoke(cmdline.main, [&#39;server&#39;, &#39;-h&#39;, &#39;127.0.0.1&#39;, &#39;-p&#39;, &#39;8080&#39;]) assert result.exit_code == 0 mock_run.assert_called_once_with(app=mocker.ANY, host=&#39;127.0.0.1&#39;, port=8080) 这是一个 Python 单元测试的代码片段。它使用了 mocker 和 cli 两个 fixture，对应了 pytest-mock 和 click.testing 提供的便利工具。
具体而言，该测试用例对命令行接口函数 cmdline.main 进行测试。首先，通过 mocker.patch.object() 方法将 uvicorn.run 方法替换为一个 MagicMock 对象，以便在测试过程中对其进行模拟和断言。然后，使用 cli.invoke() 方法调用 cmdline.main 函数，并传入一组参数，以执行实际的命令行操作。最后，使用 assert 断言检查返回结果的 exit_code 是否为 0 ，并通过 mock_run.assert_called_once_with() 方法检查 uvicorn.run 方法是否被正确地调用了一次，参数匹配与预期的主机和端口。
这个测试用例确保了当运行服务器时，使用正确的 IP 地址和端口号启动了 Uvicorn 服务器。
]]></content></entry><entry><title>Linux - 常用系统命令</title><url>/tech/linux/%E5%B8%B8%E7%94%A8%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[系统 $ uname -a # 查看内核/操作系统/CPU信息 $ head -n 1 /etc/issue # 查看操作系统版本 $ cat /proc/cpuinfo # 查看CPU信息 $ hostname # 查看计算机名 $ lspci -tv # 列出所有PCI设备 $ lsusb -tv # 列出所有USB设备 $ lsmod # 列出加载的内核模块 $ env # 查看环境变量 # 查看 CPU 信息（型号）看到有 8 个逻辑 CPU, 也知道了 CPU 型号 $ cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 8 Intel(R) Xeon(R) CPU E5410 @ 2.33GHz # 说明实际上是两颗 4 核的 CPU $ cat /proc/cpuinfo | grep physical | uniq -c 4 physical id : 0 4 physical id : 1 # 说明当前 CPU 运行在 32bit 模式下，但不代表 CPU 不支持 64bit $ getconf LONG_BIT 32 # 结果大于 0, 说明支持 64bit 计算. lm 指 long mode, 支持 lm 则是 64bit $ cat /proc/cpuinfo | grep flags | grep &#39; lm &#39; | wc -l 8 # 再完整看 cpu 详细信息，不过大部分我们都不关心而已 $ dmidecode | grep -A 30 &#39;Processor Information&#39; # 查看内存信息 $ cat /proc/meminfo # 查看当前操作系统发行版信息 $ cat /etc/issue | grep Linux $ cat /etc/issue | grep Ubuntu # 查看机器型号 $ dmidecode | grep &#34;Product Name&#34; # 查看网卡信息 $ dmesg | grep -i eth 文件管理  查看文件信息：$ ls -al(list) 切换工作目录：$ cd(chage directory) 显示当前路径：$ pwd 创建新目录：$ mkdir 创建新文件：$ touch 删除文件或目录：$ rm -rf 拷贝文件：$ cp 剪切文件：$ mv 建立链接文件：$ ln  软链接：添加 -s 参数，不占用磁盘空间，原文件删除后，链接失效 硬链接：占用磁盘空间，原文件删除后链接文件依然存在，不影响使用；只能链接普通文件，不能链接目录   查找文件：$ find 查看文件内容  cat：查看整个文件 less：按屏展示；空格下一页；d 上一页；q 退出 more：同 less，增加百分比展示 head：从文件头部开始，默认展示前 10 行，通过 -n 参数指定展示行数 tail：同 head，从文件尾部开始 diff：比较两个文件的差异   打包压缩：$ tar；-zcvf：压缩；-zxvf：解压缩；-C： 指定路径 修改文件权限：$ chmod 777 filename；r：read（4）；w：write（2）；x：execute（1）；-：无权限（0） 文件属性，如图：  文本处理（vi/vim）   跳到开始行：gg
  跳到末尾行：G（shift + g）
  行首跳行尾：$
  行尾跳行首：&lt;
  屏幕输出：echo
  输出重定向：&gt;
  资源管理 $ free -m # 查看内存使用量和交换区使用量 $ df -h # 查看磁盘各分区使用情况 $ du -sh &lt;目录名&gt; # 查看指定目录的大小 $ uptime # 查看系统运行时间、用户数、负载 $ cat /proc/loadavg # 查看系统负载 $ grep MemTotal /proc/meminfo # 查看内存总量 $ grep MemFree /proc/meminfo # 查看空闲内存量 磁盘和分区 $ mount | column -t # 查看挂接的分区状态 $ fdisk -l # 查看所有分区 $ swapon -s # 查看所有交换分区 $ hdparm -i /dev/hda # 查看磁盘参数(仅适用于IDE设备) $ dmesg | grep IDE # 查看启动时IDE设备检测状况 网络 $ ping # 测试远程主机连通性 -c 设置次数；-i 设置时间间隔 $ ifconfig # 查看所有网络接口的属性 $ iptables -L # 查看防火墙设置 $ route -n # 查看路由表 $ netstat -lntp # 查看所有监听端口 $ netstat -antp # 查看所有已经建立的连接 $ netstat -s # 查看网络统计信息 进程 $ ps -ef # 查看所有进程 $ top # 实时显示进程状态 $ kill # 结束进程; kill -9 强制杀死进程 # ps 命令 # 获得当前所有进程列表 $ ps -ef # UNIX 风格参数，单减号 # UID：启动这些进程的用户 # PID：进程 ID # PPID：进程ID # STIME：进程启动时的系统时间 # TTY：进程启动时的终端设备 # TIME：运行进程累计时间  # CMD：启动进程时的名称 $ ps aux # BSD 风格，无符号 # USER PID  # %CPU  # %MEM  # VSZ：进程在内存中的大小,以千字节(KB)为单位，虚拟内存 # RSS：进程在未换出时占用的物理内存，保留内存 # STAT：代表当前进程状态的双字符状态码 # TIME：进程运行时间 # COMMAND：启动进程时的命令 $ ps --pid pidlist # GUN 风格，双减号 # 自定义输出指标 $ ps -o pid,ppid,psr,thcount,tid,cmd -M # psr：运行在哪个 cpu 上 # thcount：线程数 # tid：线程号 # cmd：对应的执行命令 # 查看除 grep 命令外的进程名信息 $ ps -ef | grep -v grep | grep {process_name} 用户 $ w # 查看活动用户 $ id &lt;用户名&gt; # 查看指定用户信息 $ last # 查看用户登录日志 $ cut -d: -f1 /etc/passwd # 查看系统所有用户 $ cut -d: -f1 /etc/group # 查看系统所有组 服务 $ chkconfig --list # 列出所有系统服务 $ chkconfig --list | grep on # 列出所有启动的系统服务 定时任务
# 启动服务 $ service crond start # 停止服务 $ service crond stop # 重启服务 $ service crond restart # 查看服务状态 $ service crond status # 设置定时任务 $ crontab -e # 查看定时任务 $ crontab -l 程序 $ rpm -qa # 查看所有安装的软件包 ]]></content></entry><entry><title>Docker - 搭建Mysql服务</title><url>/tech/docker/%E6%90%AD%E5%BB%BAmysql%E6%9C%8D%E5%8A%A1/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[# 设为 % 使得所有客户端均可连 $ docker run --name=mysql-blocks -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -e MYSQL_ROOT_HOST=% -d mysql:8.0 # sqlalchemy 总是报错： (1045, &#34;Access denied for user &#39;root&#39;@&#39;192.168.1.3&#39; (using password: YES)&#34;) # 先把密码取消掉 $ docker run --name=mysql-blocks -p 3306:3306 --e MYSQL_ROOT_PASSWORD=&#34;&#34; e MYSQL_ROOT_HOST=% -d mysql:8.0 $ docker exec -it mysql-blocks mysql -u root -p ]]></content></entry><entry><title>Docker - 搭建Zentao禅道服务</title><url>/tech/docker/%E6%90%AD%E5%BB%BAzentao%E7%A6%85%E9%81%93%E6%9C%8D%E5%8A%A1/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html">$ docker run --name zentao -p 8081:80 \ -v /volume/zentao/zentaopms:/www/zentaopms \ -v /volume/zentao/mysqldata:/var/lib/mysql \ -e MYSQL_ROOT_PASSWORD=123456 \ -d \ easysoft/zentao:latest</content></entry><entry><title>Docker - 搭建Whistle在线抓包工具</title><url>/tech/docker/%E6%90%AD%E5%BB%BAwhistle%E5%9C%A8%E7%BA%BF%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[编写 dockerfile 文件
FROMalpineEXPOSE8899RUN apk add --no-cache nodejs npm \  &amp;&amp; npm install whistle -g \  &amp;&amp; apk del npm \  &amp;&amp; mkdir /whistleENTRYPOINT [&#34;w2&#34;, &#34;run&#34;, &#34;-M&#34;,&#34;prod&#34;, &#34;-D&#34;,&#34;/whistle&#34;]构建镜像
$ docker build -t whistle:v1 . 启动容器
$ docker run -d --name whistle -p 8899:8899 whistle:v1 启动服务
# docker-compose.yml version: &#34;3&#34; services: whistle: image: whistle:v1 container_name: whistle restart: always volumes: - &#34;/volume/whistle:/whistle&#34; - &#34;/volume/whistle/.WhistleAppData:/root/.WhistleAppData&#34; ports: - &#34;8899:8899&#34; 遇到问题 过滤请求：怎么实现根据请求实体中某个参数的值，过滤该请求？
比如请求路由为 /go，请求方法为 post，每次请求 go 的时候，我想过滤掉（不显示） body 中 space=home 的请求。
]]></content></entry><entry><title>Linux - 脚本-添加定时任务</title><url>/tech/linux/%E8%84%9A%E6%9C%AC-%E6%B7%BB%E5%8A%A0%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[#!/bin/bash  # 使用跟随的命令字符串作为 cmd 变量的值 if [ -n &#34;$1&#34; ]; then cmd=&#34;$1&#34; else read -p &#34;请输入要加入定时任务的命令: &#34; cmd fi # 表示每天凌晨 1:00 执行 cronTrigger=&#34;0 1 * * *&#34; # 检查当前用户的定时任务列表中是否已经存在相同的命令 crontab -l | grep &#34;$cmd&#34; &gt; /dev/null 2&gt;&amp;1 # 如果定时任务列表中不存在相同的命令 if test $? -ne 0; then # 则将原有的定时任务列表保存到 crontab.tmp 文件中 crontab -l &gt; crontab.tmp # 在末尾添加新的定时任务表达式和命令 echo &#34;$cronTrigger$cmd&#34; &gt;&gt; crontab.tmp # 将更新后的定时任务列表重新加载 crontab crontab.tmp fi ]]></content></entry><entry><title>Jmeter&Ms - 数据备份与恢复</title><url>/tech/jmeterms/ms-%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html"><![CDATA[数据备份 MeterSphere 备份，主要是 MySQL 数据库的数据备份和 /opt/metersphere/data 路径下的目录备份。
备份内容：
 mysqldump 手动备份 /opt/metersphere/data/mysql  编写备份脚本 ms_backup.sh 
#!/bin/bash  0,0-1 Al#!/bin/bas backupDir=/data/backup/ms_db_bak if [ ! -d &#34;$backupDir&#34; ]; then mkdir -p &#34;$backupDir&#34; fi currentTime=`date &#34;+%Y-%m-%d-%H-%M-%S&#34;` ms_data=/opt/metersphere/data ms_sql=$backupDir/ms_db_$currentTime.sql echo &#34;======= 数据库备份 ===============&#34; docker exec -i mysql mysqldump -uroot -pPassword123@mysql metersphere --max_allowed_packet=2G &gt; $ms_sql echo [Done] dumpSqlFilePath=$ms_sql echo echo &#34;======= 备份数据打包 =============&#34; backupZipFileName=ms_db_$currentTime.zip cd $backupDir zip -r $backupZipFileName $ms_sql $data # 打包完成后删除原来的 sql 备份 rm -rf $backupDir/ms_db_$currentTime.sql echo [Done] backupZipFileName=$backupZipFileName echo echo &#34;======= 仅保留最新 3 个备份 =======&#34; keepBackupNum=3 output=`ls -lt $backupDir/*.zip | awk &#39;{print $9}&#39;` step=0 for backupFile in $output ;do step=$((step+1)) echo step=$step echo $backupFile if [ $step -gt $keepBackupNum ];then echo Remove outdated backup $backupFile rm -rf $backupFile fi done 数据恢复 # 1. 进入备份 sql 目录，将 sql 复制到 mysql 容器的挂载目录 $ cp metersphere.sql /opt/metersphere/data/mysql # 2. 进入 mysql 容器，登录数据库 $ docker exec -it mysql sh $ mysql -uroot -pPassword123@mysql # 3. 使用 metersphere 库，并将数据导入到库里 $ use metersphere; $ source /var/lib/mysql/metersphere.sql 升级到 2.10.1 LTS 版本后遇到的问题 问题一：数据库迁移  容器报错信息 system-setting | Caused by: org.flywaydb.core.internal.command.DbMigrate$FlywayMigrateException: Schema metersphere contains a failed migration to version 137 !
 参考地址： 升级报错  
当前版本为 2.10.1 lts 版本，找到对应的 sql 脚本： V137__modify_novice_statistcs.sql  
# 将备份的sql数据复制至mysql容器 $ docker cp V137__modify_novice_statistcs.sql mysql:/ # 使用 metersphere 并执行 sql $ docker exec -it mysql bash $ mysql -uroot -pPassword123@mysql $ use metersphere; # 导入数据库文件 $ source /V137__modify_novice_statistcs.sql # 更新版本表 $ update metersphere_version set success=1 where version=137; # 退出容器；重启服务 $ msctl reload 问题二：prometheus 路径权限不够  容器报错信息 ts=2023-07-17T09:53:18.717Z caller=query_logger.go:91 level=error component=activeQueryTracker msg=&ldquo;Error opening query log file&rdquo; file=/prometheus/queries.active err=&ldquo;open /prometheus/queries.active: permission denied&rdquo; panic: Unable to create mmap-ed active query log
 手动添加权限即可
$ chmod +777 /opt/metersphere/conf/prometheus $ chmod +777 /opt/metersphere/data/prometheus $ docker restart ms-prometheus ]]></content></entry><entry><title>Docker - 搭建Filebrowser文件管理服务</title><url>/tech/docker/%E6%90%AD%E5%BB%BAfilebrowser%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ File Browser：一个具有漂亮界面的功能丰富的文件浏览器，支持预览、上传/下载文件、编辑文件等操作。
 由于公司的文件管理工具为 SVN，每当有需求文件提过来的时候，需要更新下 SVN 库。这么多的文件占电脑存储且不想使用 SVN 命令行工具。
所以找到了这么个在线管理文件的服务，仅需要在服务器上存储一份文件，大家都去服务器上找文件就可以了。使用界面类似于网盘，不算太丑。
部署服务 首先编写一个 json 配置文件进行一些初始化设置
// &#34;filebrowser.json&#34; 6,20 All { &#34;port&#34;: 80, &#34;baseURL&#34;: &#34;/&#34;, &#34;address&#34;: &#34;0.0.0.0&#34;, &#34;log&#34;: &#34;stdout&#34;, &#34;locale&#34;: &#34;zh-cn&#34;, &#34;database&#34;: &#34;/data/filebrowser.db&#34;, &#34;root&#34;: &#34;/srv&#34;, &#34;user&#34;: { &#34;name&#34;: &#34;admin&#34;, &#34;password&#34;: &#34;admin&#34;, &#34;lockPassword&#34;: true }, &#34;defaults&#34;: { &#34;permissions&#34;: &#34;0770&#34;, &#34;show_hidden&#34;: false }, &#34;branding&#34;: { &#34;logo_url&#34;: &#34;https://oa-beta.6du.cn/img/logo@1x.png&#34; } } 然后编写 yml 配置文件启动服务
# &#34;docker-compose.yml&#34; version: &#39;3&#39; services: filebrowser: image: filebrowser/filebrowser container_name: filebrowser volumes: # 挂载 SVN 文件目录 - /data/duban-svn:/srv # 挂载 配置文件 - /data/filebrowser.json:/etc/filebrowser/filebrowser.json # 设置下时间 - /etc/localtime:/etc/localtime:ro ports: - &#34;80:80&#34; restart: always environment: - FB_LOGO_URL=https://oa-beta.6du.cn/img/logo@1x.png 服务启动后，通过默认端口访问该服务，账号密码在配置文件中的 user 对象中。
定时同步 文件虽然是通过服务对外提供访问了，但是文件还需要自动去更新。
#!/bin/bash # 更新 SVN 目录文件 SVN_REPO=&#34;svn://svn.xxx.com/&#34; DIR_NAME=&#34;svn-dir&#34; # SVN 目录名 USERNAME=&#34;xxx&#34; PASSWORD=&#34;xxx&#34; if [ -d &#34;$DIR_NAME&#34; ]; then svn cleanup &#34;$DIR_NAME&#34; svn update &#34;$DIR_NAME&#34; --username &#34;$USERNAME&#34; --password &#34;$PASSWORD&#34; else svn co --username &#34;$USERNAME&#34; --password &#34;$PASSWORD&#34; &#34;${SVN_REPO}${DIR_NAME}&#34; fi 再编写脚本，将上面的执行命令放到定时任务中，脚本在 Linux 目录下。
]]></content></entry><entry><title>Docker - 搭建Chatgpt服务</title><url>/tech/docker/%E6%90%AD%E5%BB%BAchatgpt%E6%9C%8D%E5%8A%A1/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ 项目地址： chatgpt-web  ，通过 Docker 部署 chatGPT web 服务。
 这个作为工具来用的话，真的是太香了，省去了很多搜索的时间。CV 工程师的福音，哈哈~~
准备工作  一台安装了 docker 的服务器 注册 OpenAI 账号 去 官网   申请一个 API keys 用于接口访问  服务部署 代理 通过连接代理访问 OpenAI 官网。
我用手机开启的，PC 上也可（小猫、小飞机啥的），工具随意。
小火箭手机上不太好找路径，这里写下：
 配置里面设置好转发规则，设置-代理-代理共享 记录下 IP 地址和端口号  部署 Web 服务 通过 Dcoker 方式部署
# docker-compose.yml version: &#39;3&#39; services: app: image: chenzhaoyu94/chatgpt-web ports: - 3002:3002 environment: # 二选一 OPENAI_API_KEY: sk-上面申请的 keys # API接口地址，可选，设置 OPENAI_API_KEY 时可用 OPENAI_API_BASE_URL: https://api.openai.com # API模型，可选，设置 OPENAI_API_KEY 时可用，https://platform.openai.com/docs/models # gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314, gpt-3.5-turbo, gpt-3.5-turbo-0301, text-davinci-003, text-davinci-002, code-davinci-002 OPENAI_API_MODEL: gpt-3.5-turbo # 反向代理，可选 API_REVERSE_PROXY: # 访问前端网页时的登录密码，可自定义 AUTH_SECRET_KEY: qagogogo # 每小时最大请求次数，可选，默认 0 无限 MAX_REQUEST_PER_HOUR: 1000 # 超时，单位毫秒，可选 TIMEOUT_MS: 60000 # Socks代理，写第一步开启代理的 IP 地址 SOCKS_PROXY_HOST: xxx.xxx.xxx.xxx # Socks代理端口，写第一步开启代理的端口号 SOCKS_PROXY_PORT: xxxx # HTTPS 代理，可选，支持 http，https，socks5 HTTPS_PROXY: 进入 yml 文件路径下，启动服务
$ docker-compose up -d 浏览器访问 3002 端口，输入设置的密码即可。
备注 修改默认用户名
Docker compose 部署修改默认用户名，这里是一次性修改，如果嫌麻烦就 fork 下仓库修改后自己打镜像。
# 进入容器内 docker exec -it chatgpt-web-app-1 /bin/sh # 进入asset目录 cd app/public/assets # 更改名字，支持中文 sed -i &#39;s/ChenZhaoYu/你的名字/g&#39; *.js 然后刷新网页生效。
提示词商店
点击左侧边栏的「提示词商店」 ，下载在线词库，失败就多试几次。聊天框 &quot;/&quot; 触发提示词。
]]></content></entry><entry><title>Linux - 服务器连接不上问题定位</title><url>/tech/linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8A%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[今天早上来服务器登录不上了，ping 一下看看，是通的
$ ping 192.168.1.222 PING 192.168.1.222 (192.168.1.222): 56 data bytes 64 bytes from 192.168.1.222: icmp_seq=0 ttl=63 time=17.777 ms 64 bytes from 192.168.1.222: icmp_seq=1 ttl=63 time=11.633 ms ^C 3 packets transmitted, 2 packets received, 33.3% packet loss round-trip min/avg/max/stddev = 11.633/14.705/17.777/3.072 ms 再尝试访问服务试试，无法访问，看看端口号通不通，是通的
$ telnet 192.168.1.222 8000 Trying 192.168.1.222... Connected to 192.168.1.222. Escape character is &#39;^]&#39;. ^] telnet&gt; q Connection closed. 再试试连接服务器，连不上，看看 ssh 端口通不通，是通的
$ telnet 192.168.1.222 22 Trying 192.168.1.222... Connected to 192.168.1.222. Escape character is &#39;^]&#39;. 很奇怪~ 去机房接上个显示屏看看~
# 报错了 filesystem faild 巴拉巴拉 # 重启也没用 # 检查下修复就好了 $ 1 fsck.ext 4 /dev/磁盘 可能是前一天断过电，磁盘有影响？这件事情后赶紧把拖了好久的备份做完了。
]]></content></entry><entry><title>Python - Pip 包管理工具</title><url>/tech/python/pip-%E6%8A%A5%E9%94%99%E8%AE%B0%E5%BD%95/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[遇到的问题
装包错误：No matching distribution found for pbr $ pip install -r requirements.txt -i http://pypi.douban.com/simple/ ERROR: Could not find a version that satisfies the requirement pbr (from versions: none) ERROR: No matching distribution found for pbr 解决办法：信任该源，安装成功
$ pip install pbr --trusted-host pypi.douban.com 配置源内未找到安装包地址 安装失败，报错日志说是未在清华源中找到某个版本~ 取消掉镜像配置，重新安装。
$ vim ~/.pip/pip.conf [install] #trusted-host = pypi.douban.com [global] #index-url = https://pypi.tuna.tsinghua.edu.cn/simple pip 不可用 pip 不可用：AttributeError: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'
from pip._vendor.urllib3.contrib import pyopenssl File &#34;/usr/local/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py&#34;, line 46, in &lt;module&gt; import OpenSSL.SSL File &#34;/usr/local/lib/python3.7/site-packages/OpenSSL/__init__.py&#34;, line 8, in &lt;module&gt; from OpenSSL import crypto, SSL File &#34;/usr/local/lib/python3.7/site-packages/OpenSSL/crypto.py&#34;, line 1517, in &lt;module&gt; class X509StoreFlags(object): File &#34;/usr/local/lib/python3.7/site-packages/OpenSSL/crypto.py&#34;, line 1537, in X509StoreFlags CB_ISSUER_CHECK = _lib.X509_V_FLAG_CB_ISSUER_CHECK AttributeError: module &#39;lib&#39; has no attribute &#39;X509_V_FLAG_CB_ISSUER_CHECK&#39; pip 完全不可用，一直出现如上报错。
$ pip install pip --upgrade 解决办法：找到错误行，并注释它。
$ vim /usr/local/lib/python3.7/site-packages/OpenSSL/crypto.py /X509_V_FLAG_CB_ISSUER_CHECK # 找到该行，注释掉 # !wq 参考：https://stackoverflow.com/questions/73830524/attributeerror-module-lib-has-no-attribute-x509-v-flag-cb-issuer-check?spm=wolai.workspace.0.0.11cc417chQdpKo
psycopg2 安装失败：pg_config executable not found.  python 3.7 Mac  安装 psycopg2
$ pip install psycopg2 ... Error: pg_config executable not found. # 报错 ... 解决
 stackoverflow.com  
$ which pg_config pg_config not found # mac $ brew install postgresql@11 $ ll /usr/local/Cellar | grep postgresql drwxr-xr-x 3 lan admin 96B 12 27 12:00 postgresql@11 # pg_config 在 bin 目录下，添加到环境变量内 $ PATH=&#34;/usr/local/Cellar/postgresql@11/11.17_3/bin:$PATH&#34; $ pip install psycopg2 Successfully installed psycopg2-2.9.5 刚开始下载的 postgresql@14 失败，报错需要安装 python3.9，安装了 11 版本，问题解决。
Crypto: import error 导包失败 from Crypto.Cipher import AES # 出现 import error 解决
$ pip install pycryptodome # 进入 \Lib\site-packages # 将 crypto 首字母小写改为大写 ]]></content></entry><entry><title>Python - Alembic 数据库迁移工具</title><url>/tech/python/alembic-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB%E5%B7%A5%E5%85%B7/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ Alembic 是一个由 SQLAlchemy 开发的数据库迁移工具，可以再应用程序的开发周期中轻松地管理和升级数据库架构。
通过 Alembic，可以跟踪数据库架构变化，并在开发新功能时更新数据库模式。
 安装 $ pip install alembic # 或者 $ poetry add alembic 使用 创建一个名为 alembic.ini 的配置文件，该文件包含连接到数据库所需的详细信息。例如：
[alembic] script_location = alembic [alembic:servers] main = postgresql://user:password@localhost/dbname [alembic:target_metadata] target_metadata = myapp.models:Base.metadata 使用以下命令创建 Alembic 迁移存储库：
$ alembic init alembic 编辑生成的 alembic/env.py 文件，添加以下代码以将 target_metadata 设置为您的应用程序的数据库模型：
from myapp.models import Base target_metadata = Base.metadata 执行以下命令以创建第一个 Alembic 迁移：
$ alembic revision -m &#34;Create users table&#34; 编辑生成的 Alembic 迁移文件（位于 alembic/versions 文件夹中），添加您要进行的更改。
例如，在上述示例中，您可能会添加以下代码来创建一个 users 表：
op.create_table( &#39;users&#39;, sa.Column(&#39;id&#39;, sa.Integer(), nullable=False), sa.Column(&#39;name&#39;, sa.String(), nullable=False), sa.PrimaryKeyConstraint(&#39;id&#39;) ) 使用以下命令将此迁移应用于数据库：
$ alembic upgrade head 在上述步骤完成后，您现在可以使用 Alembic 迁移来管理您的数据库架构并跟踪架构变化了。
!&gt; 测试信息框
x&gt; 错误提示
@&gt; 引用提示
]]></content></entry><entry><title>Blog - Hugo 开启评论功能</title><url>/tech/blog/hugo-%E5%BC%80%E5%90%AF%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/</url><categories><category>Blog</category></categories><tags><tag>Blog</tag></tags><content type="html"><![CDATA[ 主题：Hogo-Themes-Next 评论插件：giscus  步骤
 请确保已配置好站点，且仓库是公开的； 安装 giscus APP  ，选择 GitPages 仓库，然后安装； 访问 giscus  ，根据提示选择好配置，将对应的配置项写在主题配置内  主要是这四个：
data-repo=&#34;作者名/仓库名&#34; data-repo-id=&#34;自动生成&#34; data-category=&#34;Comment&#34; data-category-id=&#34;自动生成&#34; 然后进入博客仓库 - Discussions   目录下，点击 Categories 右侧的编辑按钮。
修改：
 Category name：Comments Discussion Format：Open-ended discussion  点击保存即可。
]]></content></entry><entry><title>Python - Poetry 环境管理</title><url>/tech/python/poetry-%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[Poetry 是 Python 项目中创建虚拟环境、管理依赖包、打包发布的工具。
参考：
  官方文档    Github   Python 3.7+  优势：
 允许声明项目所依赖的库，并管理（安装/更新） 提供了一个锁文件来确保可重复安装 可以构建项目以进行分发 强大的依赖处理能力  Poetry 以简单的项目格式取代：
 setup.py requirements.txt setup.cfg MANIFEST.in Pipfile pyproject.toml  安装 安装 # Linux、macOS、Windows (WSL) $ curl -sSL https://install.python-poetry.org | python3 - # Windows（PowerShell） # 如果是通过 Microsoft Store 安装的 Python，将下面的 py 替换为 python (Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | py -  ⚠️ 安装遇到问题
报错日志说是未在清华源中找到某个版本~ 取消掉镜像配置，重新安装。如何取消？（去 pip-包管理工具文档中找）
 Mac 安装完成后，可执行命令默认在 ~/.local/bin/poetry
$ ~/.local/bin/poetry --version Poetry (version 1.5.1) # 由于 .local 并不在环境量下，所以还不能直接使用 poetry 命令 $ poetry --version poetry: command not founds # 复制命令到环境变量 或者 添加到环境变量 $ cp ~/.local/bin/poetry /usr/local/bin $ poetry --version Poetry (version 1.5.1) 更新 # 更新到最新版本 $ poetry self update # 更新到指定版本 $ poetry self update 1.2.0 卸载 $ curl -sSL https://install.python-poetry.org | python3 - --uninstall $ curl -sSL https://install.python-poetry.org | POETRY_UNINSTALL=1 python3 - 基本用法 创建新项目 创建方式一：默认项目
# 创建新项目 # 默认项目名和包名是一致的 $ poetry new default-project # 查看项目结构 $ cd default-project $ tree . ├── README.md ├── default_project │ └── __init__.py ├── pyproject.toml └── tests └── __init__.py 创建方式二：指定代码路径及包名
# 指定项目名称为 project-demo # 指定包名为 package-demo # 指定包存放的目录为 src $ poetry new project-demo --src --name package-demo Created package package_demo in project-demo $ tree . ├── README.md ├── pyproject.toml ├── src # &lt;== 将包放在新增的代码目录内 │ └── package_demo │ └── __init__.py └── tests └── __init__.py 在已有的项目中初始化 $ cd exists_project/ $ poetry init # 填入自定义项，默认都是确定，回车就行 ... Generated file pyproject.toml 以上项目创建或初始化完成后，都会在根目录生成 pyproject.toml 配置文件，在整个开发过程中，是逐步丰富此文件的。
这是项目的描述文件，管理项目及其依赖包，并描述了打包的配置信息。
[tool.poetry] # 指定包名，默认与项目同名，如果创建时自定义了包名，那么写自定义的名称，而不是项目名 name = &#34;package-demo&#34; version = &#34;0.1.0&#34; description = &#34;我是包的描述信息&#34; authors = [&#34;lan &lt;lanzy.nice@gmail.com&gt;&#34;] readme = &#34;README.md&#34; # 由于包名与项目名不同，所以要告诉项目包的位置在哪里；如果包名与项目名同名，则不用该配置 packages = [{include = &#34;package_demo&#34;, from = &#34;src&#34;}] [tool.poetry.dependencies] # 这里指定该项目的所有依赖包，通过 add 安装包会自动填写在这里 python = &#34;^3.10&#34; [build-system] requires = [&#34;poetry-core&#34;] build-backend = &#34;poetry.core.masonry.api&#34; [tool.poetry.scripts] # 通过包名可以直接调用该命令行执行 blog = &#34;blog.cmdline:main&#34; 当手工向配置文件添加内容后，可以通过命令来检查文件是否正常工作。
$ poetry check All set! 激活虚拟环境 配置工作完成后，还需要给项目创建一个虚拟环境。
# 项目目录下 # 执行该命令后会创建并进入虚拟环境的终端 $ poetry shell Creating virtualenv package-demo-4J6IgKuF-py3.10 in /Users/lan/Library/Caches/pypoetry/virtualenvs Spawning shell within /Users/lan/Library/Caches/pypoetry/virtualenvs/package-demo-4J6IgKuF-py3.10 关于 env 的命令
# 查看当前环境信息 $ poetry env info # 查看当前项目创建的环境列表 $ poetry env list package-demo-4J6IgKuF-py3.10 (Activated) (package-demo-py3.10) # 切换环境 $ poetry env use /full/path/to/python $ poetry env use 3 # 根据版本号 # 删除环境 $ poetry env remove /full/path/to/python 包管理 安装包 环境配置就绪，开始进行项目的开发工作，那么就需要安装一些项目的依赖包。
1、如果没有配置文件内没有配置任何依赖包，随用随装
# 安装包 并 自动添加到 配置文件中 $ poetry add click # 指定版本 $ poetry add click@latest $ poetry add click@^8.1.3 $ poetry add &#34;click&gt;=^8.1.3&#34; # Github 安装 $ poetry add git+https://github.com/sdispater/pendulum.git $ poetry add git+https://github.com/sdispater/pendulum.git#master # 本地安装 poetry add ./package-demo/ # -D 将包添加到开发依赖项中 $ poetry add -D requests 当使用了 -D 参数时，那么就会在 pyproject.toml 中生成一个新的依赖项，表示该软件包只会在开发期间使用，并且不应该被包含在生产环境中。
[tool.poetry.group.dev.dependencies] pytest = &#34;^7.3.1&#34; 2、如果配置文件内已经指定好了项目需要的依赖包，安装已有项目
# 默认安装所有依赖包 $ poetry install # 不安装开发依赖包 $ poetry install --no-dev # 移除 poetry.lock 文件中不再存在的旧依赖包 $ poetry install --remove-untracked Poetry 会简单地解析pyproject.toml文件中列出的所有依赖项并下载其文件的对应版本，默认为最新版本。
完成安装后，会在根目录写入文件 poetry.lock，锁定依赖包的特定版本，下次别人再安装就直接使用相同版本的依赖项。
更新包 当依赖项有更新时，需要使用 update 命令，等同于删除 .lock 然后重新执行 install 生成 .lock 文件。
# 获取所有依赖项的最新版本并更新 poetry.lock 文件 $ poetry update # 仅更新指定依赖项 $ poetry update requests # 不执行安装，仅更新 poetry.lock 文件 $ poetry update --lock 删除包 $ poetry remove click # 从开发环境中删除包 $ poetry remove requests --dev 查看包 查看已安装的包，这里是根据 poetry.lock 列出。
# 查看项目中安装的所有包 $ poetry show # 查看单个包的信息 $ poetry show alembic 执行 执行 python 命令 $ poetry run python -V Python 3.10.8 (package-demo-py3.10) 执行自定义的脚本 在 myproject.toml 中添加脚本的执行路径
[tool.poetry.scripts] blog = &#34;blog.cmdline:main&#34;  第一个 blog 为执行时调用的命令 第二个 blog 为包名 cmdline 为定义命令行指令的 py 文件 main 为执行函数  构建 # 打包 $ poetry build # 发布 $ poetry publish ]]></content></entry><entry><title>Fastapi - 实践经验（转载）</title><url>/tech/fastapi/%E5%AE%9E%E8%B7%B5%E7%BB%8F%E9%AA%8C%E8%BD%AC%E8%BD%BD/</url><categories><category>Fastapi</category></categories><tags><tag>Fastapi</tag></tags><content type="html"><![CDATA[ ref：https://zhuanlan.zhihu.com/p/560737058
 尽管 FastAPI 是一个很棒的框架，具有出色的文档，但如何为初学者构建更大的项目并不是很明显。
在过去的 1.5 年生产中，我们一直在做出正确和错误的决定，这些决定极大地影响了我们的开发人员体验。 其中一些值得分享。
内容
 项目结构。 一致且可预测 过度使用 Pydantic 进行数据验证 使用依赖项进行数据验证与 DB 解耦和重用依赖项。 依赖调用被缓存 不要让你的路由异步，如果你只有阻塞 I/O 操作 迁移。 蒸馏器 BackgroundTasks &gt; asyncio.create_task 小心动态的 pydantic 字段 以块的形式保存文件 如果您必须使用同步 SDK，则在线程池中运行它。  1. 项目结构。 一致且可预测
构建项目的方法有很多，但最好的结构是一致、直接且没有意外的结构。
 如果查看项目结构并不能让您了解项目的内容，那么结构可能不清楚。 如果您必须打开包才能了解其中的模块，那么您的结构就不清楚了。 如果文件的频率和位置感觉随机，那么您的项目结构很糟糕。 如果查看模块的位置和名称并不能让您了解里面的内容，那么您的结构非常糟糕。  尽管 Sebastián Ramírez 提出的项目结构（我们按文件的类型（例如 api、crud、模型、模式）分隔文件）对于微服务或范围较小的项目很有用，但我们无法将其融入我们的具有大量领域和 模块。
我发现一种更具可扩展性和可演进性的结构受到 Netflix 的 Dispatch 的启发，并稍作修改。
fastapi-project ├── alembic/ ├── src │ ├── auth │ │ ├── router.py │ │ ├── schemas.py # pydantic models │ │ ├── models.py # db models │ │ ├── dependencies.py │ │ ├── config.py # local configs │ │ ├── constants.py │ │ ├── exceptions.py │ │ ├── service.py │ │ └── utils.py │ ├── aws │ │ ├── client.py # client model for external service communication │ │ ├── schemas.py │ │ ├── config.py │ │ ├── constants.py │ │ ├── exceptions.py │ │ └── utils.py │ └── posts │ │ ├── router.py │ │ ├── schemas.py │ │ ├── models.py │ │ ├── dependencies.py │ │ ├── constants.py │ │ ├── exceptions.py │ │ ├── service.py │ │ └── utils.py │ ├── config.py # global configs │ ├── models.py # global models │ ├── exceptions.py # global exceptions │ ├── pagination.py # global module e.g. pagination │ ├── database.py # db connection related stuff │ └── main.py ├── tests/ │ ├── auth │ ├── aws │ └── posts ├── templates/ │ └── index.html ├── requirements │ ├── base.txt │ ├── dev.txt │ └── prod.txt ├── .env ├── .gitignore ├── logging.ini └── alembic.ini 当一个包需要来自其他包的服务或依赖项时 - 使用显式模块名称导入它们。
from src.auth import constants as auth_constants from src.notifications import service as notification_service from src.posts.constants import ErrorCode as PostsErrorCode 2.过度使用Pydantic进行数据验证
Pydantic 具有一组丰富的功能来验证和转换数据。
除了具有默认值的必填和非必填字段等常规功能外，Pydantic 还内置了全面的数据处理工具，如正则表达式、有限允许选项的枚举、长度验证、电子邮件验证等。
from enum import Enum from pydantic import AnyUrl, BaseModel, EmailStr, Field, constr class MusicBand(str, Enum): AEROSMITH = &#34;AEROSMITH&#34; QUEEN = &#34;QUEEN&#34; ACDC = &#34;AC/DC&#34; class UserBase(BaseModel): first_name: str = Field(min_length=1, max_length=128) username: constr(regex=&#34;^[A-Za-z0-9-_]+$&#34;, to_lower=True, strip_whitespace=True) email: EmailStr age: int = Field(ge=18, default=None) # must be greater or equal to 18 favorite_band: MusicBand = None # only &#34;AEROSMITH&#34;, &#34;QUEEN&#34;, &#34;AC/DC&#34; values are allowed to be inputted website: AnyUrl = None 3. 使用依赖项进行数据验证 vs DB
Pydantic 只能验证客户端输入的值。 使用依赖项来验证数据是否符合数据库约束，例如电子邮件已存在、未找到用户等。
# dependencies.py async def valid_post_id(post_id: UUID4) -&gt; Mapping: post = await service.get_by_id(post_id) if not post: raise PostNotFound() return post # router.py @router.get(&#34;/posts/{post_id}&#34;, response_model=PostResponse) async def get_post_by_id(post: Mapping = Depends(valid_post_id)): return post @router.put(&#34;/posts/{post_id}&#34;, response_model=PostResponse) async def update_post( update_data: PostUpdate, post: Mapping = Depends(valid_post_id), ): updated_post: Mapping = await service.update(id=post[&#34;id&#34;], data=update_data) return updated_post @router.get(&#34;/posts/{post_id}/reviews&#34;, response_model=list[ReviewsResponse]) async def get_post_reviews(post: Mapping = Depends(valid_post_id)): post_reviews: list[Mapping] = await reviews_service.get_by_post_id(post[&#34;id&#34;]) return post_reviews 作为奖励，使用公共依赖项消除了为这些路由中的每一个编写测试以验证 post_id 的需要。
4. 解耦和重用依赖。 依赖调用被缓存
依赖可以被多次重用，并且它们不会被重新计算 - FastAPI默认将依赖的结果缓存在请求的范围内，即如果我们有一个调用服务get_post_by_id的依赖，我们每次调用这个依赖时都不会访问数据库 - 只有第一个函数调用。
知道了这一点，我们可以轻松地将依赖关系解耦成多个更小的函数，这些函数在更小的域上运行，并且更容易在其他路由中重用。 例如，在下面的代码中，我们使用了 parse_jwt_data 依赖 3 次：
 valid_owned_post valid_active_creator get_user_post,  但是 parse_jwt_data 在第一次调用时只调用一次。
# dependencies.py from fastapi import BackgroundTasks from fastapi.security import OAuth2PasswordBearer from jose import JWTError, jwt async def valid_post_id(post_id: UUID4) -&gt; Mapping: post = await service.get_by_id(post_id) if not post: raise PostNotFound() return post async def parse_jwt_data( token: str = Depends(OAuth2PasswordBearer(tokenUrl=&#34;/auth/token&#34;)) ) -&gt; dict: try: payload = jwt.decode(token, &#34;JWT_SECRET&#34;, algorithms=[&#34;HS256&#34;]) except JWTError: raise InvalidCredentials() return {&#34;user_id&#34;: payload[&#34;id&#34;]} async def valid_owned_post( post: Mapping = Depends(valid_post_id), token_data: dict = Depends(parse_jwt_data), ) -&gt; Mapping: if post[&#34;creator_id&#34;] != token_data[&#34;user_id&#34;]: raise UserNotOwner() return post async def valid_active_creator( token_data: dict = Depends(parse_jwt_data), ): user = await users_service.get_by_id(token_data[&#34;user_id&#34;]) if not user[&#34;is_active&#34;]: raise UserIsBanned() if not user[&#34;is_creator&#34;]: raise UserNotCreator() return user # router.py @router.get(&#34;/users/{user_id}/posts/{post_id}&#34;, response_model=PostResponse) async def get_user_post( worker: BackgroundTasks, post: Mapping = Depends(valid_owned_post), user: Mapping = Depends(valid_active_creator), ): &#34;&#34;&#34;Get post that belong the active user.&#34;&#34;&#34; worker.add_task(notifications_service.send_email, user[&#34;id&#34;]) return post 5. 不要让你的路由异步，如果你只有阻塞 I/O 操作
在底层，FastAPI 可以有效地处理异步和同步 I/O 操作。
 FastAPI 在线程池中运行同步路由，阻塞 I/O 操作不会阻止事件循环执行任务。 否则，如果路由是异步定义的，那么它会通过 await 定期调用，FastAPI 相信您只执行非阻塞 I/O 操作。  需要注意的是，如果您未能信任并在异步路由中执行阻塞操作，则事件循环将无法运行下一个任务，直到该阻塞操作完成。
import asyncio import time @router.get(&#34;/terrible-ping&#34;) async def terrible_catastrophic_ping(): time.sleep(10) # I/O blocking operation for 10 seconds pong = service.get_pong() # I/O blocking operation to get pong from DB return {&#34;pong&#34;: pong} @router.get(&#34;/good-ping&#34;) def good_ping(): time.sleep(10) # I/O blocking operation for 10 seconds, but in another thread pong = service.get_pong() # I/O blocking operation to get pong from DB, but in another thread return {&#34;pong&#34;: pong} @router.get(&#34;/perfect-ping&#34;) async def perfect_ping(): await asyncio.sleep(10) # non I/O blocking operation pong = await service.async_get_pong() # non I/O blocking db call return {&#34;pong&#34;: pong} 第二个警告是非阻塞等待或发送到线程池的操作必须是 I/O 密集型任务（例如打开文件、数据库调用、外部 API 调用）。
 等待 CPU 密集型任务（例如繁重的计算、数据处理、视频转码）是毫无价值的，因为 CPU 必须工作才能完成任务，而 I/O 操作是外部的，服务器在等待该操作完成时什么也不做，因此它可以转到下一个任务。 由于 GIL，在其他线程中运行 CPU 密集型任务也无效。简而言之，GIL 一次只允许一个线程工作，这使得它对于 CPU 任务毫无用处。 如果您想优化 CPU 密集型任务，您应该将它们发送给另一个进程中的工作人员。  6. 迁移。蒸馏器。
 迁移必须是静态且可恢复的。如果您的迁移依赖于动态生成的数据，那么请确保唯一动态的是数据本身，而不是其结构。 生成具有描述性名称和 slug 的迁移。 Slug 是必需的，应该解释这些变化。 为新的迁移设置人类可读的文件模板。我们使用 date_slug.py 模式，例如2022-08-24_post_content_idx.py  # alembic.ini file_template = %%(year)d-%%(month).2d-%%(day).2d_%%(slug)s 7. 背景任务 &gt; asyncio.create_task
BackgroundTasks 可以像处理路由一样有效地运行阻塞和非阻塞 I/O 操作（同步函数在线程池中运行，而异步函数稍后等待）
 不要对工作人员撒谎，不要将阻塞 I/O 操作标记为异步 不要将它用于繁重的 CPU 密集型任务。  from fastapi import APIRouter, BackgroundTasks from pydantic import UUID4 from src.notifications import service as notifications_service router = APIRouter() @router.post(&#34;/users/{user_id}/email&#34;) async def send_user_email(worker: BackgroundTasks, user_id: UUID4): &#34;&#34;&#34;Send email to user&#34;&#34;&#34; worker.add_task(notifications_service.send_email, user_id) # send email after responding client return {&#34;status&#34;: &#34;ok&#34;} 8. 分块保存文件
不要希望您的客户会发送小文件。
import aiofiles from fastapi import UploadFile DEFAULT_CHUNK_SIZE = 1024 * 1024 * 50 # 50 megabytes async def save_video(video_file: UploadFile): async with aiofiles.open(&#34;/file/path/name.mp4&#34;, &#34;wb&#34;) as f: while chunk := await video_file.read(DEFAULT_CHUNK_SIZE): await f.write(chunk) 9. 小心动态的 pydantic 字段
如果您有一个可以接受类型联合的 pydantic 字段，请确保验证器明确知道这些类型之间的区别。
from pydantic import BaseModel class Article(BaseModel): text: str | None extra: str | None class Video(BaseModel): video_id: int text: str | None extra: str | None class Post(BaseModel): content: Article | Video post = Post(content={&#34;video_id&#34;: 1, &#34;text&#34;: &#34;text&#34;}) print(type(post.content)) # OUTPUT: Article # Article is very inclusive and all fields are optional, allowing any dict to become valid 不可怕的解决方案：
1.正确排序字段类型：从最严格的到松散的。
class Post(BaseModel): content: Video | Article p = Post(content={&#34;video_id&#34;: 1}) print(type(p.content)) # OUTPUT: Video 验证输入只有有效字段。  Pydantic 忽略联合类型的 ValueErrors 并对其进行迭代。 如果没有类型有效，则引发最后一个异常。
from pydantic import BaseModel, root_validator class Article(BaseModel): text: str | None extra: str | None @root_validator(pre=True) # validate all values before pydantic def has_only_article_fields(cls, data: dict): &#34;&#34;&#34;Silly and ugly solution to validate data has only article fields.&#34;&#34;&#34; fields = set(data.keys()) if fields != {&#34;text&#34;, &#34;extra&#34;}: raise ValueError(&#34;invalid fields&#34;) return data class Video(BaseModel): video_id: int text: str | None extra: str | None @root_validator(pre=True) def has_only_video_fields(cls, data: dict): &#34;&#34;&#34;Silly and ugly solution to validate data has only video fields.&#34;&#34;&#34; fields = set(data.keys()) if fields != {&#34;text&#34;, &#34;extra&#34;, &#34;video_id&#34;}: raise ValueError(&#34;invalid fields&#34;) return data class Post(BaseModel): content: Article | Video p = Post(content={&#34;video_id&#34;: 1}) print(type(p.content)) # OUTPUT: Video 如果字段很简单，请使用 Pydantic 的 Smart Union (&gt;v1.9)  如果字段像 int 或 bool 这样简单，这是一个很好的解决方案，但它不适用于像类这样的复杂字段。
没有智能联盟：
from pydantic import BaseModel class Post(BaseModel): field_1: bool | int field_2: int | str content: Article | Video p = Post(field_1=1, field_2=&#34;1&#34;, content={&#34;video_id&#34;: 1}) print(p.field_1) # OUTPUT: True print(type(p.field_2)) # OUTPUT: int print(type(p.content)) # OUTPUT: Article 使用智能联盟：
class Post(BaseModel): field_1: bool | int field_2: int | str content: Article | Video class Config: smart_union = True p = Post(field_1=1, field_2=&#34;1&#34;, content={&#34;video_id&#34;: 1}) print(p.field_1) # OUTPUT: 1 print(type(p.field_2)) # OUTPUT: str print(type(p.content)) # OUTPUT: Article, because smart_union doesn&#39;t work for complex fields like classes 10.如果一定要使用sync SDK，那就在线程池中运行
如果您必须使用 SDK 与外部服务交互，并且它不是异步的，那么请在外部工作线程中进行 HTTP 调用。
举个简单的例子，我们可以使用我们著名的来自 starlette 的 run_in_threadpool。
from fastapi import FastAPI from fastapi.concurrency import run_in_threadpool from my_sync_library import SyncAPIClient app = FastAPI() @app.get(&#34;/&#34;) async def call_my_sync_library(): my_data = await service.get_my_data() client = SyncAPIClient() await run_in_threadpool(client.make_request, data=my_data) FastAPI 是一种工具，可用于轻松构建极其简单和极其复杂的项目。 不是上面没有约定是项目不可维护的根源，而是缺乏一致性。
不管你有什么规则 - 唯一应该遵守的规则就是与你的规则保持一致。 找到一组行之有效的约定，对其进行迭代，并向其他人宣传它们。
]]></content></entry><entry><title>Chrome - 开发者工具</title><url>/tech/chrome/%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7/</url><categories><category>Chrome</category></categories><tags><tag>Chrome</tag></tags><content type="html"><![CDATA[应用 查看 cookies HttpOnly 代表是否只允许 http 请求获取 cookies
举例：当参数未开启 httpOnly 时，控制台通过 document.cookie 可以获取到该 cookie。
那么如果在链接中嵌套了该代码，就会容易造成 cookies 泄漏，比如：
&lt;a href=javascript:location.href=&#34;http://www.baidu.com?&#34;+document.cookis&gt; 兄弟，你想要的资源都在这，快来！ &lt;/a&gt; // 访问的链接就变成了 // https://www.baidu.com/?cookies1=8aa0c384-7883-480c-b407-b6a2c17b067c;cookies2=xxx 当参数未开启 HttpOnly 时，控制台通过 document.cookie 是获取不到的。
]]></content></entry><entry><title>Chrome - 插件管理</title><url>/tech/chrome/%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86/</url><categories><category>Chrome</category></categories><tags><tag>Chrome</tag></tags><content type="html">Cookie-Editor 网站 cookies 查看路径：chrome 开发者工具 - Application - cookies
管理网站的 cookies，支持 cookies 一键导出导入。</content></entry><entry><title>随笔 - Vscode</title><url>/tech/%E9%9A%8F%E7%AC%94/vscode/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html">注释代码折叠后，在后面继续写代码，折叠不生效，解决办法：
//#region /* 我是注释的代码块 */ //#endregion</content></entry><entry><title>Fastapi - 学习笔记</title><url>/tech/fastapi/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>Fastapi</category></categories><tags><tag>Fastapi</tag></tags><content type="html"><![CDATA[fastAPI 基于两个部分：
 pydantic starleete：python 异步 web 框架  ASGI 是后台服务与 python 框架之间的约定，不是可安装的包。
uvicorn 还得了解下
python 环境必须是 3.6+
教程代码片段 DEMO from fastapi import FastAPI # 创建 APP 实例 app = FastAPI() # 路径操作装饰器 @app.get(&#34;/&#34;) async def root(): &#34;&#34;&#34;路径操作函数&#34;&#34;&#34; return {&#34;message&#34;: &#34;Hello World&#34;} 路径参数 查询参数和字符串校验 使用 Query 为查询参数为参数声明额外的信息和校验。
实际上，Query、Path 和其他你将在之后看到的类，创建的是由一个共同的 Params 类派生的子类的对象，该共同类本身又是 Pydantic 的 FieldInfo 类的子类。
from typing import Union from fastapi import FastAPI, Query app = FastAPI() @app.get(&#34;/items/&#34;) async def read_items( q: Union[str, None] = Query( default=None, # 声明一个默认值，非必填，如果想要必填就别添加默认值或者默认值为 ... alias=&#34;item-query&#34;, # 别名 title=&#34;Query string&#34;, description=&#34;Query string for the items to search in the database that have a good match&#34;, min_length=3, # 参数校验：最小长度 max_length=50, # 参数校验：最大长度 regex=&#34;^fixedquery$&#34;, # 参数校验：正则 deprecated=True, # 废弃参数，如果为真则会在文档上高亮展示废弃提示 ) ): results = {&#34;items&#34;: [{&#34;item_id&#34;: &#34;Foo&#34;}, {&#34;item_id&#34;: &#34;Bar&#34;}]} if q: results.update({&#34;q&#34;: q}) return results 路径参数和数值校验 使用 Path 为路径参数声明相同类型的校验和元数据
from fastapi import FastAPI, Path, Query app = FastAPI() @app.get(&#34;/items/{item_id}&#34;) async def read_items( # 代表之后的参数都作为键值对来调用，即使没有默认值。完成对参数的排序 q 参数没有默认值可以排序到有默认值的 item_id 后面 *, item_id: int = Path(title=&#34;The ID of the item to get&#34;, ge=0, le=1000), q: str, size: float = Query(gt=0, lt=10.5), ): results = {&#34;item_id&#34;: item_id} if q: results.update({&#34;q&#34;: q}) return results 数值校验（适用于浮点型）：
 gt：大于（greater than） ge：大于等于（greater than or equal） lt：小于（less than） le：小于等于（less than or equal）  请求体 - 多个参数 多个请求体，Body 同样具有与 Query、Path 完全相同的额外交验与元数据参数。
from typing import Union from fastapi import FastAPI, Body from pydantic import BaseModel app = FastAPI() class Item(BaseModel): name: str description: Union[str, None] = None price: float tax: Union[float, None] = None class User(BaseModel): username: str full_name: Union[str, None] = None @app.put(&#34;/items/{item_id}&#34;) async def update_item(item_id: int, item: Item, user: User, importance: int = Body(gt=0)): # 多个请求体参数（Pydantic 模型） 会用参数名称作为键，形成一个合并的 json 体 results = { &#34;item_id&#34;: item_id, &#34;item&#34;: item, &#34;user&#34;: user, &#34;importance&#34;: importance # 新增一个参数到请求体中 } return results 上面多个请求体的情况下，会自动用参数名称作为键，形成一个合并的 json 请求体。
那在仅有一个请求体参数的情况下，默认是直接展示该模型的 json 内容，可以使用 Body(embed=True)，实现用参数名作为键嵌入到 json 体中。
// 默认是这样 { &#34;name&#34;: &#34;Foo&#34;, &#34;description&#34;: &#34;The pretender&#34;, &#34;price&#34;: 42.0, &#34;tax&#34;: 3.2 } // Body(embed=True) 后是这样 { &#34;item&#34;: { &#34;name&#34;: &#34;Foo&#34;, &#34;description&#34;: &#34;The pretender&#34;, &#34;price&#34;: 42.0, &#34;tax&#34;: 3.2 } } 请求体 - 字段 使用 Pydantic 的 Field 在模型内部声明校验和元数据。
Field 的工作方式和 Query、Path 和 Body 相同，包括它们的参数等等也完全相同。
from typing import Union from fastapi import Body, FastAPI from pydantic import BaseModel, Field app = FastAPI() class Item(BaseModel): &#34;&#34;&#34;必须先声明为模型类，才能对模型类属性使用 Field&#34;&#34;&#34; name: str description: Union[str, None] = Field( default=None, title=&#34;The description of the item&#34;, max_length=300 ) price: float = Field(gt=0, description=&#34;The price must be greater than zero&#34;) tax: Union[float, None] = None @app.put(&#34;/items/{item_id}&#34;) async def update_item(item_id: int, item: Item = Body(embed=True)): results = {&#34;item_id&#34;: item_id, &#34;item&#34;: item} return results 请求体 - 嵌套模型 from typing import List, Set, Union from fastapi import FastAPI from pydantic import BaseModel, HttpUrl app = FastAPI() class Image(BaseModel): &#34;&#34;&#34;定义子模型&#34;&#34;&#34; url: HttpUrl # 自动检查是否为有效的 URL name: str class Item(BaseModel): name: str description: Union[str, None] = None price: float tax: Union[float, None] = None tags: Set[str] = set() # 设置为一个集合，自动去重 images: Union[List[Image], None] = None # item 内嵌套 images 模型列表 @app.put(&#34;/items/{item_id}&#34;) async def update_item(item_id: int, item: Item): results = {&#34;item_id&#34;: item_id, &#34;item&#34;: item} return results 请求体数据如下：
{ &#34;name&#34;: &#34;Foo&#34;, &#34;description&#34;: &#34;The pretender&#34;, &#34;price&#34;: 42.0, &#34;tax&#34;: 3.2, &#34;tags&#34;: [ &#34;rock&#34;, &#34;metal&#34;, &#34;bar&#34; ], &#34;images&#34;: [ { &#34;url&#34;: &#34;http://example.com/baz.jpg&#34;, &#34;name&#34;: &#34;The Foo live&#34; }, { &#34;url&#34;: &#34;http://example.com/dave.jpg&#34;, &#34;name&#34;: &#34;The Baz&#34; } ] } 还可以继续深度嵌套模型，比如增加一个 Offer，将 item 作为它的子模型，其中 item 内又包含 image 子模型。
class Offer(BaseModel): name: str description: Union[str, None] = None price: float items: List[Item] 还可以定义纯列表请求体
from typing import List from fastapi import FastAPI from pydantic import BaseModel, HttpUrl app = FastAPI() class Image(BaseModel): url: HttpUrl name: str @app.post(&#34;/images/multiple/&#34;) async def create_multiple_images(images: List[Image]): return images 如果请求体中的键是非字符串型，比如 weights: Dict[int, float]，但是 Json 仅支持将字符串作为键。
这种情况下，pydantic 还会自动类型转换为字符串。
添加示例 传递的示例参数，不会用于任何验证，这是在文档上用于注释的目的。
除此之外还有两种方式：
 通过定义模型子类 Config 的 schema_extra 属性，添加示例 通过 Body(example={})，Query、Path 等都支持，添加示例  具体参考 官方文档  。
from typing import Union from fastapi import FastAPI from pydantic import BaseModel, Field app = FastAPI() class Item(BaseModel): name: str = Field(example=&#34;Foo&#34;) description: Union[str, None] = Field(default=None, example=&#34;A very nice Item&#34;) price: float = Field(example=35.4) tax: Union[float, None] = Field(default=None, example=3.2) @app.put(&#34;/items/{item_id}&#34;) async def update_item(item_id: int, item: Item): results = {&#34;item_id&#34;: item_id, &#34;item&#34;: item} return results cookie 使用 Cookie 声明 cookie 参数，使用方式与 Query 和 Path 类似。
from typing import Union from fastapi import Cookie, FastAPI app = FastAPI() @app.get(&#34;/items/&#34;) async def read_items(ads_id: Union[str, None] = Cookie(default=None)): return {&#34;ads_id&#34;: ads_id} header 使用 Header 来声明 header , 使用和 Query, Path 与 Cookie 相同的模式。
不用担心变量中的下划线，FastAPI 会负责转换它们。
from typing import Union from fastapi import FastAPI, Header app = FastAPI() @app.get(&#34;/items/&#34;) async def read_items( # convert_underscores 下划线到连字符的自动转换，默认自动转换 strange_header: Union[str, None] = Header(default=None, convert_underscores=False) ): return {&#34;strange_header&#34;: strange_header} 响应模型 from typing import Union from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class Item(BaseModel): &#34;&#34;&#34;创建数据模型&#34;&#34;&#34; name: str description: Union[str, None] = None price: float tax: float = 10.5 items = { &#34;foo&#34;: {&#34;name&#34;: &#34;Foo&#34;, &#34;price&#34;: 50.2}, &#34;bar&#34;: {&#34;name&#34;: &#34;Bar&#34;, &#34;description&#34;: &#34;The Bar fighters&#34;, &#34;price&#34;: 62, &#34;tax&#34;: 20.2}, &#34;baz&#34;: { &#34;name&#34;: &#34;Baz&#34;, &#34;description&#34;: &#34;There goes my baz&#34;, &#34;price&#34;: 50.2, &#34;tax&#34;: 10.5, }, } @app.get( &#34;/items/{item_id}/name&#34;, response_model=Item, # 执行返回的数据模型 response_model_include=[&#34;name&#34;, &#34;description&#34;], ) async def read_item_name(item_id: str): return items[item_id] @app.get(&#34;/items/{item_id}/public&#34;, response_model=Item, response_model_exclude=[&#34;tax&#34;]) async def read_item_public_data(item_id: str): return items[item_id] 装饰器参数：
 response_model_exclude_unset：排除未传入的字段，也就是仅有预设的默认值字段，如果设置的值与默认值相同，不会被排除掉。 response_model_include：向响应模型内增加字段，列表或集合，列表会自动转成集合 response_model_exclude：手动设置排除字段，需要是列表或集合  响应状态码 from fastapi import FastAPI, status app = FastAPI() @app.post(&#34;/items/&#34;, status_code=status.HTTP_201_CREATED) async def create_item(name: str): return {&#34;name&#34;: name} 表单数据 from fastapi import FastAPI, Form app = FastAPI() @app.post(&#34;/login/&#34;) async def login(username: str = Form(), password: str = Form()): return {&#34;username&#34;: username} ]]></content></entry><entry><title>功能测试 - 测试点分析</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%B5%8B%E8%AF%95%E7%82%B9%E5%88%86%E6%9E%90/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html">测试人员需要能够在软件开发过程中，基于软件的需求文档或者功能说明书，准确的识别和描述每一个功能点。
列举功能点是测试人员的必备技能之一，因为测试人员需要从功能的角度来评估软件的质量，以确保软件的功能符合用户的期望和需求。通过列举功能点，测试人员可以更好地了解软件的功能，从而准确地设计测试用例和测试场景，并在软件开发的不同阶段发现和报告缺陷。此外，测试人员还需要考虑到软件的性能、安全性和兼容性等方面，以确保软件的稳定性和可靠性。因此，对于测试人员来说，能够准确地列举功能点是非常重要的，这样才能够保证软件的质量和用户的满意度。
列举所有测试点可以帮助进行全面的软件测试，从而更好地保障软件的质量和可靠性。
用户界面测试点可以确保软件界面的友好性和易用性
功能性测试点可以确保软件功能符合用户需求和预期
性能测试点可以确保软件的性能符合用户的要求和预期
安全性测试点可以确保软件的安全性和保护用户数据和隐私
兼容性测试点可以确保软件在不同的平台和设备上都能够正常运行
全面的测试和评估可以提高软件的可靠性和稳定性，提高用户体验和用户满意度。
用户界面测试点 一个软件的界面布局和设计的可用性对于用户体验和软件质量有着至关重要的影响。一个好的界面设计需要考虑到用户的需求和习惯，使得用户能够方便地使用和操作软件。同时，良好的界面设计还能够提高用户的工作效率和满意度。界面布局需要合理，页面元素需要有组织和结构，以便用户快速找到所需的信息和功能。设计的可用性还需要考虑到不同用户的需求和使用环境，例如色盲或者有视力问题的用户等等。此外，还需要考虑到不同的设备和分辨率。通过对界面布局和设计的细致考虑，测试人员可以更好地评估软件的可用性和用户体验，并提出改进意见和建议，以提高软件的质量和用户满意度。
在软件测试中，用户输入和交互的准确性是一个非常重要的方面。准确的用户输入和良好的交互设计可以确保软件的功能正常运行，同时也可以强化用户体验和用户满意度。测试人员需要确保软件能够正确地接收和处理用户的输入，并且能够给予用户正确的反馈。同时，测试人员还需要测试软件的交互设计，以确保软件的操作流程和界面设计符合用户的期望和需求。测试人员还需要考虑到不同的用户场景和使用环境，例如输入的字符集、输入的格式、输入的长度等等，以确保软件能够正确处理各种情况下的用户输入。通过对用户输入和交互的准确性进行全面的测试和评估，测试人员可以发现并报告软件中的缺陷和问题，从而提高软件的可靠性和稳定性，提高软件的质量和用户体验。
在软件测试中，显示和错误信息的正确性也是非常重要的方面。良好的显示设计可以帮助用户快速地找到所需的信息和功能，同时正确性的错误信息也能够帮助用户更好地理解软件的问题并采取正确的解决方法。测试人员需要确保软件的显示信息和错误信息都是准确的，能够精确地反映软件的状态和问题。测试人员还需要测试软件在不同的环境和场景下的显示效果和错误信息的反馈，以确保软件能够正确地展示和处理各种情况下的信息。同时，测试人员还需要考虑到不同用户的需求和使用环境，例如不同语言和文化背景的用户等等，以确保软件的显示和错误信息能够适应不同用户的需求。通过对显示和错误信息的正确性进行全面的测试和评估，测试人员可以发现并报告软件中的缺陷和问题，从而提高软件的可靠性和稳定性，提高软件的质量和用户体验。
功能性测试点 软件的功能完整性指的是软件能够满足所有设计和规格要求的功能，包括基本的必需功能和额外的可选功能。而正确性则是指软件能够按照预期的要求和标准执行这些功能，且不会出现任何错误或异常情况。为了确保软件的功能完整性和正确性，需要进行各种测试，例如功能测试、回归测试、验收测试等。在测试过程中，需要验证软件是否满足所有的规格和需求，是否能够正确地执行所有的功能，以及是否存在任何错误或异常。如果发现了任何问题，需要及时解决并进行迭代测试，直到软件达到预期的功能完整性和正确性标准。只有通过全面和严格的测试，才能确保软件的可靠性、稳定性和用户满意度。
软件的输入输出准确性是指软件能够正确地接收和处理用户的输入数据，并按照预期的方式生成正确的输出结果。在软件开发过程中，需要考虑各种可能的输入情况和输入数据的格式、类型、范围等因素，以及生成输出结果的算法、逻辑和格式。为了确保输入输出的准确性，需要进行各种测试，例如边界测试、异常测试、格式测试等。在测试过程中，需要验证软件是否能够正确地处理各种输入数据，是否能够生成正确的输出结果，以及是否存在任何错误或异常。如果发现了任何问题，需要及时解决并进行迭代测试，直到软件达到预期的输入输出准确性标准。输入输出准确性是软件可靠性和稳定性的重要指标，它直接影响用户体验和用户满意度。因此，在软件开发过程中，必须注重输入输出准确性的测试和评估，以保证软件的质量和可靠性。
软件的功能是否符合需求规格说明是指软件能够满足用户需求和需求规格说明中所列举的所有功能要求。在软件开发过程中，需要详细了解用户需求和需求规格说明，并将它们转化为具体的软件功能要求。为了确保软件功能符合需求规格说明，需要进行各种测试，例如验收测试、用户场景测试、功能测试等。在测试过程中，需要验证软件能够按照需求规格说明中的要求执行各种功能，是否存在任何功能缺陷或功能冲突。如果发现了任何问题，需要及时解决并进行迭代测试，直到软件达到符合需求规格说明的标准。功能符合需求规格说明是软件开发过程中的重要目标和指标，它直接影响软件的用户满意度和市场竞争力。因此，必须注重功能符合需求规格说明的测试和评估，以保证软件的质量和可靠性。
性能测试点 系统的负载和响应时间是指在系统运行过程中，能够承受的最大负载和响应用户请求的时间。在实际应用中，系统的负载和响应时间是影响用户体验和用户满意度的重要因素。为了确保系统的负载和响应时间达到预期水平，需要进行各种测试，例如性能测试、压力测试、负载测试等。在测试过程中，需要验证系统能够在高负载情况下正常运行，是否存在性能瓶颈或资源竞争问题，并且需要测试系统的响应时间是否符合用户的期望。如果发现了任何问题，需要及时解决并进行迭代测试，直到系统达到预期的负载和响应时间标准。系统的负载和响应时间是系统可靠性和稳定性的重要指标，它直接影响用户体验和用户满意度。因此，在系统开发过程中，必须注重负载和响应时间的测试和评估，以保证系统的质量和可靠性。
要测试系统的稳定性和可靠性，需要从多个方面进行测试，例如功能测试、性能测试、压力测试、容错测试等。在功能测试中，需要验证系统的各项功能是否正常运行，是否符合用户需求和规格说明。在性能测试中，需要测试系统的响应速度、吞吐量和资源利用率等指标，以评估系统的性能。在压力测试中，需要模拟高负载情况下的系统运行，以测试系统的稳定性和可靠性。在容错测试中，需要测试系统的容错能力，例如测试系统在出现故障时是否能够快速恢复和保持服务的正常运行。同时，还需要进行安全测试，以评估系统的安全性和可靠性。通过综合测试和评估，可以全面地评估系统的稳定性和可靠性，并采取相应的措施和策略，以提高系统的质量和可靠性。
数据处理和存储的效率是指在数据处理和存储过程中，所需的时间和资源的使用效率。对于大规模的数据处理和存储任务，效率是至关重要的，因为它直接影响到系统的性能和响应时间。高效的数据处理和存储可以提高数据的可用性和可靠性，同时也能够减少系统的维护成本和资源消耗。为了提高数据处理和存储的效率，可以采用多种方法，如优化算法和数据结构、提高硬件性能、使用分布式存储和计算等技术。此外，还可以通过合理的数据压缩和索引等手段来减少数据存储的空间和提高数据查询的速度。总的来说，高效的数据处理和存储可以提高系统的性能和可靠性，从而更好地满足用户的需求。
安全性测试点 数据的安全性和保密性是指保护数据不被未授权的人员访问、修改、删除或泄露的能力。为了确保数据的安全性和保密性，需要进行全面的测试和评估。以下是常见的测试点：
访问控制：测试系统是否设置了适当的访问控制规则，包括身份验证、权限控制和审计日志等。 数据加密：测试系统是否使用了合适的加密算法和密钥管理来保护数据的机密性和完整性。 数据备份和恢复：测试系统是否支持及时的数据备份和恢复，以确保在数据丢失或系统故障时能够快速恢复数据。 安全审计：测试系统是否能够记录和报告安全事件和异常行为，以及是否具备及时响应和处理安全问题的能力。 网络安全：测试系统是否有防火墙、反病毒软件等网络安全措施，以保护系统免受网络攻击和恶意软件的侵害。 物理安全：测试系统是否有物理安全措施，如门禁、监控摄像头等，以保护服务器和存储设备不被未授权的人员访问。 威胁模拟：测试系统是否能够模拟各种安全威胁和攻击，以测试系统的安全性和弱点。 数据的安全性和保密性是现代应用程序的核心要求之一，必须进行全面的测试和评估，以确保系统的安全性和可靠性。
用户认证和授权的正确性是指系统能够正确地验证用户的身份，并且只授权给已认证用户所允许的操作和访问权限。以下是常见的测试点：
身份验证：测试系统是否能够正确验证用户的身份，包括用户名、密码、指纹、面部识别等。 会话管理：测试系统是否能够正确管理用户会话，包括会话过期时间、会话注销等，以确保用户的安全和隐私。 授权管理：测试系统是否能够正确授权用户的操作和访问权限，并能够限制用户的访问范围和操作权限。 安全审计：测试系统是否能够记录和报告安全事件和异常行为，以及是否具备及时响应和处理安全问题的能力。 单点登录：测试系统是否支持单点登录，即用户只需登录一次即可访问多个应用程序或系统。 多因素认证：测试系统是否支持多因素认证，如短信验证码、令牌等，以提高系统的安全性和可靠性。 异地登录检测：测试系统是否能够检测和防止异地登录，以避免用户的账号被盗用或不当使用。 用户认证和授权的正确性是现代应用程序的核心要求之一，必须进行全面的测试和评估，以确保系统的安全性和可靠性。
兼容性测试点 确保软件在不同操作系统和浏览器上的兼容性也是软件测试中非常重要的一个方面。以下是一些测试点：
标准兼容性：测试软件是否符合W3C标准和其他行业标准，以确保在各种浏览器和操作系统上的兼容性。 应用程序接口（API）兼容性：测试软件是否能够正确地与各种API进行交互，以确保在不同操作系统和浏览器中的兼容性。 浏览器兼容性：测试软件在不同浏览器上的兼容性，包括Internet Explorer、Firefox、Chrome、Safari等。 操作系统兼容性：测试软件在不同操作系统上的兼容性，包括Windows、Mac OS、Linux等。 分辨率和屏幕大小兼容性：测试软件在不同分辨率和屏幕大小上的兼容性，以确保在各种设备上的兼容性。 输入设备兼容性：测试软件是否能够正确地与各种输入设备进行交互，包括鼠标、键盘、触摸屏等。 多语言兼容性：测试软件在不同语言环境下的兼容性，包括中文、英文、法语、西班牙语等。 通过对以上测试点的全面测试，可以帮助确保软件在各种操作系统和浏览器上的兼容性，提高用户的使用体验和满意度。
另外确保软件在不同设备和分辨率上的兼容性也是一个不容忽视的方面。以下是一些测试点：
设备兼容性：测试软件在不同设备上的兼容性，包括PC、手机、平板电脑等。 分辨率兼容性：测试软件在不同分辨率上的兼容性，包括低分辨率、高分辨率等。 屏幕大小兼容性：测试软件在不同屏幕大小上的兼容性，包括小屏幕、大屏幕等。 操作系统兼容性：测试软件在不同操作系统上的兼容性，包括Windows、Mac OS、Linux、iOS、Android等。 输入设备兼容性：测试软件是否能够正确地与各种输入设备进行交互，包括鼠标、键盘、触摸屏等。 电池寿命兼容性：测试软件对设备电池寿命的影响，以确保软件在不同设备上的兼容性和用户体验。 多语言兼容性：测试软件在不同语言环境下的兼容性，包括中文、英文、法语、西班牙语等。 通过对以上测试点的全面测试，可以帮助确保软件在不同设备和分辨率上的兼容性，提高用户的使用体验和满意度。</content></entry><entry><title>Database - 免费在线Mysql服务</title><url>/tech/database/%E5%85%8D%E8%B4%B9%E5%9C%A8%E7%BA%BFmysql%E6%9C%8D%E5%8A%A1/</url><categories><category>Database</category></categories><tags><tag>Database</tag></tags><content type="html">由于本地开发一套后端服务，需要用到 MYSQL 数据库，通过 Mac Docker Desktop 启动容器后，电脑资源直接拉满了，风扇呼呼的转。
所以找到了一个在线的 MYSQL 服务，体验一下。
体验地址： SVNCloud ，需要先注册。
有 5M 的免费存储。
突然发现，还有 redis 需要部署。</content></entry><entry><title>Jenkins - Gitlab Webhook触发Jenkins构建任务</title><url>/tech/jenkins/%E9%80%9A%E8%BF%87gitlab-webhook%E6%9E%84%E5%BB%BA%E4%BB%BB%E5%8A%A1/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[ 提交项目到 gitlab 仓库，通过 webhook 自动构建 Jenkins 项目。
 GitLab 社区版 10.8.7 Jenkins 2.346.3 (Docker jenkinsci/blueocean:latest)   Jenkins 创建构建项目 安装 Gitlab 插件 安装路径：左侧边栏 系统管理 -&gt; 插件管理 -&gt; 可选插件
插件名称：Gitlab
安装成功后，重启 Jenkins 使插件生效，访问 /restart 路由即可重启。
版本与插件不兼容的话，参考：https://juejin.cn/post/6844903997984210958
创建项目  创建一个自由风格的项目 构建触发器 - 触发远程构建 设置一个远程访问 token，可选 Webhook URL：JENKINS_URL/job/JOB_NAME/build?token=TOKEN_NAME 保存设置  GitLab 创建 Webhook  Webhook  是一种用户自定义的 HTTP 回调。
在 Gitlab 项目上创建一个自定义的 URL 地址，当向仓库推送代码或提交 Issues 时，会自动向配置的 URL 地址发送一个 HTTP 请求。
创建方式：
 左侧边栏中选择 Settings &gt; Webhooks（集成） URL：输入 Jenkins Webhook URL（特殊字符及汉字需要 URL 编码） Secret token：输入 Jenkins 项目设置的 token 触发器：选择要触发 webhook 的 事件  ，默认推送事件，表示仓库中有代码提交时触发 Webhook SSL 证书验证：需安全验证时开启，一般不用 增加 webhook  测试：点击 Test -&gt; Push events
Hook execution failed: URL &#39;xxx&#39; is blocked: Requests to the local network are not allowed 出现该问题是由于我这里 Gitlab 服务放在公网，而 Jenkins 搭建在内网，无法通信。如果是在同一网络环境出现该问题：
 Jenkins 默认不允许从外部网络访问本地地址，在系统管理 -&gt; 安全设置里面开启允许外部 HTTP 请求 管理员访问 /admin/application_settings，在 Settings -&gt; Networks -&gt; Outbound requests 选项下开启 Allow requests to the local network from hooks and services  注意：以上两种方式我是从网上查到的，由于不在统一网络环境下，所以这两种方式我未做尝试。
正常情况下，测试通过，那就配置完成了。可以提交一次检查是否会自动构建。
TODO 由于网络原因，没办法做成 webhook 来触发构建。所以我在 Jenkins 项目中使用了「轮询」的方式，每 5 分钟检查是否有更新，有则构建无则忽略。
配置方式：项目设置 -&gt; 构建触发器 -&gt; 轮询 SCM -&gt; 配置日程表达式H/5 * * * *，每 5 分钟轮询一次仓库。
]]></content></entry><entry><title>Linux - Openvpn 使用</title><url>/tech/linux/openvpn-%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[在服务器上通过 OpenVPN Client 连接 VPN 访问内网。
安装 安装 OpenVPN 客户端软件。可以使用以下命令安装 OpenVPN 客户端：
$ sudo apt-get update $ sudo apt-get install openvpn 配置 添加配置文件
$ cd /etc/openvpn/client # 在这里放入 *.conf 配置文件，可找公司运维申请 配置文件示例
# OpenVPN client configuration file # 指定 OpenVPN 客户端模式 client # 指定使用 TUN 设备来创建 VPN 连接 dev tun # 指定 VPN 服务器的地址和端口号 remote myvpn.example.com 1194 udp # 指定密码文件 askpass /etc/openvpn/client/pwd.pass # 指定解析 DNS 失败后应该尝试多少次重新解析 DNS（无限次） resolv-retry infinite # 禁用绑定到本地 IP 地址和端口号 nobind # 使 OpenVPN 在重新启动时不生成新的密钥或 TUN/TAP 设备 persist-key persist-tun # 配置证书和密钥文件的位置和名称 ca /etc/openvpn/ca.crt cert /etc/openvpn/client.crt key /etc/openvpn/client.key tls-auth /etc/openvpn/ta.key 1 # 指定 OpenVPN 连接的保持时间和间隔时间 keepalive 10 120 # 指定检测连接是否断开以及重新启动连接的频率 ping 10 ping-restart 60 # 指定使用的加密算法 cipher AES-256-CBC # 指定压缩算法 compress lz4-v2 # 限制 OpenVPN 进程的用户和组 user nobody group nogroup # 指定日志输出级别和控制台输出的信息数量 verb 3 mute 20 启动 手动启动测试连接 $ openvpn --config /etc/openvpn/client/${配置文件名}.conf 2023-05-16 08:18:28 Initialization Sequence Completed # 测试连接是否成功 # 重新打开一个窗口，进入服务器 $ ping 172.xx.xxx.xxx PING xxx 56(84) bytes of data. 64 bytes from xxx: icmp_seq=1 ttl=62 time=25.9 ms # Ctrl + C 结束 当结束命令后，服务器与内网的连接也就自动关闭了，可用作测试配置是否能够正确连接。
自动启动 后台开启 VPN 服务的方法：
# 方式一：--daemon 参数会将 OpenVPN 服务置于后台，并且不显示任何日志信息 $ openvpn --config /etc/openvpn/client/conf_file.conf --daemon $ openvpn --config /etc/openvpn/client/conf_file.conf --daemon --log /var/log/openvpn.log # 方式二：使用 nohup 命令将 OpenVPN 进程转移到后台执行 $ nohup sudo openvpn --config /etc/openvpn/client/conf_file.conf &gt; /var/log/openvpn.log &amp; 以上方式虽然将命令运行在后台，但是存在问题：运行一段时间后，OpenVPN 会自动断开连接重新校验密码，导致服务报错。
报错日志如下，怎么解决没找到方案，参考： Github Issues 36  
2023-05-17 09:14:27 [ursnsqvmqxwe.6du.cn] Inactivity timeout (--ping-restart), restarting 2023-05-17 09:14:27 net_addr_ptp_v4_del: 192.168.20.74 dev tun0 2023-05-17 09:14:27 SIGUSR1[soft,ping-restart] received, process restarting Failed to query password: Timer expired 2023-05-17 09:16:02 ERROR: Failed retrieving username or password 2023-05-17 09:16:02 Exiting due to fatal error 通过系统命令启动 当 OpenVPN 断开连接后会尝试重连
# 注意：conf_file 不需加 .conf 后缀 $ systemctl start openvpn-client@conf_file $ systemctl status openvpn-client@conf_file # 设置开机自启动 $ systemctl enable openvpn-client@conf_file 执行 ping 命令，这时运维同学手动断开该用户连接，可以看到收发包中断，此时重启服务。
虽然是重启服务了，但是需要手动输入密码，这可不行~
Broadcast message from root@test (Thu 2023-05-18 07:35:22 UTC): Password entry required for &#39;Enter Private Key Password:&#39; (PID 2864927). Please enter password with the systemd-tty-ask-password-agent tool. 遇到该问题在 conf 配置文件中去掉 auth-nocache （阻止密码缓存）参数，可能是 Ubuntu 的原因，其他系统上没出该问题。
查看服务 不管通过哪种方式启动，当连接出现问题时，就需要查看进程，来判断服务是否正常运行。
$ ps -ef | grep openvpn | grep -v grep # 结束进程 $ kill -9 进程号 ]]></content></entry><entry><title>Python - Dotenv 加载环境变量</title><url>/tech/python/dotenv-%E5%8A%A0%E8%BD%BD%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[Python-dotenv 是一个用于从.env文件中加载环境变量的 Python 库。.env文件通常用于保存敏感信息，如 API 密钥、密码、数据库连接字符串等，可以避免这些敏感信息被意外地提交到版本控制系统中。
使用 Python-dotenv 可以方便地将.env文件中的所有变量加载到当前 Python 进程的环境变量中。
使用 安装 Python-dotenv 库
$ pip install python-dotenv 创建.env文件，并在其中添加需要的环境变量
DATABASE_URL=mysql://user:password@localhost/mydatabase API_KEY=1234567890abcdef 在程序中加载.env文件，该代码会自动查找名为 .env 的文件，并将其中的所有变量设置为当前进程的环境变量。
from dotenv import load_dotenv # 加载 .env 文件 load_dotenv() 使用环境变量
import os database_url = os.environ[&#39;DATABASE_URL&#39;] api_key = os.environ[&#39;API_KEY&#39;] 加载 .env 文件只需要在程序开头执行一次即可，不需要多次加载。在部署应用程序时，也应该避免将该文件提交到版本控制系统中，以保护敏感信息的安全性。
]]></content></entry><entry><title>Database - Mysql 查看连接数</title><url>/tech/database/mysql-%E6%9F%A5%E7%9C%8B%E8%BF%9E%E6%8E%A5%E6%95%B0/</url><categories><category>Database</category></categories><tags><tag>Database</tag></tags><content type="html"><![CDATA[# 查看当前数据库连接数 mysql&gt; show status like &#39;Threads%&#39;; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 1 | | Threads_connected | 2 | | Threads_created | 3 | | Threads_running | 1 | +-------------------+-------+ 4 rows in set (0.04 sec) # 查看当前数据库连接详细信息 # 主要是查这个表 information_schema.processlist mysql&gt; show processlist; +----+------+-----------+------+---------+-------+----------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+------+-----------+------+---------+-------+----------+------------------+ | 16 | root | localhost | test | Sleep | 14754 | | NULL | | 62 | root | localhost | NULL | Query | 0 | starting | show processlist | +----+------+-----------+------+---------+-------+----------+------------------+ 2 rows in set (0.00 sec) # 可以通过如下命令查看每个用户的连接数 mysql&gt; SELECT user, count(*) as connections FROM information_schema.processlist WHERE user &lt;&gt; &#39;system user&#39; GROUP BY user; +------+-------------+ | user | connections | +------+-------------+ | root | 2 | +------+-------------+ 1 row in set (0.00 sec) 该命令会返回所有当前连接的信息，包括连接 ID、用户名、主机名、数据库名、状态等。以下是各个字段的具体解释：
 Id：连接的线程 ID。 User：连接使用的用户名。 Host：连接所在的主机名或 IP 地址。 db：当前连接正在使用的数据库名。 Command：当前连接正在执行的 MySQL 命令或操作类型（如 Sleep、Query 等）。 Time：当前连接已经执行的时间，单位为秒。 State：当前连接的状态。 Info：当前连接正在执行的 SQL 语句或者其他操作信息。  其中，前四个字段（即 Id、User、Host 和 db）是最常用的连接信息，可以帮助用户了解与 MySQL 服务器建立连接的应用程序和客户端的基本情况，以便进行性能分析、优化和限制等操作。
 sqlalchemy 为什么建立了连接，且没有显式的关闭连接，但是在 mysql 中查看 processlist 的时候不显示呢？
备注：以下回答来自 chatGPT，我在官方文档没有查到准确的信息，并不确定是否正确。
 在使用SQLAlchemy连接MySQL数据库时，有一种称为&quot;连接池&quot;的机制。连接池是一种用于管理数据库连接的技术，其主要作用是将来自不同用户的数据库连接组织在一起，并在需要时分配给相应的用户。
当使用SQLAlchemy连接MySQL数据库时，默认情况下会启用连接池机制，这意味着即使您没有显式地关闭连接，连接也会保持打开状态以备重用。但是，这些连接不会一直在MySQL服务器上处于活动状态，而是在一段时间后变为“空闲”状态，等待下一个请求到来。
因此，在MySQL中查看processlist时，可能不会显示由SQLAlchemy连接池管理的空闲连接。这是因为这些连接实际上处于空闲状态，不占用任何资源，因此它们被MySQL服务器视为无效连接而被忽略掉了。
总之，这种行为是正常的，并不表示您的连接没有成功建立或已经关闭。如果您确实想要检查连接是否成功关闭，可以通过编写相应的代码来进行明确的关闭，而不是依赖连接池管理机制。
]]></content></entry><entry><title>Python - Sqlalchemy Navicat导出表结构并转为Orm类</title><url>/tech/python/sqlalchemy-navicat%E5%AF%BC%E5%87%BA%E8%A1%A8%E7%BB%93%E6%9E%84%E5%B9%B6%E8%BD%AC%E4%B8%BAorm%E7%B1%BB/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[在Navicat中，可以通过导出数据库表结构的方式来快速获取表结构，并转换成 SQLAlchemy ORM 框架中的 ORM 对象。
获取建表信息 打开 Navicat 并连接到相应的数据库，找到表后右键，选择「打印表」
然后就显示出来建表信息了~
网上说的邮件查看「对象信息」我找不到这个选项，就先这样了。
按照以上建表信息，用 python 创建一个 ORM 对象。
 选择文件格式：SQL 脚本文件（*.sql） 选择保存路径 选择表字段 选择附加选项 开始导出（我这里数据太多了就先不导出了）  具体操作步骤如下：
 打开Navicat并连接到相应的数据库。 选择要导出表结构的数据表，右键点击该表并选择“导出表”。 在弹出的“导出表”对话框中，选择“自定义”选项卡，并勾选“仅导出表结构”复选框。 点击“设置”按钮，进入“导出设置”对话框。在该对话框中，可以设置导出文件的名称、格式、编码等参数。 点击“确定”按钮开始导出表结构文件。导出文件将保存为一个SQL脚本文件（.sql）。 将导出的SQL脚本文件打开，并将其中的DDL语句（CREATE TABLE语句）复制到Python代码中。 在Python代码中，使用SQLAlchemy ORM框架提供的declarative_base()函数创建一个基础ORM类。该类用于表示所有ORM类的基类，并提供一些常用的方法和属性。 根据复制的DDL语句，手动编写一个ORM类，并继承自基础ORM类。该ORM类需要定义与DDL语句中各列对应的字段名、数据类型、约束条件等属性，并在类中定义相应的构造方法和其他方法。 在Python代码中，使用SQLAlchemy ORM框架提供的create_all()方法创建数据库表。该方法会自动根据ORM类生成相应的数据表，并将其映射到数据库中。  下面是一份示例代码，供参考：
from sqlalchemy import create_engine, Column, Integer, String from sqlalchemy.ext.declarative import declarative_base # 创建SQLAlchemy引擎对象并连接数据库 engine = create_engine(&#34;mysql+pymysql://user:password@localhost/database&#34;) # 创建基础ORM类 Base = declarative_base() # 定义ORM类MyTable，表示DDL语句中的数据表 class MyTable(Base): __tablename__ = &#34;my_table&#34; id = Column(Integer, primary_key=True) name = Column(String(255)) age = Column(Integer) def __init__(self, name, age): self.name = name self.age = age def __repr__(self): return &#34;&lt;MyTable(name=&#39;%s&#39;, age=%d)&gt;&#34; % (self.name, self.age) # 创建数据表 Base.metadata.create_all(engine) 在上述代码中，我们首先使用create_engine()函数创建了一个SQLAlchemy引擎对象，并指定了相应的连接参数。然后，使用declarative_base()函数创建了一个基础ORM类Base，用于表示所有ORM类的基类。
接着，手动编写了一个ORM类MyTable，用于表示DDL语句中的数据表。该类继承自基础ORM类Base，并定义了与DDL语句中各列对应的字段名、数据类型、约束条件等属性。此外，还定义了构造方法__init__()和字符串表示方法__repr__()。
最后，使用Base.metadata.create_all(engine)方法创建了数据表。该方法会自动根据ORM类生成相应的数据表，并将其映射到数据库中。
需要注意的是，在手动编写ORM类时，需要严格按照DDL语句中各列的属性、约束等信息进行设置。同时，还需要遵循SQLAlchemy ORM框架的一些规范和约定，例如使用双下划线__tablename__指定数据表名，添加主键约束等。
]]></content></entry><entry><title>Git - 存在Git子目录时提交失败解决</title><url>/tech/git/%E5%AD%98%E5%9C%A8git%E5%AD%90%E7%9B%AE%E5%BD%95%E6%97%B6%E6%8F%90%E4%BA%A4%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[在 Hugo 中使用主题时，通常需要将主题存储在一个单独的 Git 仓库中，并在 Hugo 项目中将其作为子模块引入。当在 Hugo 项目中执行 git add 命令时，如果你主题目录中包含一个 .git 子目录，Git 就会给出下面的警告。
$ git add . warning: adding embedded git repository: themes/hugo-theme-next hint: You&#39;ve added another git repository inside your current repository. hint: Clones of the outer repository will not contain the contents of hint: the embedded repository and will not know how to obtain it. hint: If you meant to add a submodule, use: hint: hint: git submodule add &lt;url&gt; themes/hugo-theme-next hint: hint: If you added this path by mistake, you can remove it from the hint: index with: hint: hint: git rm --cached themes/hugo-theme-next hint: hint: See &#34;git help submodule&#34; for more information. 方法一（不推荐）
忽略警告并继续添加文件。
在某些情况下，如果希望将主题作为子模块直接包含在 Hugo 项目中，且确认这样做是安全和必要的，则可以忽略该警告，并继续执行 git add 命令。
$ git add -f themes/hugo-theme-next 请注意，在添加嵌套的 Git 仓库时，Git 可能会折叠提交历史记录，从而导致一些问题。因此，应该谨慎使用该方法，并确保了解其潜在影响。
方法二（推荐）
将子模块添加到 .gitignore 文件中，这样 Git 就会忽略该子目录，并不再发出警告。
在 Hugo 项目根目录下的 .gitignore 文件添加以下行：
themes/hugo-theme-next/.git 后续应该在每次更新主题时显式地执行 git submodule update 命令，以确保本地子模块与远程存储库同步。
]]></content></entry><entry><title>Python - Frontmatter实现自动添加Md文件前置元信息</title><url>/tech/python/frontmatter%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0md%E6%96%87%E4%BB%B6%E5%89%8D%E7%BD%AE%E5%85%83%E4%BF%A1%E6%81%AF/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ 使用 hugo 搭建个人博客，维护文件头部的 frontmatter 变更非常麻烦，这里通过自动化来统一添加。
 环境配置 安装依赖库：frontmatter
$ pip install python-frontmatter 代码 已更新到博客仓库，这里可能不是最新。
import os import re from datetime import datetime import frontmatter def get_file_creation_time(file_path): &#34;&#34;&#34;获取文件的创建时间&#34;&#34;&#34; stat = os.stat(file_path) return datetime.fromtimestamp(stat.st_birthtime) def get_file_modification_time(file_path): &#34;&#34;&#34;获取文件的修改时间&#34;&#34;&#34; return datetime.fromtimestamp(os.path.getmtime(file_path)) def get_all_md_files(directory): &#34;&#34;&#34;递归获取目录下所有 md 后缀的文件&#34;&#34;&#34; md_files = [] for filename in os.listdir(directory): file_path = os.path.join(directory, filename) if os.path.isdir(file_path): # 如果是目录，则递归遍历该目录下的所有文件 md_files += get_all_md_files(file_path) elif filename.endswith(&#39;.md&#39;): # 如果是 Markdown 文件，则将其添加到列表中 md_files.append(file_path) return md_files def add_yml_metadata(filepath: str, append: bool = True): &#34;&#34;&#34; title、date、lastmod、tags、categories &#34;&#34;&#34; with open(filepath, &#39;r&#39;) as f: content = f.read() post = frontmatter.loads(content) if not append: del_yml_metadata(filepath) dir_name = os.path.basename(os.path.dirname(filepath)) filename = os.path.basename(filepath).replace(&#39;.md&#39;, &#39;&#39;).strip() categories = dir_name.title() # 把文件的上级目录作为分类 post.metadata = dict() post.metadata[&#39;title&#39;] = filename post.metadata[&#39;date&#39;] = get_file_creation_time(filepath).strftime(&#39;%Y-%m-%dT%H:%M:%S%z&#39;) post.metadata[&#39;lastmod&#39;] = get_file_modification_time(filepath).strftime(&#39;%Y-%m-%dT%H:%M:%S%z&#39;) post.metadata[&#39;tags&#39;]: list = [categories] post.metadata[&#39;categories&#39;]: list = [categories] with open(filepath, &#39;w&#39;) as f: f.write(frontmatter.dumps(post)) print(&#34;添加前置元数据: &#34; + os.path.basename(filepath)) def del_yml_metadata(filepath, mark=&#34;---&#34;): &#34;&#34;&#34;删除 yml 文件中的前置元数据&#34;&#34;&#34; with open(filepath, &#39;r&#39;) as f: content = f.read() modify_content = re.sub( rf&#34;^{mark}.*?{mark}\n&#34;, &#34;&#34;, content, flags=re.DOTALL | re.MULTILINE ) with open(filepath, &#39;w&#39;) as f: f.write(modify_content) print(&#34;删除前置元数据: &#34; + os.path.basename(filepath)) def get_all_md_create_and_modify_time(): # 获取该目录下的所有 Markdown 文件 md_files = get_all_md_files(dir_path) # 遍历每个 Markdown 文件，并输出其创建时间和修改时间 for md_file in md_files: creation_time = get_file_creation_time(md_file) modification_time = get_file_modification_time(md_file) print( f&#39;获取帖子文件: {os.path.basename(md_file)}: &#39; f&#39;creation time = {creation_time}, &#39; f&#39;modification time = {modification_time}&#39; ) add_yml_metadata(md_file, append=True) dir_path = &#34;content/&#34; get_all_md_create_and_modify_time() ]]></content></entry><entry><title>Python - Jwt实现Token生成与校验</title><url>/tech/python/jwt%E5%AE%9E%E7%8E%B0token%E7%94%9F%E6%88%90%E4%B8%8E%E6%A0%A1%E9%AA%8C/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[了解 PyJWT 是 Python 中处理 JSON Web Tokens（JWT）的库。
JWT 是一种用于安全地传输信息的开放式标准，可以将 JSON 格式的数据编码为安全的字符串，并使用密钥进行签名或加密。JWT 通常用于验证和身份验证，以及在分布式系统中安全地传输数据。可以使用 jwt 模块中提供的各种方法来创建、解密和验证 JWT。
例如，以下是使用 PyJWT 创建 JWT 的简单示例：
import jwt # Set the payload data payload = {&#39;user_id&#39;: 123456} # Set the secret key secret_key = &#39;my-secret-key&#39; # Create the JWT token token = jwt.encode(payload, secret_key, algorithm=&#39;HS256&#39;) print(token) 在这个例子中，我们使用 encode 方法创建了一个 JWT，其中包含了一个名为 payload 的 JSON 格式数据和一个名为 secret_key 的密钥。算法参数指定了签名算法，这里使用的是 &ldquo;HS256&rdquo; 算法。
输出结果将是一个字符串，它是经过签名的并带有过期时间的 JWT。
设置过期时间 在 PyJWT 中，可以使用 jwt.encode 函数的 exp 参数来设置 JWT 的过期时间。exp 参数是一个 Unix 时间戳，指定了 JWT 的有效期到什么时间。
以下是使用 PyJWT 设置 JWT 过期时间的示例代码：
import jwt import datetime # Set the payload data payload = {&#39;user_id&#39;: 123456} # Set the secret key secret_key = &#39;my-secret-key&#39; # Set the expiration time expires_in_minutes = 30 expires_datetime = datetime.datetime.utcnow() + datetime.timedelta(minutes=expires_in_minutes) expires_timestamp = int(expires_datetime.timestamp()) # Create the JWT token with expiration time token = jwt.encode({&#39;exp&#39;: expires_timestamp, **payload}, secret_key, algorithm=&#39;HS256&#39;) print(token) 在这个例子中，我们设置了一个名为 expires_in_minutes 的变量，它指定了 JWT 的有效期为 30 分钟。然后，我们通过计算当前时间和过期时间来确定 exp 值，并将其与其他负载数据一起传递给 jwt.encode 函数。最终生成的 JWT 将包含一个 exp 值，以便在验证时进行过期检查。
请注意，在设置 JWT 过期时间时，需要格外小心安全性问题。建议只设置短暂的过期时间，并确保使用安全的密钥来签名 JWT。
过期异常捕获 ExpiredSignatureError 是 PyJWT 包中的一个异常，表示 JWT 的签名已过期。
在使用 JWT 进行身份验证时，通常会为其设置一个过期时间。当 JWT 已经过期时，就会出现 ExpiredSignatureError 异常。
要解决这个问题，您可以尝试以下几种方法：
 检查系统时间：请确保正在使用的服务器或客户端的系统时间与网络标准时间同步。如果系统时间不正确，则可能会导致验证失败。 增加 JWT 的有效期：如果合理，可以将 JWT 的有效期延长以避免其过期。但是注意过长的有效期会影响安全性。 在处理 JWT 之前检查其过期状态：在处理 JWT 之前，可以先检查其是否已过期，从而避免出现 ExpiredSignatureError 异常。可以使用 jwt.decode 函数的 verify_exp 参数来检查 JWT 的过期状态，如下所示：  import jwt # Load the secret key from a file or configuration with open(&#39;secret.key&#39;) as f: secret_key = f.read() # Load and decode the JWT token token = &#39;your_jwt_token_here&#39; payload = jwt.decode(token, secret_key, algorithms=[&#39;HS256&#39;], verify=False) # Verify if the token is expired if &#39;exp&#39; in payload: import time current_time = int(time.time()) if payload[&#39;exp&#39;] &lt; current_time: raise Exception(&#39;Token has expired&#39;) 在这个例子中，我们加载并解码了 JWT，然后检查了其 exp 值是否小于当前时间。如果是，则抛出异常以表示过期状态。
请注意，这仅是一种简单的处理方式，并且可能需要在具体情况下进行调整。
]]></content></entry><entry><title>Git - 切换远程仓库</title><url>/tech/git/%E5%88%87%E6%8D%A2%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[可以使用以下命令：
 查看当前远程仓库的名称和 URL：  $ git remote -v 移除当前远程仓库  $ git remote rm origin 这将删除名为 origin 的当前远程仓库。如果您想删除其他远程仓库，请将 origin 替换为相应的名称。
添加新的远程仓库：  $ git remote add origin &lt;new-remote-url&gt; 将 &lt;new-remote-url&gt; 替换为要添加的远程仓库的 URL。注意，origin 是一个默认的远程仓库名称，您可以使用其他名称来标识新的远程仓库。
验证新的远程仓库是否已成功添加：  $ git remote -v 这会显示所有已配置的远程仓库及其对应的 URLs。确认新的远程仓库已正确添加后，您就可以开始使用它了。
请注意，在切换远程仓库之前，保存您的更改或创建一个分支以避免数据丢失。
]]></content></entry><entry><title>Python - Sqlalchemy 对象关系映射</title><url>/tech/python/sqlalchemy-%E5%AF%B9%E8%B1%A1%E5%85%B3%E7%B3%BB%E6%98%A0%E5%B0%84/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[Python SQLAlchemy 可以将 SQL 操作转化为 Python 对象，是对象关系映射（ORM，Object Relational Mapping）工具。
ORM 是一种将面向对象编程语言中的对象映射到关系型数据库中的数据结构的技术，它使得程序员可以使用类和对象来操作数据库而无需使用 SQL 查询语言。
优点：
 使程序更加简洁易读 封装了多种数据库引擎，代码层面操作一致 有效避免 SQL 字符串拼接带来的安全问题（SQL 注入）  缺点：性能稍不及原生 SQL，从接口测试角度来说，该问题可忽略，毕竟只是做造数和初始化工作，不面向用户。
概念了解    概念 对应数据库 说明     Engine 连接 驱动引擎   Session 连接池、事务 由此开始查询   Model 表 表的类定义   Column 列 列定义   Query 若干行数据 可以链式添加多个条件       数据类型（SQLAlchemy） 数据库数据类型 Python 数据类型 说明     Integer int int 整型   String varchar str 字符串   Text text str 长字符串   Float float float 浮点型   Boolean tinyint bool 布尔值   DateTime datetime datetime.datetime 时间（年月日时分秒毫秒）    快速入门 安装 $ pip install mysqlclient $ pip install sqlalchemy 安装 mysqlclient 报错： OSError: mysql_config not found
解决办法： 参考  
# 安装 mysql $ brew install mysql # 如果不想安装 mysql 就安装客户端也行 $ brew install mysql-client 创建连接 from sqlalchemy import create_engine engine = create_engine( &#34;mysql+pymysql://root:root@192.168.1.222:13306/test?charset=utf8&#34;, echo=True, # 是否转化为 sql 语句打印 pool_size=8, # 连接池大小，默认 5 个，0 表示无限制 pool_recycle=60 * 10, # 设置自动断开时间 ) try: conn = engine.connect() print(&#34;数据库连接成功&#34;) except Exception as e: print(f&#34;数据库连接出错：{e}&#34;) finally: conn.close() 声明模型并创建表 方法一
&#34;&#34;&#34; @Time : 2023/6/5 11:32 PM @Author : lan @DESC : DAO 层初始化所有表 &#34;&#34;&#34; from sqlalchemy import Column, Integer, MetaData, String, Table, create_engine, URL from config import settings from utils import log # 连接MySQL数据库 engine = create_engine(&#39;mysql+pymysql://root:root@192.168.1.222:3306/mysql&#39;) url = URL.create( drivername=settings.DATABASE.DRIVER, username=settings.DATABASE.get(&#34;USERNAME&#34;, None), password=settings.DATABASE.get(&#34;PASSWORD&#34;, None), host=settings.DATABASE.get(&#34;HOST&#34;, None), port=settings.DATABASE.get(&#34;PORT&#34;, None), database=None, ) log.debug(f&#34;Database URL: {url}&#34;) engine = create_engine(url, echo=True) metadata = MetaData() # 定义表结构 users_table = Table( &#39;users&#39;, metadata, Column(&#39;id&#39;, Integer, primary_key=True), Column(&#39;name&#39;, String(50)), Column(&#39;age&#39;, Integer), ) # 建立表格 metadata.create_all(engine) # 插入数据 conn = engine.connect() conn.execute(users_table.insert().values(name=&#39;Alice&#39;, age=25)) conn.execute(users_table.insert().values(name=&#39;Bob&#39;, age=30)) # 查询数据 result = conn.execute(users_table.select()) for row in result: print(row) conn.commit() 定义模型结构（表结构）
from sqlalchemy.orm import DeclarativeBase class Base(DeclarativeBase): pass class User(Base): __tablename__ = &#34;user&#34; # 表名 id = Column(INT, primary_key=True) name = Column(String(20), unique=True, comment=&#34;姓名&#34;) email = Column(String(100)) def __repr__(self) -&gt; str: return f&#34;User(id={self.id!r}, name={self.name!r}), email={self.email!r}&#34; 在 SQLAlchemy 中，DeclarativeBase 是一个用于创建基类的函数。使用该函数可以轻松地定义 ORM（对象关系映射）类，并将其映射到数据库表。
在定义 ORM 类时，先声明一个名为 Base 的新基类，可以让这个类继承自 Base，以便能够使用 SQLAlchemy 提供的所有数据库连接和查询方法。
from sqlalchemy.ext.declarative import declarative_base Base = declarative_base() # 该写法在 2.0 已经弃用 # MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). # (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9) 当表中 Index=true 时，代表建立索引。索引有啥用呢？参考：https://zhuanlan.zhihu.com/p/23624390
创建表 # 在数据库中生成表 Base.metadata.create_all(engine) 向表中添加数据 from sqlalchemy.orm import Session # session = Session(engine) # session.close() # 同上，推荐使用 with 上下文管理的风格，确保操作完成后自动关闭连接 with Session(engine) as session: tom = User(name=&#34;tom&#34;, email=&#34;tom@abc.xyz&#34;) bob = User(name=&#34;bob&#34;, email=&#34;bob@abc.xyz&#34;) luna = User(name=&#34;luna&#34;, email=&#34;luna@abc.xyz&#34;, id=8) session.add_all([tom, bob, luna]) session.commit() # 数据库查询结果 mysql&gt; select * from user; +----+------+--------------+ | id | name | email | +----+------+--------------+ | 1 | tom | tom@abc.xyz | | 2 | bob | bob@abc.xyz | | 8 | luna | luna@abc.xyz | +----+------+--------------+ 查询数据 from sqlalchemy import select with Session(engine) as session: query = select(User).where(User.name.in_([&#34;tom&#34;, &#34;bob&#34;])) users = session.scalars(query) for user in users: print(user) # 输出结果 User(id=1, name=&#39;tom&#39;, email=&#39;tom@abc.xyz&#39;) User(id=2, name=&#39;bob&#39;, email=&#39;bob@abc.xyz&#39;) 更新数据 # 更新 luna 的邮箱 with Session(engine) as session: query = select(User).where(User.name == &#34;luna&#34;) luna = session.scalars(query).one() luna.email = &#34;luna@xyz.abc&#34; session.commit() # 数据库输出，可以看到邮箱更新成功 +----+------+--------------+ | id | name | email | +----+------+--------------+ | 1 | tom | tom@abc.xyz | | 2 | bob | bob@abc.xyz | | 8 | luna | luna@xyz.abc | +----+------+--------------+ 删除数据 # 删出 luna 用户 with Session(engine) as session: query = select(User).where(User.name == &#34;luna&#34;) luna = session.scalars(query).one() session.delete(luna) session.commit() # 数据库输出，用户删除成功 +----+------+-------------+ | id | name | email | +----+------+-------------+ | 1 | tom | tom@abc.xyz | | 2 | bob | bob@abc.xyz | +----+------+-------------+ 常用 API from sqlalchemy import create_engine, Column, Integer, String from sqlalchemy.orm import sessionmaker from sqlalchemy.ext.declarative import declarative_base # 创建数据库引擎和会话 engine = create_engine(&#39;mysql://user:password@localhost/dbname&#39;) Session = sessionmaker(bind=engine) session = Session() # 创建基本类 Base = declarative_base() # 定义 User 类 class User(Base): __tablename__ = &#39;users&#39; id = Column(Integer, primary_key=True) name = Column(String(50)) age = Column(Integer) # 查询年龄不为空的用户 result = session.query(User).filter(User.age.isnot(None)).all() # 输出查询结果 for user in result: print(user.name, user.age) # 关闭会话 session.close() ]]></content></entry><entry><title>Python - Sqlalchemy 建立连接报错Access Denied</title><url>/tech/python/sqlalchemy-%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E6%8A%A5%E9%94%99access-denied/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ engine: Engine = create_engine(url, echo=True) log.debug(&#34;Connection established successfully.&#34;) with engine.connect() as conn: conn.execute(text( f&#34;CREATE DATABASE IF NOT EXISTS {url_obj.database}&#34; f&#34;default character set utf8mb4 collate utf8mb4_unicode_ci&#34; )) log.debug(f&#34;Database created successfully. DB_NAME: {url_obj.database}&#34;)  执行上面代码时，出现报错：
sqlalchemy.exc.ProgrammingError: (mysql.connector.errors.ProgrammingError) 1045 (28000): Access denied for user 'root'@'192.168.1.3' (using password: YES)
 ⚠️ 使用 URL 创建连接的正确方式是：URL.create(…) 我直接在类上实例化的，导致 密码 默认为 ***， 然后报错密码不对~~ 密码就是不对哇。。。他自动把密码转成三个星号了，，， 我无语死，耽误了一下午，各种查。。。
 下面来自 GPT
不添加执行语句就正常，执行语句就报错。
# 默认 root 用于远程不可访问，修改下可访问 $ update mysql.user set authentication_string=password(&#39;root&#39;) where user=&#39;root&#39; and host=&#39;%&#39;; 默认情况下，MySQL 8 在容器中启动时会限制 root 用户仅能通过本地连接进行访问。要允许远程 root 访问，您需要使用以下步骤进行配置：
  使用管理员权限用户登录到 MySQL 8 容器中的 MySQL 服务器。
$ docker exec -it &lt;mysql_container_name&gt; mysql -u root -p   进入 MySQL 命令行工具，并授予远程 root 用户访问权限。
mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;your_password&#39; WITH GRANT OPTION; FLUSH PRIVILEGES; 这里我们给所有数据库的所有表都授权给远程的 root 用户，如果你想只授权给特定数据库，可以将 *.* 改为 &lt;database_name&gt;.*。
  修改配置文件 /etc/mysql/my.cnf，注释掉以下代码行。
# bind-address = 127.0.0.1 这样 MySQL 服务器就可以接受从任意 IP 地址的客户端连接了。
  重新启动 MySQL 服务。
$ service mysql restart   现在，远程 root 用户就可以通过指定 MySQL 主机 IP 地址或域名以及相应的端口号（默认为 3306）来连接 MySQL 服务器了。
请注意，在开放远程 root 用户访问权限之前，请确保已经采取了适当的安全措施，例如启用 SSL/TLS 加密、限制访问 IP 地址、使用强密码等。
]]></content></entry><entry><title>Fastapi - Pity 项目分析</title><url>/tech/fastapi/pity-%E9%A1%B9%E7%9B%AE%E5%88%86%E6%9E%90/</url><categories><category>Fastapi</category></categories><tags><tag>Fastapi</tag></tags><content type="html">pity(后端项目) config.py 项目配置类，通过 BaseSettings 来声明配置项及默认值，根据环境变量切换后端环境
app crud 该目录作为 dao 层，创建 dao 接口，然后会在配置文件中定义该接口的实现类，接着就可以在模块中调用 dao 接口进行数据业务员的处理。
主要是做数据持久层的工作，与数据库进行交互。
auth models 存放通过 sqlalchemy 创建表的类信息
表信息如下：
user.py：用户表，管理注册、登录用户数据 middleware 中间件服务</content></entry><entry><title>Mac - 查看性能信息工具Istats</title><url>/tech/mac/%E6%9F%A5%E7%9C%8B%E6%80%A7%E8%83%BD%E4%BF%A1%E6%81%AF%E5%B7%A5%E5%85%B7istats/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html"> 命令行工具，可以获取 Mac 上的 CPU 温度、风扇转速和电池信息。
安装 $ sudo gem install iStats # 输入电脑密码 $ brew install iStats 使用 $ istats --- CPU Stats --- CPU 温度 CPU temp: 67.69°C ▁▂▃▅▆▇ --- Fan Stats --- 风扇转速（圈/分钟） Total fans in system: 2 Fan 0 speed: 2018 RPM ▁▂▃▅▆▇ Fan 1 speed: 2178 RPM ▁▂▃▅▆▇ --- Battery Stats --- 电池健康情况 Battery health: unknown Cycle count: 134 ▁▂▃▅▆▇ 13.4% Max cycles: 1000 Current charge: 4046 mAh ▁▂▃▅▆▇ 100% Maximum charge: 4235 mAh ▁▂▃▅▆▇ 83.2% Design capacity: 5088 mAh Battery temp: 38.59°C 如果风扇转速过快，还会变成红色。
可以通过「活动监视器」查看哪些程序消耗资源过高，根据情况停一下。</content></entry><entry><title>Nodejs - 项目工具间的关系</title><url>/tech/nodejs/%E9%A1%B9%E7%9B%AE%E5%B7%A5%E5%85%B7%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/</url><categories><category>Nodejs</category></categories><tags><tag>Nodejs</tag></tags><content type="html"><![CDATA[Node.js、nvm、npm 和 cnpm 是四个不同的工具，它们之间存在一定的关系。
 Node.js 是基于 Chrome V8 引擎的 JavaScript 运行环境，用于在服务器端执行 JavaScript 代码 node 命令则是通过 Node.js 在命令行中执行 JavaScript 代码的入口 nvm（Node Version Manager）是一个 Node.js 版本管理器，可以帮助您轻松地安装和切换不同版本的 Node.js npm（Node Package Manager）是 Node.js 的包管理器，用于安装、发布和管理 Node.js 模块 cnpm（淘宝 NPM 镜像）则是 npm 在国内的淘宝镜像源，可以提供更快速的访问速度和稳定性  下面是一个简单的 Node.js 项目启动的示例，结合了 node、nvm 和 npm 工具：
 使用 nvm 安装并切换到指定版本的 Node.js  $ nvm install 14.17.3 $ nvm use 14.17.3 在项目中初始化包管理器  $ mkdir myapp $ cd myapp $ npm init -y 这个命令会在当前目录下创建一个新的 Node.js 项目，并自动生成 package.json 文件。
使用 npm 安装所需的依赖项  $ npm install express --save 这个命令会安装 Express 框架，并将其添加到项目的依赖项列表中。
编写 app.js 文件，作为应用程序的入口点  const express = require(&#39;express&#39;) const app = express() app.get(&#39;/&#39;, (req, res) =&gt; { res.send(&#39;Hello World!&#39;) }) app.listen(3000, () =&gt; { console.log(&#39;Example app listening on port 3000!&#39;) }) 这个文件会创建一个基本的 Express.js 应用程序，监听来自客户端的请求，并响应 &ldquo;Hello World!&rdquo; 字符串。
通过 node 命令启动应用程序，监听 3000 端口  $ node app.js 使用浏览器或者 curl 工具来访问应用程序，例如：curl http://localhost:3000/
]]></content></entry><entry><title>Fastapi - Pity 环境搭建</title><url>/tech/fastapi/pity-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url><categories><category>Fastapi</category></categories><tags><tag>Fastapi</tag></tags><content type="html"><![CDATA[ 官方文档：https://wuranxu.github.io/pityDoc Github：https://github.com/wuranxu/pity 在线体验：http://121.5.2.74:8006
 下载后端项目 下载代码 启动依赖服务 直接通过 docker-compose 实现会更加方便
注意：
 mysql 要选择 8.0 的，5.7 已知会报错，需要额外增加配置项  $ git clone https://github.com/wuranxu/pity.git # 创建 python 的虚拟环境，然后装包 $ pip install --upgrade pip $ pip install -r requirements.txt -i https://pypi.douban.com/simple/ $ vim docker-compose.yml # docker-compose.yml # 启动数据库和 redis version: &#34;3&#34; services: mysql: image: mysql:8.0 container_name: mysql_pity restart: always environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: pity TZ: Asia/Shanghai volumes: - ./mysql/data:/var/lib/mysql ports: - &#34;3306:3306&#34; networks: - pity-net redis: image: redis container_name: redis_pity restart: always environment: REDIS_PASSWORD: root volumes: - ./redis/data:/data ports: - &#34;6379:6379&#34; networks: - pity-net networks: pity-net: driver: bridge # 实测版本 version: &#34;3&#34; services: pity-mysql: image: mysql:8.0 container_name: pity_mysql restart: unless-stopped ports: - &#34;3308:3306&#34; volumes: - ./mysql:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: Pitytester666666 MYSQL_DATABASE: pity TZ: Asia/Shanghai pity-redis: image: redis container_name: pity_redis command: redis-server --requirepass 123456 restart: unless-stopped environment: TZ: Asia/Shanghai ports: - &#34;6379:6379&#34; volumes: - ./redis:/data # 启动容器服务 $ docker-compose up -d 启动 py 服务 # 修改下配置文件 conf/dev.env 中 mysql redis 服务配置信息 $ python pity.py 报错记录 报错一
&gt; import aioify &gt; ... &gt; FileNotFoundError: [Errno 2] No such file or directory: &#39;/Users/lan/workspace/github/pity/venv/lib/python3.10/site-packages/stdlib_list/lists/3.10.txt&#39;  参考 Github Issues：https://github.com/yifeikong/aioify/issues/23
 解决办法：切换为 pyhon 3.9 版本。
报错二
 redis.exceptions.ResponseError: AUTH  called without any password configured for the default user. Are you sure your configuration is correct?
 取消 pity 配置文件中的密码。
前端项目 pityWeb 下载项目代码 安装依赖 $ cd pityWeb # 切换 node 版本为 20，大于 14 且不包含 15&amp;17 版本就行，否则报错 # error - Your node version 15 is not supported, please upgrade to 14 or above except 15 or 17. $ nvm use v20.1.0 # 安装 cnpm $ npm install -g cnpm --registry=https://registry.npm.taobao.org $ cnpm -v cnpm@6.1.0 (/usr/local/lib/node_modules/cnpm/lib/parse_argv.js) npm@6.13.3 (/usr/local/lib/node_modules/cnpm/node_modules/npm/lib/npm.js) node@20.1.0 (/Users/lan/.nvm/versions/node/v20.1.0/bin/node) # 安装依赖，会出现一个 node_modules 的目录 $ cnpm install # 启动服务 $ npm start 修改记录  使用 black 格式化项目代码  ]]></content></entry><entry><title>Database - Redis 命令行工具Cli安装及使用</title><url>/tech/database/redis-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7cli%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/</url><categories><category>Database</category></categories><tags><tag>Database</tag></tags><content type="html"> Mac 安装 redis-cli 命令行工具
安装 方式一
$ brew install redis 安装 redis 的同时会安装 redis-cli 工具，由于我已经通过 docker 启动 redis 服务了，所以不想再安装 redis 服务，使用方式二。
方式二：编译安装
# 打开终端，下载 Redis 的源码 $ curl -O http://download.redis.io/redis-stable.tar.gz # 解压缩源码包，并进入 src 目录 $ tar xzf redis-stable.tar.gz $ cd redis-stable/src # 编译并安装 redis-cli 工具。 $ make redis-cli $ sudo cp redis-cli /usr/local/bin/ # 检查 $ redis-cli --version redis-cli 7.0.11 命令 文档地址
# 验证服务是否开启 $ redis-cli 127.0.0.1:6379&amp;gt; ping PONG 返回 PONG 则证明服务正常启动。</content></entry><entry><title>Fastapi - 接口测试平台需求汇总</title><url>/tech/fastapi/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E9%9C%80%E6%B1%82%E6%B1%87%E6%80%BB/</url><categories><category>Fastapi</category></categories><tags><tag>Fastapi</tag></tags><content type="html"> 这里罗列一些在使用接口测试平台过程中遇到的痛点，汇总一下。
环境配置
全局环境定义
全局域名定义
支持根据域名配置公共参数（Headers、变量）
API 定义时，支持在该环境下，选择域名环境内的域名
需要支持 WebSocket 接口请求
请求方式 MeterSphere Restful Api ✅ WebSocket ❌ API 定义 ✅ 测试套件（场景） ✅ 用例执行 全局环境配置 全局变量 变量提取 场景化测试</content></entry><entry><title>Blog - Hugo 搭建博客（V2）</title><url>/tech/blog/hugo-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2v2/</url><categories><category>Blog</category></categories><tags><tag>Blog</tag></tags><content type="html"><![CDATA[下文是我自己的搭建记录（MacOS, Hugo + GithubPage）
搭建本地 Hugo 服务  Hugo 是使用 Go 语言编写的 静态网站生成器  ，页面编译速度快，支持跨平台、皮肤自定义，方便部署。
官方文档 传送门  
 📢 📢 📢
 以下是 hugo 通用的建站方式，适用于绝大多数主题。
我本次使用的主题 sulv-hugo-papermod   作者已经把相关代码全部提交到仓库里面了，所以只需要拉取仓库代码，修改配置文件即可。详情查看仓库介绍文档。
 安装 Hugo  方法一：在 Hugo 的官方网站   上下载并安装 Hugo 方法二：直接使用 Homebrew 安装  # 跳过 brew 检查更新（可以忽略） $ export HOMEBREW_NO_AUTO_UPDATE=true # 开始安装 $ brew install hugo ==&gt; Summary 🍺 /usr/local/Cellar/hugo/0.111.3: 31 files, 40.6MB $ hugo version hugo v0.111.3+extended darwin/amd64 BuildDate=unknown 建站 进入自定义目录下，新建站点
$ cd workspace $ hugo new site notebook Congratulations! 站点文件夹目录如下
. ├── archetypes # 存放帖子的模板 md 文件 ├── assets # 存放被 Hugo Pipes 处理的文件 ├── config # 配置文件；支持 JSON、YAML、TOML 三种格式配置文件，加上不同后缀即可 ├── content # 存放博客 markdown 文件 ├── data # 存放 Hugo 处理的数据 ├── layouts # 存放布局文件 ├── static # 存放静态文件 图片 CSS JS 文件 └── themes # 存放主题 添加主题 可以访问  Hugo 主题库   挑选自己喜欢的主题，复制主题的 github 仓库下载链接。
# 初始化当前目录为 git 仓库 $ cd notebook $ git init # 拉取主题 # 注意查看主题最低支持的 hugo 版本与当前版本是否匹配 $ git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod # 后续主题有更新通过如下命令拉取 $ git submodule update --init 编辑配置文件blog_name/config.toml，一般在主题下会有对应的配置文件模板exampleSite/config.toml修改修改就行。
访问 命令行启动
$ hugo server -D 在浏览器中访问 localhost:1313  ，配置配置文件后会自动刷新预览。
创建第一篇文章 # md 模板在 archetypes/default.md 设置 $ hugo new posts/tech/我的第一篇帖子.md 发布到 GitHubPages 博客静态页面搭建完成后，接下来就需要对外发布展示，这里使用免费的 GithubPages 来实现。
实现原理为：
 新建 md 文件 编辑完成后通过 hugo 命令生成 pulic 静态网页文件 将静态文件推送到远程仓库 通过域名访问  这样太麻烦了，每次还需要手动的去构建 md 为静态文件，且有点乱不方便维护，因此可以通过 Github Action 来提高效率。
最终实现效果为：
 新建 md 文件 推送 md 文件到远程仓库 Github Action 自动构建静态文件并推送到指定位置  这样就只需要关注写作就可以了。
创建 GitPages 仓库 首先 注册   账号，登录github个人页面，新建仓库，仓库名格式必须为 &lt;username&gt;.github.io
在该仓库 Settings - 左侧导航栏 Pages 页面，可查看访问域名。
# 将该项目拉到本地 $ git clone https://github.com/abeelan/abeelan.github.io.git 创建存放博客源文件仓库 创建一个仓库用来存放博客的原始 md 文件，可以是私有仓库。
# 可选 博客原始文件关联远程仓库 $ cd notebook $ git remote add orgin https://github.com/abeelan/notebook # 创建工作流文件,名字随便取 $ vim .github/workflows/hugo-deploy.yml # hugo-deploy.yml name: hugo-blog-deploy on: push: branches: - main jobs: hugo-blog-deploy: runs-on: ubuntu-latest  # 我 mac 也这么设置的，设置 macos 报错 steps: - name: Checkout source uses: actions/checkout@v2 with: submodules: recursive  # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup hugo uses: peaceiris/actions-hugo@v2 # hugo 官方 action，用于在任务环境中获取 hugo with: hugo-version: &#34;0.81.0&#34; # hugo version extended: true - name: Build run: hugo --minify  # 使用 hugo 构建静态网页 - name: Deploy uses: peaceiris/actions-gh-pages@v3 # 一个自动发布 github pages 的 action with: personal_token: ${{ secrets.PERSONAL_TOKEN }} # 无需修改，后面会为该变量设置 secret external_repository: abeelan/abeelan.github.io # 修改为你的 GitHub Pages 仓库 publish_dir: ./public publish_branch: main # 如果使用自定义域名，还需要添加下面一行配置 # cname:  配置 Github Token  点击头像 - Settings - Developer settings   - Personal access tokens - Tokens(classic）- Generate new token(classic)   Note: GITHUB_ACTION_TOKEN 自定义有效期（过期了记得更新） Select scopes：workflow、admin:repo_hook 点击生成，保存好这串 token  返回博客项目，进入 Settings - Secrets and variables - Actions - New repo secret   Name：PERSONAL_TOKEN（跟上面配置文件保持一致，注意不能以 GITHUB_ 开头，否则会出错） secret：上一步创建的 token 值 Add secret  这一步设置的 Name：PERSONAL_TOKEN 需要与上面 yml 工作流中的变量名一致。
结束 至此，配置完成。
使用 Typora 编辑文章，提交至远程仓库，自动触发 GithubActions 构建发布页。
]]></content></entry><entry><title>Booknotes - 《Python工匠》</title><url>/tech/booknotes/python%E5%B7%A5%E5%8C%A0/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html">已读完。</content></entry><entry><title>关于我</title><url>/about/</url><categories/><tags/><content type="html">目前是一名 自动化测试 工程师，这里是我的工作学习笔记。
在阅读过程中，如果看到了明显的错误 或者 遇到了问题，请联系我：
微信号 微信公众号 ，基本不维护了，偶尔看看消息 Github ，每天都会收邮件</content></entry><entry><title>Jmeter&Ms - Jsr223 自定义脚本</title><url>/tech/jmeterms/jsr223-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%84%9A%E6%9C%AC/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html"><![CDATA[JSR223 JSR223 是 Java Specification Request 223 的缩写，它定义了一种标准的接口和机制，用于在Java虚拟机中运行基于脚本的语言（例如Groovy、JavaScript等）的脚本引擎。在JMeter中，JSR223断言可以使用多种脚本语言编写验证逻辑，包括 Groovy、JavaScript、Python 等。
JSR223 断言是 JMeter 内置的一种断言类型，它允许用户使用脚本语言编写自定义的断言逻辑。这种断言类型通常用于深层次的验证或者需要进行动态计算的场景。使用 JSR223 断言可以更加灵活地对响应数据进行处理和验证，比如可以使用正则表达式匹配、解析 JSON/XML 数据等等。
在 JMeter 中，JSR223 断言的执行速度相对较慢，并且可能会导致大量 CPU 使用率，因此建议仅在必要时使用该断言。对于大多数情况下，内置的其他断言应该足够满足测试需求。
BeanShell BeanShell（也称 Bsh）是一种小巧、免费且高度可扩展的 Java 脚本语言，可以直接在 JVM 中运行。在 JMeter 中，BeanShell 可以用于编写断言、前置处理器、后置处理器等逻辑处理任务。
与 JSR223 断言不同，JMeter 内置了 BeanShell 断言，因此无需安装其他插件或库即可使用。BeanShell 语法类似于 Java，可以很容易地编写出复杂的验证逻辑和数据处理任务，同时还支持使用 Java 类和方法。
控制台常用代码片段 // 控制台打印 log.info(&#34;hello&#34;); log.info(&#34;1&#34; + &#34;1&#34;); log.info(&#34;1+{}={}&#34;, k1, k2); // 获取变量类型名 var.getClass().getName(); 后置中获取请求体 body 中的参数值 //获取当前请求body请求参数 import org.apache.jmeter.config.Arguments; Arguments arguments = sampler.getArguments(); String body = arguments.getArgument(0).getValue(); // 获取第一个表单中的值，并设置为变量 vars.put(&#34;name&#34;, body); log.info(&#34;[set var] name = &#34; + body); 生成手机号 import org.apache.commons.lang3.RandomStringUtils; // 生成随机的手机号 String phoneNumber = &#34;1&#34; + RandomStringUtils.randomNumeric(10); // 将手机号保存到变量 vars.put(&#34;phoneNumber&#34;, phoneNumber); // 使用 ${phoneNumber} 引用该变量 注意：由于 JMeter 是多线程测试，如果生成的随机手机号用于注册等类似操作，那么需要考虑并发场景下可能出现重复手机号的情况。
生成随机中文姓名 import java.util.Random; String[] surnameArray = {&#34;赵&#34;, &#34;钱&#34;, &#34;孙&#34;, &#34;李&#34;, &#34;周&#34;, &#34;吴&#34;, &#34;郑&#34;, &#34;王&#34;}; String[] givenNameArray = {&#34;一&#34;, &#34;二&#34;, &#34;三&#34;, &#34;四&#34;, &#34;五&#34;}; String randomChineseName() { String name = &#34;&#34;; Random random = new Random(); int surnameIndex = Math.abs(random.nextInt(surnameArray.length)); int givenNameIndex = Math.abs(random.nextInt(givenNameArray.length)); String surname = surnameArray[surnameIndex]; String givenName = givenNameArray[givenNameIndex]; name = surname + givenName; return name; } String name = randomChineseName(); log.info(&#34;生成随机名字: randomName = {}&#34;, name); vars.put(&#34;randomName&#34;, name); 生成指定长度的随机字符串 import java.util.Random; // 生成指定长度的随机字符串 String generateRandomString(int length) { String characters = &#34;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&#34;; StringBuilder randomString = new StringBuilder(); Random random = new Random(); for (int i = 0; i &lt; length; i++) { randomString.append(characters.charAt(random.nextInt(characters.length()))); } return randomString.toString(); } String str = generateRandomString(5); log.info(&#34;生成随机字符串为: str = {}&#34;, str); vars.put(&#34;str&#34;, str); 生成 13 位时间戳 import java.util.Date; long timestamp = new Date().getTime(); String strTimestamp = Long.toString(timestamp); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; timestamp(13): &#34; + strTimestamp); 对响应值整体进行 urldecode 解码 import java.net.URLDecoder; String response = prev.getResponseDataAsString(); log.info(&#34;{}&#34;, response); String decodedResponse = URLDecoder.decode(response, &#34;UTF-8&#34;); // decode 解码 // String encodedResponse = URLEncoder.encode(response, &#34;UTF-8&#34;); // encode 编码 log.info(&#34;{}&#34;, decodedResponse); // 将解码后的响应更新回去 prev.setResponseData(decodedResponse.getBytes()); 对响应部分字段进行 urldecode 解码 - 递归实现 import org.json.JSONArray; import org.json.JSONObject; import java.net.URLDecoder; log.info(&#34;后置脚本 开始 &gt;&gt;&gt;&gt;&gt;&#34;); void decodeJson(JSONObject json) { for (String key : json.keySet()) { Object value = json.get(key); if (value instanceof JSONObject) { decodeJson((JSONObject) value); // 递归处理子对象  } else if (value instanceof JSONArray) { JSONArray array = (JSONArray) value; for (int i = 0; i &lt; array.length(); i++) { Object item = array.get(i); if (item instanceof JSONObject) { decodeJson((JSONObject) item); // 递归处理子对象  } } } else if (value instanceof String &amp;&amp; key.contains(&#34;需要解码的字段名&#34;)) { String decodedValue = URLDecoder.decode((String) value, &#34;UTF-8&#34;); json.put(key, decodedValue); } } } // 解析 JSON 并调用递归函数 String response = prev.getResponseDataAsString(); JSONObject json = new JSONObject(response); decodeJson(json); String output = json.toString(); log.info(&#34;decodeJson: {}&#34;, output); // 将解析后的内容更新到响应体 prev.setResponseData(output); log.info(&#34;后置脚本 结束 &lt;&lt;&lt;&lt;&lt;&#34;); 修改响应头类型 // 修改响应头格式为 json prev.setResponseHeaders(&#34;Content-Type: application/json&#34;); 生成随机字符串 并 md5 import java.security.MessageDigest; import java.util.Random; // 生成随机字符串 数字 + 大写字母 String getRandomString(int length) { String str = &#34;0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ&#34;; Random rand = new Random(); StringBuilder sb = new StringBuilder(length); for (int i = 0; i &lt; length; i++) { int index = rand.nextInt(str.length()); sb.append(str.charAt(index)); } return sb.toString(); } // 将 byte 数组转换为 16 进制字符串 String bytesToHex(byte[] bytes) { StringBuilder sb = new StringBuilder(); for (byte b : bytes) { sb.append(String.format(&#34;%02X&#34;, new Object[] { b })); } return sb.toString(); } String randomString = getRandomString(13); // 计算字符串的 MD5 值 MessageDigest md = MessageDigest.getInstance(&#34;MD5&#34;); byte[] digest = md.digest(randomString.getBytes()); String md5 = bytesToHex(digest).toLowerCase(); String msg_id = &#34;c&#34; + md5; log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; Make msgId: &#34; + randomString + &#34; ==&gt; &#34; + msg_id); 将请求数据由 json 转为字符串并更新回请求体 import org.json.JSONObject; import java.net.URLEncoder; String request = sampler.getArguments().getArgument(0).getValue(); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; requests body type: &#34; + request.getClass().getName()); JSONObject json = new JSONObject(request); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; 初始请求体: {}&#34;, json); // replace data JSONObject data = json.getJSONObject(&#34;data&#34;); data.put(&#34;local_msgid&#34;, msg_id); data.put(&#34;timestamp&#34;, timestamp); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; data: {}&#34;, data); // data: json -&gt; str String dataString = data.toString(); json.put(&#34;data&#34;, dataString); String updatedRequest = json.toString(); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; requests body type（update）: &#34; + updatedRequest.getClass().getName()); // 重新添加更新后的请求体 sampler.getArguments().removeAllArguments(); // sampler.addArgument(&#34;updateRequest&#34;, updatedRequest); // 会自动 urlencode，导致编码问题 sampler.addNonEncodedArgument(&#34;&#34;, updatedRequest, &#34;&#34;); String request = sampler.getArguments().getArgument(0).getValue(); log.info(&#34;Output &gt;&gt;&gt;&gt;&gt; 最终请求体: {}&#34;, request); 提取响应中列表的长度 不支持直接使用 jsonpath 的 length 函数获取长度。
import org.json.JSONArray; import org.json.JSONObject; String response = prev.getResponseDataAsString(); JSONObject jsonResponse = new JSONObject(response); JSONArray data = jsonResponse.getJSONArray(&#34;列表名&#34;); int length = data.length(); log.info(&#34;list length: &#34; + length); // 设置为变量 vars.put(&#34;var_name&#34;, String.valueOf(length)); log.info(vars.get(&#34;var_name&#34;)); 正则 // 暂未测试通过 import java.util.regex.Matcher; import java.util.regex.Pattern; // 定义正则表达式 Pattern pattern = Pattern.compile(&#34;\&#34;id\&#34;:(.*?)&#34;); Matcher matcher = pattern.matcher(response); // 循环遍历所有匹配项，将 &#34;name&#34; 字段的值添加到列表中 while (matcher.find()) { String name = matcher.group(1); names.add(name); log.info(&#34;{}&#34;, name); } // 输出所有匹配到的 &#34;name&#34; 字段的值 for (String name : names) { log.info(&#34;Found name: &#34; + name); } // 将所有匹配到的 &#34;name&#34; 字段的值以逗号分隔的形式赋值给变量 &#34;nameList&#34; String nameList = String.join(&#34;,&#34;, names); // 将变量 &#34;nameList&#34; 添加到 JMeter 的变量列表中 vars.put(&#34;nameList&#34;, nameList); jsonpath 提取变量的所有值 jsonpath需要通过 * 提取列表的多个值，后面勾选匹配多个值，然后在下一个用例引用格式为：${var_ALL}，添加后面的 ALL 才会生效，否则找不到这个变量名。
第二种方法就是通过脚本实现：
import java.util.List; import java.util.ArrayList; import org.json.JSONArray; import org.json.JSONObject; import org.json.*; import com.jayway.jsonpath.JsonPath; String k1 = &#34;data&#34;; String k2 = &#34;id&#34;; log.info(&#34;=================== 提取 {} 中所有 {} 的值 ===================&#34;, k1, k2); String response = prev.getResponseDataAsString(); JSONObject resp = new JSONObject(response); String data_str = resp.get(k1).toString(); JSONArray data_array = new JSONArray(data_str); data_len = data_array.length(); Integer[] idArr = new Integer[data_array.length()]; for (int i = 0; i &lt; data_array.length(); i++) { JSONObject obj = new JSONObject(data_array.get(i).toString()); // String id = obj.get(k2).toString();  int id = Integer.parseInt(obj.get(k2).toString()); log.info(&#34;&gt;&gt;&gt; 提取 {}: {} (&#34; + id.getClass().getName() + &#34;)&#34;, k2, id); idArr[i] = id; } Arrays.sort(idArr); // 排序 String ids = Arrays.toString(idArr); ids = ids.replaceAll(&#34; &#34;,&#34;&#34;); // 去除列表元素中间的空格 log.info(&#34;&gt;&gt;&gt; idArr = &#34; + ids); vars.put(&#34;drafts_ids&#34;, ids); log.info(&#34;&gt;&gt;&gt; 将数据赋值给变量：${drafts_ids}, 类型为字符串&#34;); log.info(&#34;=================== 提取 {} 中所有 {} 的值 ===================&#34;, k1, k2); 前置脚本：将列表字符串转为列表类型填充进去 需求二：编写一个前置脚本，将请求体中 formId 的值由字符串转为列表类型，再填充到请求体内
{ &#34;formId&#34;: &#34;[7618, 7619]&#34;, &#34;userId&#34;: &#34;0cdbcc4a2b14099822abfa9e449a0ea9&#34;, &#34;companyId&#34;: &#34;996&#34; } log.info(&#34;=================== 将提取到的多个值转为列表 ===================&#34;); // 该方法用于前置脚本中 // 通常是将上一接口中提取到的所有值，转为列表类型并替换到当前接口的请求中  String key = &#34;id&#34;; // 参数提取时设置的变量名 且 勾选了提取多个值 String field = &#34;ids&#34;; // 当前接口中的字段名  // ----  String values = vars.get(key + &#34;_ALL&#34;); log.info(&#34;提取到的所有值为：&#34; + values); String valuesSplit = values.replaceAll(&#34;\\[|\\]&#34;, &#34;&#34;).split(&#34;,&#34;); StringBuilder array = new StringBuilder(); for (int i = 0; i &lt; valuesSplit.length; i++) { array.append(valuesSplit[i].trim()); if (i != valuesSplit.length - 1) { array.append(&#34;,&#34;); } }; // 更新请求体中的字段 String requestBody = sampler.getArguments().getArgument(0).getValue(); requestBody = requestBody.replaceAll( &#34;\&#34;&#34; + field + &#34;\&#34;:\\s*\&#34;[^\&#34;]+\&#34;&#34;, &#34;\&#34;&#34; + field + &#34;\&#34;: [&#34; + array.toString() + &#34;]&#34; ); log.info(&#34;更新后的请求体: {}&#34;, requestBody); // 回填到请求体中 sampler.getArguments().removeAllArguments(); sampler.addNonEncodedArgument(&#34;&#34;, requestBody, &#34;&#34;); sampler.setPostBodyRaw(true); log.info(&#34;=================== 将提取到的多个值转为列表 ===================&#34;); 下载 zip 文件并解压缩然后读取文件内容 log.info(&#34;=================== 通过链接下载 zip 文件，然后解压缩后读取 doc 文档内容 ===================&#34;); import java.net.URL; import java.util.zip.ZipInputStream; import java.util.zip.ZipEntry; import java.io.BufferedReader; import java.io.InputStreamReader; String urlStr = vars.get(&#34;url&#34;); log.info(&#34;&gt;&gt;&gt; url: {}&#34;, urlStr); // 创建 URL 对象 并打开链接 URL url = new URL(urlStr); ZipInputStream zipStream = new ZipInputStream(url.openStream()); // 读取压缩包内的文件 ZipEntry entry = zipStream.getNextEntry(); if (entry != null &amp;&amp; !entry.isDirectory()) { // 文件内容读取  BufferedReader br = new BufferedReader(new InputStreamReader(zipStream, &#34;UTF-8&#34;)); StringBuilder sb = new StringBuilder(); String line; while ((line = br.readLine()) != null) { sb.append(line); sb.append(&#34;\n&#34;); } br.close(); log.info(&#34;&gt;&gt;&gt; File Content: \n&#34; + sb.toString()); } zipStream.close(); log.info(&#34;=================== 通过链接下载 zip 文件，然后解压缩后读取 doc 文档内容 ===================&#34;); 脚本断言 if (!&#34;${groupName_ALL}&#34;.contains(&#34;${name}&#34;)) { AssertionResult.setFailure(true); // respCode 500  // 官方文档 按照这么来并没有提示出错误信息 todo  // AssertionResult.setFailureMessage(&#34;断言失败了！！！&#34;); } else { log.info(&#34;断言成功！&#34;); } 字符串分割 String fullname = vars.get(&#34;name&#34;); String[] parts = fullname.split(&#34;-&#34;); String lastPart = parts[parts.length - 1]; vars.put(&#34;lastPart&#34;, lastPart); log.info(&#34;提取的数字: lastPart = {}&#34;, lastPart); ]]></content></entry><entry><title>随笔 - 我作为面试官的一些心得</title><url>/tech/%E9%9A%8F%E7%AC%94/%E6%88%91%E4%BD%9C%E4%B8%BA%E9%9D%A2%E8%AF%95%E5%AE%98%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%83%E5%BE%97/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html">简历筛选阶段 格式 编写完简历一定要检查下简历格式，下面都是我在看简历过程中发现的问题：
中文与英文/字母间，需要用空格 不要犯这种低级错误：错别字、单词拼写、乱码、UI 错乱 大小标题不要混用，例：项目名三级标题，项目描述、职责啥的大标题加粗，头重脚轻的感觉 列举技术栈或者职责的时候，前面添加缩进符会好一点，不然一堆文字，看起来不直观 标点符号的使用，同一种类型有的用空格，有的用逗号，有的用顿号，符号语言统一下比较好 花里胡哨的模板尽量不要用，真的有点费眼睛，比如姓名一般后面就是名字吧，有个模板中间加彩色的 // 然后才是名字 基本情况对齐，姓名、电话、性别啥的，如果是多行保持对齐呀朋友们~ 同行都不对齐更过分了~（模板慎用） 用了简历模板，然后有的项空着不填，如果不想填就删除掉吧 中英文冒号混用，避免一下 技术栈 来个例子吧，到底是熟悉还是不熟悉：熟悉 Python 语言，Python 的变量和基本数据类型，输入输出语句，集合和元组操作 没有实际落地经验的框架不要写熟悉，是否有项目经验两句话就看出来了 项目描述 项目业务描述过多，有很多套话，花很大篇幅写之前的业务细节没必要，简单写下就行了
业务的技术架构以及用到的技术栈，在这种技术架构下采用了那些测试方法
最近的项目写在前面
能把整个项目的技术架构（前后端）这个写出来很加分
我需要了解下的东西 AppScan：做移动端还是 web 端的，或者都做？ Monyog：MySQL 数据库性能监测工具 UPR 和 UWA 都是性能测试的术语，以下是它们的具体含义：
UPR（User-perceived performance）：指用户感知的性能，也称为前端性能。UPR 通常通过测量网站的加载时间、响应时间和交互反应速度等指标来评估。
UPR 测试工具可以测量页面从开始加载到可交互的时间（TTFI）和页面完全加载所需的时间（TTLB），以及其他一些指标。这些指标可以帮助开发人员了解网站的性能瓶颈，并优化代码以提高用户体验。
UWA（User Workflow Automation）：指用户工作流自动化性能测试，也称为后端性能。UWA 测试主要关注服务器端的性能和稳定性，例如 API 响应时间和吞吐量。
在 UWA 测试中，测试工具会模拟多个用户同时访问服务器，并对服务器的响应时间和吞吐量进行测量。这些指标可以帮助开发人员评估服务器的性能瓶颈，并采取措施提高服务器的性能和稳定性。
综上所述，UPR 和 UWA 是两种不同的性能测试方法，分别用于评估前端和后端的性能。在开发过程中，使用这两种测试方法可以全面评估网站或应用程序的性能，找出瓶颈并进行优化。
我自己存在的问题 存在口音，吐字不清，注意降低语速 抛出问题的时候，给个提示；有个面试者项目写了做过 UI 自动化测试，我就直接问 UI 自动化怎么做了？他说我没做过&amp;hellip;可能他忘记最后一个项目里面写了做过的；下次这么问：我看你简历上XXX项目中写了做过UI自动化 然后再抛出问题，避免双方尴尬</content></entry><entry><title>Chrome - 插件 Switchomega</title><url>/tech/chrome/%E6%8F%92%E4%BB%B6-switchomega/</url><categories><category>Chrome</category></categories><tags><tag>Chrome</tag></tags><content type="html">介绍 谷歌浏览器网络代理。
安装 在线安装 谷歌插件商店
本地安装 适用于无法在线安装的朋友
官网 Github 发布地址 插件下载后，保存到本地，修改扩展名为 .zip，然后解压缩到任意目录；
谷歌浏览器：设置 - 更多工具 - 扩展程序 - 开发者模式 - 加载已解压的扩展程序，选择上面加压缩的文件夹。
PS：如果插件都下载不了，可以留言我发你。</content></entry><entry><title>Jenkins - 构建 Metersphere 测试计划任务</title><url>/tech/jenkins/%E6%9E%84%E5%BB%BA-metersphere-%E6%B5%8B%E8%AF%95%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[Jenkins 下载插件 点击链接进入发布页面，按照平台版本下载： metersphere/jenkins-plugin   下载 *.hpi 文件
安装插件  系统管理 - 插件管理 - 高级 - Deploy Plugin - 选择文件（.hpi） - DEPLOY
 Pipeline 新建流水线，定义 Pipeline script 如下：
pipeline { agent any stages { stage(&#39;Test&#39;) { steps{ script { meterSphere msEndpoint:&#39;http://XXXX&#39;, msAccessKey:&#39;XXXXXX&#39;, msSecretKey:&#39;XXXXXX&#39;, workspaceId:&#39;XXXXXX&#39;, projectId:&#39;XXXXXX&#39;, method:&#39;testPlan&#39;, testPlanId:&#39;XXXXXX&#39;, mode:&#39;parallel&#39;, resourcePoolId:&#39;&#39;, result:&#39;metersphere&#39; } } } } } MeterSphere 构建共提供了以下参数供用户进行配置：
 msEndpoint：MeterSphere服务地址，例如：https://demo.metersphere.com msAccessKey：右上角点击用户 - 个人信息查看，首次新建一个； msSecretKey：右上角点击用户 - 个人信息查看，首次新建一个； workspaceId：需要触发执行的测试所在的工作空间id； projectId：需要触发执行的测试所在的项目id； method：触发执行的任务类型（testplan：执行整个测试计划，single：执行指定的某个测试任务）； testPlanId：测试计划id，method参数值为testplan时有效； testCaseId：场景id/接口用例id/性能测试id，method参数值为single时有效； mode：执行方式（serial：串行执行，parallel：并行执行）； resourcePoolId：执行测试使用的测试资源池id。  ID 去对应的页面抓一下，填入即可。
 参考：https://blog.fit2cloud.com/?p=3343
 ]]></content></entry><entry><title>Chrome - 在开发者工具中重放请求</title><url>/tech/chrome/%E5%9C%A8%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%E4%B8%AD%E9%87%8D%E6%94%BE%E8%AF%B7%E6%B1%82/</url><categories><category>Chrome</category></categories><tags><tag>Chrome</tag></tags><content type="html">接口根据请求参数不同，返回不同的响应值。
在 charles 中可以使用断点的方式，那么在谷歌浏览器的控制台中怎么实现呢？
右键请求 - Copy - Copy as fetch 切换到控制台 tab，粘贴 修改参数后，按下回车 返回 network tab 即可查看到重放请求 Copy as fetch 是指在 Chrome 浏览器的开发者工具中，可以将某个网络请求复制到剪贴板中，格式为 Fetch API 代码，以便在开发过程中进行调试和测试。
使用该功能，您可以轻松地将请求示例粘贴到 JavaScript 代码中，并通过更改参数来调整和测试请求。这方面的好处是使得开发人员不必手动编写 HTTP 请求代码，而是可以通过 Chrome 自动生成代码，从而减少了代码书写的时间和工作量。
Fetch API Fetch API 是一种用于获取和发送 HTTP 请求的新型 Web API，它提供了一种现代化的方式来处理网络请求。Fetch API 提供了一组接口，可以让 JavaScript 代码轻松地处理HTTP请求和响应。
使用Fetch API，您可以向服务器发送 GET、POST 等各种类型的请求，并且可以控制请求头、请求体等参数。Fetch API 还支持 Promise，因此您可以轻松地使用异步方式处理请求和响应，而不必使用回调函数。
另外，值得注意的是，Fetch API 是基于浏览器内置的 XMLHttpRequest（XHR）对象实现的，但它提供了更为简洁、易用和灵活的 API 接口。</content></entry><entry><title>功能测试 - 禅道 问题记录</title><url>/tech/%E7%A6%85%E9%81%93/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html"><![CDATA[数据提取 比如用例的链接为：/testcase-view-1159.html，要获取 json 数据就将后缀的 html 变更为 josn 即可。
放在浏览器请求后，中文用 unicode 编码了，不方便查看数据。
这里记录将该数据格式化的过程。
方式一 vscode 下载 JSON（beautiful json） 插件，cmd+shift+j 一键搞定。
方式二  通过 在线工具   json 格式化 通过 在线工具   去转义，Unicode 转中文 将 data 前后引号去掉，再次 json 格式化  BUG 记录  问题：需求在模块 A 下面，用例在模块 A 的子模块 B 下面，用例关联需求后，就会出现点击编辑，关联需求自动清空的现象。
 请求编辑用例接口后，发现如下变更：
&#34;field&#34;: &#34;story&#34;, &#34;old&#34;: &#34;1012&#34;, &#34;new&#34;: &#34;0&#34;, 升级到最新 18.3 版本，该问题依然存在。
 回复: 感谢您的反馈 这个问题复现了 我记录下bug 在后期的版本应该会尽快修复的
 ]]></content></entry><entry><title>Jmeter&Ms - Ms 提取多个变量转为列表作为下个接口的传参</title><url>/tech/jmeterms/ms-%E6%8F%90%E5%8F%96%E5%A4%9A%E4%B8%AA%E5%8F%98%E9%87%8F%E8%BD%AC%E4%B8%BA%E5%88%97%E8%A1%A8%E4%BD%9C%E4%B8%BA%E4%B8%8B%E4%B8%AA%E6%8E%A5%E5%8F%A3%E7%9A%84%E4%BC%A0%E5%8F%82/</url><categories><category>Jmeter&Ms</category></categories><tags><tag>Jmeter&Ms</tag></tags><content type="html"><![CDATA[ 接口获取信息，提取多个值存储到列表，用于下一个接口的传参。
场景如下：
 接口一获取所有问卷 ID 接口二需要传参一个问卷 ID 列表，删除列表中所有问卷   接口一 获取所有问卷的信息列表：
{ &#34;success&#34;: true, &#34;message&#34;: &#34;success&#34;, &#34;data&#34;: [ { &#34;id&#34;: 7711, &#34;name&#34;: &#34;员工福利需求调查 - 1&#34; }, { &#34;id&#34;: 7712, &#34;name&#34;: &#34;员工福利需求调查 - 2&#34; }, { &#34;id&#34;: 7713, &#34;name&#34;: &#34;员工福利需求调查 - 3&#34; } ] } 通过「 后置操作 - 提取参数 - JsonPath提取 」，表达式为：$.data[*].id 获取所有 ID 并赋值给变量 form_ids，注意要勾选后面的「 匹配多条 」。
接口二 删除所有的表单 /delete，请求体如下：
{ &#34;companyId&#34;: &#34;996&#34;, &#34;formId&#34;: [] // 接收一个表单 ID 列表，用于删除组内所有表单 } 上面已经提取出来所有表单 ID 并赋值给变量了，这里直接通过控制台打印变量看下
log.info(vars.get(&#34;form_ids&#34;)); // 报错；获取不到变量  // 由于勾选了匹配多个，提取全部变量需要添加后缀 _ALL log.info(vars.get(&#34;form_ids_ALL&#34;)); 7711,7712,7713 由于请求体内需要的类型是数组，所以在传参的时候手动加上中括号，请求体如下：
{ &#34;companyId&#34;: &#34;996&#34;, &#34;formId&#34;: &#34;[${form_ids_ALL}]&#34; } 发送请求，发现请求体中的 formId 其实是个字符串，并不是列表类型的
&#34;formId&#34;: &#34;[7711,7712,7713]&#34; 添加前置脚本，去掉请求体中该参数值的两个引号
log.info(&#34;====== 去掉 formId 参数值前后的引号 ======&#34;); String requestBody = sampler.getArguments().getArgument(0).getValue(); log.info(&#34;初始请求体: \n{}&#34;, requestBody); requestBody = requestBody.replace(&#34;\&#34;[&#34;, &#34;[&#34;).replace(&#34;]\&#34;&#34;, &#34;]&#34;); log.info(&#34;更新请求体: \n{}&#34;, requestBody); sampler.getArguments().removeAllArguments(); sampler.addNonEncodedArgument(&#34;&#34;, requestBody, &#34;&#34;); sampler.setPostBodyRaw(true); log.info(&#34;====== 去掉 formId 参数值前后的引号 ======&#34;); 发送请求，formId 已经变成列表类型了，请求成功，返回正确的业务状态。
&#34;formId&#34;: [7711,7712,7713] 
问题解决！感觉有点复杂呀，要是有更好的办法请告诉我！😭]]></content></entry><entry><title>Andorid - Appium 1 运行原理</title><url>/tech/andorid/appium-1-%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"><![CDATA[简介  Appium   是一个移动端自动化测试框架，可用于测试：
 原生应用：安卓或 iOS 应用 移动网页应用：网页应用，h5，safari 或者手机 chrome 混合应用：原生应用嵌套 webview  支持跨平台，底层多引擎可切换，生态丰富，社区强大。
概念 客户端 / 服务器 架构 Appium 的核心一个是暴露 REST API 的 WEB 服务器。它接受来自客户端的连接，监听命令并发送指令到移动设备上执行，返回 HTTP 响应来描述执行结果。
 Appium 客户端   客户端程序库，各种语言实现的 Appium-client API，是 Appium 对 WebDriver 协议的扩展。这些库封装了标准的 Selenium 客户端，提供了所有 JSON Wire protocol   指定的常规 selenium 命令，并额外添加操控移动设备相关的命令，例如 多点触控手势 和 屏幕方向。
Appium 服务器 Appium 是一个用 Node.js 写的服务器，可以放在本机，也可以放在云端。主要负责两件事情：
  默认开启 4723 端口，监听来自客户端的 HTTP 请求
  本地开启 4724 端口，将请求转发给移动端
   预期能力（Desired Capabilities）   它告诉服务器我们想要启动什么类型的自动化会话，本质上是一个 key-value 形式的对象。脚本通过请求以 json 格式发送测试设备信息给服务端，服务端来完成该类型会话的创建。
会话（Session） 自动化测试始终在一个会话的上下文中执行，客户端程序库以各自的方式发起与服务器的会话，但最终都会发给服务器一个 POST /session 请求，请求中包含一个被称作「预期能力」的 JSON 对象。这时服务器就会开启这个自动化会话，并返回一个用于发送后续命令的会话 ID。
Session 对象存储特定用户会话所需的属性及配置信息，对应到这里其实就是 Desired Capabilities 中的配置信息参数。
 Appium Desktop  
Appium 界面版本，打包了 Appium 服务器运行需要的所有东西。提供 Inspector 查看应用程序的层级结构。
各平台测试引擎列表：
 iOS 9.3 及以上: 苹果的 XCUITest   iOS 9.3 及以下: 苹果的 UIAutomation   Android 4.3+: 谷歌的 UiAutomator / UiAutomator2   Android 2.3+: 谷歌的 Instrumentation   Windows: 微软的 WinAppDriver    框架介绍 客户端发送请求到服务端，服务端将请求转为可执行指令发送到设备，执行操作后返回结果。
以 Android 端为例
 启动 Appium Server，监听 4723 端口的请求； 运行代码，client 向 server 发送带有设备信息的 HTTP 请求，server 监听到该设备信息； 初始化移动设备，安装 bootstrap.jar 并自动开启设备的 4724 端口； server 开启 4724 端口用于和 bootstrap.jar 通信，等待客户端连接； server 根据监听到的 client 请求生成对应的自动化会话，并返回 SessionID 给 client； client 将脚本转化为请求并携带 SessionID 发送给 server； server 将请求解析后，通过 4724 端口转发给 bootstrap.jar，这时的 Appium server 转变为客户端； bootstrap.jar 将请求信息转化为 uiautomator 指令，让 uiautomator 进行处理并执行; 执行后的请求响应原路返回给脚本，脚本再进行下一次的请求； 代码执行 quit 后，关闭 session 和进程，测试结束。  Appium Server 作为服务端，同时也是客户端，是一个双向通信连接实现数据交换的过程。
 总体来说，Appium Server 既扮演着 server 的角色又扮演着 client 角色。
当它面对代码脚本的时候是一个 server，接收脚本发送的请求指令；
当它面对在终端设备上部署的原生代理（Android -&gt; bootstrap.jar | iOS -&gt; wda）时又是一个client，把接收到的网络指令以规定的形式发出去，不同平台的代理将请求解析为原生语言指令，通过原生测试框架操作 APP，这就是 appium 实现跨平台的方式。
 环境安装  java 1.8+ Android SDK Node. js (&gt;=10)、npm(&gt;=6) python3 appium-desktop（非必须） appium-python-client  Appium Server 是 node.js 写的，必须先安装 node  
# 安装 appium $ npm install -g appium $ appium # 安装 python client $ pip install Appium-Python-Client 验证环境是否正常。
from appium import webdriver desired_caps = { &#39;platformName&#39;: &#39;Android&#39;, &#39;platformVersion&#39;: &#39;10.0&#39;, &#39;deviceName&#39;: &#39;Android Emulator&#39;, &#39;appPackage&#39;: &#34;com.android.settings&#34;, &#34;appActivity&#34;: &#34;.HWSettings&#34; } driver = webdriver.Remote(&#34;http://localhost:4723/wd/hub&#34;, desired_caps) driver.quit() ]]></content></entry><entry><title>Andorid - Appium 2 元素定位与操作</title><url>/tech/andorid/appium-2-%E5%85%83%E7%B4%A0%E5%AE%9A%E4%BD%8D%E4%B8%8E%E6%93%8D%E4%BD%9C/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"><![CDATA[ Appium 常用 API。
 元素定位 DOM 结构  dom：Document Object Model，文档对象模型。 dom 应用：用于表示界面的控件层级，界面的结构化描述。常见的格式为 html\xml。核心元素为节点和属性。  Andoid 应用的层级结构和 html 不一样，是一个定制的 xml。App source 类似于 dom，表示界面所有控件的结构。每个控件都有它的属性，但没有 css 属性。
IOS 与 Android 的 dom 结构类似，但是属性有所区别，例：
 Android resourceid = iOS name Android content-des = IOS accessibility-id  Android Uiautomator 定位表达式 uiautomator 是安卓的工作引擎，比 xpath 速度快。缺点是表达式书写复杂，容易写错，IDE 没有提示。
写法参考：
   Appium Selector  
   Android Selector  
  # 点击按钮（通过文本定位） driver.find_element_by_android_uiautomator( &#39;new UiSelector().text(&#34;登录&#34;)&#39; ).click() # 输入文本（通过 ID 定位） driver.find_element_by_android_uiautomator( &#39;new UiSelector().resourceId(&#34;login_account&#34;)&#39; ).send_keys(&#34;123456&#34;) # 点击按钮（通过 ID 定位） driver.find_element_by_android_uiautomator( &#39;new UiSelector().resourceId(&#34;button_next&#34;)&#39; ).click() # 点击推荐（组合定位，通过 ID 查找父元素定位子元素） recommend = &#39;new UiSelector().resourceId(&#34;title_text&#34;).childSelector(text(&#34;推荐&#34;))&#39; driver.find_element_by_android_uiautomator(recommend).click() # 页面滑动找到「猜你喜欢」并点击（滚动查找，直到元素出现） text = &#39;new UiScrollable(&#39; \ &#39;new UiSelector().scrollable(true).instance(0)).scrollIntoView(&#39; \ &#39;new UiSelector().text(&#34;猜你喜欢&#34;).instance(0));&#39; driver.find_element_by_android_uiautomator(text).click() Toast 控件定位 简易消息提示框，在当前页面显示一个浮动的显示块，与 dialog 不同，它永远不会获得焦点，尽可能不引人注意，同时向用户提供必要的信息，时间到后自动消失。
它是系统级别的控件，APP 发送内容和指定时间给系统，由系统弹框，这类的控件不在 APP 内，需要特殊的控件识别方法。
定位原理
 appium 使用 uiautomator 底层的机制来分析抓取 toast，并且把 toast 放到控件树里面，但是它本身并不属于控件 获取页面内容 getPageSource 无法找到 必须使用 xpath 查找  driver.find_element_by_xpath(&#34;//*[@class=&#39;android.widget.Toast&#39;]&#34;).text) driver.find_element_by_xpath(&#34;//*[contains(@text, &#39;暂无更新&#39;)]&#34;).text) iOS 元素操作 元素的常用操作 # 点击 ele.click() # 输入文本 ele.send_keys(&#34;hello world&#34;) # 设置可编辑元素的内容 ele.set_value() # 清空可编辑元素的内容 ele.clear() # bool 是否展示 ele.is_dispalyed() # bool 是否可用 ele.is_enable() # bool 是否选中 ele.is_selected() # 根据属性键获取属性值 ele.get_attribute(&#34;attr_key&#34;) 元素的常用属性 # 获取元素文本  ele.text # 获取元素坐标 [&#34;y&#34;: 10, &#34;x&#34;: 300] ele.location # 获取元素尺寸 [&#34;width&#34;: 300, &#34;height&#34;: 500] ele.size &#34;&#34;&#34;获取属性示例&#34;&#34;&#34; # 只有通过元素才可以调用该方法，获取元素的属性以及元素的信息 book_image = driver.find_element_by_id(&#34;niv_image_book_shelf_item_grid&#34;) print(f&#34;书籍书籍封面 content-desc：{book_image.get_attribute(&#39;content-desc&#39;)}&#34;) print(f&#34;书籍书籍封面 resource-id：{book_image.get_attribute(&#39;resource-id&#39;)}&#34;) print(f&#34;书籍书籍封面 enabled：{book_image.get_attribute(&#39;enabled&#39;)}&#34;) print(f&#34;书籍书籍封面 clickable：{book_image.get_attribute(&#39;clickable&#39;)}&#34;) print(f&#34;书籍书籍封面 bounds：{book_image.get_attribute(&#39;bounds&#39;)}&#34;) TouchAction from appium.webdriver.common.touch_action import TouchAction # 短按 press(self, el=None, x=None, y=None) # 长按  long_press(self, el=None, x=None, y=None, duration=1000(ms)) # 点击 tap(self,el=None,x=None,y=None,count=1) # 释放，结束屏幕上的一系列动作的命令操作 release(self) # 移动到 move_to(self,el=None,x=None,y=None) # 等待 wait(self,ms=0) # 执行 perform(self) # 组合示例  # 点击 -&gt; 等待 -&gt; 移动 -&gt; 释放 -&gt; 执行 TouchAction(driver).press(x,y).wait(1000).move_to(x2,y2).release().perform() MultiTouch # 多点触控 action0 = TouchAction().tap(ele0) action1 = TouchAction().tap(ele1) MultiTouch().add(action0).add(action1).perform() ]]></content></entry><entry><title>Ios - Appium Ios 元素定位</title><url>/tech/ios/appium-ios-%E5%85%83%E7%B4%A0%E5%AE%9A%E4%BD%8D/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html"><![CDATA[iOS Predicate String 定位表达式结构：属性 + 运算符 + 值
# == 运算符: # 属性 label 的值 与 字符串 &#34;SYSTEM(TEXT)&#34; 相等 label == &#34;SYSTEM(TEXT)&#34; # AND 运算符 # 同时满足多个条件 label == &#34;SYSTEM(TEXT)&#34; AND enabled == true 运算符
比较运算符：可以用来比较数值或字符串，== &gt;= &lt;= &gt; &lt; != &lt;&gt;
范围运算符：可用于数值和字符串的范围比对，IN、BETWEEN
字符串相关运算符：CONTAINS \ BEGINSWITH \ ENDSWITH
逻辑运算符：AND \ OR \ NOT
模糊匹配：LIKE
 匹配一个字符?：label LIKE &quot;a?c?de&quot; 匹配多个字符*：label LIKE &quot;a*&quot;  正则表达式：MATCHES
 label MATCHES '^a.+d$'  元素属性  type：元素类型，className name：元素文本内容，AccessibilityId 定位方式 label：绝大数情况下，与 name 一致 enabled：元素是否可点击，布尔值 visible：元素是否可见，布尔值  webview 网页 和 混合应用的区别就是设置 bundleID 不一致。网页应用为 safari 浏览器，混合应用为应用名称。
真机调试
手机 - 设置 - safari浏览器 - 高级 - 打开网页检查器
# 安装 ios-webkit-debug-proxy $ ios_webkit_debug_proxy -f \ chrome-devtools://devtools/bundled/inspector.html # 访问：http://127.0.0.1:9221/ ]]></content></entry><entry><title>Andorid - Appium 调试 Webview</title><url>/tech/andorid/appium-%E8%B0%83%E8%AF%95-webview/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">webview Android（6.0 以上）需要打开 webview 调试开关
if (Biuld.VERSION.SDK_INT &amp;gt;= Build.VERSION_CODES.KITKAT){ WebView.setWebContentsDebuggingEnabled(true); } mumu模拟器无法获取到 webview 页面和窗口
参考</content></entry><entry><title>功能测试 - 网络基础及抓包方法汇总</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E5%8F%8A%E6%8A%93%E5%8C%85%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html"><![CDATA[网络基础 常见网络模型与常见协议 网络架构图 互联网通讯协议架构 TCP / UDP  TCP：面向连接、错误重传、拥塞控制、适用于可靠性高的场景 UDP：不需要提前建立连接，实现简单，适用于实时性高的场景  Restful 软件架构风格 借助于 http 协议的基本请求方法代表资源的状态切换
 get：获取资源 post：新增或更新资源 put：更新资源 delete：删除资源  RPC 协议 Remote Procedure Call，以本地调用的方式实现远程执行
 Dubbo（阿里）  java 上高性能 RPC 协议，Apache 开源项目，由阿里捐赠 底层应用层协议支持 dubbo 缺省 tcp 协议、http、hessian、thrift、grpc 等 Dubbo 接口本质上也是属于 TCP/IP 技术栈   gRPC（Google）  高性能通用 RPC 框架，基于 Protocol Buffers（Google） PB 是一个语言中立、平台中立的数据序列化框架，谷歌开源项目   Thrift（Facebook）  与 gRPC 类似的多语言 RPC 框架，Apache 开源项目     协议分析工具  网络监听（偏向于网络层）  TcpDump（命令行） + WireShark   代理 Proxy（代理应用层协议分析）  Charles（全平台）、安全测试 burpsuite（全平台 java） mitmproxy（自动化测试 python） fiddelr（windows）、AnyProxy（全平台）   协议客户端工具（主动发起请求）  curl（命令行） postman（Chrome 插件&amp;客户端 全平台）    网络监听 使用场景：用 tcpdump 抓包保存以后，使用 wireshark 界面工具分析。
tcpdump $ sudo tcpdump -Al host www.baidu.com  参数  -x 十六进制展示 -w file 保存文件   表达式  ip tcp 协议 host 主机名 port 80 端口号 src（来源）&amp; dst（目的地） 过滤 and or () 逻辑表达式    wireshark  官网  
 参考资料  
示例：请求百度后， TCP 连接建立过程 $ sudo tcpdump host www.baidu.com -w /tmp/tcpdump.log # 需要输入电脑密码，开启新窗口发送请求 $ curl http://www.baidu.com # 停止 tcpdump # 启动 wireshark，点击文件夹图标，打开 tcpdump.log 三次握手与四次挥手
使用 chrome 开发者工具分析网络请求  Elements：抓取页面元素，做自动化测试经常使用 Console：控制台，可以在页面上与 JavaScript 交互 Sources：源代码面板，可以设置断点调试 JavaScript Network：网络面板，用于 web 抓包，记录了每条网络操作的相关信息 Performance：录制页面性能数据 Memory：排查代码内存分配问题 Application：应用面板，使用资源面板检查加载的所有资源，包括 IndexedDB 与 Web SQL 数据库，本地和会话存储，cookie，应用程序缓存，图像，字体和样式表 Security：安全面板，用于调试混合内容、证书等问题 Lighthouse：用于提高网页质量，能够针对性能、可访问性、渐进式 Web 应用等进行审核  下图为 network 面板的功能注解。
curl 常见用法 # get $ curl $url | jq # post $ curl -d &#39;$body&#39; $url # proxy 代理网络请求 $ curl -x &#39;http://localhost:8080&#39; $url  -H：消息头设置 -u：username:password 用户认证 -d：要发送的 post 数据，@file 表示来自于文件 &ndash;data-urlencode &lsquo;page_size=50&rsquo;：对内容进行编码 -G：把 data 数据当成 get 请求的参数发送，常与 &ndash;data-urlencode 结合使用 -o：写文件，用于下载 -x：代理 http、socks5 -v：verbose 打印更详细的日志 -s：关闭一些提示输出  通过 jq   可以格式化 json 的输出内容，更加优雅。
Charles  过滤请求：Proxy - Recording Settings 弱网设置：Proxy - Throttle Settings 断点请求：Proxy - Breakpoint Settings 映射请求：Tools - Map Remote&amp;Local 重写请求：Tools - Rewrite  mitmproxy 演示：当请求百度域名的时候，会自动打印信息。
import mitmproxy.http from mitmproxy.tools.main import mitmdump class Events: def request(self, flow: mitmproxy.http.HTTPFlow): &#34;&#34;&#34; The full HTTP request has been read. &#34;&#34;&#34; flow_url = flow.request.url if &#34;baidu&#34; in flow_url: # 还可以做其他操作，比如修改搜索词 等 print(f&#34;{&#39;-&#39;*10}哈哈哈 {&#39;-&#39;*10}&#34;) addons = [ Events() ] if __name__ == &#39;__main__&#39;: # 使用 debug 模式启动 mitmdump # 端口需要使用字符串 mitmdump([&#39;-p&#39;, &#39;8080&#39;, &#39;-s&#39;, __file__]) 不仅可以代理请求，最重要的是可以自定义脚本进行二次开发，实现很多代理工具做不到的事情。
]]></content></entry><entry><title>功能测试 - 接口测试基础</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%9F%BA%E7%A1%80/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html"><![CDATA[ 做接口测试时，经常会接触到 get、post，token、cookie、session，关于他们的区别，这里详细记录一下。
 Get 与 Post 的区别 通过 curl 发送两个请求，保存信息到文件内，进行比较。
$ curl -s &#34;http://httpbin.org/status/200&#34; -v &amp;&gt;/tmp/get $ curl -s &#34;http://httpbin.org/status/200&#34; -d &#34;a=1&#34; -v &amp;&gt;/tmp/post  http 的 method 字段不同 数据传输方式不同  get：以 ？分割 URL 和传输数据，参数之间以 &amp; 相连  英文 + 数字 会原样发送 空格会转换为 + 中文或者其他字符，会转为 base64   post：数据存放在 body 内进行传输，可以支持 form、json、xml、binary 等各种数据格式   post 请求的响应头带有 Content-Length 和 Content-Type  Content-Length 代表 body 的长度，这个长度必须精准 Content-Type 代表响应的数据格式   行业通用的规范  无状态变化的建议使用 get 请求 数据的写入与状态的修改建议使用 post 请求    Cookie cookie 是一个非常具体的东西，指的就是浏览器里面能永久存储的一种数据，仅仅是浏览器实现的一种数据存储功能。
cookie 由服务器生成，发送给浏览器，浏览器把 cookie 以 kv 形式保存到文本文件内，下次请求同一网站时会把该 cookie 发送给服务器。由于 cookie 是存在客户端上的，所以浏览器加入了一些限制确保 cookie 不会被恶意使用，同时不会占据太多磁盘空间，所以每个域的 cookie 数量是有限的，且每个域的 cookie 只作用于自己的网站。
Session session 从字面上讲，就是会话。这个就类似于你和一个人交谈，你怎么知道当前和你交谈的是张三而不是李四呢？对方肯定有某种特征（长相等）表明他就是张三。
session 也是类似的道理，服务器要知道当前发请求给自己的是谁。为了做这种区分，服务器就要给每个客户端分配不同的“身份标识”，然后客户端每次向服务器发请求的时候，都带上这个“身份标识”，服务器就知道这个请求来自于谁了。至于客户端怎么保存这个“身份标识”，可以有很多种方式，对于浏览器客户端，大家都默认采用 cookie 的方式。
服务器使用 session 把用户的信息临时保存在了服务器上，用户离开网站后 session 会被销毁。这种用户信息存储方式相对 cookie 来说更安全，可是 session 有一个缺陷：如果web服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候 session 会丢失。
Token Token 是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个 Token 返回给客户端，以后客户端只需带上这个 Token 前来请求数据即可，无需再次带上用户名和密码。
最简单的 token 组成:
 uid(用户唯一的身份标识) time(当前时间的时间戳) sign(签名，由token的前几位+盐以哈希算法压缩成一定长的十六进制字符串，可以防止恶意第三方拼接 token 请求服务器)  使用 Token 的目的是为了减轻服务器的压力，减少频繁的查询数据库，使服务器更加健壮。
传统身份验证 HTTP 是一种没有状态的协议，也就是它并不知道是谁访问应用。客户端通过用户名和密码进行身份验证后，再次发送请求，还得验证一下。
解决办法：用户身份验证通过后，在服务端会生成一条记录用来保存用户数据，然后把这条记录的 ID 号发送给客户端，客户端将收到的 ID 号存储在 Cookie 里。客户端再次发送请求的时候，带着 Cookie 信息，服务端收到请求后会验证 Cookie 信息是否已经存在，如果存在，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。
这就是 Session 的工作流程，服务端保存登录用户的信息，并返回 sessionId，sessionId 可以放在请求的 cookie 或 query 中标记。Session 并不是永久性存储，服务端会定期清理过期的 Session 。
基于 Token 的身份验证 使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：
 客户端使用用户名跟密码请求登录 服务端收到请求，去验证用户名与密码 验证成功后，服务端会签发一个 Token，发送给客户端，Token 可以设置有效期 客户端收到 Token 以后存储起来，比如放在 Cookie 里或者 Local Storage 里 客户端每次向服务端发起请求都需要带着 Token 服务端收到请求，验证 Token 的真实性和有效期  成功，向客户端返回数据 失败，返回错误信息，重新登录    Token 是个凭据，丢失后可以重新认证。当然也会存在泄漏问题，比如别人拿到你的手机，获取到 Token，在过期之前就都可以以你的身份在别的地方登录。
解决这个问题办法：将请求URL、时间戳、Token 三者进行合并加盐签名，服务端校验有效性。
cookie 与 session 的区别   cookie 数据存放在客户端上，session 数据放在服务器上。
  cookie 不安全，别人可以分析存放在本地的 cookie 进行复用，考虑到安全应当使用session。
  session 会保存在服务器上一段时间，当用户增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用 cookie。
  单个 cookie 保存的数据不能超过 4K，很多浏览器都限制一个站点最多保存 20 个 cookie。
  一般将登录等重要信息存放为 SESSION，其他信息如果需要保留，可以放在 COOKIE 中。
  session 与 token 的区别   session 和 token 并不矛盾，作为身份认证 token 安全性比 session 好，因为每个请求都有签名还能防止监听以及重放攻击。
  Session 是一种 HTTP 存储机制，目的是为无状态的 HTTP 提供的持久机制。所谓 Session 认证只是简单的把用户信息存储到 Session 里，因为 SID 的不可预测性，暂且认为是安全的，这是一种认证手段。 而 Token，如果指的是 OAuth Token 或类似的机制的话，提供的是认证和授权，认证是针对用户，授权是针对应用。其目的是让应用有权利访问用户的信息。这里的 Token 是唯一的。不可以转移到其它 App 上，也不可以转到其它 用户 上。
  Session 只提供一种简单的认证，即有此 SID，即认为有此用户的全部权利，是需要严格保密的，这个数据应该只保存在站方，不应该共享给其它网站或者第三方 App。 所以简单来说，如果你的用户数据可能需要和第三方共享，或者允许第三方调用 API 接口，用 Token。如果永远只是自己的网站，自己的 App，用什么就无所谓了。
打破误解 “只要关闭浏览器 ，session 就消失了？”
不对。对session来说，除非程序通知服务器删除一个 session，否则服务器会一直保留，程序一般都是在用户做 log off 的时候发个指令去删除 session。
然而浏览器从来不会主动在关闭之前通知服务器它将要关闭，因此服务器根本不会有机会知道浏览器已经关闭。
之所以会有这种错觉，是大部分 session 机制都使用会话 cookie 来保存 session id，而关闭浏览器后这个 session id 就消失了，再次连接服务器时也就无法找到原来的 session。如果服务器设置的 cookie 被保存在硬盘上，或者使用某种手段改写浏览器发出的 HTTP 请求头，把原来的 session id 发送给服务器，则再次打开浏览器仍然能够打开原来的 session.
恰恰是由于关闭浏览器不会导致 session 被删除，迫使服务器为 session 设置了一个失效时间，当距离客户端上一次使用 session 的时间超过这个失效时间时，服务器就可以以为客户端已经停止了活动，才会把session 删除以节省存储空间。
 来源  
]]></content></entry><entry><title>功能测试 - 抓包工具 Whistle</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7-whistle/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html"> Whistle 官方文档
安装启动 $ brew install whistle &amp;amp;&amp;amp; w2 start --init 安装成功后，打开 Whistle 管理界面: http://local.whistlejs.com
命令行 # 启动 $ w2 start # 加入账号密码启动 $ w2 start -n yourusername -w yourpassword # 重启 $ w2 restart # 停止 $ w2 stop # 调试模式启动 $ w2 run # 默认端口 8899，如果被占用，通过 -p 参数指定端口号
遇到的问题 安卓配置好代理后，实际没走代理 电脑连接了 VPN，有两个 IP 地址。设备 A 连接 VPN IP 可以正常代理请求，设备 B 不行，切换成本地 IP 后成功代理请求。
安卓无法下载 https 证书，下载任务一直等待中 配置好手机代理后，扫描下载证书的二维码，下载任务一直等待中，证书不能下载。
解决办法：
更换 chrome 浏览器，别用自带的浏览器 访问 http://{IP}:8899/cgi-bin/rootca 下载 参考：https://github.com/avwo/whistle/issues/184</content></entry><entry><title>随笔 - Chatgpt 账号注册及使用</title><url>/tech/%E9%9A%8F%E7%AC%94/chatgpt-%E8%B4%A6%E5%8F%B7%E6%B3%A8%E5%86%8C%E5%8F%8A%E4%BD%BF%E7%94%A8/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html"> 参考教程
注册过程 开启全局网络代理（非内地和香港地区），进入官网页面：https://chat.openai.com
进入验证手机号页面
在 接码平台 购买一个马来西亚的手机号（印度的不行了~）
输入验证码完成注册
20230405 更新：英格兰可以正常使用 解决 注册完成后出现提示：OpenAI’s services are not available in your country
在当前页面浏览器地址栏手动输入 javascript: 然后粘贴下面内容，刷新页面。
window.localStorage.removeItem(Object.keys(window.localStorage).find(i=&amp;gt;i.startsWith(&amp;#39;@@auth0spajs&amp;#39;)))</content></entry><entry><title>Python - Pytest Allure报告数据设置</title><url>/tech/python/pytest-allure%E6%8A%A5%E5%91%8A%E6%95%B0%E6%8D%AE%E8%AE%BE%E7%BD%AE/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[allure 命令行工具 生成测试报告不启动服务
$ allure generate {allure_result} # -o 指定生成报告目录 # --clean 在生成新的 Allure 报告目录之前，清除该目录 $ allure generate {allure_result} -o {allure_report} --clean 启动服务，展示报告。
$ allure open {allure-report} 生成测试报告并启动服务，在网页上展示。相当于自动 generate + open
$ allure serve {result_path} 修改报告内 fixture 方法名展示 @allure.title(&#34;我是 fixture&#34;) def setup_session(autouse=True, scope=&#34;session&#34;) print(&#34;setup&#34;) yield print(&#34;teardown&#34;) 报告内的自动调用前置就会变成定义的名称，可读性更好。
]]></content></entry><entry><title>Httprunner - Hrp4 使用环境变量</title><url>/tech/httprunner/hrp4-%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url><categories><category>Httprunner</category></categories><tags><tag>Httprunner</tag></tags><content type="html"><![CDATA[python 设置环境变量 import os # 设置环境变量 os.environ[&#34;token&#34;] = token # 获取环境变量 token = os.environ[&#34;token&#34;] token = os.getenv(&#34;token&#34;) # 移除环境变量 os.environ.pop(&#34;token&#34;) Httprunner 设置环境变量 获取环境变量方式：${ENV(token)}
同文件中使用全局变量
config = ( Config(&#34;request methods testcase with functions&#34;) .export(*[&#34;token&#34;] # 导出为全局变量 ) teststeps = [ Step( RunRequest(&#34;get with params&#34;) .get(&#34;$base_url/get&#34;) .extract() .with_jmespath(&#34;body.args.token&#34;, &#34;token&#34;) # 这里提取变量的值 .validate() .assert_equal(&#34;status_code&#34;, 200) ), Step( RunRequest(&#34;post form data&#34;) .post(&#34;$base_url/post&#34;) .with_data(&#34;token=$token&#34;) # 在其他步骤中使用 .validate() .assert_equal(&#34;status_code&#34;, 200) ) ] 跨文件使用全局变量
]]></content></entry><entry><title>Httprunner - Hrp4 Websocket</title><url>/tech/httprunner/hrp4-websocket/</url><categories><category>Httprunner</category></categories><tags><tag>Httprunner</tag></tags><content type="html"><![CDATA[ 说明文档：https://testerhome.com/topics/33229
 本地 ws 服务
import asyncio import websockets # 接收客户端消息并处理，这里只是简单把客户端发来的返回回去 async def recv_user_msg(websocket): while True: recv_text = await websocket.recv() print(&#34;recv_text:&#34;, websocket.pong, recv_text) response_text = f&#34;Server return: {recv_text}&#34; print(&#34;response_text:&#34;, response_text) await websocket.send(response_text) # 服务器端主逻辑 async def run(websocket, path): while True: try: await recv_user_msg(websocket) except websockets.ConnectionClosed: print(&#34;ConnectionClosed...&#34;, path) # 链接断开 break except websockets.InvalidState: print(&#34;InvalidState...&#34;) # 无效状态 break except Exception as e: print(&#34;Exception:&#34;, e) if __name__ == &#39;__main__&#39;: print(&#34;127.0.0.1:8181 websocket...&#34;) asyncio.get_event_loop().run_until_complete(websockets.serve(run, &#34;127.0.0.1&#34;, 8181)) asyncio.get_event_loop().run_forever() Hrun 用例
config: name: 本地websocket测试 base_url: ws://127.0.0.1:8181 teststeps: - name: open connection websocket: type: open url: &#34;/&#34; headers: User-Agent: HttpRunnerPlus validate: - check: status_code assert: equals expect: 101 msg: check open status code - check: headers.Connection assert: equals expect: Upgrade msg: check headers - name: ping pong test websocket: type: ping url: &#34;/&#34; timeout: 5000 - name: 客户端发送消息 websocket: type: w url: &#34;/&#34; text: &#34;你好&#34; - name: 客户端读取服务端返回的消息 websocket: type: r url: &#34;/&#34; validate: - check: body assert: contains expect: &#34;你好&#34; msg: validate msg - name: write and read text websocket: type: wr url: &#34;/&#34; text: &#34;先发后读&#34; validate: - check: body assert: contains expect: &#34;先发后读&#34; msg: check length equal - name: close connection websocket: type: close url: &#34;/&#34; close_status: 1000 timeout: 30000 validate: - check: status_code assert: equals expect: 1000 msg: check close status code ]]></content></entry><entry><title>Python - 关键字 Else 语法总结</title><url>/tech/python/%E5%85%B3%E9%94%AE%E5%AD%97-else-%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ else 使用汇总。
 问题 阅读别人代码，有点疑惑，精简后如下：
def code_example(arg=None): for i in range(5): if arg: break else: print(&#39;else branch&#39;) 循环语句后面直接跟了 else 语句，未报错，程序正常运行。一般 else 都是配合判断语句用，那么这里的 else 是什么作用呢？
尝试
for i in range(2): print(i) else: print(&#34;else branch&#34;) &gt;&gt;&gt; 0 1 else branch test01：根据打印信息发现，for 循环正常执行完成后执行了 else 分支；
for i in range(2): continue else: print(&#34;else branch&#34;) &gt;&gt;&gt; else branch test02：循环体内增加 continue 跳出，执行完成循环后，正常执行 else 分支；
for i in range(2): break else: print(&#34;else branch&#34;) &gt;&gt;&gt; test03：如果 break 掉循环，打断循环，没有任何输出，也就是不走 else 分支；
def test(): for i in range(2): return else: print(&#34;else branch&#34;) &gt;&gt;&gt; test04：尝试 return 语句，打断循环，也是不走 else 分支。
结论 for … else …
 仅当循环体全部执行完成，才执行 else 分支； 当循环过程被打断，则不执行 else 分支。   扩展 Python 支持 else 语句汇总：
 for … else … while … else … try … except … else … if … elif … else …  while 与 for 循环相同步骤测试，结论一样
try
 当 try 内无异常执行完成后，执行 else 分支； 当 try 内出现异常，执行到 except，不再执行 else 分支。  def test_01(): try: print(&#34;try&#34;) except: print(&#34;except&#34;) else: print(&#34;else&#34;) &gt;&gt;&gt; try else ----------------------- def test02(): try: 5 / 0 except: print(&#34;except&#34;) else: print(&#34;else&#34;) &gt;&gt;&gt; except 总结  for、while 循环 当循环语句全部正常执行完成(包括 continue)，会继续执行 else 分支；当循环语句被打断(break\return)，不再执行 else 分支 try 异常处理 当 try 语句无异常执行完成时，会继续执行 else 分支；当抛出异常后，不再执行 else 分支 if 条件判断 不符合 if 或者 elif，才执行 else 分支  ]]></content></entry><entry><title>Python - Pymysql 连接数据库</title><url>/tech/python/pymysql-%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ python 连接数据库操作
 pymysql import pymysql def get_connect(): connect = pymysql.connect( host=&#34;xxx.com&#34;, port=3306, user=&#34;test&#34;, password=&#34;test1234&#34;, database=&#34;database_name&#34;, charset=&#34;utf8mb4&#34; ) return connect def execute_sql(sql): connect = get_connect() cursor = connect.cursor() cursor.execute(sql) # 执行 sql record = cursor.fetchone() # 查询记录 return record if __name__ == &#39;__main__&#39;: print(execute_sql(&#34;select * from table_name&#34;)) ]]></content></entry><entry><title>Python - Traceback 获取调用者的函数名称</title><url>/tech/python/traceback-%E8%8E%B7%E5%8F%96%E8%B0%83%E7%94%A8%E8%80%85%E7%9A%84%E5%87%BD%E6%95%B0%E5%90%8D%E7%A7%B0/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[def _is_page(self, locator): &#34;&#34;&#34;判断是否到达指定页面&#34;&#34;&#34; caller_name = traceback.extract_stack()[-2][2] is_page = self.ele_actions(locator).exists() self.log.opt(depth=1).info(f&#34;{caller_name}: {is_page}&#34;) if not is_page: raise PageObjectException return is_page 在 basepage 内封装好判断方法后，在其他页面调用该方法，需要打印其他页面的函数名。
因此要再该函数内获取调用者的函数名称。
import traceback caller_name = traceback.extract_stack()[-2][2] ]]></content></entry><entry><title>Python - Pytest Setup中的实例变量每条用例都会重置</title><url>/tech/python/pytest-setup%E4%B8%AD%E7%9A%84%E5%AE%9E%E4%BE%8B%E5%8F%98%E9%87%8F%E6%AF%8F%E6%9D%A1%E7%94%A8%E4%BE%8B%E9%83%BD%E4%BC%9A%E9%87%8D%E7%BD%AE/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[记录一个测试类变量初始化问题。
测试场景：初始化变量 a=1 ，每执行一条测试用例前，都使变量 a 自增 1，保证每条用例内的 a 都是不等的。
就像实例变量的值传递一样，如下：
class Demo: def __init__(self): self.a = 1 print(&#34;init: &#34;, self.a) def func_a(self): self.a += 1 print(&#34;func a: &#34;, self.a) def func_b(self): self.a += 1 print(&#34;func b: &#34;, self.a) if __name__ == &#39;__main__&#39;: d = Demo() d.func_a() d.func_b() &gt;&gt;&gt; init: 1 func a: 2 func b: 3 当用 pytest 框架编写测试用例时，提供了两个初始化的方式：
 setup_class：执行测试类时初始化，一个类仅初始化一次 setup：执行测试方法时初始化，测试类内的每个测试方法执行之前，都会执行  在 setup_class 内初始化变量 self.a=1，setup 内给变量 a 自增 1，这样每条测试方法执行前都会去自增 1，思考一下，这样是否能满足需求呢？
class Test: def setup_class(self): self.a = 1 print(&#34;exec setup class: &#34;, self.a) def setup(self): self.a += 1 print(&#34;exec setup -&#34;, self.a) def test_1(self): print(self.a) def test_2(self): print(self.a) def test_3(self): print(self.a) 以上代码的执行结果执行如下，跟我预期不同。
&gt;&gt;&gt; exec setup class exec setup - 2 2 exec setup - 2 2 exec setup - 2 2 测试方法 1 自增完成后等于 2，执行测试方法 2 的初始化时，变量 a 的值又重新变为 1 自增 1 得到 2，测试方法三同理。
查看 unittest 实现：
class TestDemo(unittest.TestCase): @classmethod def setUpClass(cls): cls.a = 1 print(&#34;exec setup class: &#34;, cls.a) def setUp(self) -&gt; None: self.a += 1 print(&#34;exec setup: &#34;, self.a) def test_01(self): print(&#34;test case 01: &#34;, self.a) def test_02(self): print(&#34;test case 01: &#34;, self.a) &gt;&gt;&gt; exec setup class: 1 exec setup: 2 test case 1: 2 exec setup: 2 test case 2: 2 与 pytest 执行结果一致。
通过 debug 看下用例执行过程， 执行测试用例 1 的初始化，初始化一个实例对象。
执行测试用例 1 时，实例对象不变，所以 a 的值是共用的。
执行测试用例 2 的初始化，发现实例变更，所以 a 的初始值并不为 2 ，而是重新创建了一个测试对象后变更为 1。
上面这个 demo，踩了个小坑，记录一下，以后别这么用了。为了应对开头的场景，我使用随机数分配给测试用例，问题得到了解决。
]]></content></entry><entry><title>Python - Pytest 基础笔记</title><url>/tech/python/pytest-%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[通过 python 调用 $ python -m pytest [...] 等同于直接调用 pytest，通过 python 调用会将当前目录添加到 sys.path
退出码
 Exit code 0: 找到所有测试用例并测试通过 Exit code 1: 部分用例运行失败 Exit code 2: 用户中断了测试 Exit code 3: 执行过程中发生了内部错误 Exit code 4: pytest 命令行使用错误 Exit code 5: 没有找到任何测试用例  命令行参数 # 显示 pytest 的 import 的路径 $ pytest --version # 显示所有 fixtures $ pytest --fixtures # 显示帮助信息 $ pytest -h | --help # 说明：可以输出用例更加详细的执行信息，比如用例所在的文件及用例名称等 $ pytest -v # 说明：输出用例中的调试信息，比如控制台打印信息等 $ pytest -s # 说明：标记，执行特定的测试用例 $ pytest -m # 说明：&#34;关键字&#34;执行用例包含“关键字”的用例 $ pytest -k # 说明：简化控制台的输出，两个.. 点代替了 pass 结果 $ pytest -q # 控制台输入不展示警告信息 $ pytest -v -p no:warnings --color=yes # 按 features 运行测试用例 $ pytest --alluredir=report/xml --allure_features=测试登录功能 test_case.py # 按 story 运行测试用例 $ pytest --alluredir=report/xml --allure_stories=测试登录成功的场景 test_case.py # 按 severity 运行测试用例 $ pytest --alluredir=report/xml --allure_severities=blocker test_case.py &#34;&#34;&#34; 指定失败次数后停止 &#34;&#34;&#34; # 用例失败1次后停止执行 $ pytest -x # 用例失败5次后停止执行 $ pytest --maxfail=5 &#34;&#34;&#34; 运行指定测试用例 &#34;&#34;&#34; $ pytest test_demo.py # 指定目录 $ pytest test/ # 指定关键字：包含 demo 且 不包含 foo 的用例 # and not 是表达式 $ pytest -k &#34;demo and not foo&#34; # 通过 :: 指定 $ pytest test_demo.py::TestClass::test_method # 通过标签指定 @pytest.mark.smoke $ pytest -m smoke &#34;&#34;&#34; 修改 traceback 的打印 &#34;&#34;&#34; # 在回溯信息中显示本地变量 $ pytest --showlocals $ pytest -1 # 不同信息显示方式，auto 为默认 $ pytest --tb=auto | long | short | line | native | no &#34;&#34;&#34; 生成简略的报告汇总 &#34;&#34;&#34; $ pytest -ra # 可追加参数列表如下： f - failed E - error s - skipped x - xfailed X - xpassed p - passed P - passed with output a - all except pP &#34;&#34;&#34; 分析测试时间 &#34;&#34;&#34; # 显示最慢的 10 个测试步骤 # 小于 0.01s 不会显示异常，如需显示，追加 -vv 参数 $ pytest --durations=10 # 禁用插件 doctest $ pytest -p no:doctest &#34;&#34;&#34; 在 python 代码中运行 pytest &#34;&#34;&#34; pytest.main() pytest.main([&#39;-x&#39;, &#39;testdir&#39;]) # 指定插件 pytest.main([&#39;-q&#39;], plugins=[MyPlugins()]) 对异常断言 import pytest def test_exc(): with pytest.raises(ZeroDivisionError): 1 / 0 def test_excinfo(): with pytest.raises(RuntimeError) as excinfo: def f(): f() f() assert &#34;Maximun recursion&#34; in str(excinfo.value) # excinfo 包含了异常的详细信息，属性为 type、value、traceback # 可以通过 match 参数来正则匹配一个异常发生 def func(): raise ValueError(&#34;Exception 123 raised&#34;) def test_excinfo_match(): with pytest.raises(ValueError, match=r&#34;.* 123 .*&#34;): func() # pytest.warns 来判断是否产生了特定的警告信息 # conftets.py def pytest_assertrepr_compare(config, op, left, right) # 自定义断言注释 if isinstance(left, Demo) and isinstance(right, Demo) and op==&#34;==&#34;: return [&#34;test：&#34;, f&#34;{left.val}!= {right.val}] ... autouse   pytest.fixture(autouse=True)表示无需其他声明会自动调用这个 fixture
  autouse fixture 遵守 scope 的定义，如果为 session，则无论定义在哪儿都只会运行一次，如果为 class，则表示在每个 class 中只运行一次。
  如果在 conftest.py 中定义了 autouse，那么该目录下所有的测试用例都会自动使用该 fixture
  谨慎使用该功能，如果只是希望提在项目中提供一个 fixture，而不是想要在每个测试用例中激活使用的，那么可以将 fixture 移动到 conftest.py 中并不要定义 autouse
# conftest.py @pytest.fixture def demo(request, db): db.begin() yield db.rollback() # use @pytest.mark.usefixtures(&#34;demo&#34;) class TestClass: def test_method(self) ... TestClass 内所有的用例都会调用 demo fixture，而其他测试类或测试函数则不会调用，除非他们也添加了 fixture 的引用。
重写 fixtures 在 conftest 层重写 tests/ __init__.py conftest.py import pytest @pytest.fixture def username(): return &#34;username&#34; test_something.py def test_username(username): assert username == &#34;username&#34; subfolder/ __init__.py conftest.py import pytest @pytest.fixture def username(username): return &#34;overridden‐username&#34; test_something.py def test_username(username): assert username == &#34;overridden‐username&#34; 在 module 层重写 tests/ __init__.py conftest.py import pytest @pytest.fixture def username(): return &#34;username&#34; test_something.py @pytest.fixture def username(): return &#34;overridden‐username&#34; def test_username(username): assert username == &#34;overridden‐username&#34; 参数化重写 tests/ __init__.py conftest.py import pytest @pytest.fixture def username(): return &#34;username&#34; test_something.py @pytest.mark,parametrize(&#34;username&#34;, [&#39;username-demo&#39;]) def test_username(username): assert username == &#34;username-demo&#34; Monkeypatch 有时我们需要修改函数的全局配置或类似网络访问这些不容易测试的代码。monkeypatch 可以用来安全的设置、删除一个属性、字典项或环境变量。
临时文件  可以通过 tmp_path 来提供一个唯一的临时文件夹供函数调用。 tmp_path_factory：是一个 session 作用域的 fixture，可以在任意的 fixture 或者用例中创建任何想要的临时文件 tmpdir：可以为测试用例提供一个唯一的临时文件夹。 tmpdir_factory  捕获警告信息 import warnings def api_v1(): warnings.warn(UserWarning(&#34;api v1, should use func from v2&#34;)) return 1 def test_demo(): assert apu_v1() == 1 运行用例后，会在日志信息内展示警告信息。
-W 参数可以用来控制是否显示警告，甚至控制是否将警告转为 Error
$ pytest -q test_demo.py -W error::UserWarning 将警告信息转为报错。
在 pytest.ini 中也可以控制警告。
[pytest] # 忽略所有的用户告警，但是会将其他的所有告警转换成 error filterwarnings = error ignore::UserWarning # 禁止捕获告警 addopts = -p no::warnings # 废弃告警和将要废弃告警 # 忽略能够匹配所给正则表达式的DeprecationWarning filterwarnings = ignore:.*U.*mode is deprecated:DeprecationWarning 当一个告警与多个配置匹配的话，那么放在最后的配置项生效。
skip 和 xfail 跳过测试用例
# 方式一 装饰器 @pytest.mark.skip(reason=&#34;skip test&#34;) def test_skip(): ... # 方式二 代码内 def test_skip2(): if not flag: pytest.skip(&#34;flag is False, skip!&#34;) 跳过整个模块
import sys import pytest if not sys.platform.startswith(&#34;win&#34;): pytest.skip(&#34;skipping windows-only tests&#34;, allow_module_level=True) 可以使用 skipif 控制在某些条件下跳过测试。
import sys @pytest.mark.skipif(sys.version_info &lt; (3, 6), reason=&#34;require python 3.6 or higher&#34;) def test_func(): ... 在查找用例时，如果判断 skipif 的条件是 True，该用例会被跳过。
可以再各个模块中共享 skipif 标记。
# test_module.py import module_name minversion = pytest.mark.skipif( module_name.__versioninfo__ &lt; (1, 1), reason=&#34;at least module-1.1 required&#34; ) @minversion def test_func(): ... # test_other_module.py from test_module import minversion @minversion def test_module(): ... 在大型项目中一般将这些共享标记放在一个文件里供其他模块调用。
]]></content></entry><entry><title>Python - Pytest Html 报告</title><url>/tech/python/pytest-html-%E6%8A%A5%E5%91%8A/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[测试报告生成插件： pytest-html  
安装 适用版本：Python &gt;=3.6.
$ pip install pytest-html 使用 准备测试代码
# test_login.py class TestLogin: def test_success(self): print(&#34;login success.&#34;) def test_fail(self): print(&#34;login fail.&#34;) $ pytest --html=report.html test/test_login.py # &gt;&gt;&gt; generated html file: file:/report.html 执行后在当前目录创建测试报告，得到的报告如下：
 assets  style.css   report.html  独立报告 默认情况下，CSS 和图像等资源会与 HTML 分开存储，当报告需要共享其他同事时就不太方便了。通过以下方式生成报告：
$ pytest --html=report.html --self-contained-html 这样执行得到的就是一个包含 CSS 样式和外部资源链接的 HTML 文件。
自定义报告 该插件还提供了 Hooks 函数，可以对报告数据、样式做出自定义修改。
# 将标题添加到报告之前调用 pytest_html.hooks.pytest_html_report_title(标题) # 将摘要部分添加到报告之前调用 pytest_html.hooks.pytest_html_results_summary（前缀，摘要，后缀） # 构建结果表头后调用 pytest_html.hooks.pytest_html_results_table_header(表头) # 构建结果表附加 HTML 后调用 pytest_html.hooks.pytest_html_results_table_html(报告,数据) # 在构建结果表行后调用 pytest_html.hooks.pytest_html_results_table_row（报告，单元格） 修改标题 测试报告内标题默认为 HTML 文件名。
# conftest.py def pytest_html_report_title(report): report.title = &#34;我是测试报告&#34; 修改环境（Environment） 测试报告内展示测试运行环境配置相关的信息。
# conftest.py import pytest def pytest_configure(config): &#34;&#34;&#34; 测试运行之前修改环境参数 &#34;&#34;&#34; config._metadata[&#34;测试环境&#34;] = &#34;线上&#34; # 新增 config._metadata.pop(&#34;JAVA_HOME&#34;) # 移除 @pytest.hookimpl(tryfirst=True) def pytest_sessionfinish(session, exitstatus): &#34;&#34;&#34; 测试运行之后修改环境参数 &#34;&#34;&#34; session.config._metadata[&#34;测试状态&#34;] = &#34;已完成&#34; session.config._metadata.pop(&#34;Base URL&#34;) 环境表内的 Base URL 项，是运行测试之后，环境管理插件自动生成的参数，需要放在运行测试之后的 hook 函数内删除，否则会报错找不到这个 key，而 JAVA_HOME 是环境变量，运行测试之前就存在，放在第一个 hook 函数内是可以成功删除的。
修改汇总信息（Summary） # conftest.py # Pycharm 可能会出报错提示，不影响执行 from py.xml import html def pytest_html_results_summary(prefix, summary, postfix): prefix.extend([html.p(&#34;hello world！&#34;)]) 修改结果表格（Results）  修改表格：插入列、删除列  # conftest.py import pytest from py.xml import html from datetime import datetime def pytest_html_results_table_header(cells): &#34;&#34;&#34; 修改表头属性，增加 Time 列，删除 Link 列 &#34;&#34;&#34; cells.insert(1, html.th(&#34;Time&#34;, class_=&#34;sortable time&#34;, col=&#34;time&#34;)) cells.pop() # 删除最后一列 def pytest_html_results_table_row(report, cells): &#34;&#34;&#34; 修改表格属性，同步表头修改&#34;&#34;&#34; cells.insert(1, html.td(datetime.utcnow(), class_=&#34;col-time&#34;)) cells.pop() 删除表格中所有通过的结果  # conftest.py def pytest_html_results_table_row(report, cells): &#34;&#34;&#34; 修改表格属性 用例状态（不区分大小写）： passed、skipped、failed、error、xfailed、xpassed、rerun &#34;&#34;&#34; if report.passed: del cells[:] 根据用例执行结果指定日志输出  # conftest.py def pytest_html_results_table_html(report, data): # 通过的用例，指定日志输出内容 if report.passed: del data[:] data.append(html.div(&#34;Case PASS.&#34;, class_=&#34;empty log&#34;)) 向表格内添加内容 # conftest.py @pytest.hookimpl(hookwrapper=True) def pytest_runtest_makereport(item, call): &#34;&#34;&#34; HTML：extra.html(&#39;&lt;div&gt;Additional HTML&lt;/div&gt;&#39;) JSON：extra.json({&#39;name&#39;: &#39;pytest&#39;}) TEXT：extra.text(&#39;Add some simple Text&#39;) LINK：extra.url(&#39;http://www.example.com/&#39;) IMAGE： extra.image(image, mime_type=&#39;image/gif&#39;, extension=&#39;gif&#39;) extra.image(&#39;/path/to/file.png&#39;) extra.image(&#39;http://some_image.png&#39;) extra.png/jpg/svg(image) &#34;&#34;&#34; pytest_html = item.config.pluginmanager.getplugin(&#34;html&#34;) outcome = yield report = outcome.get_result() extra = getattr(report, &#34;extra&#34;, []) if report.when == &#34;call&#34;: # always add url to report extra.append(pytest_html.extras.url(&#34;http://www.example.com/&#34;)) xfail = hasattr(report, &#34;wasxfail&#34;) if (report.skipped and xfail) or (report.failed and not xfail): # only add additional html on failure extra.append(pytest_html.extras.html(&#34;&lt;div&gt;Additional HTML&lt;/div&gt;&#34;)) report.extra = extra 也可以通过 fixture 来实现：
# test_login.py from pytest_html import extras def test_success(self, extra): print(&#34;login success.&#34;) extra.append(extras.text(&#34;login Success&#34;)) ]]></content></entry><entry><title>Python - Pytest Rerunfailures 失败用例重试</title><url>/tech/python/pytest-rerunfailures-%E5%A4%B1%E8%B4%A5%E7%94%A8%E4%BE%8B%E9%87%8D%E8%AF%95/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[  pytest-rerunfailures   插件，功能是用例执行失败可以重试。
 python 3.6+ pytest 5.3+   用例重试时，fixture 或 setup_class 也将被重新执行。
安装
$ pip install pytest-rerunfailures 使用
命令行使用
# 用例失败重试 3 次 $ pytest --reruns 3 # 用例失败重试 3 次，每次重试间隔时间为 2 秒 $ pytest --reruns=3 \  --reruns-delay=2 # 仅重试指定异常的用例 $ pytest --reruns=2 \  --only-rerun=AssertionError # 指定多个异常 pytest --reruns 2 \  --only-rerun AssertionError \  --only-rerun ValueError # 仅重试与指定异常不匹配的用例，仅重试非断言失败的用例 $ pytest --reruns 2 \  --rerun-except AssertionError # 指定多个 $ pytest --reruns 2 \  --rerun-except AssertionError \  --rerun-except OSError 用例内使用装饰器
import pytest &#34;&#34;&#34;执定重试次数&#34;&#34;&#34; @pytest.mark.flaky(reruns=2) def test_example(): assert False &#34;&#34;&#34;指定重试间隔时间&#34;&#34;&#34; @pytest.mark.flaky(reruns=2, reruns_delay=2) def test_example(): assert False &#34;&#34;&#34;指定重试条件&#34;&#34;&#34; # linux 系统下开启重试， mac 执行不重试 @pytest.mark.flaky(reruns=2, condition=sys.platform.startswith(&#34;Linux&#34;)) def test_example(): assert False # 非 linux 系统开启重试，mac 执行重试生效 @pytest.mark.flaky(reruns=2, condition=not sys.platform.startswith(&#34;Linux&#34;)) def test_example(): assert False 兼容性
 不能与 fixture 一起使用 与 pytest-xdist –looponfail 自动监听功能不兼容 与 –pdb 调试功能不兼容  ]]></content></entry><entry><title>Python - Pytest Reruns&Timeout插件兼容性问题</title><url>/tech/python/pytest-rerunstimeout%E6%8F%92%E4%BB%B6%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"> 记录一个 pytest-reruns 插件和 pytest-timeout 插件的 兼容性问题 。
先说结论：当两个插件一起使用时，需要设置 timeout_func_only=true，否则阻塞。
问题 接口自动化项目在容器内执行时 reruns 插件闪退，配置的 timeout 时间不生效，导致项目一直在阻塞状态，本文记录下该问题。
看看这个项目构建时长，受得了吗！？
复现步骤 编写测试用例
import pytest import time def test_rerun(): for i in range(5): time.sleep(1) print(f&amp;#34;sleep {i + 1}&amp;#34;) assert 0 验证插件各自都正常工作
$ pytest test.py -raR --reruns 2 Results (15.14s): 1 failed - test.py:14 test_rerun 2 rerun $ pytest test.py -raR --timeout 3 E Failed: Timeout &amp;gt;3.0s 两个插件结合使用
$ pytest test.py -sraR \ --reruns 2 --reruns-delay=2 \ --timeout==3 timeout: 3.0s timeout method: signal timeout func_only: False sleep 1 sleep 2 sleep 1 sleep 2 sleep 3 sleep 4 sleep 5 sleep 1 sleep 2 sleep 3 sleep 4 sleep 5 可以看到重试用例后，超时并没有生效，依然等待 5 秒。
解决 官方仓库内找到解决办法，需要增加一个配置项。
# -o 代表覆盖 pytest.ini 内定义的配置项 $ pytest test.py -sraR \ --reruns 2 --reruns-delay=2 \ --timeout=3 \ -o timeout_func_only=true # 需增加配置项 timeout=3 timeout: 3.0s timeout method: signal timeout func_only: True sleep 1 sleep 2 sleep 1 sleep 2 sleep 1 sleep 2 或者在配置文件内增加
[pytest] timeout = 5 timeout_func_only=true</content></entry><entry><title>Python - Pytest Xdist 分布式执行</title><url>/tech/python/pytest-xdist-%E5%88%86%E5%B8%83%E5%BC%8F%E6%89%A7%E8%A1%8C/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[分布式测试插件： pytest-xdist  
安装 $ pip install pytest-xdist 使用 测试代码准备
class Test: def test_sleep_2(self): sleep(2) assert False def test_sleep_3(self): sleep(3) assert True # 未使用插件执行，共等待 5 秒 $ pytest test_xdist.py # 1 failed, 1 passed in 5.22s # 调起 2 个进程执行任务 $ pytest -n 2 # 1 failed, 1 passed in 3.87s # 调起与计算机 CPU 内核一样多的进程 $ pytest -n auto # 1 failed, 1 passed in 4.84s 由于启动 CPU 进程也需要时间，所以用例较少的情况下，8 个进程甚至比 2 个进程消耗的时间还要长。用例过多的情况下，系统资源占用过高，导致性能下降。
因此，不推荐使用 auto 参数，指定一半的进程数给测试任务就可以了。
分发算法配置  &ndash;dist load：默认算法，分发用例给任何可用于执行的进程，不保证顺序； &ndash;dist loadscope：根据类分组，同一个类下的测试用例都分配给同一个进程运行； &ndash;dist loadfile：根据 py 文件分组，同一个文件内的用例分配给同一个进程运行，当文件数小于进程数时，启动文件数个进程； &ndash;dist each：每个进程都会运行此用例，也就是有多少个进程用例就运行多少遍。 &ndash;dist no：不使用并发执行  工作原理  控制器在测试开始时根据 -n 参数指定的值产生一个或多个工人，每个工人就是一个迷你的执行器； 工人收集完成的测试用例，将测试集发送会控制器，控制器本身不执行任何收集； 控制器接收所有工人反馈的集合，并执行一些健壮性检查以确保所有工人收集的测试是相同的，如果出现不同，则退出。 如果都相同，那么将测试集合转换为简单索引列表，与原测试集合索引位置相同，这样做可以节省带宽，控制器分配给工人需要执行的索引列表，工人根据列表内 ID 执行测试集合内对应的任务； 如果 &ndash;dist each，则向每一个工人都发送完整的测试索引列表； 如果 &ndash;dist load，每次分配大约 25% 的索引列表给每个工人，剩余任务等工人执行完成后继续分发； 当工人执行完全部任务时，会将结果返回给控制器，控制器就可以继续使用其他插件，比如报告插件； 全部工作执行完成后，控制器向工人发送关闭信号，进程结束。  遇到的问题 ERROR collecting：Different tests were collected between gw0 and gw1 原因是参数化测试用例，使用了随机值，导致并发收集测试用例时，gw0 和 gw1 两个工人收集到的 test id 出现不一致，解决这个问题的办法就是使用固定的参数，即参数生成好后存放起来，再传给参数化装饰器。
在 GitHub   上找到了关于这个错误的解释，设计如此，所以修改自己的测试用例吧！
如何让 scope=session 的 fixture 在 test session 中仅仅执行一次 pytest-xdist是让每个worker进程执行属于自己的测试用例集下的所有测试用例
这意味着在不同进程中，不同的测试用例可能会调用同一个scope范围级别较高（例如session）的fixture，该fixture则会被执行多次，这不符合scope=session的预期。
解决办法：虽然pytest-xdist没有内置的支持来确保会话范围的夹具仅执行一次，但是可以通过使用锁定文件进行进程间通信来实现。
小栗子  下面的示例只需要执行一次login（因为它是只需要执行一次来定义配置选项，等等） 当第一次请求这个fixture时，则会利用FileLock仅产生一次fixture数据 当其他进程再次请求这个fixture时，则会从文件中读取数据  import pytest from filelock import FileLock @pytest.fixture(scope=&#34;session&#34;) def login(): print(&#34;====登录功能，返回账号，token===&#34;) with FileLock(&#34;session.lock&#34;): name = &#34;testyy&#34; token = &#34;npoi213bn4&#34; # web ui自动化 # 声明一个driver，再返回 # 接口自动化 # 发起一个登录请求，将token返回都可以这样写 yield name, token print(&#34;====退出登录！！！====&#34;) ]]></content></entry><entry><title>Git - 记录向开源项目提交Pr过程</title><url>/tech/git/%E8%AE%B0%E5%BD%95%E5%90%91%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E6%8F%90%E4%BA%A4pr%E8%BF%87%E7%A8%8B/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[准备  创建 github 账号 网络通畅  开始 1、进入项目主页，以Httprunner为例。
https://github.com/httprunner/httprunner 2、点击项目右上角的 Fork 按钮，把项目克隆到自己的远程仓库，方便后续修改提交。
点击后页面会自动跳转到自己的远程仓库，把代码 Clone 到本地。
# 查看远程仓库链接 $ git remote -v origin git@github.com:abeelan/httprunner.git (fetch) origin git@github.com:abeelan/httprunner.git (push) 3、与原项目建立链接
$ git remote add upstream git@github.com:httprunner/httprunner.git $ git remote -v origin git@github.com:abeelan/httprunner.git (fetch) origin git@github.com:abeelan/httprunner.git (push) upstream git@github.com:httprunner/httprunner.git (fetch) upstream git@github.com:httprunner/httprunner.git (push) 4、创建新的分支，修复问题
$ git checkout -b bug-abee Switched to a new branch &#39;bug-abee&#39;  .env 文件未忽略注释及空行； HTTPS 请求无法获取客户端和服务端的 IP 、端口号。  5、提交修复后的分支代码到远程仓库
$ git add . $ git commit -m &#34;bug fixed&#34; # 提交到远程仓库 $ git push origin bug-abee To github.com:abeelan/httprunner.git * [new branch] bug-abee -&gt; bug-abee 6、进入远程仓库页面，发起 PR 请求。
点击按钮，自动跳转到原项目仓库创建 PR 页面。
编辑完成后，点击创建即可。
刷新页面，在 PR 列表就能看到了。
审核通过后就自动成为该项目的贡献者了。
]]></content></entry><entry><title>Docker - Lazydocker命令行可视化工具</title><url>/tech/docker/lazydocker%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html">下载对应系统的可执行文件
https://github.com/jesseduffield/lazydocker/releases/tag/v0.20.0
$ wget https://github.com/jesseduffield/lazydocker/releases/download/v0.20.0/lazydocker_0.20.0_Linux_x86_64.tar.gz $ tar -zxvf lazydocker_0.20.0_Linux_x86_64.tar.gz $ cd lazydocker $ cp lazydocker /usr/local/bin/ &amp;amp;&amp;amp; chmod +x /usr/local/bin/lazydocker $ lazydocker</content></entry><entry><title>Jenkins - 主题设置</title><url>/tech/jenkins/%E4%B8%BB%E9%A2%98%E8%AE%BE%E7%BD%AE/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"> jenkins 最新版本适配的 theme 有哪些？
更新于 2023-03-17，以下回答来自 ChatGPT
Jenkins 最新版本 (Jenkins 2.303 LTS) 目前支持以下几种官方适配的主题:
Classic Jenkins Theme：Jenkins 的默认主题，也是最老的主题，已经被逐步取代。在 Jenkins 2.303 LTS 版本中，Classic Jenkins Theme 已经被移除了。 Blue Ocean：基于 React 开发的全新界面，提供了现代化的用户界面和改进的用户体验。 Dark Theme：深色主题，提供了更舒适的夜间使用体验。 此外，还有一些社区开发的主题可供使用，例如： Material Theme：基于 Google Material Design 设计规范的主题。 Jenkins Simple Theme：简洁易用的主题，提供了多种自定义配置选项。 Bootstrap Theme：基于 Twitter Bootstrap 框架的主题，提供了响应式设计和多种样式配置选项。 需要注意的是，不同的 Jenkins 版本可能适配的主题有所不同。同时，使用第三方开���的主题可能会导致一些不兼容或者不稳定的情况发生。因此，在选择和使用主题时需要仔细考虑并测试其稳定性和兼容性。
安装 Material Theme 主题 Material Theme
系统管理 - 系统配置 - 插件管理 - 可安装，搜索 material-theme 插件，下载后重启。
重启方法：在 jenkins 访问地址后面加上 /restart，页面上确认重启。
更换主题：系统管理 - 系统配置 - Themes
只能修改主题颜色，图标啥的都跟原来一样~ job 控制台输出会好看很多，黑色背景~
安装 simple theme 主题 定制主题
Jenkins 2.346.3 使用该主题样式错乱，别换了。
1、可以点击上面连接，设置喜欢的颜色，公司的 LOGO，然后下载生成的 CSS 文件。
2、Jenkins：系统管理 - 系统配置 - 插件管理 - 下载插件：simple theme，重启生效
3、css 文件放到 var/jenkins_home/userContent 目录下
$ scp Downloads/jenkins-material-theme.css test@192.168.1.xxx:/data $ mv /data/jenkins-material-theme.css /volume/jenkins/jenkins_home/userContent/ 4、Jenkins：系统管理 - 系统匹配 - Theme
新增 - CSS URL，填写 http://jenkins访问地址/userContent/theme.css
点击保存即可。</content></entry><entry><title>Docker - 搭建Xmind2Testcase测试用例转换服务</title><url>/tech/docker/%E6%90%AD%E5%BB%BAxmind2testcase%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%E8%BD%AC%E6%8D%A2%E6%9C%8D%E5%8A%A1/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ 需求：部门使用禅道管理测试用例，但是由于迭代时间紧迫，大部分小伙伴都习惯使用 xmind 编写测试用例，后续再向禅道迁移。
为解决这一痛点，在网上找到 xmind 转 csv 的 python 库，本文记录该服务搭建过程。
 本文记录该服务搭建过程，需要用到的工具如下：
 xmind2testcase：基于该 python 库，定制化一些转换规则 docker：容器化部署服务，可以 web 页面操作转换 gitlab：项目源码管理、webhook  fork 项目源码 项目地址：https://github.com/zhuifengshen/xmind2testcase 基于公司用例编写习惯，改改代码；项目非常贴心的提供了 flask 前端访问页面，直接通过命令启动：
$ python webtool/application.py 测试没问题的话，就把项目扔到 gitlab 上
编写 Dockerfile 打成镜像，方便服务部署
FROMpython:3.10-alpine# 将当前目录中的所有��件复制到容器的 /app 目录中COPY . /app# 在容器中设置工作目录为 /appWORKDIR/app# 安装依赖项RUN pip install -r requirements.txt -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com# 启动服务EXPOSE8000CMD [&#34;python&#34;, &#34;webtool/application.py&#34;]
Jenkins 上创建项目  创建一个自由风格的项目 配置项目源码地址 编写项目构建 shell 命令  NAME=xmind2testcase docker build -t $NAME:latest . if docker ps -aqf name=$NAME | grep -q .; then docker rm -f $NAME fi docker run --name $NAME -d -p 8000:8000 -v /volume/$NAME/webtool/uploads:/app/webtool/uploads $NAME 进行构建，访问 8000 端口，即可。
自动构建 通过定时任务，或者 gitlab-webhook 实现自动构建，目前该服务无需求，通过手动构建即可。
]]></content></entry><entry><title>功能测试 - 禅道 取消上传附件大小限制</title><url>/tech/%E7%A6%85%E9%81%93/%E5%8F%96%E6%B6%88%E4%B8%8A%E4%BC%A0%E9%99%84%E4%BB%B6%E5%A4%A7%E5%B0%8F%E9%99%90%E5%88%B6/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html"> 禅道18.2镜像，限制附件上传大小为 50 M，如何取消或者修改这个限制呢？
要取消或修改禅道 18.2 镜像中的附件上传大小限制，需要按照以下步骤进行操作：
需要修改的三个配置项：
post_max_size：帖子大小限制 upload_max_filesize：附件大小限制 max_execution_time：上传超时时间 需要修改的三个配置文件：
php.ini .ztaccess .htaccess 我这里将默认的 50M 调整为 100M，开始操作
# 进入容器 $ docker exec -it zentao bash # 查找 php.ini 文件 $ find ./ -name php.ini ./etc/php/7.2/apache2/php.ini # &amp;lt;-- ./etc/php/7.2/cli/php.ini # 编辑并修改 # vi 中搜索：/post_max_size n 跳转下一个命中的关键词 $ vi ./etc/php/7.2/apache2/php.ini # 超时时间修改为 60 $ vi /www/zentaopms/www/.htaccess $ vi /www/zentaopms/www/.ztaccess 有两个 php 版本的配置，18.2 的修改 &amp;lt;IfModule mod_php7.c&amp;gt; 就可以。
修改后，重启服��。
$ apachectl restart 可以访问禅道并尝试上传一个大于 50M 的附件，以确保更改已经生效。
其他禅道搭建方式修改，可以参考如下信息，来自禅道官方群聊回复。
关于上传附件的大小限制： 1、windows一键安装包最大附件默认设置成50M。 如果还不够用，推荐把附件放到公共硬盘上，禅道中留下访问地址即可。 一定要修改的话，可以修改 xampp/zentao/www/.ztaccess 和 xampp\runner\res\ztaccess\下面的default.access、pro.access 中的post_max_size 和 upload_max_filesize值。 2、linux一键安装包：可以修改zentao/www/.ztaccess 文件中的参数 post_max_size 和 upload_max_filesize值 3、源码部署环境，php默认2M为最大附件，调整php.ini中的post_max_size和upload_max_filesize值，重启apache即可。 4、docker部署环境，在容器中调整php.ini中的post_max_size和upload_max_filesize值，重启apache即可。 5、如果是nginx服务器或者使用nginx代理，nginx有一个上传附件大小的配置client_max_body_size参数，默认是1M，调整后重启。 apachectl start</content></entry><entry><title>Docker - 搭建Nextcloud网盘服务</title><url>/tech/docker/%E6%90%AD%E5%BB%BAnextcloud%E7%BD%91%E7%9B%98%E6%9C%8D%E5%8A%A1/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"> 开发同学直接打包发到群里，包名都一样，没有版本的概念；包环境也无法区分，所以想自己做个部门的归档服务。
$ docker pull nextcloud $ docker run -d --restart=always --name nextcloud -p 80:80 nextcloud 体验了下有点重，TODO</content></entry><entry><title>Docker - Docker 配置Vpn网络代理</title><url>/tech/docker/docker-%E9%85%8D%E7%BD%AEvpn%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%90%86/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"> ubuntu 服务器想要通过 VPN 访问内网，如果通过 docker 实现？
使用 OpenVPN 直接在宿主机上开启 VPN
# 安装 openvpn $ apk install openvpn $ cd /etc/openvpn/client/ # 放入连接的密码及认证文件 pass.txt test_pub.conf # 设置开机启动 $ systemctl enable openvpn-client@test_pub.service # 启动；重启 restart $ systemctl start openvpn-client@test_pub.service # 停止 $ systemctl stop openvpn-client@test_pub.service # 查看状态 $ systemctl status openvpn-client@test_pub.service
使用 docker-ipsec-vpn-server 这个方法未验证，直接在宿主机上安装 VPN 客户端了。
1. 安装 Docker 并启动 Docker 服务 在 Ubuntu 上安装 Docker 并启动 Docker 服务，具体命令可以参考 Docker 的官方文档。
使用以下命令创建一个 Docker 网络：
$ docker network create vpn 2. 运行 VPN 客户端容器 VPN 客户端： docker-ipsec-vpn-server 使用以下命令在 Docker 网络中启动一个 VPN 客户端容器。
# 创建一个 VPN 环境配置文件，模板地址 # https://github.com/hwdsl2/docker-ipsec-vpn-server/blob/master/vpn.env.example $ vim ./vpn.env VPN_IPSEC_PSK=你的PSK密码 VPN_USER=你的VPN用户名 VPN_PASSWORD=你的VPN密码 $ docker run \ --name ipsec-vpn-server \ --env-file ./vpn.env \ --net vpn \ --restart=always \ -v /volume/ikev2-vpn-data:/etc/ipsec.d \ -v /lib/modules:/lib/modules:ro \ -p 500:500/udp \ -p 4500:4500/udp \ -d --privileged \ hwdsl2/ipsec-vpn-server 在该命令中，我们使用 docker run 的 -v 选项来创建一个名为 ikev2-vpn-data 的新 Docker 卷，并且将它挂载到容器内的 /etc/ipsec.d 目录下。IKEv2 的相关数据（比如证书和密钥）在该卷中保存，之后当你需要重新创建 Docker 容器的时候，只需指定同一个卷。
推荐在使用本镜像时启用 IKEv2。如果你不想启用 IKEv2 而仅使用 IPsec/L2TP 和 IPsec/XAuth (&amp;ldquo;Cisco IPsec&amp;rdquo;) 模式连接到 VPN，可以去掉上面 docker run 命令中的第一个 -v 选项。
请确保在启动容器时使用了 --privileged 参数以获得必要的权限。
3. 运行需要访问内网的容器 使用以下命令在 Docker 网络中启动需要访问内网的容器，并将其连接到 VPN 客户端容器：
$ docker run --net vpn --name ${container} -d ${container-image} 这样，你的容器应该可以通过 VPN 客户端容器访问内网了。</content></entry><entry><title>Mac - 查找并删除大文件（其他项占用过多解决方案）</title><url>/tech/mac/%E6%9F%A5%E6%89%BE%E5%B9%B6%E5%88%A0%E9%99%A4%E5%A4%A7%E6%96%87%E4%BB%B6%E5%85%B6%E4%BB%96%E9%A1%B9%E5%8D%A0%E7%94%A8%E8%BF%87%E5%A4%9A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html"><![CDATA[ Mac 存储空间中「其他」项占用非常大，通过工具来查看文件并清除大文件。 工具名称：OmniDiskSweeper 官网下载地址  
 OS X 里面的 Other 就是所有其他的文件。所有的文档，包括
 .pdf .doc .psd 所有的压缩文件和磁盘映像 包括 .zip .dmg .iso所有的用户数据所有的系统文件 包括 System 文件夹 和 cache 文件夹 所有的 Spotlight 不认识的文件 包括 .exe 在内的对 OS X 来说奇奇怪怪的后缀名 所有的不是 OS X 标准格式的视频、音频文件 所有的应用插件和扩展  安装 方式一：官网直接下载 方式二：命令行下载，通过 brew 安装
$ brew install omnidisksweeper ==&gt; Downloading https://downloads.omnigroup.com/software/MacOSX/10.14/OmniDiskSweeper-1.13.dmg ######################################################################## 100.0% ==&gt; Installing Cask omnidisksweeper ==&gt; Moving App &#39;OmniDiskSweeper.app&#39; to &#39;/Applications/OmniDiskSweeper.app&#39; 🍺 omnidisksweeper was successfully installed! 使用  启动 APP，选择磁盘，点击查找按钮即可 等待查找完毕 选择大文件，点击左下角的废纸篓完成删除  ]]></content></entry><entry><title>功能测试 - 抓包工具 Charles 使用手册</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7-charles-%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html"><![CDATA[ 很多年前跟同事（yanan）一起写的使用手册，放在这里做个备份吧~
 抓取 PC 端请求 [Charles 使用手册.md](Charles 使用手册.md) HTTP 请求 默认抓取pc端http请求（可在 Proxy - Windows Proxy 勾选抓取/不勾选不抓取）
HTTPS 请求  选择 Help-&gt;SSL Proxying-&gt;Install Charles Root Certificate，下载安装证书  点击安装证书，然后一路下一步，显示导入成功，点击确定。   此时去IE浏览器 工具栏 - internet选项 - 内容 - 证书 - 受信任的根证书颁发机构下找到Charles Proxy证书为成功。 如下图：
如找不到，则在中级证书颁发机构导出，受信任的根证书颁发机构导入。
抓取移动端请求 设置 Charles 要截取手机上的网络请求，首先需要将 Charles 的代理功能打开。
 在Charles的菜单栏上选择 “Proxy”-&gt;“Proxy Setting” 填入代理端口 8888（默认）并且勾选 “Enable transparent HTTP proxying” 就完成了再Charles上的设置。  手机设置 iPhone设置抓取 HTTP   获取Charles运行所在电脑的IP地址： Charles的顶部菜单的 Help-&gt;Local IP Address，即可在弹出的对话框中看到IP地址。
  在iPhone的 设置-&gt;无限局域网中，找到当前链接的 WiFi，点击右边的详情键，进入WiFi详细信息，包括IP地址，子网掩码等信息。在其最底部有【HTTP代理】一项，将其切换成手动，然后填上Charles运行所在的电脑IP，以及端口 8888。
  设置好之后，打开 iPhone 上的任意需要网络通讯的程序，就可以看到 Charles 弹出 iPhone请求连接的确认菜单，点击“allow”即可完成设置。
  Android 设置抓取 HTTP 在手机的设置-&gt;WLAN中，找到当前连接的WiFi名称：
 长按连接的WiFi或者点击连接的WiFi 打开高级选项或者滑动到底部代理处 在代理一栏选择手动 代理服务器主机名填写电脑的IP地址 代理服务器端口填写Charles设置的端口号：8888 点击【保存】/【确定】后即可 打开手机上的任意需要网络通讯的程序，就可以看到 Charles 弹出 iPhone 请求连接的确认菜单，点击“allow”即可完成设置。  iphone/Android 抓取 HTTPS   选择 Help -&gt; SSL Proxying -&gt; Install Charles Root Certificate on a Mobile Device or Remote Browser，弹框点击确定；
  Android/iphone手机浏览器访问地址： chls.pro/ssl , 根据提示下载安装ca证书;
  安装完成后，点击Proxy -&gt; SSL Proxy Settings -&gt; SSL Proxy-&gt;勾选 Enable SSL Proxying Add添加要抓取的站点、端口号（*代表任意的站点）
  再次抓取，即可成功（Andorid 7.0 以上无法抓取，需要客户端修改配置文件） 如何修改？  
  Map 功能  Map Remote 是将指定的网络请求重定向到另一个网址 Map Local 是将指定的网络请求重定向到本地文件  Map Local Map Local 功能，需要填写重定向的源地址和本地的目标文件。对于一些复杂的网络请求结果，可以先使用Charles 提供的“Save Response…”功能，将请求结果保存到本地，如下图所示。然后稍加修改，使其成为我们的目标映射文件。
下图是一个示例，将一个指定的网络请求通过Map Local 功能映射到了本地的一个经过修改的文件中，分两步进行介绍:
  首先选中某个请求（eg:status_control.m）右键，选择Map Local，出现如图所示：   将修改后的文件，导入Charles中，如下图：   重新刷新页面，就可以看到调试的那个文件其实是从本地加载的。
  Map Remote Map Remote 功能，需要分别填写网络重定向的源地址和目的地址，对于不需要限制的条件，可以留空。
  首先选中某个请求（eg: a.com）右键，选择 Map Remote，表示匹配 a.com 下的所有文件，将其重定向到 b.com 下;
  上面的配置通过 map Remote 就是实现了区别对待本地系统的不同请求，将指定路径下的请求重定向到指定的环境。
  Rewrite Rewrite功能重写对应的内容，主要可以对某些匹配请求的 header、host、url、path、query param、response status、body进行 rewrite。 Rewrite规则简单说明，指出对应的作用及其使用场景。 Header
 作用：可以对请求或者响应的 header 内容进行操作，包括添加、修改及删除 使用场景：在需要对header进行处理时用到，例如为了用上某个环境数据，可能需要对应cookie，这时本地开发是可以在请求的header中加上cooker信息；也可以重写响应header的信息  Host
 主要是对请求就行host修改，以达到本地请求获取指定host环境中的数据，常见于mock数据  url
 作用：修改url中某些部分，可以用别的url进行替换或者url裁剪时间戳或者md5等 使用场景：场景使用非常多，既可以对host也可以对path进行rewrite，可以满足指定host下的请求重定向到其他host对应的path下  Path 主要 rewrite path 内容使用指定rewrite规则的path来响应指定的请求的path，它可以对path进行裁剪
query param
 作用：可以对param进行操作，包括修改、添加、删除等 使用场景：有时请求可能多传递了不必要的参数，这时可以rewrite功能去掉多余的参数；另外也可以添加请求必须而暂时无法提供的参数  response status
 很少用到，就是对response的状态码进行rewrite  Body
 作用：对请求的相应内容做修改，一般是对某一个或几个值进行rewrite，用新的值来替代返回的值 使用场景：可以用来mock数据，比如说在开发中为了测试功能需要请求的某个数组字段有值，但是当前环境无法给出，就可以使用该功能    选择 Tools-&gt;Rewrite，在弹出的对话框中勾选 Enable Rewrite 启用 rewrite 功能。点击左侧Sets 中的 Add 按钮，添加一条 Rewrite 规则，可以设置一个名字；
  点击右侧 Location 中的 Add，可以全部留空匹配所有请求，也可以根据要过滤的指定接口，然后点击OK确认；
  点击 Rules 中的 Add 按钮，添加一条规则，弹出窗口设置如下： 修改 Response Header 匹配 Content-Type=text/plain 的项，并将其替换成 Content-Type=application/json;charset=UTF-8（根据实际情况进行设置），点击ok保存;
  再次使用MapLocal功能时，发现乱码问题已经解决了（前提是所映射的本地文件也是UTF-8编码，通常在Mac系统中，默认支持的中文编码就是UTF-8）
  Throttle（模拟慢网速请求） 选择 Proxy-&gt; Throtting setting，打开后如下图设置：（如果要针对某一个地址限速，在Hosts里可以add要限速的url） 在工具栏点击图标，即可直接开启模拟慢速网络。
Breakpoints 对于只是想临时修改一次网络请求结果，这个时候，使用 Rewrite 功能虽然也可以达到目的，但是过于麻烦，对于临时性的修改，最好使用 Breakpoints 功能。
Breakpoints 功能类似我们在 Xcode 中设置的断点一样，当指定的网络请求发生时，Charles 会截获该请求，这个时候，我们可以在 Charles 中临时修改网络请求的返回内容。
  找到需要进行断点设置的请求（在请求的父目录打断点），如下图：   查看未修改前，手机上对应请求的界面显示
  再次进入手机这个界面，会通过刚从打断点的域名来请求数据，就会被断点拦住，如下图：   可以编辑请求，点击执行，如果响应也打了断点，则响应回来了也可以编辑响应；
  编辑完成后，点击执行，即可看到客户端展示断点设置的内容。
  简单的压力并发 右键请求 - Repeat Advanced 设置并发线程数及打压次数，设置完毕，点击 ok ]]></content></entry><entry><title>Docker - Docker Compose配置文件参数详解</title><url>/tech/docker/docker-compose%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[示例文件：docker-compose.yml
version: &#39;3.8&#39; # Docker Compose 文件版本号 services: # 定义应用程序中的服务，每个服务对应一个容器 web: # 定义一个名为 web 的服务 image: nginx:latest  # 指定该服务使用的 Docker 镜像名称 build: .  # 指定 Dockerfile 的路径，Docker Compose 将自动构建该服务的 Docker 镜像 container_name: nginx  # 指定该容器的名称 ports: # 指定容器和宿主机之间的端口映射关系，格式为宿主机端口:容器端口 - &#34;8080:80&#34; # 将宿主机的 8080 端口映射到容器的 80 端口 volumes: # 指定容器和宿主机之间的数据卷映射关系，格式为宿主机路径:容器路径 - ./nginx.conf:/etc/nginx/nginx.conf:ro  # 将宿主机上的 nginx.conf 文件映射到容器的 /etc/nginx/nginx.conf 文件，并设置为只读模式 environment: # 指定容器的环境变量 - NGINX_PORT=80  # 设置一个名为 NGINX_PORT 的环境变量，值�� 80 command: nginx -g &#39;daemon off;&#39;  # 指定容器启动后要执行的命令，即运行 nginx，并设置为后台模式 restart: always  # 指定容器退出后的重启策略，可选值为 no、always、on-failure、unless-stopped depends_on: # 指定容器之间的依赖关系，使得一个容器启动前必须先启动其依赖的容器 - db  # 表示该容器依赖于名为 db 的服务 networks: # 指定容器所属的网络 - backend  # 将该容器加入名为 backend 的网络中 db: # 定义一个名为 db 的服务 image: mysql:5.7  # 指定该服务使用的 Docker 镜像名称 restart: on-failure:5  # 指定容器退出后的重启策略，on-failure:5 表示在容器退出代码非零时重启容器，最多重试 5 次 environment: # 指定容器的环境变量 - MYSQL_ROOT_PASSWORD=root  # 设置一个名为 MYSQL_ROOT_PASSWORD 的环境变量，值为 root - MYSQL_DATABASE=mydb  # 设置一个名为 MYSQL_DATABASE 的环境变量，值为 mydb - MYSQL_USER=user  # 设置一个名为 MYSQL_USER 的环境变量，值为 user - MYSQL_PASSWORD=password  # 设置一个名为 MYSQL_PASSWORD 的环境 build build 还可继续设置参数，包括：
 context：指定构建上下文路径，默认为当前目录。 dockerfile：指定 Dockerfile 文件路径，默认为 ./Dockerfile。 args：设置构建时的构建参数，格式为一个 key-value 的映射，可以在 Dockerfile 文件中使用 ${key} 来引用该参数。  具体含义如下： context：构建上下文路径，即指定在哪个目录下寻找 Dockerfile 文件以及构建上下文。如果该路径是相对路径，则相对于 docker-compose.yml 所在目录。构建上下文路径中的所有文件和文件夹都会被发送到 Docker 引擎以供构建使用，因此如果上下文路径中包含大量不必要的文件，则会导致构建时间过长和镜像体积过大。
dockerfile：Dockerfile 文件路径，即指定使用哪个 Dockerfile 文件进行构建。默认为 ./Dockerfile，即当前目录下的 Dockerfile 文件。如果指定了相对路径，则相对于构建上下文路径。如果指定了绝对路径，则会忽略上下文路径。
args：构建参数，即在构建过程中传递给 Dockerfile 文件的变量。可以在 Dockerfile 文件中使用 ${key} 的方式引用该变量。例如，可以使用 args: { APP_ENV: production } 设置一个名为 APP_ENV 值为 production 的构建参数。在 Dockerfile 文件中可以使用 ${APP_ENV} 引用该参数。
除此之外，build 参数还可以包含一些其他的选项，例如：
 cache_from：从指定的镜像中使用缓存来加速构建。 labels：为构建过程添加元数据标签。 network：指定构建时使用的网络。 shm_size：指定共享内存区的大小。 target：指定使用 Dockerfile 文件中的哪个构建阶段进行构建。  ]]></content></entry><entry><title>Docker - Docker Compose Restart策略</title><url>/tech/docker/docker-compose-restart%E7%AD%96%E7%95%A5/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"> restart 策略用于控制容器在退出后的行为。
on-failure 是指在容器退出时，当其退出状态码不为0（即失败）时，自动重启该容器。具体来说，它会重启那些在容器退出时返回非0状态码的容器。如果容器在退出时返回状态码0，则不会自动重启该容器。 no：容器退出时不重启容器； always：容器退出时总是重启容器； unless-stopped：容器退出时重启容器，除非容器被手动停止。 部署服务时，应该根据服务的性质和重要程度选择合适的 restart 策略。下面列举了几种常见的情况和建议的 restart 策略：
Web 服务器：建议使用 always 或 unless-stopped 或 on-failure 策略，以确保 Web 服务器始终处于运行状态，可以提供服务。 数据库服务器：建议使用 unless-stopped 策略，因为在某些情况下，数据库服务器可能需要手动停止，例如在执行升级操作时。unless-stopped 策略可以在容器被手动停止时不重启容器，从而避免意外的数据丢失。 队列服务：建议使用 always 策略，因为队列服务需要一直运行来处理任务。如果容器在处理任务时出现故障，自动重启能够及时恢复服务，避免任务积压。 日志收集服务：建议使用 no 策略，因为这种服务通常只需要在容器启动时运行一次，然后在后台持续运行，不需要重启容器。 当然，这只是一些常见的情况和建议，实际上应该根据具体服务的需求和重要性来选择合适的 restart 策略。</content></entry><entry><title>Booknotes - 《计算机网络原理》计算题汇总</title><url>/tech/booknotes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E8%AE%A1%E7%AE%97%E9%A2%98%E6%B1%87%E6%80%BB/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html">计算题汇总 计算机网络性能 题一 题二 题三 HTTP 连接 题一 页面：建立连接 + 请求页面 = 1 + 1 图片：建立连接 + 请求图片 = (1 + 1) x 8 答：共需要 18 RTTh
![image-20230308233241159](/Users/lan/Library/Application Support/typora-user-images/image-20230308233241159.png)
页面：建立连接 + 请求页面 = 1 + 1 图片：建立连接 + 请求图片 = （1 + 1） + （1 + 1），由于配置了并行连接，每次 5 个，需要两次 答：共需要 6 RTTh
![image-20230308233438567](/Users/lan/Library/Application Support/typora-user-images/image-20230308233438567.png)
非流水方式：
页面：建立连接 + 请求页面 = 1 + 1 图片：请求 8 张图片 = 8 流水方式：
页面：建立连接 + 请求页面 = 1 + 1 图片：8 张图以前请求且不需要建立连接 = 1 答：非流水方式需要 10 RTTh；流水方式需要 3 RTTh
题二 ![image-20230308234420827](data:image/svg+xml,)
Socket 编程基础 问题一：socket 函数调用代码填空 基于 TCP 的调用过程中：ms 主服务分发子任务 ss 去执行相关请求，ms 主服务继续监听其他请求。
P2P 文件分发（简单了解） 采用 C/S 体系结构实现文件分发时间
采用 P2P 体系结构实现文件分发
TCP 拥塞控制 TCP 连接建立与拆除 IP IP 分片 分片步骤：
第一步：每个分片最多可以封装多少字节的数据 第二步：分片数 第三步：标志位 第四步：片偏移量（单位为8字节） 假设有一个总长度为5000字节的IP数据报，需要通过MTU为1500字节的链路传输。
该IP数据报应分为几片？ 4片 最后一片的长度是多少？ 560B 每片的DF、MF值是多少？ DF：0000 MF：1110 每片的片偏移值是多少？ 0、185、370、555 IP 地址计算 已知IP 地址172.32.1.113对应的子网掩码为255.255.254.0，求出：
（1）这个IP 地址所在的网络的网络地址；（写出计算过程）
（2）这个网段的IP 地址范围；
（3）这个网段可分配的IP 地址范围；
（4）这个网段的广播地址。
路由算法</content></entry><entry><title>Booknotes - 《计算机网络原理》个人笔记</title><url>/tech/booknotes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html"><![CDATA[计算机网络概述 基本概念 起源：计算机网络是计算机技术与通信技术融合的产物。
定义：计算机网络是互连的、自治的计算机的集合。
ISP：因特网服务提供商（Internet Service Provider）。
协议 网络协议：网络通信实体之间在数据交换过程中需要遵循的规则或约定。
协议三要素：
 语法：定义实体之间交换信息的格式与结构 语义：定义实体直接交换信息中的控制信息 时序：同步，定义实体之间交换信息的顺序以及如何匹配或适应彼此的速度  计算机网络功能  硬件资源共享：云存储、云计算 软件资源共享：大型办公软件 SaaS、大型数据库系统 信息资源共享：信息检索、新闻浏览  计算机网络分类 按照覆盖范围分类：
 个域网（PAN）：1~10m 局域网（LAN）：10m~1km 城域网（MAN）：5~50km 广域网（WAN）：50km+  按照拓扑结构分类：
 星形拓扑结构：中央结点故障，全网瘫痪；规模受限于中央结点端口数量 总线型拓扑结构：广播通信，容易产生冲突 环形拓扑结构：某个结点故障，全网瘫痪；加新结点麻烦 网状拓扑结构：网络可靠性高，成本高，用于核心网络 树形拓扑结构：根结点要求高；目前局域网 混合拓扑结构：绝大多数实际网络  按照交换方式分类：
 电路交换方式 报文交换方式 分组交换方式（计算网络采用此方式）  按网络用户属性分类：公用网、私有网
计算机网络结构 计算机网络结构：网络边缘、接入网络、网络核心。
网络边缘：连接到网上的所有端系统
接入网络：
 电话拨号接入：利用电话网络接入 非对称数字用户线路 ADSL：利用电话网络接入、基于频分多路复用技术、非对称、独享式接入 混合光纤同轴电缆 HFC：利用有线电视网络接入、基于频分多路复用技术、非对称、共享式接入 局域网：典型的局域网技术是以太网、WiFi 移动接入网络：3G、4G、5G网络  网络核心：由通信链路互连的分组交换设备构成的网络，实现网络边缘中主机之间的中继与转发
数据交换技术 交换设备：多通信端口，同时连接多个通信结点。
数据交换是实现在大规模网络核心上进行数据传输的技术基础。
三种交换技术：
 电路交换：最早出现；电话网络是最早、最大的电路交换网络；三个阶段：建立电路、传输数据、拆除电路 报文交换：存储-转发的交换方式；报文过大会丢失 分组交换：存储-转发的交换方式；包交换；最广泛的交换技术；为每个数据块附加上地址、序号等控制信息。优点：  交换设备存储容量要求低 交换速度快 可靠传输效率高 更加公平    分组交换：若其他条件相同，分组越长，延迟时间越长（合理范围：16B~4096B）
计算机网络性能 速率与带宽、时延、时延带宽积、丢包率、吞吐量
速率与带宽 速率：单位时间内传送的数据量，描述网络传输数据的快慢，也叫比特率。
 单位：bit/s（位每秒）| bps（位每秒） 换算：bit-Kbit-Mbit-Gbit，使用 1000 换算  带宽：指一条链路或信道的最高数据速率；单位：bit/s（位每秒）
时延 时延：也称延迟，指数据从网络中的一个结点到达另一个结点所需要的时间。
跳：连接两个结点的直接链路称为一个“跳步”。
分组的每跳传输过程产生 4 类时间延迟：
时延带宽积 物理链路的传播时延与链路带宽的乘积，记为 G，表示一段链路可以容纳的数据位数，也称：以位为单位的链路长度。
G = 传播时延 x 链路带宽 = dp x R，得到的单位：bit
丢包率 反映网络的拥塞程度。
丢包率 = （实际发送的数据 - 实际收到的数据）/ 实际发送的数据
吞吐量 单位时间内源主机通过网络向目的主机实际送达的数据量，记为 Thr；单位 bit/s 或 B/s；1B = 8bit
当存在多个链路时，吞吐量选择最小的（木桶原理）
 ARPAnet 是第一个分组交换计算机互连的网络，也是当今因特网的祖先。
 计算机网络体系结构 计算机网络体系结构：计算机网络所划分的层次以及各层次协议的集合。
分为三类：
 OSI 参考模型（7 层）+ 各层协议 TCP/IP 参考模型（4 层）+ 各层协议 五层参考模型（5 层）+ 各层协议   应用层：报文 传输层：数据段或报文段 网络层：分组或包 数据链路层：帧 物理层：比特流或位流  相关术语：
数据单元：在层的实体之间传送的比特组
协议数据单元（PDU）：对等层之间传输的数据单元
服务访问点（SAP）：相邻层间是通过服务访问点进行的，每个 SAP 都有一个唯一的地址号码
服务原语：每一层都是为上一层服务的，提供服务用一组原语描述：请求、指示、响应、证实
OSI 7层参考模型  应用层、表示层、会话层、传输层、网络层、数据链路层、物理层（物联网叔会使用）
   自上而下逐层传递，接收端从下而上
  发送方跟接收方的对等层不直接通信，称为虚拟通信
  两个物理层端点进行物理通信，称为实通信
  中间系统通常只实现（路由器等网络设备）：物理层、数据链路层、网络层功能（后三层）
  结点到结点层：后三层
  端到端层：传输层（第一个端到端层）、会话层、表示层、应用层（前四层）
  TCP/IP 4层参考模型 传输层主要包括:
 TCP：面向连接、提供可靠数据流传输的传输控制协议 UDP：无连接，不提供可靠数据传输的数据报协议  四层模型：
 应用层（报文） 传输层（段） 网络互联层（数据报；核心） 网络接口层（帧）  五层参考模型  应用层（报文） 传输层（段） 网络层（数据报） 链路层（帧） 物理层（比特流）  计算机网络中最常用、最接近实际网络的参考模型。
网络应用 计算机网络应用体系结构  C/S 结构网络应用：最典型、最基本的网络应用；客户主动发起，服务器被动接收，服务器必须先运行 纯 P2P 结构网络应用：没有客户端服务器之分；应用于上传下载 混合结构网络应用：以上两种相结合  网络应用通信基本原理 基本通信过程：运行在不同主机上的应用进程间以 C/S方式 进行的通信
网络应用编程接口：套接字（Socket），用端口号标识套接字
域名系统（DNS） 域名系统：将域名映射为 IP 地址，实现映射的过程叫域名解析（分布式数据库存储映射关系数据）。
域名命名规则：层次树状结构命名方式，每个域名由不同级别的域名构成，用点分隔；不区分大小写。
层次化域名空间 顶级域名的分类：
 国家顶级域名：cn、us、uk 通用顶级域名：com、org、gov、edu 基础结构域名：仅一个，arpa  域名服务器  根域名服务器：最重要，全球有 13 个，用 a~m 命名，首先求助该服务器 顶级域名服务器：管理注册的所有二级域名(www(三级).baidu(二级).com(一级)) 权威域名服务器：负责一个区的域名服务器，保存该区中所有主机的域名和IP地址的映射 中间域名服务器：域名过长，才会用到该域名服务器，最少四级域名才会用到  本地域名服务器：主机进行域名查询时首先被查询的域名服务器，不在电脑上，在电脑周围（非本地 Hosts 文件）
 查询顺序：主机 - 本地 - 根 - 顶级 - 权威
 浏览器解析 IP 地址：最短一个 RTTd，最长四个 RTTd。
域名解析过程：
 递归解析：主机 - 本地；本地 - 根；根 - 顶级 &hellip; 找到谁谁去找下一个 迭代解析：主机 - 本地；本地 - 根；本地 - 顶级 &hellip; 每次本地去挨个找  万维网应用 包括三个部分：
 Web 服务器 浏览器 超文本传输协议（HTTP）  统一资源定位符 URL，组成部分：主机域名（或 IP）和对象的路径名称。
HTTP 浏览器向服务器发送请求前，首先建立 TCP 连接
 非持久连接（HTTP 1.0）：发一次断一次 并行连接：建立多条并行 TCP 连接，并行发送请求和接收请求，仍然发一次断一次 持久链接  非流水方式持久连接：收到响应报文后，不断开连接，等上一次响应收到后才继续请求 流水方式持久连接（HTTP 1.1）：并行请求，不断开连接    请求报文和响应报文的主要区别在于起始行：
HTTP 典型的请求方法：
 GET：最常见，读取信息 HEAD：请求信息首部 POST：添加信息 OPTION：请求一些选项信息 PUT：在指明的 URL 下存储一个文档  响应报文的状态码：
 3xx：重定向 4xx：客户端错误（404 请求对象不存在） 5xx：服务器错误  cookie 小型文本文件，服务器给的，存储在用户本地。
包括 4 部分内容：
 请求报文头行：Cookie 响应报文头行：Set-Cookie 用户浏览器本地存储的 cookie 文件 网站后台数据库中存储、维护 Cookie 信息  作用：用户跟踪
 准确统计网站实际访问人数 限制某些特定用户的访问 存储用户操作习惯和行为偏好 记录用户名、密码等信息 实现“购物车”功能  Internet 电子邮件 邮件系统结构：
 邮件服务器：核心 用户代理：Apple Mail、Fox Mail、Outlook 等 简单邮件传输协议（SMTP） 邮件读取协议（POP3、IMAP、HTTP）  SMTP 通过三个阶段的应用层交互完成邮件传输：握手阶段、邮件传输阶段、关闭阶段
SMTP 的特点：
 只能传送 7 位 ASCII码文本内容 传送的邮件内容中不能包含 CRLF.CRLF（回车换行），因为用该信息表示邮件内容结束 是推动协议（HTTP 是拉动协议） 使用的 TCP 连接是持久的  邮件包括：首部（To 必填）、空白行、行主体
MIME 互联网邮件扩展（MIME）：依据一个标准将非 7 位 ASCII 码文本内容转换为7位ASCII码文本内容，然后再传输。
主要包括的内容：
 5 个 MIME 邮件首部字段 标准化多媒体电子邮件格式 邮件内容格式化  邮件读取协议  第三版邮局协议（POP3）：授权阶段、事务处理阶段、更新阶段；操作不会反应在服务器上 互联网邮件访问协议（IMAP）：对邮件的操作会反应的服务器上，支持仅读取邮件部分内容 Web 邮件系统的邮件读取协议（HTTP）：浏览器网页邮箱  FTP 文件传送协议：在两个主机间实现文件互传的网络应用，其应用层协议称为 FTP（带外控制）。
需要建立两条连接：
 控制连接（端口号 21）：持久连接，客户/服务器之间传输控制信息，比如登录、上传下载命令等 数据连接（端口号 20）：临时连接，实际传送文件的内容  FTP 是有状态的协议，用户账号和控制连接有关联。
P2P 应用  BitTorrent、PPLive、PPStream  Socket 编程基础   创建套接字：socket()
  TCP：流式套接字 SOCK_STREAM
  UDP：数据报套接字 SOCK_DGRAM
  IP：原始套接字 SOCK_RAM
    绑定套接字的本地端点地址：bind()
  设置监听：listen()
  建立连接(TCP；UDP 不需要)：
  客户端：connect()
  服务端：accept()
    接收数据：TCP：recv()；UDP：recvfrom()
  发送数据：TCP：send()；UDP：sendto()
  关闭套接字：close()
  传输层 传输层的基本服务 传输层的功能 （吩咐刘墉寻差错-可靠）
1)对应用层报文进行分段和重组;
2)面向应用层实现复用与分解;
3)实现端到端的流量控制;
4)拥塞控制;
5)传输层寻址;
6)对报文进行差错检测;
7)实现进程间的端到端可靠数据传输控。
传输层寻址和端口 利用 地址 + 端口号唯一标识一个通信端点。
传输层端口号 16 位整数（2**16）
常用端口小于 256
无连接服务与面向连接服务 传输层的复用与分解 多路复用与多路分解  多路复用：在源主机，传输层协议将不同应用进程的数据块，封装上首部信息构成报文段，发送给网络层。 多路分解：在接收端，传输层协议标识出报文段的套接字，将数据准确交付给正确的套接字。  无连接的多路复用与多路分解 UDP：用户数据报协议，将应用层的数据块封装成一个 UDP 报文段，包括：应用数据、源端口号、目的端口号等。
UDP 套接字二元组：&lt;目的 IP 地址，目的端口号&gt;
面向连接的多路复用与多路分解 TCP：传输控制协议
TCP 套接字四元组：&lt;源 IP 地址，源端口号，目的 IP 地址，目的端口号&gt;
停-等协议与滑动窗口协议 不可靠传输信道在数据传输中可能发生错误：
 比特差错 出现乱序 数据丢失  为了实现可靠数据传输，需要采取措施：
 差错检测：差错编码 确认：接收方反馈接收状态（ACK 确认 NAK 否定确认） 重传：发送方重新发送 序号：确保数据按序提交 计时器：解决数据丢失问题  停-等协议 综合应用了上述措施，简单且所需缓冲空间小，但是信道利用率低。
滑动窗口协议 为了解决信道利用率低的问题，在发送方没有收到确认前连续发送多个分组，就是流水线协议（管道协议）。典型的流水线协议：滑动窗口协议。
GBN 协议 和 SR 协议 GBN：回退 N 步协议
 发送方**（Ws&gt;=1）**，连续发送多个分组 接收方**（Wr=1）**，只按序一个一个接收，未按序到达分组丢弃，让发送方重传  SR：选择重传协议
 发送方**（Ws&gt;=1）**，连续发送多个分组 接收方**（Wr&gt;=1）**，逐个确认接收的分组，让发送方仅重传未被确认接收的分组  SR 发送方主要响应 3 个事件：上层调用、计时器超时、收到 ACKn
UDP 提供无连接、不可靠、数据报尽力传输服务
 无需建立连接 会出现分组丢失和重复 无连接状态 首部开销小，只有 8 字节  数据报结构
 首部四个字段，每个字段 2 字节，共 8 字节 源端口号和目的端口号，用于 UDP 实现复用和分解 长度：指示 UDP 报文段中的字节数（首部和数据总和） 校验和：接收方用来检测报文段是否出错，有错就丢弃  UDP 校验和 校验和分为三个部分：伪首部、UDP 首部、应用层的数据。
伪首部仅用来计算校验和，既不向下传送也不向上递交。协议号为 17
计算方法：
 发送方全零放入校验和字段，添加伪首部，三部分按 16 位对齐，非偶数字节则在末尾高位补零 求和：加法 + 进位回卷，求和后取反码，填充到校验和 接收方拿三部分求和，再加上校验和，如果是全 1，则通过校验。  TCP 传输控制协议：提供面向连接、可靠、有序、字节流传输服务。
 源端口号、目的端口号分别占 2 个字节 序号字段：占 4 字节，对每字节的数据进行编号 确认序号：占 4 字节，期望从非对方接收的字节序号（尚未收到） 首部长度：占 1 字节，以 4 字节为计算单位，最短 20 字节，最长 60 字节 保留：占 6 位，保留为今后使用，目前值为 0 标志位字段各 1 为位，共 6 位 接收窗口：占 2 字节，想对方通知接收窗口大小 校验和：占 2 字节，计算方式与 UDP 相同，协议号为 6 紧急指针字段占 2 字节，URG=1 时生效，指出紧急数据字节数  连接建立（三次握手） 连接拆除（四次挥手） TCP 实现可靠数据传输服务的工作机制  应用数据被分割成最适合发送的数据块 启动计时器，等待目的端收到该报文段 通过首部校验和，检测传输过程中是否有差错 报文段到达后可能失序，如有必要，TCP 会重新排序 存在网络延迟和重传机制，若收到重复报文段，则根据序号丢弃重复 TCP 能够提供流量控制  TCP 拥塞控制 通过合理调度向网络中发送数据的主机量、发送速率、数据量，以避免拥塞的发生。
TCP 拥塞算法包括：
 慢启动：阈值之前的阶段，每经过 RTT，拥塞窗口大小加倍 拥塞避免：阈值之后的阶段，每经过 RTT，拥塞窗口大小增加 1 快速重传：接收端收到 3 次重复确认，则推断该报文段已经丢失，立即重发 快速恢复：当发生 3 次重复确认时，不再重新从慢启动阶段开始，直接从新的阈值开始，直接进入拥塞避免阶段  窗口调整的基本策略（AIMD）：  网络未发生拥塞时，加性增大窗口 网络拥塞时，乘性快速减小窗口大小  拥塞消除策略：先拥塞检测，再采取措施
拥塞预防策略：流量整形技术，规范主机向网络发送数据的流量
TCP 流量控制 协调发送方与接收方的数据发送与接收速度。通信过程中，接收方通过设置报文段的接口窗口字段将窗口大小通知给发送方。
网络层 网络层的核心任务：将数据从源主机送达到目的主机。
网络层的主要功能：转发、路由选择、连接建立。
数据报网络与虚电路网络 网络互连与网络互连设备 异构网络互连  异构网络：两个或以上网络的通信技术和运行协议不同，或者是采用相同的无线接入技术但属于不同的无线运营商。
 异构网络互连的基本策略：
 协议转换：采用支持异构之间协议转换的网络中间设备（交换机或者多协议路由器） 构建虚拟互联网络：在异构网络基础上构建一个同构的虚拟互联网络  路由器 最典型的网络层设备，主要任务是获取与维护路由信息及转发分组。
从功能体系结构角度分类：
 输入端口：查找、转发、到达分组，缓存排队功能 交换结构：完成具体的转发工作，将输入端口的IP数据报交换到指定的输出端口  基于内存交换：性能最低，路由器价格最便宜 基于总线交换：同一时刻只能有一个分组通过总线进行传输 基于网络交换：性能最高，路由器价格昂贵   输出端口：缓存排队，从队列中取出分组进行数据链路层数据帧的封装、发送 路由处理器：执行命令、路由协议运行、路由计算、路由表的更新和维护  网络层拥塞控制 网络拥塞：一种持续过载的网络状态。用户对网络资源(包括链路带宽、存储空间和处理器处理能力等)的总需求超过了网络固有的容量。
网络负载在膝点附近时，吞吐量和分组平均延迟达到理想的平衡，网络的使用效率最高。
发生拥塞的原因：
 缓冲区容量有限 传输线路带宽有限 网络结点处理能力有限 网络中某些部分发生了故障  网络层拥塞控制措施 1.流量感知路由 网络经常被抽象为一张带权无向图，权值能够根据网络负载动态调整，可以将网络流量引导到不同的链路上，均衡网络负载，从而延缓或避免拥塞的发生。
2. 准入控制 对新建虚电路审核，如果新建立的虚电路会导致网络变得拥塞，那么网络拒绝建立该新虚电路。
3. 流量调节 在网络拥塞时，可以通过调整发送方发送数据的速率来消除拥塞。
 抑制分组：感知到拥塞的路由器选择一个被拥塞的数据报，给该数据报的源主机返回一个抑制分组。 背压:抑制分组在从拥塞结点到源结点的路径上的每一跳，都发挥抑制作用。  4. 负载脱落 通过有选择地主动丢弃一些数据报，来减轻网络负载，从而缓解或消除拥塞。
Internet 网络层 Internet 网络层主要协议：
 网际协议 路由协议 互联网控制报文协议  IP 协议版本：IPV4 和 IPV6
IPV4：Internet 网络层最核心的协议：
 定义了如何封装上层协议（UDP、TCP等）报文段 定义了 Internet 网络层寻址（IP 地址）以及如何转发 IP 数据报等内容  IP 数据报格式  版本号：4 位（IPV4、IPV6） 首部长度：4 位 区分服务：8 位，标识期望获得那种类型的服务 数据报长度：16 位，指出 IP 数据报的总字节数 标识:字段占 16 位，标识一个 IP 数据报 标志:占 3 位  DF 禁止分片标志：DF=0，允许分片；DF=1，禁止分片 MF 更多分片标志：MF=0，未被分片或最后一片；MF=1，一定是分片且非最后一个   片偏移量:占 13 位，以 8 字节为单位。表示一个 IP 数据报分片与原 IP 数据报数据的相对偏移量 生存时间:8 位，表示 IP 数据报在网络中可以通过的路由器数(或跳步数) 上层协议:8 位，指示该 IP 数据报封装的是哪个上层协议（TCP:6;UDP:17） 首部校验和:占 16 位，利用校验和实现对 IP 数据报首部的差错检测 源 IP 地址字段占 32 位，发出 IP 数据报的源主机的 IP 地址 目的 IP 地址字段占 32 位，IP 数据报的需要送达的主机的 IP 地址 选项:长度可变 数据字段：存放 IP 数据报所封装的传输层报文段  当片偏移量为 0 且 MF=1 时，标识这是一个 IP 分片，且是第一个分片。
IP 数据报分片 MTU：最大传输单元
 通过 PingPlotter 工具发送一个总长度为 3400 字节的 IP 数据报，通过 MTU=1500 字节的链路转发。
 IPv4 编址 IPv4 地址的长度为 32 位（4 字节）
IPv4 地址的三种标记方式：
 二进制标记法 点分十进制标记法 十六进制标记法  IPv4 地址分配，主机 IP 地址划分为两个部分：
 前缀，网络部分用于描述主机所归属的网络  分类地址：定长前缀 无类地址：前缀长度可变   后缀，主机部分用于表示主机在网络中的唯一地址  分类寻址  A、B、C 类地址可以用于标识网络中的主机或路由器 D 类地址作为组广播地址 E 类地址是保留地址  特殊地址 私有地址 无类地址 网络前缀不定长，可以是 0-32 位的任意值。
网络地址形式为 a.b.c.d/x，称为无类域间路由（CIDR）
子网划分 子网化：将一个较大的子网划分为多个较小子网的过程
超网化：将具有较长前缀的相对较小的子网合并为一个具有稍短前缀的相对较大的子网，超网化是子网化的逆过程。
子网掩码：32 位，对应网络前缀全部为 1，其余为全部为 0。例如：255.255.255.0
路由聚合 提高路由效率，减少路由表项数，将子网聚合成一个大的子网。
动态主机配置协议 HDCP 当组织分配到一个网络地址块后，就可以为该组织内的主机和路由器接口分配 IP 地址。
 静态分配：手动配置 动态分配：动态主机配置协议（HDCP）来分配  DHCP 工作过程：
 DHCP 服务器发现：广播方式 DHCP 服务器提供：广播方式 DHCP 请求：广播方式 DHCP 确认  网络地址转换（NAT） NAT 工作原理：
 对于从内网出去，进入公共互联网的 IP 数据报，将其 IP 替换为 NAT 服务器拥有的合法的公共 IP 地址，同时替换源端口号，并将替换关系记录到 NAT 转换表中； 对于从公共互联网返回的 IP 数据报，依据其目的 IP 地址与目的端口号检索 NAT 转换表，并利用检索到的内部私有 IP 地址、端口号替换目的 IP 地址与端口号，最后将 IP 数据报转发到内部网络  互联网控制报文协议（ICMP） ICMP：在主机或路由器键实现差错信息报告、信息探测
报文格式：类型、代码、校验和、数据部分
ICMP 差错报告报文有 5 种：
 终点不可达 源点抑制 时间超时 参数问题 路由重定向  ICMP 询问报文：回声（echo）请求/应答、时间戳请求/应答
IPv6 地址长度为 128 位，通常采用 8 组冒号分隔的十六进制数地址形式表示。
IPv6 地址分类：单播地址、组播地址、任播地址三类。
IPv4 迁移到 IPv6：
 双协议栈：既支持 IPV6 同时也支持 IPv4。具备发送 IPV4 与 IPV6 数据报的能力。 为了实现 IPv4 与 IPv6 共存采用双协议栈，其中通过 DNS 可以解决一个结点感知通信另一结点提供什么版本的网络层服务。 隧道：可以很好地解决 IPv6 通信中经过 IPv4 路由器的问题，同时也不会出现信息丢失 的问题  IP 地址计算
 根据子网中某 IP 地址和子网掩码，计算出
 子网的网络地址（主机地址与子网掩码地址「按位与」运算） 广播地址（最后一个主机地址） IP 地址总数 可分配的 IP 地址数量（需要减去子网地址与广播地址）   比如：IP 地址 203.123.1.135；子网掩码 255.255.255.192
 通过子网掩码计算网络位：三个 255 就是 24 位，192 是两位，得出 26 位 前 26 位不变，后 6 位全零得到子网地址 前 26 位不变，后 6 位全 1 得到广播地址 IP 地址总数为 2^6 为 64 可分配的需要减去两个，得出 64-2=62  注：上面是简化后的算法，与子网掩码按位与，给出的子网掩码网络位是全 1，按位与还是给出的 IP 地址的数字，所以计算出网络位后，网络位的就不用去算了，直接看主机位。
路由算法与路由协议 路由选择算法分类  关键问题： 结点到结点的最小代价路径是什么？
路由算法：发现最小代价路径的算法
 第一种分类：是否基于网络的全局信息
第二种分类：算法是静态的还是动态的
第三种分类：是否负载敏感
 负载敏感的路由选择算法 负载迟钝的路由选择算法  链路状态路由选择算法（LS 算法） 利用 Dijkstra 算法求最短路径
是典型的单源最短路径算法，用于计算一个节点到其他所有节点的最短路径。主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止（泛洪）
距离向量路由选择算法（B-F 方程） 算法的基础是 Bellman-Ford 方程
层次化路由选择 自治系统（AS）：互联网按组织边界、管理边界、网络技术边界或功能划分多个自治系统，每个自治系统由运行相同路由协议和路由算法的路由器组成。
网关路由器：每个自治系统都存在至少一个与其他路由器互连的路由器。
层次化路由选择：实现大规模网络路由最有效、可行的解决方案。
层次化路由选择原理：将大规模互联网路由划分两层
 自治系统内路由选择：计算机到达自治系统内目的网络的路由 自治系统间路由选择：负责其他自治系统网络的可达性信息  路由器转发表：由自治系统内路由选择协议和自治系统间路由选择协议共同设置。
Internet 路由选择协议 Internet 自治系统内路由选择协议称为内部网关协议（IGP）
 路由信息协议**（RIP）** 开放最短路径优先协议**（OSPF）**  Internet 自治系统间路由选择协议称为外部网关协议（EGP）
 边界网关协议**（BGP）**  路由信息协议 RIP 小规模 AS，基于距离向量路由选择算法的 IGP，封装在 UDP 数据报。
限制在网络直径不超过 15 跳的自治系统内使用。
开放最短路径优先协议 OSPF 较大规模 AS，基于链路状态选择算法的 IGP，封装在 IP 数据报传输。
OSPF 路由分类：区域边界路由器、主干路由器、AS 边界路由器
边界网关协议 BGP 跨自治系统的路由信息交换，封装在 TCP。
数据链路层与局域网 数据链路层服务  数据链路层：负责通过一条链路，从一个结点向另一个物理链路直接相连的相邻结点，传送网络层数据报，中间不经过任何其他交换结点。
 数据链路在物理链路之上，基于通信协议来控制数据帧传输的逻辑数据通路。
实现数据链路层协议的典型硬件实体是：网络适配器（NIC、网卡）
数据链路层的传输单元为帧。
数据链路层提供的服务：
 组帧：  帧头（帧首）：发送结点和接收结点的地址信息，定界字符 帧尾：用于差错检测的差错编码，定界字符   链路接入  点对点链路：发送结点和接收结点独占信道 广播链路：通信链路被多个结点共享   可靠交付  无线链路（出错率高）：支持可靠数据传输 光纤、双绞线（出错率低）：不提供可靠传输服务   差错控制：通过差错编码技术，实现对信息传输差错的检测，共进行差错纠错和处理  可能会出现比特翻转的差错 误比特率：出现差错的比特数 / 传出比特总数    差错控制的基本方式 检错重发：
 发送端：待发送数据进行差错编码后发送 接收端：利用差错编码检测是否出错，若出错要求重发数据  前向纠错：差错纠正
 发送端：利用纠错编码编码数据 接收端：监测数据传输过程中是否发生了错误，定位错误位置并直接纠正 适用于单工链路或者对实时性要求比较高的应用  反馈校验
 接收端：接收到的数据原封不动的发回发送端 发送端：通过对比接收端反馈的数据，确认是否正确接收，若有不同，立即重传 优点：原理简单，易于实现，无需差错编码 缺点：传输效率低，实时性差  检错丢弃
 直接丢弃错误数据 适用于实时性较高的系统 如果网络应用对可靠性要求不高，可以采用  差错编码 差错编码的基本原理：在待传输数据信息的基础上，附加一定的冗余信息。冗余信息：与数据信息建立某种关联关系。
差错编码的检错与纠错能力：与编码集的汉明距离有关。
 编码集：差错编码所有有效码字的集合 汉明距离：两个等长码字之间，对应位数不同的位数（1011101 和 1001001 汉明距离为 2） 编码集的汉明距离：该编码集中任意两个码字之间汉明距离的最小值  检错能力：对于检错编码，如果编码集的汉明距离 ds=r+1，则该差错编码可以检测 r 位的差错。
纠错能力：对于纠错编码，如果编码集的汉明距离 ds=2r+1，则该差错编码可以纠正 r 位的差错。如果发生一位差错，则错码距离发生错误的有效码字的汉明距离最近，可以恢复为有效码字。
典型的差错编码：奇偶校验码、循环冗余码
奇偶校验码  奇校验码：编码后的码字中 1 个数是奇数 偶校验码：编码后的码字中 1 个数是偶数  循环冗余码（CRC 码） 广泛应用的差错编码；将二进制位串看成是系数为 0 或 1 的多项式的系数。
 【例题】假设 CRC 编码采用的生成多项式 G(x)=x^4+x+1，请为位串 10111001 进行 CRC 编码。
 第一步：写出多项式对应的比特串：10011
第二步：待编码位串：10111001 - 101110010000（添加最高项位个 0，也就是 4 个）
第三步：用得到的新的编码位串除以多项式对应的比特串（10011）
第四步：求得的余数（1011）添加在待编码位串后，即 CRC 编码后的码：101110011001
 接收方收到带校验和的帧之后，怎么判断是否有错？
用收到的串除以多项式对应的比特串
 余数为 0，无错 余数不为 0，有错，丢弃   多路访问控制协议  多路访问控制：采取一定的措施，使得结点之间的通信不会发生干扰的情况
 MAC 协议的根本任务：解决信道的共享问题
信道划分 MAC 协议 利用多路复用技术实现信道共享的 MAC 协议，就是信道划分 MAC 协议。
 频分多路复用（FDM）：多路信号频谱不重叠，从而公用一个信道 时分多路复用（TDM）：每路信号占用不同的时隙，在时域上不重叠，实现信道共享  同步时分多路复用（STDM）：按固定顺序把时隙分配给各路信号 异步时分多路复用（ATDM）：统计时分多路复用（STDM），时隙和用户间没有固定的对应关系   波分多路复用（WDM）：一根光纤中传输多路不同波长的光信号，由于波长不同，各路互不干扰 码分多路复用（CDM）：利用相互正交的码组分别编码各路原始信息的每个码元，是一种扩频的通信形式  随机访问 MAC 协议 所有用户都可以根据自己的意愿随机的向信道上发送信息，若多个用户发送信息，产生冲突，每个用户随机退让一段时间后，再次尝试发送。
ALOHA 协议（只说不听）：最早的，最基本的无线数据通信协议 纯 ALOHA
工作原理：任何一个站点有数据发送时就可以直接发送至信道。发送数据后对信道进行侦听，如果收到应答信号，说明发送成功；否则说明发生冲突，等待一个随机时间重新发送，直到成功为止。
性能：网络负载不能大于 0.5
时隙 ALOHA
工作原理：把信道时间划分为离散的时隙，每个时隙为发送一帧所需的时间，每个通信站点只能在每个时隙开始的时刻发送帧。如果在一个时隙内发送帧出现冲突，下一个时隙以概率 p 重发该帧，直到帧发送成功。p 不能为 1，否则会出现死锁。
性能：网络负载不能超过 1
载波监听多路访问协议（先听后说）CSMA 基本原理：通过硬件装置（载波监听装置），使通信站发送数据之前，监听信道上其他站点是否在发送数据，如果在发送，则暂时不发送。
根据监听策略不同：
 非坚持 CSMA：信道空闲，直接发送；信道繁忙，等待一个随机延迟时间再去发送 1-坚持 CSMA：持续监听，直到信道空闲，立即发送 P-坚持 CSMA：延迟一个时间后，再去监听，重复步骤，直到信道空闲，立即发送  带冲突检测的载波多路访问协议（先听后说，边听边说）CSMA/CD 基本原理：通信站使用 CSMA 协议进行数据发送，如果发送期间检测到碰撞，立即终止发送，并发出一个冲突强化信号，使所有通信站点都知道冲突的发生；发出冲突强化信号后，等待一个随机时间，再重复上述过程。
CSMA/CD 的工作状态分为：传输周期、竞争周期、空闲周期。
信道的三种状态：传输状态、竞争状态、空闲状态。
在使用 CSMA/CD 协议实现多路访问控制时，需要满足下列约束条件：
受控接入 MAC 协议 受控接入：各个用户不能随意的接入信道而必须服从一定的控制，分为：
 集中式控制：系统有一个主机负责调度其他通信站接入信道，从而避免冲突；轮询 分散式控制：令牌技术，一个通信站想要发送数据就必须首先获得令牌，令牌丢失和数据帧无法撤销是环网上最严重的两种错误。  局域网  局域网（LAN）：一般采取广播的方式，局部区域网络，覆盖面积小，网络传输速率高，传输的误码率低。
 IEEE802 委员会将局域网的数据链路层分为两个子层：
 逻辑链路控制（LLC）子层 介质访问控制 MAC 子层  数据链路层寻址与 ARP MAC 地址：物理地址、局域网地址。MAC 地址具有唯一性，每个接口（网络适配器）对应一个 MAC 地址。
 以太网和无线局域网，MAC 地址长度为 6 字节，共有 2^48 个可能的 MAC 地址 通常采用十六进制表示法，用 - 或 : 连接起来 IEEE 负责分配 MAC 地址的前 24 位，厂商自己分配后 24 位  MAC 广播地址：FF-FF-FF-FF-FF-FF
地址解析协议（ARP）
根据本网内的目的主机或默认网关的 IP 地址，发送请求获取其 MAC 地址。
 ARP 查询分组是通过一个 广播帧 发送的，ARP 响应分组是通过一个标准的单播帧发送的；发送的时候是广播的，当目的主机收到请求后，就单播返回响应 ARP 是即插即用的，一个 ARP 表是自动建立的，不需要系统管理员来配置  以太网 目前最流行的有线局域网技术。
成功的原因：
 第一个广泛部署的告诉局域网 数据速率方面比 FDDI、ATM 毫不逊色 以太网硬件价格及其便宜，网络造价成本低  经典的以太网是采用粗同轴电缆连接的总线型以太网（10Base-5）
 传输速率为 10Mbit/s，无连接不可靠 在一个冲突域中往返总的传播时延为 51.2 微秒，所以最短帧长为 64字节 网段和网段中间用中继器连接，最多有 4 个中继器 MAC 协议采用 CSMA/CD 协议。  以太网帧结构：
除数据部分：18 字节。以太网帧最短 64 字节，那么数据字段最短 46 字节。
以太网技术：
交换机 应用最广泛的数据链路层设备。
以太网交换机转发和过滤：交换机的基本工作原理是当一帧到达时，交换机首先需要决策将该帧丢弃还是转发，如果转发，还必须进一步决策将该帧转发到哪个端口。决策依据是，以目的 MAC 为主键查询内部转发表。
以太网交换机的自学习（建立转发表）：
 以太网交换机有 4 个端口，各连接一台计算机，其 MAC 地址分别是 ABCD 开始，以太网交换机里面的转发表是空白的 A 向 B 发送一个帧，从端口 1 进入交换机 交换机先查询转发表，没找到往哪里转发该帧 交换机就把这个帧的源 MAC 地址 A 和端口 1 写入交换表，完成第一次学习 除向端口 1 以外所有端口泛洪(广播)这个帧  以太网交换机的优点：消除冲突、支持异质链路、网络管理。
虚拟局域网 VLAN 一种基于交换机的逻辑分割广播域的局域网应用形式。
划分虚拟局域网的方法：
 基于交换机端口划分 基于 MAC 地址划分 基于上层协议类型或地址划分  点对点链路协议 点对点协议（PPP 协议） 点对点协议：全世界使用得最多的点对点链路协议。适合单个发送方和单个接收方的点对点链路。
主要提供三类功能：
 成帧：确定一帧的开始和结束，支持错误检测；以 01111110 开始和结束 链路控制协议（LCP）：启动线路、检测线路、协商参数、关闭线路 网络控制协议（NCP）：协商网络层选项  PPP 是面向字节的，PPP 帧的长度都是整数字节，使用字节填充技术，插入特殊的控制转义字节 01111101
高级数据链路控制协议（HDLC 协议） 高级数据链路控制：应用于点对点链路和点对多点链路。
HDLC 有三种类型的帧：信息帧、管理帧、无序号帧
HDLC 协议是面向位的，使用位填充技术。当发送的数据链层在数据中遇到 5 个连续的 1 时，自动在其后插入一个 0 到输出比特流中，这叫位填充技术。当接收方看到 5 个连续的 1 后面跟着一个 0 时，自动将此 0 删除。
物理层 数据通信基础 数据通信基本概念 消息：人类能够感知的描述。
信息：对事物状态或存在方式的不确定性表述。
通信：在一点精确或近似的再生另一点的信息。
通信系统：能够实现通信功能的各种技术、设备和方法的总体。
信号：在通信系统中，传递信息需要合适的载体在传输通道中传播，这个载体就是信号。
数据：对客观事物的性质状态以及互相关系等进行记载的符合及其组合，通常可以是数字、文字、图像等，也可以是其他抽象的符号。
数据通信系统模型 数据通信系统的构成：
 信源：将消息转换为信号的设备 发送设备：将信源产生的信号进行适当变换的装置，主要包括编码和调制 信道：传输信号的媒介 接收设备：完成发送设备的反变换，即进行译码和解调 信宿：信号的终点，将信号转换为供人们识别的信息 噪声：自然界和通信设备所固有的，对通信信号产生干扰和影响的各种信号  模拟通信：信号的因变量完全随连续消息的变化而变化的信号
 自变量：可以是连续、可以是离散 因变量：一定是连续的  数字通信：
 自变量：离散 因变量：离散  数字通信方式：
 数据传输方向：单向通信；双向交替通信（半双工）；双向同时通信（全双工） 数据传输时空顺序：并行通信和串行通信 数据同步技术：  异步通信：发送字符，不需要建立同步时钟，实现简单，适用低速网络 同步通信：发送数据块，建立同步时钟，实现和控制复杂，适用高速网络    物理介质 导引型传输介质 有线信道，以导线为传输介质，传输效率高，部署不够灵活。
 架空明线：传输损耗较低；易受天气和外界电磁干扰，对噪声敏感，带宽有限 双绞线：将两根互相绝缘的铜线并排绞合在一起可以减少对相邻导线的电磁干扰  屏蔽双绞线（STP）：性能好，价格高，安装工艺复杂 非屏蔽双绞线（UTP）：普遍应用   同轴电缆：对外界干扰屏蔽效果好，具有较好的抗电磁干扰性能。多用于有线电视网络 光纤：利用光的全反射现象，按照光纤内光波传输模式不同，分为多模光纤和单模光纤  非导引型传输介质 根据电磁波频率、通信距离位置的不同，电磁波的传播分为：
 地波传播：（频率）2MHz 以下，沿地表 天波传播（电离层反射波）：2-30MHz，距离地表 60-400km 视线传播：高于 30MHz，电离层之上  信道与信道容量 信道分类与模型 按功能划分信道：调制信道和编码信道
调制信道：从调制器的输出端到解调器的输入端经过的部分
编码信道：数字信号由编码器输出端到译码器输入端经过的部分
信道传输特性 不同类型的信道对信号的影响差异较大
 随机参数信道（随参信道）：信号通过信道发生畸变是时变的 恒定参数信道（恒参信道）：信号通过信道发生畸变和时间无关  恒参信道传输特性：
 对信号幅值产生固定的衰减 对信号输出产生固定的时延  随参信道传输特性：
 信号的传输衰减随时间随机变化 信号的传输时延随时间随机变化 存在多径传播现象  信道容量 信道容量：描述或衡量信道的传输能力，信道无差错传输信息的最大平均信息速率。
奈奎斯特理想的、无噪声的信道容量：
连续信道容量，香农有噪声连续信道容量：
信噪比的单位为功率，分贝和功率的换算公式：
化简后的公式：10*n(dB)=10^n
 例题：已知某信道带宽为 8kHz，信噪比为 30dB，试求该信道的信道容量 C。
 基带传输 基带信号：信源发出的没有经过调制的原始信号
信源：
 模拟信源：发出的原始信号是模拟基带信号（例如电话） 数字信源：发出的原始信号为数字基带信号（例如计算机）  数字基带传输系统
 基带传输：直接在信道传送基带信号，实现基带传输的系统就称为基带传输系统 数字基带传输：在信道中传输数字基带信号，相应的系统称为数字基带传输系统  数字基带传输编码 将数据映射为脉冲信号的编码（信息码）
1. 单极不归零码（NRZ）：0（零电平）1（正电平） 例如：1100100111
双极不归零码：0（负电平）1（正电平） 例如：1100100111
3. 单极归零码（RZ）：0（零电平）1（正电平） 脉冲中间时间，回归零电平
例如：1100100111
4. 双极归零码：0（负电平）1（正电平） 脉冲中间时间，回归零电平
例如：1100100111
5. 差分码（相对码）0（相邻电平无跳变）1（相邻电平有跳变） 利用电平的变化与否来表示信息
例如：1100100111
数字基带信号的基本码型变为适合传输的数字传输基带传输码型
1. 信号交替反转码（AMI 码）：0（零电平）1（交替用正电平和负电平表示） 脉冲中间时间，回归零电平
例如：100001000011000011
2. 双相码（曼彻斯特码）0（负电平跳到正电平）1（正电平跳到负电平） 例如：1100101101
3. 差分双向码（差分曼彻斯特码）0（相邻电平无跳变）1（相邻电平有跳变） 例如：1100101101
4. 米勒码：延迟调制码  1：正电平跳到负电平 或 负电平跳到正电平，脉冲期间跳变 0：延续前面 1 的电平，正或负；脉冲期间不跳变  例如：1100101101
5. 信号反转码（CMI 码）：0（负正）1（正、负交替编码） 例如：1100101101
频带传输 数字调制：利用数字基带信号控制载波信号的某些特征参量，使载波信号的这些参量的变化反映数字基带信号的信息，进而将数字基带信号变换为数字通带信号的过程。
数字解调：在接收数据端需要将调制到载波信号中的数字基带信号卸载下来，还原为数字基带信号的过程。
通常将实现调制、传输与解调的传输系统称为数字频带传输系统。
数字调制的基本方法 利用数字基带信号调制或控制载波信号的某个参数的变化（利用 0 或 1 控制或选择载波的幅值、评率或相位）
 如果调制载波的幅值：幅移键控（ASK） 如果调制载波的频率：频移键控（FSK） 如果调制载波的相位：相移键控（PSK）  二进制数字调制 二进制幅移键控（2ASK）：利用二进制基带控制信号控制载波信号的幅值变化。
0（0）1（A），比如 11001001
二进制频移键控（2FSK）：快的为 1，慢的为 0
二进制相移键控（2PSK）
1 的波形由 0 开始往下画；0 的波形由 0 开始往上画。
二进制差分相移键控（2DPSK）
11001001，默认从 0 开始，发生变化就是 1，未发生变化就是 0
二进制数字调制性能主要体现在：频带利用率、误码率、对信道特性的敏感性。
多进制数字调制  Rb：数据传输速率（bit/s） RB：码元传输速率（码元：一个固定时长的信号波形） M：进制数（二进制、十进制等）  正交幅值调制 QAM（幅值相位联合键控（APK）） 基本思想是：二维调制技术；对载波信号的幅值和相位同时进行调制的联合调制技术。
优点：频带利用率搞；抗噪声能力强；调制解调系统简单
物理层接口规程 物理层主要任务：
 在传输介质上实现无结构比特流的传输 规定数据终端设备（DTE）和数据通信设备（DCE）之间接口的相关特性  物理层接口特性：
 机械特性：指明通信实体间 硬件连接口的机械特点：电源插头尺寸有严格规定 电气特性：规定了物理连接上，导线的电气连接及有关特性：接收器和发送器电路特性的说明 功能特性：指明物理接口各条信号线的用途等 规程特性：通信协议，指明利用接口传输比特流的全过程  无线与移动网络 无线网络 无线网络的基本结构  无线主机 无线链路 基站  蜂窝网络中的蜂窝塔 IEEE 802.11 无线局域网中的接入点（AP）通常读法：I triple E：意思就是三个 E，不是知识点，只是好奇，哈哈~   网络基础设施  无线网络模式  基础设置模式：无线主机与基站关联 自组织网络或特定网络，Ad Hoc 网络，移动 Ad Hoc 网络中的每个结点都兼有路由器和主机两种功能。  无线链路与无线网络特性 无线链路的特点：
 信号强度的衰减：路径损耗 干扰 多径传播  隐藏站现象
 站点 A、C 都向站点 B 发送数据； 站点 A、C 之间有物理阻挡，双方都无法检测出对方发送的信号 站点 A、C 都向 B 发送数据时，发生碰撞，站点 B 无法正确接收任何一方的数据  无线网络特点
 使用不同链路技术的无线网络覆盖区域和链路速率不同 多路访问控制协议更复杂  移动网络 移动网络基本原理
 从网络层的角度分析用户的移动性 移动节点的地址始终保持不变的重要性 可用的有线基础设置的支持  移动网络的基本概念和术语
 一个移动结点的永久居所：归属网络，家网 在归属网络中代表移动结点执行移动管理功能的实体：归属代理，家代理 移动结点当前所在非归属网络：外部网络，被访网络 在外部网络中帮助移动结点做移动管理功能的实体：外部代理 通信者：与该结点通信的实体  蜂窝网络 蜂窝网络的系统结构 蜂窝网络
  小区（Cell）：蜂窝网覆盖的区域被分成若干个小区
  蜂窝：小区的地理覆盖区域
  以 2G 蜂窝移动通信网络为例的蜂窝网络体系结构
 收发基站（BTS）：负责向小区内的移动站点发送或接收信号 基站控制器（BSC）：服务于收发基站，为用户分配 BTS 无线信道、执行寻呼，执行移动用户的切换 移动交换中心（MSC）：在用户鉴别和账户管理以及呼叫建立和切换中起决定性作用。  蜂窝网络发展史
 第一代蜂窝移动通信（1G）：淘汰 第二代蜂窝移动通信（2G）：GSM 系统；短信服务；GPRS（通用分组无线服务技术）；EDGE（增强型数据速率 GSM 演进技术） 3G、4G、5G  蜂窝网络中的移动性管理 GSM 标准采用的是间接路由选择方法管理移动性
 GSM 的归属网络维护一个归属位置注册器的数据库：每个用户的永久蜂窝电话号码，用户个人信息，用户当前的位置信息 GSM 的被访网络维护一个访问位置注册器的数据库：为每一位当前在其服务网络的移动用户体用一个表项  GSM 通信过程：
 通信者拨打移动用户的电话号码 归属移动交换中心收到该呼叫，查询归属位置注册器来确定移动用户的位置，并确定移动用户的漫游号码 漫游号码确定后，归属移动交换中心通过网络呼叫被访网络的移动交换中心，被访网络的移动交换中心呼叫移动用户  移动通信 2G/3G/4G/5G 网络 2G 网络
 GSM 系统是第二代移动电话系统的开端 GSM 业务，分为：承载业务、电信业务、附加业务三大类 GSM 系统采用的是 FDMA 和 TDMA 混合接入的方式  3G 网络
 国际电信联盟（ITU）提出并研究 在 2000 年确定三大技术标准 3G 是采用宽带 CDMA 技术的通信系统  4G/LTE 网络
 3GPP 组织在 2004 年开始长期演进 4G 特点：高速率传输、智能化、业务多样化、无缝接入、向后兼容、经济  5G 网络
 技术目的：构建网络社会 网络社会：超高速率船速、超高容量、超可靠性、随时随地可接入性  移动 IP 网络 移动 IP：国际互联网工程任务组开发，允许计算机移动到外地时，任然保持其原来的 IP 地址。
移动 IP 标准：代理发现；向归属地代理注册，数据报的间接路由选择。
代理发现 当移动 IP 站点到达一个新网络时，移动结点都必须知道相应的外部代理或归属代理的身份。
代理发现的实现方式：
 代理通告：代理周期性的广播一个类型字段为 9 的 ICMP 报文 代理请求  向归属代理注册 移动 IP 定义了移动结点或外部代理向一个移动结点的归属代理注册或注销 COA 所使用的协议。一旦某个移动 IP 结点收到一个 COA，则该地址必须向归属代理注册。
注册过程
 当收到一个外部代理通告后，移动结点向外部代理发送一个移动 IP 注册报文 外部代理收到注册报文并记录移动结点的永久 IP 地址，分配一个 COA。并且把注册请求发送给归属代理 归属代理接收注册请求并检查真实性和正确性 外部代理接收注册应答，然后将其转发给移动结点  其他典型无线网络  Wi Max 蓝牙：2.4GHZ 频段；小范围、低速率、低成本 ZigBee：低功率、低数据速率、低工作周期  网络安全基础 网络安全概述 网络安全通信需要的基本属性：
 机密性：只有发送方和接收方能理解报文的内容 消息完整性：消息未被篡改，发生篡改一定会被检测到 可访问性与可用性：对授权用户提供有效服务 身份认证：双方确认彼此真实身份  典型的网络安全威胁：
 报文传输方面：窃听、插入、假冒、劫持等 拒绝服务 DoS 以及分布式拒绝服务 DDoS 映射：Namp 是国外广为使用的端口扫描工具之一 分组嗅探：Wireshark 是一个典型的分组嗅探工具软件 IP 欺骗  数据加密 通信加密模型
 明文：未加密的消息 密文：被加密的消息 加密：明文变为密文的过程（密钥） 解密：密文变为明文的过程（密钥）  根据密码体制的特点以及出现的先后时间可以将密码方式分类为：
 传统加密方式：替代密码；换位密码 对称密钥加密 公开密钥加密（非对称密钥加密）  传统加密方式：替代密码 凯撒密码是替代密码的典型应用。
加密原理：利用 k=3 的凯撒密码加密，就是当前字母向后推 3 位得到的字母拼接
只改变明文内容，不改变明文结构
传统加密方式：换位密码（置换密码） 根据一定规则重新排列明文，以便打破明文的结构特性。只改变明文结构，不改变明文内容。
换位密码：列置换密码和周期置换密码。
加密原理：
 确定密钥长度（几个字母），并且确定字母在 26 个字母表中的顺序 将明文按顺序横向排列展示，具体展开几列，由密钥的长度决定 输出顺序确定，密钥字母顺序和表格对应，按顺序输出加密后的结果  对称密钥加密 加密密钥和解密的密钥是相同的
对称密钥加密
 分组密码（块密码）：DES、AES、IDEA 流密码（序列密码）  DES 加密算法
加密过程：使用 56 位的密钥，明文为 64 位分组序列，共进行 16 轮加密。
三重 DES：使用两个密钥，执行三次 DES 算法，密钥长度达到 112 位。
AES 加密算法（高级加密标准）
加密过程：字节替代、行移位、列混淆、轮密钥加
密钥长度：128/192/256 位
IDEA 加密算法
国际数据加密算法，广泛应用在安全电子邮件 PGP 中，密钥长度 128 位。
非对称/公开密钥加密 通信双方都有两个密钥：公钥（任何人都可以给）、私钥（自己保存）
典型的公开密钥加密算法：Diffie-Hellman 算法和 RSA 算法
加密过程（A 与 B 通信）：
 A 将公钥发出给到 B B 收到公钥后，使用公钥加密明文，得到密文 将密文发送给 A A 用自己的私钥解密，得到明文  消息完整性与数字签名 消息完整性检测方法 报文/消息完整性，也称为报文/消息认证
 证明报文确实来自声称的发送方 验证报文在传输过程中没有被篡改 预防报文的时间、顺序被篡改 预防报文持有期被篡改 预防抵赖  检测方法：用散列函数对报文进行散列化。
密码散列函数的特性：
 散列函数算法公开 快速计算 对任意长度报文进行散列产生定长输出 对于任意报文无法预知其散列值（抗弱碰撞性） 不同报文产生不同的散列值（抗强碰撞性） 单向性：散列后不能原样恢复  典型的散列函数
 MD5：128 位散列值 SHA-1：160 位散列值  报文认证 检测消息完整性的重要目的：报文认证
报文认证：消息的接收者能够检验收到的消息是否是真实的犯法
报文认证的目的有两个：
 消息源的认证 消息的认证  简单报文验证 原理：
 发送方对报文 m 应用散列函数，得到报文摘要 h，将扩展报文（m,h）发送给接收方 接收方收到扩展报文后，提取出报文 m 和报文摘要 h，对报文 m 应用散列函数得到新的报文摘要 H（m），将 H（m）和 h 进行比较 若相同，报文认证成功；若不同，则认证失败  数字签名 数字签名：在公钥密码体制中，一个主体使用自己的私钥加密消息，得到的密文使用该主体的公钥解密来恢复成原来的消息。如此生成的密文对该消息提供认证服务。
数字签名应满足：
 接收方能够确认发送方的签名，但不能伪造 发送方发出签名的消息给接收方后，就不能再否认他所签发的消息 接收方对已收到的签名消息不能否认，有收报认证 第三者可以确认收发双方之间的消息传送，但不能伪造这一过程  简单数字签名
 A 利用自己的私钥对报文 m 加密，创建签名报文。将扩展报文（报文，签名报文）发送给 B B 收到报文 m 以及签名报文，利用 A 的公钥解密签名报文，并检验解密后的签名报文和报文 m 是否一致 若一致则签名报文的一定是 A 的私钥  签名报文摘要
 A 对报文 m 应用散列函数 H 生成报文摘要 H（m），然后 A 通过其私钥对报文摘要进行加密，生成加密的报文摘要，将扩展报文（报文，机密的报文摘要）发送给 B B 收到报文 m 及加密的报文摘要，B 利用 A 的公钥解密 加密的报文摘要，并对报文 m 应用散列函数生成新的报文摘要 如果两者一致，则签名报文 m 的一定是 A 的私钥  身份认证 身份认证：身份鉴别。一个实体经过计算机网络向另一个实体证明其身份的过程。
 基于共享对称密钥的身份认证 基于公开密钥的身份认证 一次性随机数：避免重放攻击  密钥分发中心与证书认证机构 密钥分发中心 对称密钥分发的典型解决方案：通信各方建立一个大家都新来的密钥分发中心（KDC），解决对称密钥安全可靠的分发。
方式一：通信发起方生成会话密钥
 A 和 B 进行保密通信。A 随机选择一个会话密钥，用 A 和 KDC 之间长期的共享密钥加密会话密钥，发送给 KDC KDC 得到后，解密获得会话密钥，以及所希望通信方 B。KDC 利用其和 B 的长期共享密钥加密密钥，发送给 B B 解密，获得会话密钥，并且得知期望和自己通信的是 A  方式二：KDC 为 A、B 生成通信的会话密钥
 A 在希望和 B 通信时，首先向 KDC 发送请求消息 KDC 接收到请求消息后，随机选择一个会话密钥，并将会话密钥分别用和 A、B 的长期共享密钥加密，再分发给 A、B A、B 收到 KDC 的密文后，分别解密，获得会话密钥。  证书认证机构 认证中心（CA）：将公钥与特定的实体绑定
CA 的作用：
 CA 可以证实一个实体的真实身份 一旦 CA 验证了某个实体的身份，CA 会生成一个把其身份和实体的公钥绑定起来的证书，其中包含该实体的公钥以及全局唯一的身份识别信息等，并由 CA 对证书进行数字签名。  防火墙与入侵检测系统 防火墙：能够隔离组织内部网络与公共互联网，允许某些分组通过，而阻止其他分组进入或离开内部网络的软件、硬件或软硬件结合的一种设施。
防火墙的分类：
 无状态分组过滤器：典型部署在内网和网络边缘路由器上的防火墙。路由器逐个检查数据报，根据访问控制表（ACL）实现防火墙规则 有状态分组过滤器：跟踪每个 TCP 连接建立、拆除，根据状态确定是否允许分组通过 应用网关：应用网关实现授权用户通过网关访问外部网络的服务  入侵检测系统（IDS）：当观察到潜在的恶意流量时，能够产生警告的设备或系统
网络安全协议 安全电子邮件 电子邮件对网络安全的需求：机密性、完整性、身份认证性、抗抵赖性
安全电子邮件标准（PGP 标准）提供的服务：邮件加密、报文完整性、数字签名
采用的加密算法：公钥加密算法（如 RSA）、对称加密算法、散列算法
安全套接字层 SSL 一般 Web 服务器越强大，包含安漏洞的概率越高。普通 Web 应用的应用层数据，在传输过程中都已明文形式传输，可能受到攻击。
在电子商务背景下，提出 HTTP 安全电子商务交易协议：在传输层之上构建一个安全层：
 安全套接字（SSL） 传输层安全（TLS）  SSL 可以提供的服务：机密性、完整性、身份认证等安全服务
SSL协议栈（协议的总和）：SSL 是介于 TCP 和 HTTP 等应用层协议之间的一个可选层，大多数应用层协议直接建立在 SSL 协议之上，SSL 是两层协议。
 SSL 握手协议：作用是协商密码组和建立密码组；服务器认证与鉴别和客户认证与鉴别 SSL 更改密码协议：通信双方修改密码组，标志着加密策略的改变 SSL 警告协议：为对等实体传递 SSL 警告或终止当前连接，包含两个字段：警告级别和警告代码 SSL 记录协议：描述了信息交换过程中的消息格式，前面 3 个协议需要记录协议进行封装与传输  虚拟专用网 VPN 和 IP 安全协议 IPSec 虚拟专用网 VPN 建立在公共网络上的安全通道，是用户通过公用网络建立的临时的、安全的连接。实现远程用户、分支机构、业务伙伴等机构总部网络的安全连接，从而构建针对特定组织结构的专用网络。
虚拟专用网最重要的特点就是虚拟。
虚拟专用网一般是指构建在 Internet 上能够自我管理的专用网络。
关键技术：
VPN 涉及的关键技术：
 隧道技术（如 IPSec） 数据加密 身份认证 密钥管理 访问控制 网络管理  隧道：通过 Internet 提供的点对点的数据传输的安全通道，通过数据加密保证安全。
 数据进入隧道时，由 VPN 封装成 IP 数据报，通过隧道在 Internet 上传输； 离开隧道后，数据便不再受 VPN 保护  IPSec 是网络层使用最广泛的安全协议，但 IPSec 不是一个单一的协议，而是一个安全体系。
主要包括：
 封装安全载荷协议 ESP：核心 认证头（AH）协议：核心 安全关联（SA） 密钥交换与管理（IKE）：IPSec 唯一的密钥管理协议  IPSec 传输模式：
 传输模式：主机模式，IPSec 数据报的发送和接受都由端系统完成 隧道模式：将 IPSec 的功能部署在网络边缘的路由器上，路由器之间建立安全隧道，数据报在其中传输  传输模式和协议组合：
 传输模式 AH 隧道模式 AH 传输模式 ESP 隧道模式 ESP：最广泛和最重要的 IPSec 形式  ]]></content></entry><entry><title>Andorid - Adb远程连接</title><url>/tech/andorid/adb-%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"><![CDATA[背景 在一些移动云测手机机房里 Android 设备是分批挂载在专门的 宿主机  集群上的，而执行自动化脚本的机器是在另外一个执行机集群中，因此就会产生这样的需求：执行机上的自动化脚本需要通过网络远程连接的方式来控制宿主机上的 Android 设备。
今天分享两个实现远程连接 Android 设备的方案。
实现 ADB Host 模式 手机连接电脑，执行如下命令
$ adb kill-server &amp;&amp; adb -a -P 5037 nodaemon server 然后在执行脚本的服务器上通过下面的命令远程连接设备：
# {device_hub_ip} 是指挂载 Android 设备的宿主机 IP $ adb -H {device_hub_ip} -P {port} {其他 adb 命令} # 如果是原生命令，则通过下面的方式连接使用 $ adb -H 10.x.x.x -P 5037 devices ADB WIFI 连接 1、将手机通过USB连接上手机，打开手机的USB调试模式，通过下述命令确认设备连接成功：
$ adb devices 2、打开adb监听端口，直接在电脑上运行
adb tcpip 5555 这里的端口号可以指定其他值，该命令将会重启手机上的adbd，开启网络调试功能。
3、远程连接，断开手机和PC的有线连接，直接使用 adb 命令远程连接：
$ adb connect ip:port 注意这里的IP是手机的IP，如果想要通过宿主机的IP连接，那么需要再做一次端口转发：
adb kill-server &amp;&amp; adb -a -P 5037 nodaemon server adb -H 10.x.x.x tcpip 5555 adb -H 10.x.x.x forward tcp:50001 tcp:5555 adb connect 10.x.x.x:50001 这时候再通过devices命令查看，就可以看到连接好的设备：
adb devices 4、断开远程连接
adb disconnect ip:port ]]></content></entry><entry><title>Andorid - uiautomator2 常用api汇总</title><url>/tech/andorid/uiautomator2-%E5%B8%B8%E7%94%A8api%E6%B1%87%E6%80%BB/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"><![CDATA[命令行 # 帮助文档 $ python -m uiautomator2 # 查看版本号 $ uiautomator2 version # 初始化 手机安装 atx、minicap 等  $ uiautomator2 init # 获取当前包名信息 $ uiautomator2 current # 安装包，支持 url 安装 $ uiautomator2 install demo.apk # 卸载 $ uiautomator2 uninstall demo.apk # 启动应用 $ uiautomator2 start 包名 # 停止应用 $ uiautomator2 stop 包名 # 下载初始化安装的应用 $ uiautomator2 purge 常用 API 设备连接 import uiautomator2 as u2 # 连接单台设备 d = u2.connect() # 连接指定设备 d = u2.connect(serialNo) # 通过 WiFi 连接 d = u2.connect_wifi(&#39;IP:port&#39;) 基本信息 # 获取设备信息（分辨率、厂商名、SDK版本等） d.info # 更详细的信息 d.device_info # 屏幕尺寸 d.window_size() 文件传输 # 本地文件 - 手机 d.push() # 手机文件 - 本地 d.pull() app 操作 # 安装 d.app_install(apk_path) # 卸载 d.app_uninstall(pkg_name) # 重置包 d.app_clear(pkg_name) # 获取包名 d.app_current() # 启动 d.app_start(pkg_name, activity) # 关闭 d.app_stop(pkg_name) # 列出所有运行中的包 d.app_list_running() 获取页面源码 d.dump_hierarchy(compressed=False, pretty=False) 按键操作 d.press(&#34;home&#34;) d.press(&#34;back&#34;) 元素定位 driver UiObject.info -&gt; uiautomator2.session.UiObject
 text, textContains, textMatches, textStartsWith className, classNameMatches description, descriptionContains, descriptionMatches, descriptionStartsWith checkable, checked, clickable, longClickable scrollable, enabled, focusable, focused, selected packageName, packageNameMatches resourceId, resourceIdMatches index, instance  # id d(resourceId=&#34;id&#34;) # 文本定位 d(text=&#34;文本&#34;) # 多节点通过下标定位 d(text=&#34;文本&#34;, instance=0) # 文本包含 d(textContains=&#34;文本&#34;) # xpath d(xpath=&#39;//*[@content-desc]=&#34;分享&#34;&#39;) # className d(className=&#34;className&#34;) # 子节点 d(className=&#34;android.widget.ListView&#34;).child(text=&#34;Bluetooth&#34;) # 兄弟节点 d(text=&#34;Google&#34;).sibling(className=&#34;android.widget.ImageView&#34;) # 通过节点的位置判断 left, right, top, bottom. d(text=&#34;Wi‑Fi&#34;).right(className=&#34;android.widget.Switch&#34;) xpathSelector # 获取第一个元素 x = d.xpath(f&#39;//*[@text=&#34;签到&#34;]&#39;) print(type(x)) # &lt;class &#39;uiautomator2.xpath.XPathSelector&#39;&gt; print(type(x.get()) # &lt;class &#39;uiautomator2.xpath.XMLElement&#39;&gt; # 获取该元素所有属性 print(x.get().attrib) { &#39;index&#39;: &#39;1&#39;, &#39;text&#39;: &#39;签到&#39;, &#39;resource-id&#39;: &#39;com.joyame.sixduoanew:id/tv_app_name&#39;, &#39;package&#39;: &#39;com.joyame.sixduoanew&#39;, &#39;content-desc&#39;: &#39;&#39;, &#39;checkable&#39;: &#39;false&#39;, &#39;checked&#39;: &#39;false&#39;, &#39;clickable&#39;: &#39;false&#39;, &#39;enabled&#39;: &#39;true&#39;, &#39;focusable&#39;: &#39;false&#39;, &#39;focused&#39;: &#39;false&#39;, &#39;scrollable&#39;: &#39;false&#39;, &#39;long-clickable&#39;: &#39;false&#39;, &#39;password&#39;: &#39;false&#39;, &#39;selected&#39;: &#39;false&#39;, &#39;visible-to-user&#39;: &#39;true&#39;, &#39;bounds&#39;: &#39;[657,987][747,1048]&#39; } # 获取该元素单个属性 print(x.get().attrib.get(&#34;resource-id&#34;)) # 获取一组元素，all() 返回的是一组 &lt;class &#39;uiautomator2.xpath.XMLElement&#39;&gt; # 相当于 XPathSelector.get() x.all() # 通过下标指定 ele = x.all()[0] ele.attrib.get(&#34;content-desc&#34;, &#34;&#34;) # 获取属性，并设置默认值 ele.attrib[&#34;text&#34;] = &#34;hello&#34; # 设置属性 ele.attrib.pop(&#34;clickable&#34;) # 删除属性 # 点击 d.xpath(&#34;//*[@content-desc=&#39;分享&#39;]&#34;).click() # 获取文本内容 ele.text ele.get_text() ele.attrib.get(&#34;text&#34;) 判断元素存在 d(text=&#34;Settings&#34;).exists d.exists(text=&#34;Settings&#34;) # 在规定时间内等待元素出现 d(text=&#34;Settings&#34;).exists(timeout=3) d(text=&#34;Settings&#34;).wait_gone(timeout=1.0) 动作操作 # 元素信息 d(resourceId=&#34;iv&#34;).info # 点击 d.click(x, y) # 点坐标 d(text=&#34;文本&#34;).click() d(resourceId=&#34;iv&#34;).click() # 点元素 d(text=&#34;Settings&#34;).click(timeout=10) # 点元素 且 设置超时时间 d(text=&#34;Settings&#34;).click(offset=(0.5, 0.5)) # 通过偏移量点击 clicked = d(text=&#39;Skip&#39;).click_exists(timeout=10.0) # 如果存在则点击 d.long_click(x, y, duracion=1.5) # 长按坐标 d(text=&#34;Settings&#34;).long_click() # 长按元素 d.double_click(x, y) # 双击坐标 # 输入 d.send_keys(text) # 文本操作 d(text=&#34;Settings&#34;).get_text() d(text=&#34;Settings&#34;).set_text(&#34;My text...&#34;) d(text=&#34;Settings&#34;).clear_text() d.clear_text() # 获取元素坐标 x, y = d(text=&#34;Settings&#34;).center() # 拖拽 # notes : drag can not be used for Android&lt;4.3. # drag the UI object to a screen point (x, y), in 0.5 second d(text=&#34;Settings&#34;).drag_to(x, y, duration=0.5) # drag the UI object to (the center position of) another UI object, in 0.25 second d(text=&#34;Settings&#34;).drag_to(text=&#34;Clock&#34;, duration=0.25) # 滑动 d.swipe() d.swipe(x1, y1, x2, y2) d(text=&#34;Settings&#34;).swipe(&#34;right&#34;) d(text=&#34;Settings&#34;).swipe(&#34;left&#34;, steps=10) d(text=&#34;Settings&#34;).swipe(&#34;up&#34;, steps=20) # 1 steps is about 5ms, so 20 steps is about 0.1s d(text=&#34;Settings&#34;).swipe(&#34;down&#34;, steps=20) # 截整图 d.screenshot(&#34;./demo.png&#34;) # 或 filename = &#39;debug/GameScreenshot/20191209_171115.png&#39; d.screenshot(filename) # 截元素 im = d(text=&#34;Settings&#34;).screenshot() im.save(&#34;settings.jpg&#34;) 等待 # 强制等待 time.sleep(2) # 隐式等待 # 全局 d.implicitly_wait(5) d.settings[&#34;wait_timeout&#34;] = 10 # 局部 d.wait_activity(&#34;.MainActivity&#34;, timeout=10) Toast d.toast.show(text, duraction) d.toast.get_message(timeout, cachetime, message) 弹框监控 # 定义监控 d.watcher.when(&#34;//*[@text=&#39;同意&#39;]&#34;).click() # 开始监控 d.watcher.start() d.watcher.start(2) # 间隔 # 运行所有监控 d.watcher.run() # 移除监控 d.watcher.remove() # 停止监控 d.watcher.stop() ]]></content></entry><entry><title>Ios - 搭建自动化测试Wda</title><url>/tech/ios/%E6%90%AD%E5%BB%BA%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95wda/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html">原理图
环境 iPhone 15.4 xcode 12.4 tidevice 0.6.6 WebDriverAgent v4.8.4 初始化工作
# 安装 tidevice $ pip install -U tidevice # 安装 python wda client $ pip install -U facebook-wda # clone wda 源码 $ cd workspace $ git clone https://github.com/appium/WebDriverAgent.git $ cd WebDriverAgent # 目前的版本不需要执行 ./Scripts/bootstrap.sh # 双击打开 WebDriverAgent.xcodeproj 项目 编译安装 APP 请参考： IOS测试 | facebook-wda 环境搭建篇
出现如下报错信息需要信任开发者，点击「通用 - VPN与设备管理 - 信任开发者」即可。
The operation couldn’t be completed. Unable to launch com.facebook.WebDriverAgentRunner.lan.xctrunner because it has an invalid code signature, inadequate entitlements or its profile has not been explicitly trusted by the user.
通过 tidevice 启动 wda：
$ tidevice -u [udid] wdaproxy -B [wda bundle Id] --port 8100 ... WebDriverAgent start successfully DEMO 抓取页面元素 注意，在当前版本中，/inspector 接口已经移除，不能使用。
mykola-mokhnach: The built-in inspector module has been removed from the fork in favour of Appium Desktop&amp;rsquo;s one
内置的检查器模块已经从 fork 中移除，取而代之的是 Appium Desktop。
不想下载 appium Desktop，这里使用源码方式获取元素属性。
c.source() # xml 格式 c.source(accessible=True) # json 格式 在 dom 结构内找到预期元素的属性，进行定位。</content></entry><entry><title>Ios - Xcode基本使用</title><url>/tech/ios/xcode%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html">App Store 直接下载。
构建应用到真机 可以随意构建应用到模拟器。但是如果要构建到真机上的话，需要苹果的开发者证书。
开发者证书：调试真机设备 发布证书：将应用提交到 APPStore 设置证书和应用 ID 后，即可进行真机构建。
查看 bundleID 方式 如果报错提示 bundleId 不唯一，则需要在这里修改下，提交应用商店的唯一 ID，类似于安卓的包名。
查看应用程序生成的位置 点击 build 后，会构建出一个应用包。包的路径查看方式如图。
注意构建到模拟器和构建到真机的 APP 不通用，构建到真机的包需要签名。</content></entry><entry><title>Ios - 自动化环境准备</title><url>/tech/ios/%E8%87%AA%E5%8A%A8%E5%8C%96%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html"><![CDATA[环境准备 libimobiledevice 是一个跨平台的软件库，可以管理已安装应用，获取通讯录、日程、备注和书签等信息
# github.com/libimobiledevice/libimobiledevice $ brew install --HEAD libimobiledevice ideviceinstaller 是一个命令行工具，主要用于管理 ios 设备上应用程序的安装与卸载，以及查看相关信息
$ brew install ideviceinstaller carthage WDA 依赖
$ brew install carthage ios-deploy 终端安装和调试 iphone 应用的第三方开源库
$ brew install ios-deploy iwdp 通过 websocket 连接，代理来自 usbmuxd 守护进程的请求，允许开发人员在真实和模拟的 ios 设备上向 MobileSafari 和 UIWebViews发送命令，appium 依赖此工具进行 webview 控件的操作。
$ brew install ios-webkit-debug-proxy APP 在应用商店安装 Xcode，下载测试应用项目并打开
# https://github.com/appium/ios-uicatalog $ git clone git@github.com:appium/ios-uicatalog.git $ cd ios-uicatalog/UICatalog $ open UICatalog.xcodeproj 在 xcode 内选择设备或模拟器进行构建，本次使用模拟器。
常用命令  操作模拟器命令 xcrun simctl 操作真机命令 idevice  查看设备
# 查看已安装的模拟器 $ xcrun simctl list devices # 查看已开机的模拟器 $ xcrun simctl list devices | grep Booted iPhone 12 (DD05973B-7423-4FDE-98E8-B8B57F31A954) (Booted) # 查看真机 udid 信息 $ idevice_id -l 启动模拟器
$ xcrun simctl boot &lt;device&gt; 安装应用
# 模拟器 单机 $ xcrun simctl install booted demo.app # 多设备需要指定设备 id $ xcrun simctl install &lt;device&gt; demo.app # 真机 $ ideviceinstaller --install demo.app $ ideviceinstaller -i demo.app 卸载应用
# 模拟器 $ xcrun simctl uninstall &lt;device&gt; &lt;bundleId&gt; # 真机 $ ideviceinstaller --uninstall &lt;bundleId&gt; $ ideviceinstaller -U &lt;bundleId&gt; 查看应用的 bundleID
# 模拟器 # 右键 app 安装包 - 显示包内容 - info.plist - Bundle identifier # 真机 $ ideviceinstaller -l wda WebDriverAgent 由 Facebook 推出的移动端测试框架。
xcode 8 移除 UIAutomation，使用 webdriveragent 代替。
]]></content></entry><entry><title>Docker - Docker Compose报错汇总</title><url>/tech/docker/docker-compose%E6%8A%A5%E9%94%99%E6%B1%87%E6%80%BB/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ 汇总遇到的报错信息。
 1. ParserError: while parsing a block mapping $ docker-compose down ERROR: yaml.parser.ParserError: while parsing a block mapping in &#34;./compose.yml&#34;, line 1, column 1 expected &lt;block end&gt;, but found &#39;&lt;block mapping start&gt;&#39; in &#34;./compose.yml&#34;, line 25, column 3 原因是空格导致未对齐，检查 25 行格式错误。
]]></content></entry><entry><title>Selenium - 发起Api请求Seleniumwire</title><url>/tech/selenium/%E5%8F%91%E8%B5%B7api%E8%AF%B7%E6%B1%82seleniumwire/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[  SeleniumWire   是 Selenium 的扩展，可以获取浏览器发出的请求数据。编写代码方式不变，增加额外的 API 来检查请求和响应并即时更改它们。
 特性  纯 Python，用户友好的 API 捕获 HTTP 和 HTTPS 请求 拦截请求和响应 即时修改标题、参数、正文内容 捕获 websocket 消息 支持 HAR 格式 代理服务器支持  兼容性：
 Python 3.7+ Selenium 4.0.0+ 支持 Chrome、Firefox、Edge 和 Remote Webdriver  安装 # python 库安装 $ pip install selenium-wire # 需要 OpenSSL 来解密 HTTPS 请求。 # Linux # For apt based Linux systems $ sudo apt install openssl # For RPM based Linux systems $ sudo yum install openssl # For Linux alpine $ sudo apk add openssl # For Mac $ brew install openssl # windows 无需安装 # check $ openssl version LibreSSL 2.8.3 使用 from seleniumwire import webdriver driver = webdriver.Chrome() driver.get(&#39;https://www.example.com&#39;) # Access requests via the `requests` attribute for request in driver.requests: if request.response: print( request.method, request.url, request.response.status_code, request.response.headers[&#39;Content-Type&#39;], request.response.body, request.response.date ) driver.quit() 远程浏览器 TODO：目前报错，需要启动一个远程代理服务，接收请求
options = { &#39;addr&#39;: &#39;127.0.0.1&#39; } driver = webdriver.Remote( command_executor=&#39;http://www.example.com&#39;, seleniumwire_options=options ) 访问请求 driver.requests # 按时间顺序排列的捕获请求列表 driver.last_request # 最近捕获的请求, driver.requests[-1] 等待匹配的请求返回
# pat 是一个正则表达式，返回找到的第一个请求 # 未在指定时间返回，引发异常 TimeoutException driver.wait_for_request(pat, timeout=10) # 点击页面后，等待返回 12345 接口 button_element.click() request = driver.wait_for_request(&#39;/api/products/12345/&#39;) 将请求保存为 har 格式
# 必须设置浏览器：enable_har=true driver.har # 返回捕获请求的迭代器。在处理大量请求时很有用。 driver.iter_requests() # 用于设置请求拦截器。请参阅拦截请求和响应。 driver.request_interceptor # 用于设置响应拦截器。 driver.response_interceptor # 要清除以前捕获的请求和 HAR 条目，请使用del del driver.requests Selenium Wire 默认忽略 OPTIONS 请求，因为这些通常是无趣的，只会增加开销。如果要捕获 OPTIONS 请求，则需要将ignore_http_methods 选项  设置为[].
请求对象 请求对象具有以下属性。
  body
请求正文为bytes. 如果请求没有正文，则 的值为body空，即b''.
  cert
字典格式的有关服务器 SSL 证书的信息。对于非 HTTPS 请求为空。
  date
发出请求的日期时间。
  headers
请求标头的类似字典的对象。标头不区分大小写，并且允许重复。请求request.headers['user-agent']将返回User-Agent标头的值。如果您希望替换标题，请确保先使用 删除现有标题del request.headers['header-name']，否则您将创建一个副本。
  host
请求主机，例如www.example.com
  method
HTTP 方法，例如GET或POST等。
  params
请求参数字典。如果同名参数在请求中多次出现，它在字典中的值将是一个列表。
  path
请求路径，例如/some/path/index.html
  querystring
查询字符串，例如foo=bar&amp;spam=eggs
  response
与请求关联的 响应对象。  None如果请求没有响应，就会出现这种情况。
  url
请求网址，例如https://www.example.com/some/path/index.html?foo=bar&amp;spam=eggs
  ws_messages
如果请求是 websocket 握手请求（通常以 URL 开头wss://），ws_messages则将包含发送和接收的所有 websocket 消息的列表。请参阅 WebSocketMessage 对象  。
  请求对象具有以下方法。
  abort(error_code=403)
使用提供的错误代码触发立即终止请求。在请求拦截器中使用。请参阅 示例：阻止请求  。
  create_response(status_code, headers=(), body=b'')
创建一个响应并返回它而不向远程服务器发送任何数据。在请求拦截器中使用。请参阅 示例：模拟响应  。
  WebSocketMessage 对象 这些对象表示在浏览器和服务器之间发送的 websocket 消息，反之亦然。它们由request.ws_messageswebsocket 握手请求保存在列表中。它们具有以下属性。
  content
消息内容可以是str或bytes。
  date
消息的日期时间。
  from_client
True消息何时由客户端发送以及False何时由服务器发送。
  响应对象 响应对象具有以下属性。
  body
响应主体为bytes. 如果响应没有正文，则 的值为body空，即b''。有时正文可能已被服务器压缩。disable_encoding 您可以使用选项  来防止这种情况。要手动解码编码的响应主体，您可以执行以下操作：
  from seleniumwire.utils import decode body = decode(response.body, response.headers.get(&#39;Content-Encoding&#39;, &#39;identity&#39;))   date
收到响应的日期时间。
  headers
类似字典的响应标头对象。标头不区分大小写，并且允许重复。请求response.headers['content-length']将返回Content-Length标头的值。如果您希望替换标题，请确保先使用 删除现有标题del response.headers['header-name']，否则您将创建一个副本。
  reason
原因短语，例如OK或Not Found等。
  status_code
响应的状态代码，例如200或404等。
  拦截请求和响应 除了捕获请求和响应，Selenium Wire 还允许您使用拦截器动态修改它们。拦截器是一个函数，在请求和响应通过 Selenium Wire 时被调用。在拦截器中，您可以根据需要修改请求和响应。
driver.request_interceptor在开始使用驱动程序之前，您可以使用和driver.response_interceptor属性设置拦截器函数。请求拦截器应该接受请求的单个参数。响应拦截器应该接受两个参数，一个用于原始请求，一个用于响应。
示例：添加请求头 def interceptor(request): request.headers[&#39;New-Header&#39;] = &#39;Some Value&#39; driver.request_interceptor = interceptor driver.get(...) # All requests will now contain New-Header 如何检查标头是否已正确设置？您可以在页面加载后使用 打印捕获的请求的标头driver.requests，或者将网络驱动程序指向https://httpbin.org/headers，这会将请求标头回显给浏览器，以便您可以查看它们。
示例：替换现有请求标头 HTTP 请求中允许重复的标头名称，因此在设置替换标头之前，您必须先使用del以下示例中的 like 删除现有标头，否则将存在两个具有相同名称的标头（request.headers是一个特殊的类字典对象，允许重复).
def interceptor(request): del request.headers[&#39;Referer&#39;] # Remember to delete the header first request.headers[&#39;Referer&#39;] = &#39;some_referer&#39; # Spoof the referer driver.request_interceptor = interceptor driver.get(...) # All requests will now use &#39;some_referer&#39; for the referer 示例：添加响应标头 def interceptor(request, response): # A response interceptor takes two args if request.url == &#39;https://server.com/some/path&#39;: response.headers[&#39;New-Header&#39;] = &#39;Some Value&#39; driver.response_interceptor = interceptor driver.get(...) # Responses from https://server.com/some/path will now contain New-Header 示例：添加请求参数 请求参数与标头的工作方式不同，因为它们是在请求中设置时计算的。这意味着您首先必须读取它们，然后更新它们，然后再将它们写回——就像下面的例子一样。参数保存在常规字典中，因此具有相同名称的参数将被覆盖。
def interceptor(request): params = request.params params[&#39;foo&#39;] = &#39;bar&#39; request.params = params driver.request_interceptor = interceptor driver.get(...) # foo=bar will be added to all requests 示例：更新 POST 请求正文中的 JSON import json def interceptor(request): if request.method == &#39;POST&#39; and request.headers[&#39;Content-Type&#39;] == &#39;application/json&#39;: # The body is in bytes so convert to a string body = request.body.decode(&#39;utf-8&#39;) # Load the JSON data = json.loads(body) # Add a new property data[&#39;foo&#39;] = &#39;bar&#39; # Set the JSON back on the request request.body = json.dumps(data).encode(&#39;utf-8&#39;) # Update the content length del request.headers[&#39;Content-Length&#39;] request.headers[&#39;Content-Length&#39;] = str(len(request.body)) driver.request_interceptor = interceptor driver.get(...) 示例：基本身份验证 如果站点需要用户名/密码，您可以使用请求拦截器为每个请求添加身份验证凭据。这将阻止浏览器显示用户名/密码弹出窗口。
import base64 auth = ( base64.encodebytes(&#39;my_username:my_password&#39;.encode()) .decode() .strip() ) def interceptor(request): if request.host == &#39;host_that_needs_auth&#39;: request.headers[&#39;Authorization&#39;] = f&#39;Basic {auth}&#39; driver.request_interceptor = interceptor driver.get(...) # Credentials will be transmitted with every request to &#34;host_that_needs_auth&#34; 示例：阻止请求 您可以使用它request.abort()来阻止请求并将立即响应发送回浏览器。可以提供可选的错误代码。默认值为 403（禁止）。
def interceptor(request): # Block PNG, JPEG and GIF images if request.path.endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.gif&#39;)): request.abort() driver.request_interceptor = interceptor driver.get(...) # Requests for PNG, JPEG and GIF images will result in a 403 Forbidden 示例：模拟响应 您可以使用request.create_response()将自定义回复发送回浏览器。不会向远程服务器发送任何数据。
def interceptor(request): if request.url == &#39;https://server.com/some/path&#39;: request.create_response( status_code=200, headers={&#39;Content-Type&#39;: &#39;text/html&#39;}, # Optional headers dictionary body=&#39;&lt;html&gt;Hello World!&lt;/html&gt;&#39; # Optional body ) driver.request_interceptor = interceptor driver.get(...) # Requests to https://server.com/some/path will have their responses mocked 您还有其他您认为有用的示例吗？欢迎提交 PR。
取消设置拦截器 要取消设置拦截器，请使用del：
del driver.request_interceptor del driver.response_interceptor 限制请求捕获 Selenium Wire 的工作原理是通过它在后台启动的内部代理服务器重定向浏览器流量。当请求流经代理时，它们会被拦截和捕获。捕获请求可以稍微减慢速度，但您可以采取一些措施来限制捕获的内容。
  driver.scopes
这接受将匹配要捕获的 URL 的正则表达式列表。它应该在发出任何请求之前在驱动程序上设置。当为空（默认）时，将捕获所有 URL。driver.scopes = [ '.*stackoverflow.*', '.*github.*' ] driver.get(...) # Start making requests # Only request URLs containing &quot;stackoverflow&quot; or &quot;github&quot; will now be captured请注意，即使请求超出范围且未被捕获，它仍将通过 Selenium Wire 传输。
  seleniumwire_options.disable_capture
使用此选项关闭请求捕获。请求仍将通过 Selenium Wire 和您配置的任何上游代理传递，但不会被拦截或存储。请求拦截器不会执行。options = { 'disable_capture': True # Don't intercept/store any requests } driver = webdriver.Chrome(seleniumwire_options=options)
  seleniumwire_options.exclude_hosts
使用此选项可以完全绕过 Selenium Wire。对此处列出的地址发出的任何请求都将直接从浏览器发送到服务器，而不涉及 Selenium Wire。请注意，如果您配置了上游代理，那么这些请求也将绕过该代理。options = { 'exclude_hosts': ['host1.com', 'host2.com'] # Bypass Selenium Wire for these hosts } driver = webdriver.Chrome(seleniumwire_options=options)
  request.abort()
 您可以通过在请求拦截器  中使用request.abort()from 来提前中止请求。这将立即向客户端发送响应，而无需进一步传输请求。您可以使用此机制来阻止某些类型的请求（例如图像）以提高页面加载性能。def interceptor(request): # Block PNG, JPEG and GIF images if request.path.endswith(('.png', '.jpg', '.gif')): request.abort() driver.request_interceptor = interceptor driver.get(...) # Start making requests
  请求存储 默认情况下，捕获的请求和响应存储在系统临时文件夹（/tmp在 Linux 上，通常C:\Users\&lt;username&gt;\AppData\Local\Temp在 Windows 上）中名为.seleniumwire. 要更改.seleniumwire文件夹的创建位置，您可以使用以下request_storage_base_dir选项：
options = { &#39;request_storage_base_dir&#39;: &#39;/my/storage/folder&#39; # .seleniumwire will get created here } driver = webdriver.Chrome(seleniumwire_options=options) 内存存储 Selenium Wire 还支持仅在内存中存储请求和响应，这在某些情况下可能很有用 - 例如，如果您运行的是短期 Docker 容器并且不希望磁盘持久性的开销。request_storage您可以通过将选项设置为启用内存存储memory：
options = { &#39;request_storage&#39;: &#39;memory&#39; # Store requests and responses in memory only } driver = webdriver.Chrome(seleniumwire_options=options) 如果您担心可能消耗的内存量，您可以限制使用该request_storage_max_size选项存储的请求数：
options = { &#39;request_storage&#39;: &#39;memory&#39;, &#39;request_storage_max_size&#39;: 100 # Store no more than 100 requests in memory } driver = webdriver.Chrome(seleniumwire_options=options) 当达到最大大小时，旧请求将在新请求到达时被丢弃。driver.requests请记住，如果您限制存储的请求数量，当您使用或driver.wait_for_request()等检索它们时，请求可能已经从存储中消失。
代理 如果您正在访问的站点位于代理服务器后面，您可以在传递给网络驱动程序的选项中告诉 Selenium Wire 有关该代理服务器的信息。
配置采用以下格式：
options = { &#39;proxy&#39;: { &#39;http&#39;: &#39;http://192.168.10.100:8888&#39;, &#39;https&#39;: &#39;https://192.168.10.100:8888&#39;, &#39;no_proxy&#39;: &#39;localhost,127.0.0.1&#39; } } driver = webdriver.Chrome(seleniumwire_options=options) 要将 HTTP Basic Auth 与您的代理一起使用，请在 URL 中指定用户名和密码：
options = { &#39;proxy&#39;: { &#39;https&#39;: &#39;https://user:pass@192.168.10.100:8888&#39;, } } 对于 Basic 以外的身份验证，您可以Proxy-Authorization使用该custom_authorization选项为标头提供完整值。例如，如果您的代理使用 Bearer 方案：
options = { &#39;proxy&#39;: { &#39;https&#39;: &#39;https://192.168.10.100:8888&#39;, # No username or password used &#39;custom_authorization&#39;: &#39;Bearer mytoken123&#39; # Custom Proxy-Authorization header value } } Proxy-Authorization可以在 此处  找到有关标头的更多信息。
代理配置也可以通过名为HTTP_PROXY,HTTPS_PROXY和的环境变量加载NO_PROXY：
$ export HTTP_PROXY=&#34;http://192.168.10.100:8888&#34; $ export HTTPS_PROXY=&#34;https://192.168.10.100:8888&#34; $ export NO_PROXY=&#34;localhost,127.0.0.1&#34; Socket 使用 SOCKS 代理与使用基于 HTTP 的代理相同，但您将方案设置为socks5：
options = { &#39;proxy&#39;: { &#39;http&#39;: &#39;socks5://user:pass@192.168.10.100:8888&#39;, &#39;https&#39;: &#39;socks5://user:pass@192.168.10.100:8888&#39;, &#39;no_proxy&#39;: &#39;localhost,127.0.0.1&#39; } } driver = webdriver.Chrome(seleniumwire_options=options) 如果您的代理不需要身份验证，您可以省略user和。pass
以及socks5，计划socks4和socks5h支持。socks5h当您希望 DNS 解析发生在代理服务器而不是客户端时使用。
将 Selenium Wire 与 Tor 结合使用
如果您想使用 Tor 运行 Selenium Wire，请参阅 此示例。  
动态切换 如果要更改现有驱动程序实例的代理设置，请使用driver.proxy属性：
driver.get(...) # Using some initial proxy # Change the proxy driver.proxy = { &#39;https&#39;: &#39;https://user:pass@192.168.10.100:8888&#39;, } driver.get(...) # These requests will use the new proxy 要清除代理，请设置driver.proxy为空 dict {}。
该机制还支持no_proxy和custom_authorization选项。
机器人检测 如果 Selenium Wire 在您的环境中找到它，它将与 undetected-chromedriver集成。  该库将透明地修改 ChromeDriver 以防止其在网站上触发反机器人措施。
如果你想利用这一点，请确保你已经安装了 undetected_chromedriver：
pip install undetected-chromedriver 然后在您的代码中，导入seleniumwire.undetected_chromedriver包：
import seleniumwire.undetected_chromedriver as uc chrome_options = uc.ChromeOptions() driver = uc.Chrome( options=chrome_options, seleniumwire_options={} ) 证书 Selenium Wire 使用它自己的根证书来解密 HTTPS 流量。浏览器通常不需要信任此证书，因为 Selenium Wire 告诉浏览器将其添加为例外。这将允许浏览器正常运行，但它会在地址栏中显示“不安全”消息（和/或解锁的挂锁）。如果您希望摆脱此消息，您可以手动安装根证书。
 您可以在此处  下载根证书。下载后，导航到浏览器设置中的“证书”，然后在“权限”部分导入证书。
使用您自己的证书 如果您想使用自己的根证书，您可以使用ca_cert和ca_key选项提供证书路径和私钥。
如果您确实指定了自己的证书，请务必手动删除 Selenium Wire 的 临时存储文件夹  。这将清除可能从以前的运行中缓存的任何现有证书。
所有选项 可以通过seleniumwire_optionswebdriver 属性传递给 Selenium Wire 的所有选项的摘要。
  addr
运行 Selenium Wire 的机器的 IP 地址或主机名。这默认为 127.0.0.1。如果您使用的是 远程 webdriver   ，您可能希望将其更改为机器（或容器）的公共 IP 。
  options = { &#39;addr&#39;: &#39;192.168.0.10&#39; # Use the public IP of the machine } driver = webdriver.Chrome(seleniumwire_options=options)   auto_config
Selenium Wire 是否应该为请求捕获自动配置浏览器。True默认。
  ca_cert
如果您更喜欢使用自己的证书而不是使用默认证书，则为根 (CA) 证书的路径。
  options = { &#39;ca_cert&#39;: &#39;/path/to/ca.crt&#39; # Use own root certificate } driver = webdriver.Chrome(seleniumwire_options=options)   ca_key
如果您使用自己的根证书，则为私钥的路径。使用您自己的证书时，必须始终提供密钥。
  options = { &#39;ca_key&#39;: &#39;/path/to/ca.key&#39; # Path to private key } driver = webdriver.Chrome(seleniumwire_options=options)   disable_capture
禁用请求捕获。当True没有任何内容被拦截或存储时。False默认。
  options = { &#39;disable_capture&#39;: True # Don&#39;t intercept/store any requests. } driver = webdriver.Chrome(seleniumwire_options=options)   disable_encoding
要求服务器发回未压缩的数据。False默认。当True这将Accept-Encoding标头设置identity为所有出站请求时。请注意，它并不总是有效 - 有时服务器可能会忽略它。
  options = { &#39;disable_encoding&#39;: True # Ask the server not to compress the response } driver = webdriver.Chrome(seleniumwire_options=options)   enable_har
当True保留 HTTP 事务的 HAR 存档时，可以使用driver.har. False默认。
  options = { &#39;enable_har&#39;: True # Capture HAR data, retrieve with driver.har } driver = webdriver.Chrome(seleniumwire_options=options)   exclude_hosts
应完全绕过 Selenium Wire 的地址列表。请注意，如果您配置了上游代理，那么对排除的主机的请求也将绕过该代理。
  options = { &#39;exclude_hosts&#39;: [&#39;google-analytics.com&#39;] # Bypass these hosts } driver = webdriver.Chrome(seleniumwire_options=options)   ignore_http_methods
Selenium Wire 应忽略且不捕获的 HTTP 方法列表（指定为大写字符串）。默认是['OPTIONS']忽略所有 OPTIONS 请求。要捕获所有请求方法，请设置ignore_http_methods为空列表：
  options = { &#39;ignore_http_methods&#39;: [] # Capture all requests, including OPTIONS requests } driver = webdriver.Chrome(seleniumwire_options=options)   port
Selenium Wire 后端监听的端口号。您通常不需要指定端口，因为系统会自动选择随机端口号。
  options = { &#39;port&#39;: 9999 # Tell the backend to listen on port 9999 (not normally necessary to set this) } driver = webdriver.Chrome(seleniumwire_options=options)   proxy
如果您使用代理，则为上游 代理服务器配置。  
  options = { &#39;proxy&#39;: { &#39;http&#39;: &#39;http://user:pass@192.168.10.100:8888&#39;, &#39;https&#39;: &#39;https://user:pass@192.168.10.100:8889&#39;, &#39;no_proxy&#39;: &#39;localhost,127.0.0.1&#39; } } driver = webdriver.Chrome(seleniumwire_options=options)   request_storage
要使用的存储类型。Selenium Wire 默认为基于磁盘的存储，但您可以通过将此选项设置为以下来切换到内存存储memory：
  options = { &#39;request_storage&#39;: &#39;memory&#39; # Store requests and responses in memory only } driver = webdriver.Chrome(seleniumwire_options=options)   request_storage_base_dir
Selenium Wire 在使用其默认的基于磁盘的存储时存储捕获的请求和响应的基本位置。这默认为系统临时文件夹（/tmp在 Linux 上，通常C:\Users\&lt;username&gt;\AppData\Local\Temp在 Windows 上）。将在此处创建一个名为的子文件夹.seleniumwire来存储捕获的数据。
  options = { &#39;request_storage_base_dir&#39;: &#39;/my/storage/folder&#39; # .seleniumwire will get created here } driver = webdriver.Chrome(seleniumwire_options=options)   request_storage_max_size
使用内存存储时要存储的最大请求数。默认无限制。使用默认的基于磁盘的存储时，此选项当前无效。
  options = { &#39;request_storage&#39;: &#39;memory&#39;, &#39;request_storage_max_size&#39;: 100 # Store no more than 100 requests in memory } driver = webdriver.Chrome(seleniumwire_options=options)   suppress_connection_errors
是否抑制与连接相关的回溯。True默认情况下，这意味着有时在浏览器关闭时发生的无害错误不会提醒用户。当被抑制时，连接错误消息被记录在 DEBUG 级别，没有回溯。设置为False允许异常传播并查看完整的回溯。
  options = { &#39;suppress_connection_errors&#39;: False # Show full tracebacks for any connection errors } driver = webdriver.Chrome(seleniumwire_options=options)   verify_ssl
是否应验证 SSL 证书。False默认情况下，这可以防止自签名证书出错。
  options = { &#39;verify_ssl&#39;: True # Verify SSL certificates but beware of errors with self-signed certificates } driver = webdriver.Chrome(seleniumwire_options=options) ]]></content></entry><entry><title>Selenium - Chromedriver</title><url>/tech/selenium/chromedriver%E8%84%9A%E6%9C%AC/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[批量杀死 chromedriver 进程
$ ps -ef \ | grep chromedriver | grep -v grep \ | awk &#39;{print $2}&#39; \ | awk &#39;BEGIN{RS=&#34;&#34;;FS=&#34;\n&#34;;OFS=&#34; &#34;}{$1=$1;print $0}&#39; \ | xargs kill -9 ]]></content></entry><entry><title>Selenium - 调试阶段复用浏览器</title><url>/tech/selenium/%E5%9F%BA%E7%A1%8010%E8%B0%83%E8%AF%95%E9%98%B6%E6%AE%B5%E5%A4%8D%E7%94%A8%E6%B5%8F%E8%A7%88%E5%99%A8/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[ selenium debug 模式，远程调试，复用浏览器。
 场景 比如测试京东购物流程，必须扫码登录成功后，才能进行后续操作。
用例编写调试时，每次运行都会打开一个新的浏览器窗口，得重新扫码登录才行。
原因是ChromeDriver默认每次被调用启动时都会加载一个新的会话，像这种频繁调试的场景，就比较浪费时间。
对此，ChromeDriver通过开放远程端口提供debug的能力。
将 ChromeOptions   对象中的debuggerAddress参数，设置为要连接的调试器服务器地址，格式为：
&lt;hostname/ip:port&gt;
即可，后续操作都在当前窗口进行，达到浏览器复用的目的。
配置  将chromedriver添加到环境变量；  # bin 目录已经配置好环境变量 # 这里可以直接将下载好的 driver 放到该目录下 $ mv chromedriver /usr/local/bin  设置 - 隐私设置和安全性 - 网站设置 - 后台同步 - 默认行为 - 勾选 最近关闭的网站可以完成数据收发操作；
  完全关闭浏览器，点击鼠标右键 - 退出；
  开启浏览器远程调试端口，这个端口可以自定义，不与本地已开端口冲突就行；
  $ /Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome -remote-debugging-port=9222 # 正在现有的浏览器会话中打开。 # 如果出现上面提示，重新关闭浏览器，执行命令 执行脚本，在options内添加远程浏览器的IP地址和端口号，执行测试。  @pytest.fixture(scope=&#34;session&#34;) def driver(): options = Options() # 设置复用浏览器的端口，地址 options.debugger_address = &#34;127.0.0.1:9222&#34; driver = webdriver.Chrome(options=options) driver.get(&#34;https://baidu.com&#34;) yield driver driver.quit() def test_demo(driver): driver.find_element(By.ID, &#34;kw&#34;).send_keys(&#34;selenium&#34;) 这时不管运行多少次测试用例，都复用同一个调试浏览器，不会打开新的浏览器窗口。
]]></content></entry><entry><title>Selenium - 使用Cookies</title><url>/tech/selenium/%E5%9F%BA%E7%A1%809%E4%BD%BF%E7%94%A8cookies/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[ WebDriver 与 cookie 进行交互的方法。
 cookie 通常用于网站识别用户的身份，保持登录状态或追踪用户浏览记录。
 Name：cookie 的名称 Value：cookie 的值 Domain：允许接收 cookie 的主机 Path：请求 URL 路径 Expires/Max-Age：cookie 有效期 Size：cookie 的大小 HttpOnly：是否仅能通过 HTTP 请求（true/false） Secure：是否仅通过 HTTPS 请求（true/false） SameSite：是否限制第三方 cookie Priority：优先级，包含低、中（默认）或高值  添加 cookie 添加操作只接收一组定义的、可序列化的JSON对象。
from selenium import webdriver driver = webdriver.Chrome() driver.get(&#34;http://www.example.com&#34;) # Adds the cookie into current browser context driver.add_cookie({&#34;name&#34;: &#34;foo&#34;, &#34;value&#34;: &#34;bar&#34;}) 获取 cookie 根据name获取单条cookie。
driver.add_cookie({&#34;name&#34;: &#34;foo&#34;, &#34;value&#34;: &#34;bar&#34;}) print(driver.get_cookie(&#34;foo&#34;)) &#34;&#34;&#34; {&#39;domain&#39;: &#39;example.com&#39;, &#39;httpOnly&#39;: False, &#39;name&#39;: &#39;foo&#39;, &#39;path&#39;: &#39;/&#39;, &#39;secure&#39;: False, &#39;value&#39;: &#39;bar&#39;} &#34;&#34;&#34; 获取所有 cookie。
driver.add_cookie({&#34;name&#34;: &#34;test1&#34;, &#34;value&#34;: &#34;cookie1&#34;}) driver.add_cookie({&#34;name&#34;: &#34;test2&#34;, &#34;value&#34;: &#34;cookie2&#34;}) print(driver.get_cookies()) &#34;&#34;&#34; [ {&#39;domain&#39;: &#39;example.com&#39;, &#39;httpOnly&#39;: False, &#39;name&#39;: &#39;test2&#39;, &#39;path&#39;: &#39;/&#39;, &#39;secure&#39;: False, &#39;value&#39;: &#39;cookie2&#39;}, {&#39;domain&#39;: &#39;example.com&#39;, &#39;httpOnly&#39;: False, &#39;name&#39;: &#39;test1&#39;, &#39;path&#39;: &#39;/&#39;, &#39;secure&#39;: False, &#39;value&#39;: &#39;cookie1&#39;} ] &#34;&#34;&#34; 删除 cookie 根据 name 删除单条 cookie。
driver.add_cookie({&#34;name&#34;: &#34;test1&#34;, &#34;value&#34;: &#34;cookie1&#34;}) driver.add_cookie({&#34;name&#34;: &#34;test2&#34;, &#34;value&#34;: &#34;cookie2&#34;}) driver.delete_cookie(&#34;test1&#34;) print(driver.get_cookies()) &#34;&#34;&#34; [ {&#39;domain&#39;: &#39;example.com&#39;, &#39;httpOnly&#39;: False, &#39;name&#39;: &#39;test2&#39;, &#39;path&#39;: &#39;/&#39;, &#39;secure&#39;: False, &#39;value&#39;: &#39;cookie2&#39;} ] &#34;&#34;&#34; 删除所有 cookie。
driver.add_cookie({&#34;name&#34;: &#34;test1&#34;, &#34;value&#34;: &#34;cookie1&#34;}) driver.add_cookie({&#34;name&#34;: &#34;test2&#34;, &#34;value&#34;: &#34;cookie2&#34;}) driver.delete_all_cookies() print(driver.get_cookies()) &#34;&#34;&#34; [] &#34;&#34;&#34; cookie 保存与读取 在项目中，通常把获取到的 cookie 保存到文件，在调用处直接读取即可。
&#34;&#34;&#34; cookies 保存到文件 &#34;&#34;&#34; driver.get(&#34;已经登录后的网站&#34;) cookies = driver.get_cookies() with open(&#34;cookies.yaml&#34;, &#34;w&#34;, encoding=&#34;utf-8&#34;) as f: yaml.dump(cookies, f) &#34;&#34;&#34; 使用 cookies 时从文件进行读取 &#34;&#34;&#34; driver.get(&#34;重新打开一个未登录的窗口&#34;) with open(&#34;cookies.yaml&#34;, encoding=&#34;utf-8&#34;) as f: cookies = yaml.safe_load(f) for cookie in cookies: driver.add_cookie(cookie) SameSite SameSite 是用来限制第三方Cookie的属性，该设置防止CSRF(跨站请求伪造)攻击和用户追踪。
使用限制：
 chrome(80+version) Firefox(79+version) Selenium v4+  属性设置：
 Strict：严格模式，完全禁止携带 cookies 与第三方网站请求一起发送 Lax：宽松模式，允许携带 cookies 与第三方网站 GET 请求一起发送  from selenium import webdriver driver = webdriver.Chrome() driver.get(&#34;http://www.example.com&#34;) # 设置方式 driver.add_cookie({&#34;name&#34;: &#34;foo1&#34;, &#34;value&#34;: &#34;value&#34;, &#39;sameSite&#39;: &#39;Strict&#39;}) driver.add_cookie({&#34;name&#34;: &#34;foo2&#34;, &#34;value&#34;: &#34;value&#34;, &#39;sameSite&#39;: &#39;Lax&#39;}) cookie1 = driver.get_cookie(&#39;foo1&#39;) cookie2 = driver.get_cookie(&#39;foo2&#39;) print(cookie1) print(cookie2) ]]></content></entry><entry><title>Bookmarks - 测开路线参考</title><url>/tech/bookmarks/%E6%B5%8B%E5%BC%80%E8%B7%AF%E7%BA%BF%E5%8F%82%E8%80%83/</url><categories><category>Bookmarks</category></categories><tags><tag>Bookmarks</tag></tags><content type="html"><![CDATA[ 转载自「测试人」论坛。
 我的测试开发成长路线和面试经验 首先，我认为一定要有自己的学习方向，目标是要做到 T 字型人才，保证广度的时候也一定要有一两项专精，这样才能够在面试时候脱颖而出。
分享下我个人的学习路线和面试前重点准备技能：
 pytest-&gt;完善接口自动化框架-&gt;UI自动化框架-&gt;Linuxs三剑客-&gt;计算机网络-&gt;自动化原理-&gt;MySQL-&gt;排序算法-&gt;数据结构-&gt;Python-&gt;Shell 脚本-&gt;Docker-&gt;持续集成/交付-&gt;安全-&gt;测试用例计划思维-&gt;中间件-&gt;socket-&gt;pandas-&gt;前后端框架
 重要是完善接口，UI 自动化测试框架实战技能，这部分是一定要去落地实施的，不然你无法真正接触到业务核心难点。所谓师傅领进门，修行在个人。
pytest 是最流行的 Python 自动化测试框架，需要重点掌握。
UI 自动化测试 除了 PO 思想，简单完成页面封装后。我们要去增加用例，只有用例数足够多时候，你会发现还需要如何在多个 py 文件中管理用例顺序？driver 调度是否合理这一系列问题。也可以去增加相关的日志，报告模块的封装，将部分 JS 处理同步集成到 Basepage 模块中，还有一系列的系统操作，SeleniumGrid 的集成等等。
UI 自动化扩展：增加 log 存储，Allure 报告存储（此处的 Allure 必须要结合趋势图，例如这一次生成报告后，你需要保存 result 中的 history 文件，等下一次生成时，覆盖到 report 中的 histroy 中），seleniumgrid 的执行命令，使用 pytest.ini 进行定制，使用pytest钩子函数定制，使用 pytest-xdist 进行并发用例等）。
对于接口自动化 其实很多时候，企业不仅限于满足只断言接口状态响应码，部分字段等。对于编写速度，稳定性，数据真实性也是有很多的要求。对于速度，我们可以通过 mustache 模板技术生成测试用例，可以通过 Charles 生成的 chls 文件进行部分处理生成 JSON 或者 YAML 文件；对于稳定性，可以通过在设计阶段，生成对应接口正确的 jsonschema 进行对比；对于数据真实性，可以通过 mitmproxy，让流量走特地接口，直接生成线上数据，真实模拟用户操作回放。
接口自动化扩展：（增加 log 存储，Allure 报告存储，异常处理机制，链接数据库，失败用例重跑 pytest-rerunfailures，用例执行控制 pytest-ordering ，重复执行 pytest-repeat，使用 jsonschema 进行断言，通过 charles 文件自动生成 YAML 或 JSON 文件，通过 mitmproxy 进行线上流量回放等）。
对于 Linux 三剑客 （1）匹配 nginx.log 中 404 和 500 有多少行？
# 过滤输出了$9一列 $ cat nginx.log | awk &#39;{print$9}&#39; | grep -E &#39;404|500&#39; | wc -l # 只将$9匹配，输出的仍是完整行 $ awk &#39;$9~/404|500/&#39; nginx.log | wc -l （2）统计 nginx.log中 出现次数最多的 IP
$ cat nginx.log | awk &#39;{print $1}&#39; | sort | uniq -c | sort -rn | head -3 | awk &#39;{print$2}&#39; # sort 排序 sort -n 按数字排序 sort-r 反转 # uniq 去重 uniq -c 去重并统计重复次数 # head -3 头三个 tail -3 尾三个 （3）将 nginx.log 中的 topics 后面的数字替换成 number
$ sed -E &#39;s/topics\/[0-9]*/topics\/number/g&#39; nginx.log # -E 采用正则 &#39;s/old/new/g&#39; 固定替换公式 # [0-9]匹配数字，[0-9]*匹配 0个或者多个数字 # \/ 表示 / 符号，进行转义 （4）将 nginx.log 中的 ip 地址横向打印
$ awk &#39;{print $1}&#39; nginx.log | sed -e &#39;:1;N;s/\n/|/g;t1&#39; # :1 ~ t1 指设置一个标记，若成功，则重复执行 # N指追加前面的IP 例如：216.x.x.x \n 216.x.x.x # s/\n/|/g 指将换行符替换成| 三剑客方面除了常见的一些命令之外，建议熟练掌握正则使用，正则非常强大。
对于计算机网络 （1）网络七层模型，TCP/IP模型
   OSI七层模型 TCP/IP模型 5层结构      应用层 应用层 应用层 TELENT，HTTP,DNS,FTP,SMTP,POP3   表示层      会话层      传输层 传输层 传输层 TCP/UDP   网络层 网络层 网络层 P,ARP,RARP,ICMP,IGMP   数据链路层 网络接口层 数据链路层 以太网，物理网络，LAN/WAN   物理层  物理层     （2）UDP 与 TCP 区别
 TCP 有连接；UDP 无连接（基于无状态传输）； TCP 需要建立三次握手，含有确认、拥塞、重传机制，对系统资源要求多； UDP 不需要一系列复杂认证，速度快；TCP 速度慢； TCP 含有确认机制，数据可靠，有序；UDP 不可靠，无序； TCP 面向字节流（流模式）；UDP 面向报文（数据报模式）；  （3）HTTP 与 HTTPS 区别
 端口：http 80； https 443； 资源：https 需要加解密需要消耗更多 CPU 内存； 安全：https 需要认证证书，http 无法验证身份；  （4）HTTPS 的通信加解密过程，证书为什么更安全
HTTPS 含有证书，CA 证书需层层认证，用上层公钥解开 CA 的 hash 签名获取 hash 值；且与权威机构存储 hash 值对比，判断认证可信；
过程：
 客户端使用 HTTPS 的 URL 访问服务器，要求建立 SSL 连接，发送相关数据及随机数给服务端 服务端收到请求，发送相关数据，随机数，证书信息（含公钥）给客户端 客户端校验证书，生成随机数 pre-master，并用服务器公钥进行加密，发送已加密随机数 pre-master 与客户端证书给服务端 服务端校验证书 客户端，服务端通过对端随机数，已方随机数，pre-master推算出对称密钥 通过对称密钥加密传输  （5）http1.0与https1.1有什么区别
 http1.0为短连接；http1.1请求头携带connetion:keep-alive，建立长链接 http1.0一个连接对应一个请求一个响应；1.1连接过程中可实现多个请求多个响应，且不需等待响应可发送下一个请求 http1.1增加了100状态码，允许客户端向服务端发送请求头待确认后再发送请求体内容，节省了带宽 http1.0认为一个主机拥有唯一IP；http1.1中一个IP对应多个主机，增加了host指明主机名 http1.1增加更多新请求头，错误响应状态码与缓存机制  （6）get和post区别
 GET 请求参数在 URL 中，POST 请求参数放在请求正文中 GET 请求参数有限制（例如浏览器对 URL 长度限制），POST 无限制； GET 请求在回退浏览器时是无害的，POST 则会再次提交表单； GET 请求会被浏览器主动缓存，POST 请求则不会； GET 参数存放在链接中直接保存在浏览器历史记录中，较不安全； GET 大多数用于信息获取，POST 用于信息修改，对服务器安全影响程度不同  （7）session,token,cookies 区别
 Cookie：由服务器生成，保存在客户端中 Session：一般通过Cookie传输，用于区分用户，存储在服务器中（容易占用服务器资源，且服务器故障，负载均衡等容易丢失或请求到其他服务器中） Token：一般通过Cookie传输，将用户数据进行签名（加密），并将签名和用户数据整合成token发送给客户端，客户端携带token请求时，将token中用户数据再次签名，与token中的签名进行对比，一致认为用户已认证登录，不需要存储在服务器中  （8）http三次握手四次挥手过程
认知概念：
 序号：Seq 序号，用来标识从TCP端向目的端发送的字节流 确认号：Ack序号，当ACK标志位为1时，确认号有效，Ack=Seq+1 标志位：URG（紧急指针有效），ACK（确认序号有效），PSH（接受方应尽快把报文交给应用层），RST（重置连接），SYN（发起新连接），FIN（释放链接）  三次握手与四次挥手：
[补充说明：在客户端与服务端传输 TCP 报文中，双方Ack与Seq都在彼此Ack与Seq基础上计算，这样保证了 TCP 报文传输的连贯性，一旦报文丢失，则无法继续握手
四次挥手：
[补充说明：
 与“三次握手”一致，在彼此Seq,Ack上计算，保证TCP连贯性 “三次握手”被动服务器方不需要任何准备 “四次挥手“被动服务器方不能立即释放连接，还有必要数据处理，经过CLOSE-WAIT阶段准备 客户端在最后需等待2MSL，确保客户端收到服务器端FIN，FIN发送后，若2MSL内未收到ACK则再次发送FIN  （9）请求一个网址发生的完整过程
 DNS解析：通过浏览器缓存-&gt;操作系统缓存-&gt;路由器缓存-&gt;DNS缓存（运营商）-&gt;根域名服务器 建立TCP连接，发起三次握手 发送HTTP请求 服务器处理请求 浏览器解析渲染页面：  浏览器读取响应加载 HTML 静态资源加载 动态资源加载   释放TCP连接，四次挥手  （10）常见网络状态响应码
  1XX 指示信息，请求已接受，等待继续处理
  2XX 请求接受
  3XX 重定向
  4XX 客户端错误
  5XX 服务端错误
  301 永久性转移，302 暂时性转移，400 客户端请求有错（安全拦截），401 请求未授权，403 禁止访问，404 资源未找到
  501 服务器内部错误，502 错误网关，503 服务器不可用，504 网关超时
  （11）HTTP 请求，响应结构
 qingqiu921×414 12.2 KB  
 状态888×410 13.5 KB  
对于自动化测试原理 重点掌握
 Selenium 自动化原理 接口 Request 原理 接口 Mitmproxy 代理原理（中间人攻击） Appium 自动化测试原理  对于数据库 MySQL 重点复习 inner join，left join ，right join，union，子查询，order by，group by …having，distinct，事务，索引类型、原理，存储过程，慢 SQL，优化等。
对于排序与数据结构 主要掌握冒泡法，插入排序，选择排序，快排，归并算法，希尔排序等（大部分面试过程，快排是最核心的，其余排序掌握两三种即可）。
个人学习题目： https://github.com/testQx/math 289  
主要掌握顺序表，链表（单向，双向，循环等），栈，队列，树
对于算法，除上方的数据结构外，还需掌握 hash 散列表，动态规划等，建议刷 LeetCode 初中级题目，刷一百题左右足够了。
对于 Python 学习  深浅拷贝 各数据结构特点、区别 垃圾回收机制 Python 缓冲池 装饰器原理与实现 线程，进程，协程区别、实现 迭代器与生成器等  对于 Shell 脚本 Shell 语法编写规则：
 同一个 shell 中编写函数 a，function a() ，不需要事先定义有多少个变量，需要调用函数时，直接传参 a 123，则此&quot;123&quot; 想要在 function a 中体现时，则 echo $1，参数由1开始计数，调用函数返回值，则在执行完函数时，echo $? 则输出上一个运算的返回值。
 编写循环语句：
 while xxx; do xxxxx done 结构 for i in {0…9};do xxx done 或者 for i in((i=1;i&lt;=j;i++)) 编写条件判断语句； if [ “xxx” = “xxx” ]; then xxxxx fi 注意中间各个空格必须隔开 多重判断： if [ “xxxx” = “xxxxx” ];then xxxxx else if [ “xxxx” = “xxxx” ];then else xxxxx fi 判断条件逻辑符号：&amp;&amp; 与，|| 或，！非 ； 判断条件数值大小符号： -eq 等于，-ne 不相等， -gt 大于， -ge 大于等于，-lt 小于，-le 小于等于； 跟踪 shell 执行：sh +x xxxx.sh (会将可能输出的结果进行打印)； a=‘123’ 想要输出a的变量 尽量使用${a} 而不是$a ，避免拼接变量时搞错值 $( )与等同，执行里面的程序命令 执行一串命令，可用()和{} 当使用（xxxx;xxx）中间使用;隔开使用{xxx;xxxx;}，中间、尾部必须使用;隔开，且第一个命令前必须有空格； $(( )) 表示进行整数计算； 条件语句中表示匹配中括号的字符，[!..]表示不匹配中括号的字符； =代表赋值，==代表判断；  对于 Docker 重点复习学院课程的 dockerfile，docker 网络模式，dockercompose，docker 文件管理系统等。
对于持续集成/交付 这部分主要复习学院课程相关视频即可，掌握 Jenkins 的构建，插件，Maven 打包等。
对于安全  命令注入：只用;拼接 shell 命令； SQL注入：使用 OR 类似拼接引号达到绕过; XSS漏洞：注入 HTML 闭合 JS 这些 &gt;&lt;script&gt;&lt;/script&gt; CSRF漏洞：伪造请求，将链接发给已登录的浏览器，点击时自动触发更改；利用 URL，图片这些点击； 使用 zap、appcran 等工具扫描，zap 可集成到 Jenkins 中，也可以通过调用 API 实现自身特殊的安全扫描；  对于测试思维 面试时候大部分会询问你以往工作经验中某一个模块功能，让你说出你是如何设计测试计划（此处需重点查看，面试官非常喜欢问）和测试用例。
例如从点线面出发编写功能性用例，UI层用例，兼容性用例，安全性用例，性能用例，接口用例等。
对于中间件 这部分个人也仍在探索，需要多看一下 Kafka，Zookeeper，Redis，mq 原理，相关消费机制，优化机制等（面试测试开发是很好的一个加分项）；
对于 Socket 如何简单建立一个服务端与客户端的通讯等等；
对于 pandas 通过 Python 进行数据分析，后续课程中也有涉及，这部分为扩展加分项；
对于前后端框架 学院的测试开发后续课程中也有涉及，这部分为扩展加分项；
面试测试开发的时候，大家也不需要太紧张，除了以往的测试经验外，更多会考察你对开发方面的理解，对语言的熟悉程度，以及你站在测试开发方向，对软件测试和质量保障全局的一个理解。
另，Python 开发进阶，个人比较推荐《流畅的 Python》这一本书。
最后，再次感谢学院各位老师尤其是思寒大佬的指导，祝学院越办越好，也祝大家都学有所成，找到心仪的工作~~
]]></content></entry><entry><title>Selenium - 执行Js脚本</title><url>/tech/selenium/%E5%9F%BA%E7%A1%808%E6%89%A7%E8%A1%8Cjs%E8%84%9A%E6%9C%AC/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[ 在当前窗口或框架上下文中，执行 JavaScript 脚本。
 使用JavaScript操作页面：
 解决点击不生效的问题 页面滚动 修改元素属性  JavaScript // 进入浏览器 -&gt; 检查 -&gt; console // 获取网页名称 document.title // 显示 alert window.alert(&#34;hello selenium&#34;) // 获取网页的性能数据 JSON.stringify(performance.timing) Selenium 调用 def execute_script(self, script, *args): # script: JavaScript 代码 # args: 任何适用于 JavaScript 的参数 ... # 示例：返回 h1 标签元素的文本 driver.get(&#34;https://www.selenium.dev/&#34;) header = driver.find_element(By.CSS_SELECTOR, &#34;h1&#34;) # return: 返回 js 执行结果 # arguments: 参数传递 text = driver.execute_script(&#39;return arguments[0].innerText&#39;, header) assert text == &#34;Selenium automates browsers. That&#39;s it!&#34; # 示例：通过 js 打开一个新窗口 driver.execute_script(&#39;window.open(&#34;https://www.baidu.com&#34;);&#39;) 定位元素 js = &#39;return document.getElementById(&#34;su&#34;)&#39; driver.execute_script(js) 滑动 常见的滑动场景分为四种：
 滑动至底部 滑动至顶部 滑动至具体位置 滑动至目标元素可见  # 模拟鼠标滚轮，滑动页面至底部 js = &#34;window.scrollTo(0, document.body.scrollHeight)&#34; driver.execute_script(js) # 模拟鼠标滚轮，滑动页面至顶部 js = &#34;window.scrollTo(0, 0)&#34; driver.execute_script(js) js = &#34;window.scrollBy(0, 500)&#34; # 向下滑动500个像素 js = &#34;window.scrollBy(0, -500)&#34;　# 向上滚动500个像素 js = &#34;window.scrollBy(500, 0)&#34; # 向右滑动500个像素 js = &#34;window.scrollBy(-500, 0)&#34;　# 向左滚动500个像素 # 滑动到具体位置 driver.execute_script(&#34;window.scrollTo(x, y)&#34;) # 向下滚动至-元素可见 driver.execute_script(&#34;arguments[0].scrollIntoView();&#34;, element) # 向上滚动至-元素可见 driver.execute_script(&#34;arguments[0].scrollIntoView(false);&#34;, element) 示例：操作控件 &amp; 获取返回值 # 场景：百度搜索结果页，滑动到页面底部，点击下一页 &#34;&#34;&#34; 1. 进入搜索结果页 &#34;&#34;&#34; driver.get(&#34;http://www.baidu.com&#34;) driver.find_element_by_id(&#34;kw&#34;).send_keys(&#34;selenium&#34;) ele_search = driver.execute_script(&#39;return document.getElementById(&#34;su&#34;)&#39;) ele_search.click() &#34;&#34;&#34; 2. 通过 JavaScript 滑动到页面底部 &#34;&#34;&#34; js_code = &#34;document.documentElement.scrollTop=10000&#34; driver.execute_script(js_code) sleep(2) driver.find_element_by_css_selector(&#34;#page a:nth-last-child(1)&#34;).click() &#34;&#34;&#34; 3. 断言页面跳转，打印页面标题和页面性能数据 &#34;&#34;&#34; # 方法一: 多条 js 脚本分别执行 js_codes = [ &#34;return document.title&#34;, &#34;return JSON.stringify(performance.timing)&#34; ] for code in js_codes: print(self.driver.execute_script(code)) # 方法二 合并执行 # 注意，在 title 处已经返回，后续不会执行 js_code = &#34;return document.title;return JSON.stringify(performance.timing)&#34; title = self.driver.execute_script(js_code) assert title == &#34;selenium_百度搜索&#34; # 会打印 timing ，因为 title 未返回 js_code = &#34;document.title;return JSON.stringify(performance.timing)&#34; print(self.driver.execute_script(js_code)) 示例：修改控件属性 &#34;&#34;&#34; 时间控件属性为 readonly 手动测试时：手动去选择对应的时间 自动化测试时：使用 js 修改控件属性 - 要取消日志的 readonly 属性 - 给 value 赋值 场景：12306 网站内修改出发日期 &#34;&#34;&#34; &#34;&#34;&#34; 1. 打开 12306 &#34;&#34;&#34; driver.get(&#34;https://www.12306.cn/index/&#34;) &#34;&#34;&#34; 2. 修改出发日期为 2021-5-12 &#34;&#34;&#34; driver.execute_script( &#39;train_date=document.getElementById(&#34;train_date&#34;);&#39; &#39;train_date.removeAttribute(&#34;readonly&#34;);&#39; &#39;train_date.value = &#34;2021-05-12&#34;&#39; ) &#34;&#34;&#34; 3. 打印出发日期 &#34;&#34;&#34; print(driver.execute_script( &#39;return document.getElementById(&#34;train_date&#34;).value&#39;) ) driver.quit() ]]></content></entry><entry><title>Selenium - 动作接口</title><url>/tech/selenium/%E5%9F%BA%E7%A1%807%E5%8A%A8%E4%BD%9C%E6%8E%A5%E5%8F%A3actionchains/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[ 用于向 Web 浏览器提供虚拟化输入操作的低级接口。
 键盘输入 鼠标输入 笔或触摸设备的指针输入 滚轮输入（v4.2+）   实现动作交互依赖ActionChains库，是对更底层动作类ActionBuilder的封装。
当调用ActionChains操作方法时，操作事件被存储在ActionChains对象的队列中。在调用perform()时，将按照操作事件的顺序一个接一个触发执行。
暂停（Pause） 鼠标操作链中设置等待时间。
clickable = driver.find_element(By.ID, &#34;clickable&#34;) ActionChains(driver) .move_to_element(clickable) .pause(1) .click_and_hold() .pause(1) .send_keys(&#34;abc&#34;) .perform() 释放（Clear） 当已经生成了动作链但是没有进行perform操作，即使后面创建了新的动作类实例，鼠标依然处于先前的状态，所以需要释放已经生成但没有执行的动作链。
from selenium.webdriver.common.actions.action_builder import ActionBuilder # 释放所有 actions ActionBuilder(driver).clear_actions() 鼠标（Mouse） 点击 # 鼠标左键并按住不放 ActionChains(driver)\ .click_and_hold(clickable)\ .perform() # 鼠标左键 clickable = driver.find_element(By.ID, &#34;click&#34;) ActionChains(driver)\ .click(clickable)\ .perform() # 鼠标右键 clickable = driver.find_element(By.ID, &#34;clickable&#34;) ActionChains(driver)\ .context_click(clickable)\ .perform() # 鼠标左键双击 clickable = driver.find_element(By.ID, &#34;clickable&#34;) ActionChains(driver)\ .double_click(clickable)\ .perform() &#34;&#34;&#34; 鼠标键 部分鼠标无按键不支持，经测试 Mac 与罗技无线鼠标均可 &#34;&#34;&#34; # 鼠标后退键（v4.2+） action = ActionBuilder(driver) action.pointer_action.pointer_down(MouseButton.BACK) action.pointer_action.pointer_up(MouseButton.BACK) action.perform() # 鼠标前进键（v4.2+） action = ActionBuilder(driver) action.pointer_action.pointer_down(MouseButton.FORWARD) action.pointer_action.pointer_up(MouseButton.FORWARD) action.perform() 移动 # 将鼠标移动到元素的中心点 hoverable = driver.find_element(By.ID, &#34;hover&#34;) ActionChains(driver)\ .move_to_element(hoverable)\ .perform() &#34;&#34;&#34; 按偏移量移动 offset(13, 15) 向右移动 13，向下移动 15 offset（-15, -20） 向左移动 15，向上移动 20 &#34;&#34;&#34; # 从元素偏移（左上原点） mouse_tracker = driver.find_element(By.ID, &#34;mouse-tracker&#34;) ActionChains(driver)\ .move_to_element_with_offset(mouse_tracker, 8, 0)\ .perform() # 从元素偏移（中心原点） action = ActionBuilder(driver) action.pointer_action.move_to_location(8, 0) action.perform() # 基于当前指针位置的偏移量 ActionChains(driver)\ .move_by_offset( 13, 15)\ .perform() 拖放 # 点击并按住 A 元素，移动到 B 元素，释放鼠标 draggable = driver.find_element(By.ID, &#34;draggable&#34;) droppable = driver.find_element(By.ID, &#34;droppable&#34;) ActionChains(driver)\ .drag_and_drop(draggable, droppable)\ .perform() # 点击并按住 A 元素，移动到给定的偏移量，释放鼠标 draggable = driver.find_element(By.ID, &#34;draggable&#34;) start = draggable.location finish = driver.find_element(By.ID, &#34;droppable&#34;).location ActionChains(driver)\ .drag_and_drop_by_offset(draggable, finish[&#39;x&#39;] - start[&#39;x&#39;], finish[&#39;y&#39;] - start[&#39;y&#39;])\ .perform() 键盘（Keyboard） Key 模拟键盘上的键操作。
from selenium.webdriver import Keys &#34;&#34;&#34; The Keys implementation. &#34;&#34;&#34; 按下键 from selenium.webdriver import Keys, ActionChains from selenium.webdriver.common.by import By # 按下 shift 键不放，输入字母，得到大写字母 ActionChains(driver)\ .key_down(Keys.SHIFT)\ .send_keys(&#34;abc&#34;)\ .perform() 抬起键 # 按下 shift 输入大写 A # 松开 shift 输入小写 b ActionChains(driver)\ .key_down(Keys.SHIFT)\ .send_keys(&#34;a&#34;)\ .key_up(Keys.SHIFT)\ .send_keys(&#34;b&#34;)\ .perform() 输入字符 # 基于当前元素 ActionChains(driver)\ .send_keys(&#34;abc&#34;)\ .perform() 向指定元素输入字符 text_input = driver.find_element(By.ID, &#34;textInput&#34;) ActionChains(driver)\ .send_keys_to_element(text_input, &#34;abc&#34;)\ .perform() 复制粘贴 cmd_ctrl = Keys.COMMAND if sys.platform == &#39;darwin&#39; else Keys.CONTROL &#34;&#34;&#34; 官方文档通过 firefox_driver 执行 &#34;&#34;&#34; ActionChains(driver)\ .send_keys(&#34;Selenium!&#34;)\ .send_keys(Keys.ARROW_LEFT)\ .key_down(Keys.SHIFT)\ .send_keys(Keys.ARROW_UP)\ .key_up(Keys.SHIFT)\ .key_down(cmd_ctrl)\ .send_keys(&#34;xvv&#34;)\ .key_up(cmd_ctrl)\ .perform() &#34;&#34;&#34; chrome 通过下面的方法实现 &#34;&#34;&#34; ele = driver.find_element(value=&#34;textInput&#34;) ele.send_keys(&#39;Selenium!&#39;) ele.send_keys(cmd_ctrl, &#39;a&#39;) time.sleep(2) # 键盘的复制操作 ele.send_keys(cmd_ctrl, &#39;c&#39;) time.sleep(2) # 键盘的剪切操作 ele.send_keys(cmd_ctrl, &#39;x&#39;) time.sleep(2) # 键盘的粘贴操作 ele.send_keys(cmd_ctrl, &#39;v&#39;) time.sleep(2) # 键盘的删除操作 ele.send_keys(cmd_ctrl, &#39;a&#39;) ele.send_keys(Keys.BACKSPACE) 笔（Pen）  仅支持 chromium；v4.2+
 笔是一种指针输入，具有与鼠标基本相同的行为，但也可以具有手写笔独有的事件属性。此外，鼠标有5个按钮，而笔有3个等效的按钮状态：
 0：触摸（默认，相当于左键单击） 2：筒状按钮（相当于右键单击） 5：橡皮擦按钮（目前不支持）  driver.get(&#39;https://www.selenium.dev/selenium/web/pointerActionsPage.html&#39;) pointer_area = driver.find_element(By.ID, &#34;pointerArea&#34;) pen_input = PointerInput(POINTER_PEN, &#34;default pen&#34;) action = ActionBuilder(driver, mouse=pen_input) # 使用笔 action.pointer_action\ .move_to(pointer_area)\ .pointer_down()\ .move_by(2, 2)\ .pointer_up() action.perform() # 添加指针事件属性 action.pointer_action\ .move_to(pointer_area)\ .pointer_down()\ .move_by(2, 2, tilt_x=-72, tilt_y=9, twist=86)\ .pointer_up(0) action.perform() 滚轮（Wheel） 滚动到元素 一直滚动，直到指定元素出现在屏幕中。
iframe = driver.find_element(By.TAG_NAME, &#34;iframe&#34;) ActionChains(driver)\ .scroll_to_element(iframe)\ .perform() 按指定偏移量滚动 # 传入一个 delta x 和 delta y 值，表示向右和向下滚动的量。负值分别代表左和上。 footer = driver.find_element(By.TAG_NAME, &#34;footer&#34;) # rect 具有元素位置和大小的字典，取元素的 y 值 # {&#39;height&#39;: 23, &#39;width&#39;: 1169, &#39;x&#39;: 8, &#39;y&#39;: 5217.5} delta_y = int(footer.rect[&#39;y&#39;]) ActionChains(driver)\ .scroll_by_amount(0, delta_y)\ .perform() 基于元素向指定偏移量滚动 &#34;&#34;&#34; 第一个表示起始点，我们将其指定为元素，后两个是 delta x 和 delta y 值。 如果元素在可见窗口之外，它将滚动到屏幕底部，然后页面将根据提供的 delta x 和 delta y 值滚动。 &#34;&#34;&#34; iframe = driver.find_element(By.TAG_NAME, &#34;iframe&#34;) scroll_origin = ScrollOrigin.from_element(iframe) ActionChains(driver)\ .scroll_from_origin(scroll_origin, 0, 200)\ .perform() 基于元素的偏移量向指定偏移量滚动 footer = driver.find_element(By.TAG_NAME, &#34;footer&#34;) scroll_origin = ScrollOrigin.from_element(footer, 0, -50) ActionChains(driver)\ .scroll_from_origin(scroll_origin, 0, 200)\ .perform() 基于原点的偏移量向指定偏移量滚动 scroll_origin = ScrollOrigin.from_viewport(10, 10) ActionChains(driver)\ .scroll_from_origin(scroll_origin, 0, 200)\ .perform()  如果是 4.0.0+ 的版本，不支持TouchActions，模拟鼠标操作的建议使用 ActionChains 如果还是要使用 TouchActions 的话 建议降低 selenium 版本 $ pip install selenium==3.141.0
 TouchAction 动作链接（4.0+ 不支持）  可以针对 PC、移动端 H5 进行模拟鼠标、键盘操作 手势控制  tap：在指定元素上敲击 double_tap：在指定元素上双击 tap_and_hold：在指定元素上点击但不释放 move：手势移动到指定偏移（不释放） release：释放手势 scroll：手势点击并滚动 scroll_from_element：从某个元素开始手势点击并滚动（向下滑动为负数，向上滑动为正数） long_press：长按元素 flick：手势滑动 flick_element：从某个元素开始手势滑动（向上滑动为负数，向下滑动为正数） perform：执行    &#34;&#34;&#34; @Time : 2021/5/8 11:37 下午 @Author : lan @Mail : lanzy.nice@gmail.com @Desc : 如果是 4.0.0+ 的版本 模拟鼠标操作的建议使用 ActionChains 如果还是要使用 TouchActions 的话 建议降低 selenium 版本 $ pip install selenium==3.141.0 &#34;&#34;&#34; from time import sleep from selenium import webdriver from selenium.webdriver import TouchActions from selenium.webdriver.common.by import By class TestTouchAction: def setup_class(self): # 滑动操作会报如下错误 # selenium.common.exceptions.WebDriverException: Message: unknown command:  # Cannot call non W3C standard command while in W3C mode # 添加 w3c=False 后解决 option = webdriver.ChromeOptions() option.add_experimental_option(&#34;w3c&#34;, False) self.driver = webdriver.Chrome(options=option) self.driver.maximize_window() self.driver.implicitly_wait(5) self.action = TouchActions(self.driver) def teardown_class(self): sleep(2) self.driver.quit() def test_touch_action(self): &#34;&#34;&#34;百度搜索后滑动到最底部&#34;&#34;&#34; self.driver.get(&#34;http://www.baidu.com&#34;) ele_box = self.driver.find_element(By.ID, &#34;kw&#34;) ele_btn = self.driver.find_element(By.ID, &#34;su&#34;) ele_box.send_keys(&#34;selenium 测试&#34;) self.action.tap(ele_btn).perform() # 如果不重新获取 输入框元素就会报错，原因是页面已经刷新过，之前的元素不能重用 # Message: stale element reference: element is not attached to the page document ele_box = self.driver.find_element(By.ID, &#34;kw&#34;) self.action.scroll_from_element(ele_box, 0, 2000).perform() # 继续点击「下一页」 ele_next = self.driver.find_element(By.XPATH, &#34;//*[@class=&#39;n&#39;]&#34;) ele_next.click() ]]></content></entry><entry><title>Selenium - 页面弹框Alert操作</title><url>/tech/selenium/%E5%9F%BA%E7%A1%806%E9%A1%B5%E9%9D%A2%E5%BC%B9%E6%A1%86alert%E6%93%8D%E4%BD%9C/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[ Selenium 页面消息框处理2
 alert：警告消息框 confirm：确认消息框 prompt：提示消息对话框  还有一种是页面弹框，类似百度登录，这种可以直接定位到，此处忽略。
 操作 alert 的方法
# 获取当前页面上的警告框 alert = switch_to.alert() alert.text # 返回文本信息 alert.accept() # 确定 alert.dismiss() # 取消 alert.send_keys(&#34;hello&#34;) # 输入文本 1. alert  alert()方法用于显示带有一条指定消息和一个 确认 按钮的警告框。
 示例
&#34;&#34;&#34; 1. 切换到 iframe 内，点击按钮，弹出弹窗 2. 弹窗内点击确定或取消 3. 退出 alert，返回初始页面 &#34;&#34;&#34; driver.get(&#34;https://www.runoob.com/try/try.php?filename=tryjs_alert&#34;) driver.switch_to.frame(&#34;iframeResult&#34;) driver.find_element(By.XPATH, &#39;//*[@value=&#34;显示警告框&#34;]&#39;).click() # 切换到 alert 弹框内 alert = driver.switch_to.alert alert.accept() # 点击确定 # 退出弹框界面 driver.switch_to.default_content() assert driver.find_element(By.ID, &#34;submitBTN&#34;).text == &#34;点击运行 》&#34; 2. confirm  confirm()方法用于显示一个带有指定消息和确认及取消按钮的对话框。
如果访问者点击&quot;确定&quot;，此方法返回 true，否则返回 false。
 根据点击按钮不同，页面展示会有不同。
&#34;&#34;&#34; 1. 切换到 iframe 内，点击按钮，弹出弹窗 2. 弹窗内分别点击 确定/取消 3. 验证页面展示文本为：你按下了&#34;确定/取消&#34;按钮! &#34;&#34;&#34; driver.get(&#34;https://www.runoob.com/try/try.php?filename=tryjs_confirm&#34;) driver.switch_to.frame(&#34;iframeResult&#34;) # 切换到 alert 弹框内，点击「确定」，断言文案 driver.find_element(By.XPATH, &#34;//body/button&#34;).click() # 点我 alert = driver.switch_to.alert alert.accept() # 点击确定 assert driver.find_element(By.ID, &#34;demo&#34;).text == &#39;你按下了&#34;确定&#34;按钮!&#39; # 切换到 alert 弹框内，点击「取消」，断言文案 driver.find_element(By.XPATH, &#34;//body/button&#34;).click() # 点我 alert = driver.switch_to.alert alert.dismiss() # 点击取消 assert driver.find_element(By.ID, &#34;demo&#34;).text == &#39;你按下了&#34;取消&#34;按钮!&#39; 3. prompt  prompt()方法用于显示可提示用户进行输入的对话框。
这个方法返回用户输入的字符串。
 支持用户在弹框内输入文本，用于后续处理。
&#34;&#34;&#34; 1. 切换到 iframe 内，点击按钮，弹出弹窗 2. 弹窗内点击取消，验证获取文本为空，文本展示元素不存在 3. 弹窗内输入文本点击确定，验证文本展示与输入一致 &#34;&#34;&#34; driver.get(&#34;https://www.runoob.com/try/try.php?filename=tryjs_prompt&#34;) # 1. 切换到 iframe 内，点击按钮，弹出弹窗 self.driver.switch_to.frame(&#34;iframeResult&#34;) self.driver.find_element(By.XPATH, &#34;//body/button&#34;).click() # 2. 弹窗内点击取消，验证获取文本为空，文本展示元素不存在 alert = self.driver.switch_to.alert alert.dismiss() assert self.driver.find_element(By.ID, &#34;demo&#34;).is_selected() is False # 3. 弹窗内输入文本点击确定，验证文本展示与输入一致 self.driver.find_element(By.XPATH, &#34;//body/button&#34;).click() alert = self.driver.switch_to.alert assert alert.text == &#34;请输入你的名字&#34; alert.send_keys(&#34;father&#34;) alert.accept() assert &#34;father&#34; in self.driver.find_element(By.ID, &#34;demo&#34;).text ]]></content></entry><entry><title>Selenium - 多Frame定位</title><url>/tech/selenium/%E5%9F%BA%E7%A1%804%E5%A4%9Aframe%E5%AE%9A%E4%BD%8D/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[frame 简介 frame 是 html 中的框架导航。同一个框架集中，点击某一框架的超链接，内容会在另一个框架的窗口中展示。
比如后台管理页面，点击左侧导航栏按钮，在右侧区域展示加载的内容，而不是打开一个新的窗口。
代码如下，可访问在线 html 运行网站编辑查看。a
&lt;!-- https://www.w3school.com.cn/tiy/t.asp?f=html_frame_cols --&gt; &lt;html&gt; &lt;frameset rows=&#34;15%,*&#34;&gt; &lt;frame src=&#34;/example/html/frame_a.html&#34;&gt; &lt;frameset cols=&#34;20%,*&#34;&gt; &lt;frame src=&#34;/example/html/frame_b.html&#34;&gt; &lt;frame src=&#34;/example/html/frame_c.html&#34; name=&#34;show&#34;&gt; &lt;/frameset&gt; &lt;/frameset&gt; &lt;/html&gt; 在左侧导航栏页面添加 href 标签和 traget 属性，即可实现页面框架跳转。
&lt;!-- 1、定义框架集中每个框架的名称 --&gt; &lt;frame src=&#34;/example/html/frame_c.html&#34; name=&#34;show&#34;&gt; &lt;!-- 2、左侧导航栏页面内添加 target 属性 --&gt; &lt;a href=url target=&#34;show&#34;&gt; fram 定位 frame标签包含三种：
 frameset和普通的标签定位方式一致，通过id、name等常规方式； frame与iframe则需要切换进入frame内，才能进行定位。  在web自动化中，如果某个元素定位不到，则很有可能是隐藏在frame中。
多 frame 切换 切换 frame 方式如下。
# 通过 id 切换 driver.switch_to.frame(&#39;buttonframe&#39;) # 通过 web element 切换 iframe = driver.find_element(By.CSS_SELECTOR, &#34;#modal &gt; iframe&#34;) driver.switch_to.frame(iframe) # 多元素通过 index 切换 iframe = driver.find_elements(By.TAG_NAME,&#39;iframe&#39;)[1] driver.switch_to.frame(iframe) # 回到默认 frame driver.switch_to.default_content() # 切换到父 frame driver.switch_to.parent_frame() 对于嵌套的 frame，需要先进入到父节点，再切换进入子节点，然后对子节点进行操作。
driver.switch_to.frame(&#34;父节点&#34;) driver.switch_to.frame(&#34;子节点&#34;) 示例
with webdriver.Chrome() as driver: driver.get(&#34;https://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#34;) btn_locator = (By.ID, &#34;draggable&#34;) # 该元素是「请拖拽我」，运行报错：NoSuchElementException # 因为该元素在 iframe 标签内，直接无法定位到元素 # driver.find_element(*btn_locator).text) driver.switch_to.frame(&#34;iframeResult&#34;) # 切换到 iframe 内 assert driver.find_element(*btn_locator).text == &#34;请拖拽我！&#34; submit_locator = (By.ID, &#34;submitBTN&#34;) # 点击提交按钮，运行报错：NoSuchElementException # 因为提交按钮在当前 iframe 外，还需要切出去 # driver.find_element(*submit_locator).click() driver.switch_to.parent_frame() # 切回父 frame assert driver.find_element(*submit_locator).text == &#34;点击运行 》&#34; ]]></content></entry><entry><title>随笔 - 面试题整理</title><url>/tech/%E9%9A%8F%E7%AC%94/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html"><![CDATA[接口测试 做接口测试的过程中发现过哪些 bug?   前端公共参数拼接错误，导致功能未生效；
  充值活动赠券，产品需求赠送固定金额，修改充值金额依然可以获取赠送数量
  平常你是怎么测试接口的？  通能测试同时抓包，验证功能跟接口返回值 功能基本通过后，修改参数进行不同组合验证 最后添加到测试脚本内，线上监控  平常用什么工具测接口?   charles：配合功能测试
  postman：方便快速测试、调试
  mitmproxy：复杂场景测试，比如：统计广告请求各方比例、配合UI自动化数据mock等
  webService 接口是如何测试的?  restful 非 restful  没有接口文档，如何做接口测试？  根据需求，验证功能 抓包请求，验证参数 跟开发人员核对并记录参数  在手工接口测试或者自动化接口测试的过程中，上下游接口有数据依赖如何处理？  手工记录 实现 api 的功能调用，返回数据 数据保存起来供使用，可以存入配置文件、环境变量或者实例变量等  依赖于第三方数据的接口如何进行测试？  对方是否提供测试支持 mock 数据（可以自己抓或对方提供接口文档）  mock 经典场景就是广告测试，用于模拟不同类型的广告物料和打点
当一个接口出现异常时候，你是如何分析异常的？  接口请求异常  分析状态码 定位前后端   接口业务异常  分析错误码 校验参数正确性    如何模拟弱网测试 charles Throttle Settings
如何分析一个 bug 是前端还是后端的？  抓包查看接口返回数据 验证前端请求头、传参是否正确 接口数据符合预期，前端展示错误，前端问题； 接口数据不符合预期，前端与接口数据展示一致，后端问题。  浏览器输入网址到打开网页，整个过程发生了什么？ “打开一个网页发生了什么”，是一个经典的不能再经典的面试题。在技术面这一关卡中，不论是校招，还是社招，是必考的一道题。
那这道看似平平无奇的题目，为什么会成为一道必考题呢？其实是因为，如果要答好这道题，必须掌握以下这些知识点才能答得精彩漂亮：
 DNS 解析过程。 Nginx 负载均衡。 网络协议之 TCP 与 HTTP 协议。 前端渲染过程。  这就是打开一个网页过程涉及到的基本流程，如果做进一步细化的话，甚至可以涉及到 微服务、中间件、消息队列、数据库等知识。
从上面这些涉及到的知识体系，就可以看出，这道题考察的难度远远不像它的标题那样简单。
答案解析
关于这一问题，很多同学应该会如此回答：
 在浏览器输入网址，按下回车 跳转并加载相关页面 展示页面信息  如果我们作为一个普通的互联网用户，如此回答其实也是正确的。但是如果是一个计算机学院相关的学生，或者是计算机相关的从业人员，如此回答便显得不够专业了。
首先我们需要了解到，这道题的整体流程主要分为以下几个大阶段：
 浏览器阶段（DNS 解析） 网络请求阶段 前端渲染阶段  其中，每个阶段又可以细化出多个步骤。
1、浏览器阶段（DNS 解析）
在浏览器输入网址阶段，其实主要考察的是我们对于 DNS 解析过程的理解。首先先看下面这张图片
总结一下，在 DNS 解析过程中，流程应该为:
  浏览器是否存在对应的缓存记录，如果没有话，则继续后面的步骤。
  hosts 文件和操作系统是否存在对应的缓存记录，如果没有话，则继续后面的步骤。
  向域名解析服务器查找是否存在对应的记录，如果没有话，则域名解析错误，浏览器提示如下所示：
   如果请求过程中，在任何一个环境找到对应的记录，则会返回服务器对应的 ip 地址，进入网络请求阶段。  2、网络请求阶段
在整个网络请求阶段，流程就更加的复杂了，具体步骤如下：
  是否有在 Nginx 配置负载均衡，如果有的话，则上一步 DNS 解析过程中获取到的 ip 地址为 Nginx 代理服务器的地址。然后在访问过程中，Nginx 根据我们设定的分配算法和规则，选择一台后端的真实 Web 服务器；如果没有配置的话，就直接访问对应的Web服务器。
  TCP 三次握手建立连接。
  查看请求信息是否加密，即是否使用的是HTTPS的协议。如果使用HTTPS的协议，那么就握手建立安全连接后再发起请求，如果没有，则直接发起请求。
  Web服务器收到请求后产生对应的响应信息。
  同样如果有在 Nginx 配置负载均衡。那么Web服务器收到请求后，产生响应，并将网页发送给Nginx负载均衡服务器。然后Nginx再将原本的响应数据返回给浏览器（客户端）；如果没有配置的话，则直接将原本的响应数据返回给浏览器（客户端）
  3、前端渲染阶段
最后，涉及到展示页面信息：
 解析 HTML，然后构建 DOM 树。 加载样式之后，解析样式，构建样式规则树。 加载 javascript 之后，执行 javascript 代码。 将 DOM 树和样式规则树（CSS Rule Tree）匹配构建渲染树（Render Tree）。 计算元素位置进行布局。 绘制页面。 显示页面。  从这个过程中我们可以看到，一些肉眼看到的过程在短短的数秒内，其实有一个非常复杂的逻辑处理过程。
如果想要回答好这道题，一定要对这三大阶段的过程倒背如流。
 浏览器阶段（DNS 解析） 网络请求阶段 前端渲染阶段  接口自动化面试题 json 和字典的区别？  json 是一种数据格式对象，格式上会有限制，比如键值必须使用双引号 字典是一种数据类型 json任意key存在默认值 undifined，字典不存在 json 空值是 null，字典是 None  测试的数据你放在哪？  yaml 文件 py 文件  什么是数据驱动，如何参数化？  框架数据驱动：通过向测试引擎内填充数据，完成测试；类似 hrun 用例数据驱动：通过 pytest.mark.parametrize填充数据完成参数化  下个接口请求参数依赖上个接口的返回数据 同上 6 题
依赖于登录的接口如何处理  封装 login fixture，需要登录的接口直接调用 测试开始前进行登录，获取 token 存入 fixture 或全局变量或测试文件内  依赖第三方的接口如何处理  对方测试环境 数据 mock  不可逆的操作，如何处理，比如删除一个订单这种接口如何测试  构造数据 删除数据  还需要考虑：
 删除不存在的 重复删除 删除其他用户的订单号 删除空订单号  接口产生的垃圾数据如何清理  在用例开始前初始化数据 在 teardown 中还原测试过程中的垃圾数据 直接操作数据库（一般不允许）  一个订单的几种状态如何全部测到  下单未支付  再次支付 取消订单   下单已支付 下单已完成 下单后退款  退款成功 退款失败    python 如何连接数据库操作？  pymysql pyAcheme  运行出报告、代码管理（git）、运行策略和持续集成 jenkins 相关  allure 报告 git 代码管理 每日定时执行，发送报告邮件 jenkins pipline 持续集成  selenium 面试题 如何判断一个页面上元素是否存在？  is_abled is_exist  如何提高脚本的稳定性  显式等待 异常处理 元素定位表达式精准  如何定位动态元素  通过 xpath 标签定位 用字符串包含模式，模糊匹配 用字符串开头匹配，模糊匹配 用字符串结尾匹配，模糊匹配  如何通过子元素定位父元素 xpath 定位，.. 表示上级目录
如果截取某一个元素的图片，不要截取全部图片 ele.screenshot(&quot;../demo.img&quot;)
平常遇到过哪些问题?如何解决的 一个元素明明定位到了，点击无效（也没报错），如果解决？  是否切换 frame 查看元素属性是否可点击  app 测试面试题 1.什么是 activity?
2.Activity 生命周期?
3.Android 四大组件?
4.app 测试和 web 测试有什么区别？
5.android 和 ios 测试区别？
6.app 出现 ANR，是什么原因导致的？
7.App 出现 crash 原因有哪些？
8.app 对于不稳定偶然出现 anr 和 crash 时候你是怎么处理的？
9.app 的日志如何抓取?
10.你平常会看日志吗, 一般会出现哪些异常（Exception）?
转载：小米一面 小米一面
 自我介绍 Python全局变量怎么玩的 Python浅拷贝和深拷贝的区别 list和tuple的区别, 我怎么给一个数组去重？ 用过哪些测试工具？用过Python unittest？讲讲怎么用的，setUp和teardown是干啥的 Python内存机制 都用过Python装饰器干什么 tcp三次握手讲一讲 tcp和udp的区别讲一下 讲讲常见的数据结构，怎么链表里面怎么插入一个节点？ 你认为测开是干嘛的 编程题1：找出n个数中最小的k个值，升序打印 编程题2：有m盏灯，第一次操作是1的倍数的灯，第二次操作是2的倍数的灯，第三次操作是3的倍数的灯。。。第n次后剩几盏灯是亮着的？  **额外题目 **
下面这两个return语句有什么区别?（已知a的类型为list，b为任意类型的对象）
def function(a, b): return a.append([b]) def fucntion(a, b): return a += [b] 面试官小姐姐还是很和蔼的，奈何太紧张两个简单的算法都没做出来…而且冒泡都用错了…
转载：面试题 1：python自动化实现的思路
2：使用DDT进行数据驱动时你excel表格中的用例数据怎么做参数化处理
3：unnittest与pytest的区别
4：unnittest与pytest中分别是怎么处理用例的执行顺序的
5：appium的二次开发与appium运行原理
6：对requests的post 和get的封装
7：怎么提升App自动化脚本的运行效率
8：xpath与css选择器的使用场景以及你常使用的轴定位名称
9：App自动化测试中面对toast弹框你是怎么定位以及设置等待的
10：怎么给手机开一个“5555”端口？对于手机应用卡顿这块你是怎么分析与测试的
11：在手机中对于同一时间有多个应用在占用内存，你是怎么判断当前的这个应用的内存本身是否有问题的
12：性能测试中控制业务占比的组件是使用哪个
13：性能测试中怎么判断当前的网络不是压测的瓶颈
14：性能测试中出现系统资源使用不上去，tps很低但是响应时间却增加怎么去分析定位问题
15：开发在代码层面做了一次修改，怎么去看它对操作系统的性能影响到底有多大(perf stat)
16：redis缓存雪崩，击穿及穿透是什么以及对应的解决方案，怎么判断redis当前的碎片率及解决方法
17：压测中对mysql你使用的是什么工具进行监控的？使用什么工具进行sql语句剖析的以及你是怎么做的
18：请使用多种方法查询每个学生的每门课分数&gt;80的学生姓名
19：面对项目多，测试人力不足，开发提测延期并且领导压缩测试工期怎么保证测试质量
20：项目与绩效目标你是如何设定和分拆的
美团测开（25k） 给定场景，说说你的测试用例设计思路 比如说登录模块
功能角度 — 边界值、等价类划分、错误推测法
 用户名密码正确 正确用户名，错误密码 特殊字符 未注册的用户 都为空或二者之一为空 验证码登录  正确验证码 错误验证码 验证码为空    &hellip;
用户体验角度
 是否支持快捷键 前端是否限制用户名密码长度 输入框聚焦、UI 等 &hellip;  兼容性角度
 不同浏览器下 同浏览器的不同版本下 不同系统下（移动 &amp; PC） 不同分辨率界面下  安全性角度
 密码框是否加密、是否大小写敏感 刷新页面验证码是否失效 用户登录后数据、权限是否正确 是否暴力破解（验证码） 输入框 sql 注入 验证码时效性是否正确 账号密码接口是否加密  性能角度
 单用户登录接口响应时间是否小于 3 秒 高并发情况下，响应时间是否小于 5 秒，服务端监控指标是否合格 大量用户登录登出，或者做数据更新操作，是否会出现内存泄漏 &hellip;  说下session和token检验的区别 session 、 token 是登录校验的一种方式。
session
 提交用户名和密码 后端校验通过，登录成功。服务器保存用户的登录信息，并返回一个 sessionId 放在 cookie内给到客户端 客户端每次请求会自动带着cookie 内的 sessionId 访问服务器，服务器校验 sessionId是否已经存在，如果存在则认为登录，否则未登录。  测试点：
 部分浏览器或者工具禁用 cookie，当禁用后是否正确响应 session 保存数量（同时在线人数 — 并发在线）是否影响服务器的性能（内存、磁盘、IO） 多台服务器间的 session 共享  token
 提交用户名和密码 后端验证成功，登录成功。生成令牌（特殊字符串）响应给客户端。  一般服务器不存储任何登录记录 这个字符串不是随便生成的，有特定规则算法生成 不限于 cookie、响应体（json）等 客户端通常要自行保存，前端人员去处理   后续请求携带token，服务端校验是否合法  测试点：
 时效性，过期是否可用 新老版本 token 是否可用  区别：
 session 在服务器存储登录信息，token 不需要存储 sessionId 一般是服务器在cookie 中返回，token 没有规定 token 具有自证功能，保存在客户端（APP、小程序基本上都是用 token）  谈谈你对tcp三次握手的理解 三次握手：http 应用层请求之前，传输层做了三次网络交互
四次挥手
selenium 的底层原理 ]]></content></entry><entry><title>Selenium - 无头浏览器</title><url>/tech/selenium/%E5%9F%BA%E7%A1%8011%E6%97%A0%E5%A4%B4%E6%B5%8F%E8%A7%88%E5%99%A8/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[打印浏览器页面，要求为无头浏览器 from selenium.webdriver.common.print_page_options import PrintOptions print_options = PrintOptions() print_options.page_ranges = [&#39;1-2&#39;] driver.get(&#34;printPage.html&#34;) base64code = driver.print_page(print_options) from seleniumwire import webdriver options = webdriver.ChromeOptions() options.add_argument(&#39;--headless=True&#39;) # 无头浏览器模式 options.add_argument(&#39;disable-infobars&#39;) # 隐藏提示：&#34;Chrome正在受到自动软件的控制&#34; options.add_argument(&#39;lang=zh_CN.UTF-8&#39;) # 设置中文 options.add_argument(&#39;window-size=1920x3000&#39;) # 指定浏览器分辨率 options.add_argument(&#39;--hide-scrollbars&#39;) # 隐藏滚动条, 应对一些特殊页面 # options.add_argument(&#39;--remote-debugging-port=9222&#39;) # 开启 debug 模式 # options.add_argument(&#39;proxy-server=127.0.0.1:8081&#39;) # 设置代理 # options.add_argument(&#39;blink-settings=imagesEnabled=false&#39;) # 设置图片不加载 options.add_argument(&#39;user-agent=hello world&#39;) # 更换请求头 UA # 创建浏览器对象 driver = webdriver.Chrome(chrome_options=options) driver.implicitly_wait(10) # 访问URL driver.get(&#39;https://www.baidu.com&#39;) print(driver.current_url) # 获取页面的地址 print(driver.title) # 百度一下，你就知道 print(driver.requests[0].headers) # 请求头修改成功 driver.quit() 自定义请求头 options = webdriver.ChromeOptions() options.add_argument(&#39;--headless=True&#39;) def interceptor(request): request.headers[&#34;test&#34;] = &#34;hello world&#34; # 新增 request.headers = {&#34;a&#34;: 1, &#34;b&#34;: 2} # 重置 driver = webdriver.Chrome(chrome_options=options) driver.request_interceptor = interceptor driver.get(&#39;https://www.baidu.com&#39;) print(driver.requests) print(driver.requests[0].headers) ]]></content></entry><entry><title>Selenium - 窗口操作</title><url>/tech/selenium/%E5%9F%BA%E7%A1%803%E5%A4%9A%E7%AA%97%E5%8F%A3%E6%93%8D%E4%BD%9C/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[ selenium 窗口处理相关操作。
 窗口操作 # 窗口最大化 driver.maximize_window() # 窗口最小化 driver.minimize_window() # 窗口全屏化 driver.fullscreen_window() # 获取窗口大小 size = driver.get_window_size() width = size.get(&#34;width&#34;) height = size.get(&#34;height&#34;) # 设置窗口大小 driver.set_window_size(1024, 768) # 获取窗口左上角坐标位置 position = driver.get_window_position() x = position.get(&#39;x&#39;) y = position.get(&#39;y&#39;) # 设置窗口左上角坐标位置 driver.set_window_position(0, 0) # 窗口截图 driver.save_screenshot(&#39;./image.png&#39;) # 对特定元素截图 ele = driver.find_element(By.ID, &#39;su&#39;) ele.screenshot(&#39;./image.png&#39;) 多窗口场景处理 网页上点击某个链接，有可能会打开一个新的标签页。这种情况，需要切换到新的窗口来执行后续操作。
每个窗口都有一个唯一标识句柄，通过句柄来切换窗口。
# 当前标签页 driver.current_window_handle # 所有标签页 driver.window_handles # 切换标签页 driver.switch_to.window(handle) # 关闭当前窗口 driver.close() # 关闭所有窗口，退出驱动 driver.quit() &#34;&#34;&#34; selenium &gt; 4.0 &#34;&#34;&#34; # 新建浏览器标签页并切换 handle driver.switch_to.new_window(&#39;tab&#39;) # 新建浏览器窗体并切换 handle driver.switch_to.new_window(&#39;window&#39;) 示例
from selenium import webdriver from selenium.webdriver.common.by import By class TestSwitchWindow: def setup(self): self.driver = webdriver.Chrome() self.driver.maximize_window() self.driver.implicitly_wait(3) self.driver.get(&#34;http://www.baidu.com&#34;) def teardown(self): self.driver.quit() def test_switch_register_to_home(self): &#34;&#34;&#34; 百度首页，点击注册，会新打开一个注册页面； 在注册页面输入账号密码后切换回第一个窗口 &#34;&#34;&#34; self.driver.find_element(By.LINK_TEXT, &#34;登录&#34;).click() self.driver.find_element(By.LINK_TEXT, &#34;立即注册&#34;).click() home_handle = self.driver.current_window_handle # 当前窗口句柄 windows = self.driver.window_handles # 所有窗口句柄：list # 切换到最后一个窗口，也就是新打开的「注册」页面 self.driver.switch_to.window(windows[-1]) self.driver.find_element(By.ID, &#34;TANGRAM__PSP_4__userName&#34;).send_keys(&#34;login_username&#34;) # 切换到第一个，输入用户名密码 self.driver.switch_to.window(home_handle) # self.driver.switch_to.window(windows[0]) self.driver.find_element(By.ID, &#34;TANGRAM__PSP_11__userName&#34;).send_keys(&#34;login_username&#34;) def test_switch_windows_by_loop(self): &#34;&#34;&#34; 打开多个窗口，最后定位到「百度图片窗口」 &#34;&#34;&#34; home_handle = self.driver.current_window_handle # 当前窗口句柄 tab_texts = [&#34;新闻&#34;, &#34;视频&#34;, &#34;图片&#34;, &#34;贴吧&#34;] for text in tab_texts: self.driver.find_element(By.LINK_TEXT, text).click() self.driver.switch_to.window(home_handle) for handle in self.driver.window_handles: self.driver.switch_to.window(handle) if &#34;百度图片&#34; in self.driver.title: break assert self.driver.title == &#34;百度图片-发现多彩世界&#34; def test_window_close(self): &#34;&#34;&#34; 通过百度首页打开新闻页面，然后关闭首页 &#34;&#34;&#34; home_handle = self.driver.current_window_handle self.driver.find_element(By.LINK_TEXT, &#34;新闻&#34;).click() self.driver.close() # print(self.driver.title) # 窗口关闭后，再次操作报错：NoSuchWindowException # 因为首页已经被关闭，需要手动切换到已存在的窗口上 self.driver.switch_to.window(self.driver.window_handles[-1]) assert &#34;百度新闻&#34; in self.driver.title ]]></content></entry><entry><title>Selenium - 三种等待方式</title><url>/tech/selenium/%E5%9F%BA%E7%A1%802%E4%B8%89%E7%A7%8D%E7%AD%89%E5%BE%85%E6%96%B9%E5%BC%8F/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[ selenium 三种等待方式演示。
 强制等待 隐式等待 显式等待   强制等待 import time # 整个程序强制等待 3 秒 time.sleep(3) 隐式等待 设置一个全局的等待时间，以隐式等待找到元素或完成命令。每个会话只需要调用一次此方法。
# Amount of time to wait (in seconds) driver.implicitly_wait(3) 显式等待 定义等待条件，满足条件才继续向下执行，否则继续等待，超时后抛出异常。更加灵活的等待方式，项目中最常用的等待方式。
显示等待类 WebDriverWait 初始化接收四个参数：
 driver：自动化驱动 timeout：总等待时间 poll_frequency：轮询间隔时间 ignored_exceptions：忽略预期的异常类型  两个判断条件：
def until(self, method, message=&#39;&#39;): &#34;&#34;&#34; 调用传入的方法作为参数，直到返回值不是 False &#34;&#34;&#34; def until_not(self, method, message=&#39;&#39;): &#34;&#34;&#34; 调用传入的方法作为参数，直到返回值为 False &#34;&#34;&#34; 示例
import time from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions from selenium.webdriver.support.wait import WebDriverWait from selenium.common.exceptions import StaleElementReferenceException class TestWait: def setup_class(self): self.driver = webdriver.Chrome() self.driver.get(&#34;https://www.baidu.com&#34;) self.driver.implicitly_wait(5) # 隐式等待 def teardown_class(self): self.driver.quit() def test_sleep(self): &#34;&#34;&#34; 强制等待 无论元素是否出现都强制等待 &#34;&#34;&#34; ele = self.driver.find_element(By.ID, &#34;kw&#34;) time.sleep(10) ele.send_keys(&#34;hello&#34;) def test_implicitly_wait(self): &#34;&#34;&#34; 隐式等待 设置在初始化 driver 处，元素 5 秒不出现才报错 &#34;&#34;&#34; ele = self.driver.find_element(By.ID, &#34;test&#34;) # 随便设置个元素 ele.click() def test_webdriver_wait_by_def(self): &#34;&#34;&#34; 显式等待 自定义方法编写条件 &#34;&#34;&#34; def wait(x): # 参数为必传项 hot_search_items = self.driver.find_elements( By.XPATH, &#39;//*[@class=&#34;title-content-title&#34;]&#39; ) return len(hot_search_items) == 6 # 等待百度热搜出现 6 条则继续向下执行，否则最大等待时间为 10 秒，0.5 秒轮询一次 WebDriverWait(self.driver, 10).until(wait) def test_webdriver_wait_by_ec(self): &#34;&#34;&#34; 显式等待 使用预置的等待条件库 expected_conditions &#34;&#34;&#34; # 等待热搜词可点击才继续向下执行，否则最大等待时间为 10 秒，每秒轮询一次 WebDriverWait(self.driver, 1, 10).until( expected_conditions.element_to_be_clickable( (By.XPATH, &#39;//*[@class=&#34;title-content-title&#34;]&#39;) ) ) def test_webdriver_wait_until_not(self): &#34;&#34;&#34; 显式等待 每 5 秒看一次该元素是否展示，如果不展示则用例直接通过 &#34;&#34;&#34; WebDriverWait(self.driver, 5, 10).until_not( expected_conditions.element_to_be_clickable( (By.XPATH, &#39;hello&#39;) ) ) def test_webdriver_wait_ignored_exceptions(self): &#34;&#34;&#34; 显式等待 忽略某种预期内的异常，继续轮询等待 &#34;&#34;&#34; WebDriverWait(self.driver, 1, 5, StaleElementReferenceException).until( # 可以在 WebDriverWait 初始化时添加忽略异常, 如上当页面元素未更新时也不会报错，继续轮询 # 默认为 NoSuchElementException expected_conditions.element_to_be_clickable( (By.ID, &#34;test&#34;) ) ) expected_conditions API &#34;&#34;&#34; * Canned &#34;Expected Conditions&#34; which are generally useful within webdriver * tests. &#34;&#34;&#34; class title_is(object): &#34;&#34;&#34;标题完全匹配，返回 bool&#34;&#34;&#34; class title_contains(object): &#34;&#34;&#34;标题包含匹配，区分大小写&#34;&#34;&#34; class url_contains(object): &#34;&#34;&#34;url 片段匹配，区分大小写，返回 bool&#34;&#34;&#34; class url_matches(object): &#34;&#34;&#34;url 正则匹配，返回 bool&#34;&#34;&#34; class url_to_be(object): &#34;&#34;&#34;url 精确匹配，返回 bool&#34;&#34;&#34; class url_changes(object): &#34;&#34;&#34;url 不匹配则为真，否则为假&#34;&#34;&#34; class presence_of_element_located(object): &#34;&#34;&#34;页面元素是否存在，并不一定可见，接收一个 locator&#34;&#34;&#34; class visibility_of_element_located(object): &#34;&#34;&#34;元素是否在页面中必须展示，且高度宽度大于0，接收一个 locator&#34;&#34;&#34; class visibility_of(object): &#34;&#34;&#34;元素是否可见，可见则返回元素，否则返回 false&#34;&#34;&#34; class presence_of_all_elements_located(object): &#34;&#34;&#34;查找一组元素，无论是否在页面可见&#34;&#34;&#34; class visibility_of_any_elements_located(object): &#34;&#34;&#34;查找一组元素，返回该元素中所有在页面可见的元素&#34;&#34;&#34; class visibility_of_all_elements_located(object): &#34;&#34;&#34;查找一组元素，该元素都页面中可见&#34;&#34;&#34; class text_to_be_present_in_element(object): &#34;&#34;&#34;检查指定文本是否存在于元素的文本当中&#34;&#34;&#34; class text_to_be_present_in_element_value(object): &#34;&#34;&#34;检查指定文本是否存在于元素的属性值当中&#34;&#34;&#34; class frame_to_be_available_and_switch_to_it(object): &#34;&#34;&#34;检查是否可以切换到指定 locator 的 frame 当中&#34;&#34;&#34; class invisibility_of_element_located(object): &#34;&#34;&#34; 元素在页面中不可见或不存在 &#34;&#34;&#34; class element_to_be_clickable(object): &#34;&#34;&#34;元素是否可被点击&#34;&#34;&#34; class staleness_of(object): &#34;&#34;&#34;元素是否停止加载，依然加载返回 false，否则为 true&#34;&#34;&#34; class element_to_be_selected(object): &#34;&#34;&#34;获取元素对象的 is_selected 属性&#34;&#34;&#34; class element_located_to_be_selected(object): &#34;&#34;&#34;通过 locator 定位元素，获取该元素的 is_selected 属性&#34;&#34;&#34; class element_selection_state_to_be(object): &#34;&#34;&#34;当前元素是否为选中状态&#34;&#34;&#34; class element_located_selection_state_to_be(object): &#34;&#34;&#34;当前元素是否可被选中&#34;&#34;&#34; class number_of_windows_to_be(object): &#34;&#34;&#34;判断当前浏览器窗口数量&#34;&#34;&#34; class new_window_is_opened(object): &#34;&#34;&#34;检查是否打开了一个新窗口&#34;&#34;&#34; class alert_is_present(object): &#34;&#34;&#34;alert 弹窗是否chu&#39;xian&#34;&#34;&#34; 显式等待 + 窗口切换官方示例 from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC with webdriver.Chrome() as driver: # Open URL driver.get(&#34;https://www.baidu.com&#34;) # Setup wait for later wait = WebDriverWait(driver, 10) # Store the ID of the original window original_window = driver.current_window_handle # Check we don&#39;t have other windows open already assert len(driver.window_handles) == 1 # Click the link which opens in a new window driver.find_element(By.LINK_TEXT, &#34;新闻&#34;).click() # Wait for the new window or tab wait.until(EC.number_of_windows_to_be(2)) # Loop through until we find a new window handle for window_handle in driver.window_handles: if window_handle != original_window: driver.switch_to.window(window_handle) break # Wait for the new tab to finish loading content wait.until(EC.title_is(&#34;百度新闻——海量中文资讯平台&#34;)) ]]></content></entry><entry><title>Andorid - Android基础</title><url>/tech/andorid/android%E5%9F%BA%E7%A1%80/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">Android/iOS 基础知识 Android 是通过容器的布局属性来管理子控件的位置关系，布局过程就是把界面上的所有控件根据间距大小摆放到正确的位置。
布局是一种可放置很多控件的容器，它可以按照一定得规律调整内部控件的位置，从而编写精美的界面。布局内部除了放置空间外，也可以放置布局，通过多布局的嵌套，能完成一些很复杂的界面。
七大布局：
LinearLayout 线性布局 RelativeLayout 相对布局 FrameLayout 帧布局 TableLayout 表格布局 GridLayout 网格布局 ConstraintLayout 约束布局 常用的控件：
TextView（文本控件）、EditText（可编辑文本控件） Button（按钮）、ImageButton（图片按钮）、ToggleButton（开关按钮） ImageView（图片控件） CheckBox（复选框控件）、RadioButton（单选框控件） Android 四大组件：
activity：与用户交互的可视化界面 service：实现程序后台运行的解决方案 content provider：内容提供者，提供程序所需要的数据 broadcast receiver：广播接收器，监听外部事件的到来（比如来电）</content></entry><entry><title>Selenium - 八大定位方式</title><url>/tech/selenium/%E5%9F%BA%E7%A1%801%E5%85%AB%E5%A4%A7%E5%AE%9A%E4%BD%8D%E6%96%B9%E5%BC%8F/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[对元素的操作方法 # 点击元素 ele.click() # 输入文本 ele.send_keys(&#34;hello world&#34;) # 上传图片 # input 标签可以直接使用 send_keys(文件地址) 上传文件 driver.get(&#34;https://image.baidu.com/&#34;) driver.find_element(By.ID, &#34;sttb&#34;).click() driver.find_element(By.ID, &#34;stfile&#34;).send_keys(&#34;/Users/lan/Pictures/7.jpeg&#34;) sleep(10) # 获取元素的尺寸 ele.size # 获取元素的坐标 ele.location # 获取元素的文本（a 标签、p 标签或者 div 标签中的文本内容） ele.text # 获取元素属性值;通过属性名获取属性值 ele.get_attrbut(&#34;attr_name&#34;) 八大元素定位方式 id import time from selenium import webdriver from selenium.webdriver.common.by import By # 1. 打开浏览器 driver = webdriver.Chrome() # 2. 打开网址 -- 百度 driver.get(&#34;http://www.baidu.com&#34;) # 3. 定位搜索框元素，输入搜索词 driver.find_element(By.ID, &#34;kw&#34;).send_keys(&#34;Hello World!&#34;) # 4. 点击搜索按钮 driver.find_element(By.ID, &#34;su&#34;).click() # 5. 验证结果 time.sleep(1) assert driver.title == &#34;Hello World!_百度搜索&#34; # 6. 退出浏览器 driver.quit() name # name=&#34;wd&#34; driver.find_element(By.NAME, &#34;wd&#34;).send_keys(&#34;Hello World!&#34;) class 该属性用于指定控件样式，很多情况下不唯一。
# class=&#34;s_ipt&#34; driver.find_element(By.CLASS_NAME, &#34;s_ipt&#34;).send_keys(&#34;Hello World!&#34;) tag &amp; 定位组元素 HTML中一个tag往往用来定义一类元素的功能，页面元素较多，很难通过tag区分。
# 如果页面有多个 input 标签，那么会自动与第一个元素进行交互 driver.find_element(By.TAG_NAME, &#34;input&#34;).send_keys(&#34;Hello World!&#34;) # 出现报错：元素不可交互 # 原因是百度首页第一个 input 标签并不是可见的 由于百度首页有多个input标签，这里就需要通过 find_elements来获取整组元素，按元素下标精准定位。
# 按下标取元素，取第 8 个 driver.find_elements(By.TAG_NAME, &#34;input&#34;)[7].send_keys(&#34;Hello World!&#34;) 注意：当页面有更新，根据 tag 定位的元素不一定可靠，所以一般不单独用tag定位，更多是用于组合定位。
link 通过带有链接的文本进行定位。
# 通过「关联 herf 标签的文本」定位 driver.find_element(By.LINK_TEXT, &#34;关于百度&#34;).click() partial link 针对带有链接的文本，模糊匹配。当需要定位的文本过长，支持根据其中一部分文本进行定位，但需要保证模糊匹配的唯一性。
# 定位的也是「关于百度」 driver.find_element(By.PARTIAL_LINK_TEXT, &#34;关于&#34;).click() Xpath XML Path Language
 用于解析 html 和 xml 支持 appium 和 selenium 缺点是查找慢  `/` 是在当前目录的子目录下查找 `//` 是在当前目录的子子孙孙目录下查找 `[]` 表示需要满足的条件 百度页面示例
// 进入百度页面，点击检查，进入 Console clear() // 清空当前屏幕  // 练习 1: 通过 xpath 查找输入框 // name 和 id 通常都是唯一的，通过该属性可以直接定位 $x(&#39;//*[@name=&#34;wd&#34;]&#39;) $x(&#39;//*[@id=&#34;kw&#34;]&#39;) // 练习 2: 查看搜索框下面的「网页」tab 栏 // 在 b 标签下 $x(&#39;//*[@id=&#34;s_tab&#34;]//b&#39;) // 练习 3: 查看搜索框下面的其他 tab 栏 // 共 9 个, 都是在 a 标签下 $x(&#39;//*[@class=&#34;s_tab_inner&#34;]//a[1]&#39;) $x(&#39;//*[@class=&#34;s_tab_inner&#34;]//a[9]&#39;) // 直接定位到最后一个 $x(&#39;//*[@class=&#34;s_tab_inner&#34;]//a[last()]&#39;) // 定位到最后第二个 $x(&#39;//*[@class=&#34;s_tab_inner&#34;]//a[last()-1]&#39;) // 练习 4: 定位右上角设置和登录按钮 $x(&#39;//*[@id=&#34;u1&#34;]/span&#39;) // 设置 $x(&#39;//*[@id=&#34;u1&#34;]/a&#39;) // 登录 # 在 console 调试好表达式后，直接在代码中使用 driver.find_element(By.XPATH, &#39;//*[@name=&#34;wd&#34;]&#39;).send_keys(&#34;Hello World!&#34;) Css Selector  appium 原生的控件不支持该方式定位 selenium 支持 webview 推荐这种定位方式，更简洁  .test // 选择 class=&#34;test&#34; 的所有元素 #test // 选择 id=&#34;test&#34; 的所有元素 * // 选择所有元素  // 空格代表子子孙孙全部元素 p // 代表选择所有 &lt;p&gt; 元素 div,p // 代表选择所有 &lt;div&gt; 和 &lt;p&gt; 元素 div&gt;p // 选择父元素为 &lt;div&gt; 元素的所有 &lt;p&gt; 元素 div+p // 选择紧接在 &lt;div&gt; 元素之后的所有 &lt;p&gt; 元素  [id=kw] // 选择 id=&#34;kw&#34; 的所有元素 p:nth-child(2) // 选择父元素第 2 个子元素 p~ul // 选择前面有 &lt;p&gt; 元素的每个 &lt;ul&gt; 元素 // 练习 1 查找搜索框，进入搜索结果页 $(&#34;#kw&#34;) // 方法一 $(&#34;[id=kw]&#34;) // 方法二  // 练习 2 查找「网页」tab $(&#34;#s_tab b&#34;) // 练习 3 查看「资讯」tab $(&#34;#s_tab :nth-child(2)&#34;) // 练习4 查看最后一个 tab $(&#34;#s_tab a:nth-last-child(1)&#34;) # 最后一个元素 $(&#34;#s_tab a:nth-last-child(2)&#34;) # 最后第二个元素 driver.find_element(By.CSS_SELECTOR, &#39;#kw&#39;).send_keys(&#34;Hello World!&#34;) ]]></content></entry><entry><title>Python - Websocket请求发送</title><url>/tech/python/websocket%E8%AF%B7%E6%B1%82%E5%8F%91%E9%80%81/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ websocket 测试
 from websocket import create_connection # 测试地址：http://www.websocket-test.com/ def websocket_protocol(): # 发起连接 ws = create_connection(&#34;ws://IP或域名:端口&#34;) # 获取服务器返回信息 result = ws.recv() print(result) # 发送请求信息 ws.send(&#34;hello world&#34;) result_send = ws.recv() print(result_send) ws.close() ]]></content></entry><entry><title>Python - Requests请求鉴权</title><url>/tech/python/requests-%E8%AF%B7%E6%B1%82%E9%89%B4%E6%9D%83/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[接口鉴权的通用解决方案：
 认证信息的获取 认证信息的携带  auth 鉴权请求方法
import requests from requests.auth import HTTOBasicAuth proxy = { &#34;http&#34;: &#34;http://127.0.0.1:8888&#34;, &#34;https&#34;: &#34;https://127.0.0.1:8888&#34; } r = requests.get( url=&#34;https://baidu.com&#34;, proxies=proxy, verify=False, auth=HttpBasicAuth(&#34;username&#34;, &#34;password&#34;) ) ]]></content></entry><entry><title>Python - Requests Xmltodict将Xml内容转为字典</title><url>/tech/python/requests-xmltodict%E5%B0%86xml%E5%86%85%E5%AE%B9%E8%BD%AC%E4%B8%BA%E5%AD%97%E5%85%B8/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html">xml 格式转换为 dict
# 0.13 版本及以上 $ pip install xmltodict ![image-20221023223603798](/Users/lan/Library/Application Support/typora-user-images/image-20221023223603798.png)
![image-20221023224021093](/Users/lan/Library/Application Support/typora-user-images/image-20221023224021093.png)</content></entry><entry><title>Python - Requests Proxy为请求添加代理</title><url>/tech/python/requests-proxy%E4%B8%BA%E8%AF%B7%E6%B1%82%E6%B7%BB%E5%8A%A0%E4%BB%A3%E7%90%86/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[通过 APP 发送一个请求，编写接口自动化测试脚本。
编写的过程中，如果脚本的请求跟实际不一致，通过代理的方式查看两次请求有什么不一致。
# 伪代码 proxies = { &#34;http&#34;: &#34;http://127.0.0.1:8080&#34;, &#34;https&#34;: &#34;http://127.0.0.1:8080&#34;, } r = requests.post(url=&#34;http://www.baidu.com&#34;, prixies=proxies, verify=Falses) 这样打开 charles，就可以代理脚本发出的请求，再通过客户端发送一条请求，这样就能对比出两条请求有什么区别。
作用：
  对比两次请求的区别，更直观的排查脚本请求错误，相当于 debug
  获取真实的接口请求响应信息
  通过代理可以自定义响应信息
  ]]></content></entry><entry><title>Andorid - Adb连接失败原因</title><url>/tech/andorid/adb-%E8%BF%9E%E6%8E%A5%E5%A4%B1%E8%B4%A5%E5%8E%9F%E5%9B%A0/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"> adb 连接不上设备的解决办法。
首先确保电脑上的android-platform-tools版本与设备的API版本匹配。
$ adb --version Android Debug Bridge version 1.0.40 Version 4986621 Installed as /usr/local/Caskroom/android-platform-tools/28.0.1/platform-tools/adb 比如上面，我电脑的adb版本是28，连接一个10.0系统(API 29)的设备，死活连接不上。。。
所以当遇到设备无法连接，先检查或尝试更新adb版本，确保版本可以匹配。
版本匹配参考 Android SDK
# brew 更新 adb 命令 $ brew upgrade android-platform-tools 如果还是连接不上，通常的解决办法：
重新插拔数据线； 重新关开开发者选项，插拔数据线； 重新关开 USB 调试，插拔数据线； 撤销 USB 调试授权，插拔数据线。 常见错误 不显示设备 已通过数据线连接手机和电脑，但是不显示设备号。
$ adb devices List of devices attached * daemon not running; starting now at tcp:5037 * daemon started successfully 遇到这种情况，先检查设备是否真正的连接到电脑上了，执行如下命令。
$ system_profiler SPUSBDataType ... ELE-AL00: Product ID: 0x107e Vendor ID: 0x12d1 (Huawei Technologies Co., Ltd.) ... 当执行完命令，没有在输出内找到设备信息，那就更换 USB 数据线重试吧。
记录设备的Vendor ID并添加到adb_usb.ini文件内，如果没有该文件就新建一个。
$ vim /Users/用户名/.android/adb_usb.ini 插拔设备重试。
未授权 显示连接设备，但是设备处于unauthorized状态，且手机不弹授权的提示框。
$ adb devices GBG5T19731003744 unauthorized 不弹授权的弹框，可能是电脑上有过这款手机的历史授权记录，即使授权失败了，也不会再弹窗。
$ cd /Users/用户名/.android/ $ rm adbkey adb_usb.ini 删除上面两个配置文件，插拔设备重试。</content></entry><entry><title>Ios - 爱维每日签到自动打卡</title><url>/tech/ios/%E7%88%B1%E7%BB%B4%E6%AF%8F%E6%97%A5%E7%AD%BE%E5%88%B0%E8%87%AA%E5%8A%A8%E6%89%93%E5%8D%A1/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html"><![CDATA[ 本文介绍 iOS 设备自动化签到、完成每日任务。
 环境  iPhone 15.4 xcode 12.4 tidevice 0.6.6 WebDriverAgent v4.8.4  初始化工作
# 安装 tidevice $ pip install -U tidevice # 安装 python wda client $ pip install -U facebook-wda # clone wda 源码 $ cd workspace $ git clone https://github.com/appium/WebDriverAgent.git $ cd WebDriverAgent # 目前的版本不需要执行 ./Scripts/bootstrap.sh # 双击打开 WebDriverAgent.xcodeproj 项目 编译安装 APP 请参考： IOS测试 | facebook-wda 环境搭建篇
出现如下报错信息需要信任开发者，点击「通用 - VPN与设备管理 - 信任开发者」即可。
 The operation couldn’t be completed. Unable to launch com.facebook.WebDriverAgentRunner.lan.xctrunner because it has an invalid code signature, inadequate entitlements or its profile has not been explicitly trusted by the user.
 通过 tidevice 启动 wda：
$ tidevice -u [udid] wdaproxy -B [wda bundle Id] --port 8100 ... WebDriverAgent start successfully DEMO 抓取页面元素 注意，在当前版本中，/inspector 接口已经移除，不能使用。
 mykola-mokhnach: The built-in inspector module has been removed from the fork in favour of Appium Desktop&rsquo;s one
内置的检查器模块已经从 fork 中移除，取而代之的是 Appium Desktop。
 不想下载 appium Desktop，这里使用源码方式获取元素属性。
c.source() # xml 格式 c.source(accessible=True) # json 格式 在 dom 结构内找到预期元素的属性，进行定位。
项目代码 需求：打开爱维宝贝 APP，自动签到，自动完播广告。
# 部分 api pkg = &#34;com.zhongwei.aiweibaby&#34; c = wda.Client(&#39;http://localhost:8100&#39;) # 8100为启动WDA设置的端口号 c.session().app_terminate(pkg) # 杀死应用 c.session().app_activate(pkg) # 打开应用 c(name=&#34;跳过&#34;).click_exists(timeout=5) if c(name=&#34;签到得红花&#34;).exists: c(name=&#34;签到得红花&#34;).click() logger.info(&#34;签到成功&#34;) if c(name=&#34;今日已签到&#34;).exists: logger.info(&#34;今日已签到&#34;) def watch_video(): &#34;&#34;&#34;已经进入校园页面&#34;&#34;&#34; c(name=&#34;去观看&#34;).click() for i in range(3): sleep(10) logger.info(f&#34;等待 {10}s&#34;) x = randint(200, 300) y = randint(200, 700) c.click(x, y) # 随机点模拟人工 logger.info(f&#34;click({x}, {y})&#34;) # TODO：需另起线程监控系统弹窗、跳出APP拉回 if c.app_current() != pkg: c.session().app_activate(pkg) # 打开应用 c(name=&#34;endcard_close&#34;).click_exists(timeout=30) # 完播关闭 ]]></content></entry><entry><title>Andorid - 快应用测试</title><url>/tech/andorid/%E5%BF%AB%E5%BA%94%E7%94%A8%E6%B5%8B%E8%AF%95/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">快应用测试 准备 下载快应用环境( https://www.quickapp.cn/docCenter/post/69 )，分别下载：
快应用预览版 快应用调试器 客户端提测后，拿到 rpk 安装包并下载到手机上。
安装 打开快应用调试器，选择本地安装，选择 rpk文件，即可安装成功。</content></entry><entry><title>Mac - 安装Obs推流直播</title><url>/tech/mac/%E5%AE%89%E8%A3%85obs%E6%8E%A8%E6%B5%81%E7%9B%B4%E6%92%AD/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">下载 OBS 推流软件 地址：https://obsproject.com/
使用方法：
新建场景（来源 + 号） - 选择「显示器采集」，根据需求添加摄像头、麦克风等 右键「显示器采集」，选择「调整输出大小（到源大小）」 菜单栏进入设置页面，选中「推流」子菜单，服务选择「自定义」 平台直播 去直播平台获取推流地址：
抖音需要 1000 粉丝以上 视频号需要认证后才可以 bilibili 需要上传手持身份证照片 真是费劲了呀，算求，不播了~</content></entry><entry><title>Blog - Markdown 测试文档</title><url>/tech/blog/markdown-%E6%B5%8B%E8%AF%95%E6%96%87%E6%A1%A3/</url><categories><category>Blog</category></categories><tags><tag>Blog</tag></tags><content type="html"><![CDATA[目录 [toc]
第一章	一级标题 1.1 二级标题 1.1.1 三级标题 1.1.1.1 四级标题 1.1.1.1.1 五级标题 1.1.1.1.1.1 六级标题 一级标题 归去来兮辞	陶渊明 〔魏晋〕
思源笔记   归去来兮，田园将芜胡不归？既自以心为形役，奚惆怅而独悲？悟已往之不谏，知来者之可追。实迷途其未远，觉今是而昨非。舟遥遥以轻飏，风飘飘而吹衣。问征夫以前路，恨晨光之熹微。
CSS（层叠样式表） | MDN   乃瞻衡宇，载欣载奔。僮仆欢迎，稚子候门。三径就荒，松菊犹存。携幼入室，有酒盈樽。引壶觞以自酌，眄庭柯以怡颜。倚南窗以寄傲，审容膝之易安。园日涉以成趣，门虽设而常关。策扶老以流憩，时矫首而遐观。云无心以出岫，鸟倦飞而知还。景翳翳以将入，抚孤松而盘桓。
四级标题 归去来兮，请息交以绝游。世与我而相违，复驾言兮焉求？悦亲戚之情话，乐琴书以消忧。农人告余以春及，将有事于西畴。或命巾车，或棹孤舟。既窈窕以寻壑，亦崎岖而经丘。木欣欣以向荣，泉涓涓而始流。善万物之得时，感吾生之行休。
五级标题 已矣乎！寓形宇内复几时？曷不委心任去留？胡为乎遑遑欲何之？富贵非吾愿，帝乡不可期。怀良辰以孤往，或植杖而耘耔。登东皋以舒啸，临清流而赋诗。聊乘化以归尽，乐夫天命复奚疑！
六级标题 已矣乎！寓形宇内复几时？曷不委心任去留？胡为乎遑遑欲何之？富贵非吾愿，帝乡不可期。怀良辰以孤往，或植杖而耘耔。登东皋以舒啸，临清流而赋诗。聊乘化以归尽，乐夫天命复奚疑！
1、英文
`abcdefghijklmnopqrstuvwxyz
ABCDEFGHIJKLMNOPQRSTUVWXYZ
1234567890
!@#$%^&amp;*()-=[];',./_+{}|:&quot;&lt;&gt;?`~:
2、加粗
镜湖月	jinghu-moon	1234567890
3、斜体
镜湖月jinghu-moon	jinghu-moon	1234567890
4、高亮
==镜湖月==	==jinghu-moon==	此样式不在 GFM 规定中。在 GitHub 上阅读 MD 文件，不会渲染此样式。
已矣乎！寓形宇内复几时？==曷不委心任去留？胡为乎遑遑欲何之？富贵非吾愿，帝乡不可期。怀良辰以孤往，或植杖而耘耔。登东皋以舒啸，临清流而赋诗。==聊乘化以归尽，乐夫天命复奚疑！
5、下划线
这是带有下划线的一句话。
6、链接
 思源笔记 - 本地优先的个人知识管理系统，支持 Markdown 排版、块级引用和双向链接  
7、行内代码
abcdefghijklmnopqrstuvwxyz
ABCDEFGHIJKLMNOPQRSTUVWXYZ	1234567890
镜湖月镜湖月镜湖月
8、代码块
#include&lt;stdio.h&gt;int main() { printf(&#34;1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890\n&#34;); return 0; printf(&#34;1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890\n&#34;); // 测试 }  + 增加 - 减少 9、表格
   镜湖月 镜湖月 镜湖月     镜湖月 镜湖月 镜湖月   镜湖月 镜湖月 镜湖月   镜湖月 镜湖月 镜湖月       镜湖月镜湖月 镜湖月镜湖月 镜湖月镜湖月     镜湖月镜湖月镜湖月 镜湖月镜湖月 镜湖月镜湖月   镜湖月镜湖月 镜湖月镜湖月镜湖月 镜湖月镜湖月   镜湖月镜湖月 镜湖月镜湖月 镜湖月镜湖月镜湖月    10、有序列表
 哈哈哈  哈哈哈  哈哈哈     哈哈哈  11、无序列表
 哈哈哈  哈哈哈  哈哈哈     哈哈哈  12、任务列表
 任务一  任务二  任务三     任务四  13、引用
 abcdefghijklmnopqrstuvwxyz
ABCDEFGHIJKLMNOPQRSTUVWXYZ
1234567890
镜湖月
 14、引用样式块
 Warning / 注意 This is H3 inside a block quote.
  Quote / 参考 This is H4 inside a block quote.
  Tips / 提示 This is H5 inside a block quote.
  Expand / 拓展 This is H6 inside a block quote.
 15、网络图片标识
16、图片错误显示
17、链接 logo
仅部分网站有对应 Logo，如下：
18、脚注
第一个脚注1，第二个脚注2，第三个脚注3
  第一个脚注的内容。&#160;&#x21a9;&#xfe0e;
 第二个脚注的内容。&#160;&#x21a9;&#xfe0e;
 第三个脚注的内容。&#160;&#x21a9;&#xfe0e;
   ]]></content></entry><entry><title>Booknotes - 《数据库系统原理》个人笔记</title><url>/tech/booknotes/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html"><![CDATA[题型  单选题：15 * 2 = 30 填空题：10 * 1 = 10 文字题：5 * 6 = 30 综合题：2 * 15 =30   考试时间：150 分钟
 设计题 - 关系代数、SQL 语句
综合题 - ER图、范式
一、数据库系统概述 1. 数据库基本概念 数据（Data） 是描述事物的符号记录，是指利用物理符号记录下来的、可以鉴别的信息。数据是信息存在的一种形式，只有通过解释或处理的数据才能成为有用的信息。
数据库（Database, DB） 是指长期储存在计算机中的有组织的、可共享的数据集合。
数据要按照一定的数据模型组织、描述和存储，具有较小的冗余度、较高的数据独立性，系统易于扩展，并可以被多个用户分享。
数据库管理系统（DBMS） 是专门用于建立和管理数据库的一套软件，介于应用程序和操作系统之间。
数据库管理系统及其功能
  数据定义功能
  数据操纵功能
  数据库的运行管理功能
  数据库的建立和维护功能
  数据组织、存储和管理功能
  其他功能
  数据库系统（DBS） 一个完整的数据库系统包括：
 数据库（DB） 数据库管理系统（DBMS） 数据库管理员（DBA） 应用程序 用户  2. 数据库管理技术的发展 三个发展阶段：
  人工管理阶段：数据不保存、应用程序管理数据、数据面向应用
  文件系统阶段：数据可长期存储；不能实现数据普通共享，只能文件级的共享、数据冗余
  数据库系统阶段，全是优点：
   数据集成（主要目的） 数据共享性高 数据冗余小 数据一致性 数据独立性高 实施统一管理与控制：主要包括数据的独立性、完整性、并发控制与故障恢复等，即数据库保护 减少应用程序开发与维护的工作量  3. 数据库系统的结构 3.1 数据库系统的结构分类 3.2 三级模式结构 模式（核心）：概念模式、逻辑模式；概念视图
外模式：子模式、用户模式；数据视图，即用户视图
内模式：存储模式、物理模式；内部视图或存储视图
三级模式结构的两层映像与数据独立性
映像就是一种对应规则，两层映像：
 模式/内模式映像：保证了数据与程序的物理独立性 外模式/模式映像：保证了数据与程序的逻辑独立性  3.3 客户/服务器结构  表示层：客户端、前台；主要完成与数据库使用者的交互任务 数据层：服务器、后台；主要负责数据管理  分为两种工作方式：单机方式、网络方式。
3.4 浏览器/服务器结构 是一种基于 web 应用的客户/服务器结构，也称为三层客户/服务器结构。
 表示层：UI 处理层：中间层 数据层  4. 数据模型 模型是现实世界特征的模拟和抽象表达。
数据模型是对现实世界数据特征的抽象，描述的是数据的共性内容。
数据模型是模型化数据和信息的工具，也是数据库系统的核心和基础。
数据模型需满足三点：
 比较真实的模拟现实世界 容易为人们理解 便于在计算机上实现  数据模型的特征 静态特征：数据的基本结构、数据间的联系、数据取值范围的约束
动态特征：指对数据可以进行符合一定规则的操作
数据模型组成的三大要素 数据结构：描述的是系统的静态特征，即数据对象的数据类型、内容、属性以及数据对象之间的联系。
数据操作：描述的是系统的动态特征。
数据约束：描述数据结构中数据间的语法和语义关联。
数据模型的分类   概念模型（现实世界抽象为信息世界）概念层数据抽象级别的最高层。也称为信息模型，主要用于数据库的设计阶段；
  逻辑模型（信息世界转化为机器世界）逻辑层是数据抽象级别的中间层。任何 DBMS 都是基于某种逻辑数据模型；
  物理模型（机器世界）物理层描述数据在存储介质上的组织结构，是逻辑模型的物理实现，是数据库最底层的抽象，设计目标是提高数据库性能和有效利用存储空间。
  概念模型 信息世界涉及的基本概念：
 实体（Entity）：具体的项目、职工等 属性（Attribute）：姓名、性别等 码或键（Key）：唯一标识 域（Domain）：属性的取值范围 实体型（Entity Type）：实体+属性 实体集（Tntity Set）：同类型实体 联系（Relationship）：实体之间的关系  数据模型中有**“型”（type）和“值”（value）**两个概念。
概念模型的表示方法（E-R 图）
 长方形表示实体型 椭圆表示属性 菱形表示联系  逻辑模型的类型 层次模型：（层次数据库）最早使用，有且仅有一个结点没有父结点，称作根节点，其他结点有且仅有一个父结点
网状模型：（网状数据库）以网状结构表示实体与实体间的联系，允许结点有多于一个父结点，允许无父结点
关系模型：（关系数据库）用二维表结构表示实体间的联系。建立在严格的数学概念的基础上、概念单一、存取路径对用户透明，有更高的数据独立性，更好的安全保密性
面向对象模型：即使概念模型又是逻辑模型，表达能力丰富，对象可复用、维护方便
二、关系数据库 1. 关系数据模型 组成要素：
  关系数据结构
  关系操作集合
  关系完整性约束
  1.1 关系数据结构 **表（Table）**也称为关系，由表名、列、若干行数据组成，表名必须唯一；
关系的三种类型：
 基本关系：基本表、基表，实际存在的表 查询表：虚表 视图表：虚表  列（Column）也称为字段（Field）或属性（Attribute），同一列数据类型相同。字段名必须唯一，不同表中可以出现相同的字段名。
属性的个数称为关系的元或度，列的值称为属性值，其取值范围称为值域。
行（Row）也称为元组（Tuple）或记录（Record），表中的数据按行存储。
元组（行）中的一个属性值，称为分量（Component）。
码或键（Key）：属性（或属性组）的值都能用来唯一标识该关系的元组，则称这些属性（或属性组）为该关系的码或键。
超码或超键（Super Key）：在码中去除某个属性，它仍然是这个关系的码。
候选码或候选键（Candidate Key）：在码中不能从中移去任何一个属性，否则它就不再是这个关系的码或键。候选码或候选键是这个关系的最小超码或超键。
主属性（Primary Attribure）或非主属性（Nonprimary Attribute）：包含在任何一个候选码中的属性称为称为主属性或码属性。
主码或主键（Primary Key）：在若干个候选码中指定一个唯一标识关系的元组（行）。由主观意愿指定。
全码或全键（All Key）：一个关系模式的所有属性集合是这个关系的主码或主键。
外码或外键（Foreign Key）：某个属性（或属性组）不是这个关系的主码或候选码，而是另一个关系的主码。
参照关系（Referencing Relation）和被参照关系（Referenced Relation）：参照关系也称为从关系，被参照关系也称为主关系，他们是指以外码相关联的两个关系。
域（Domain）：表示属性的取值范围。
数据类型（Data Type）：每个列都有相应的数据类型，它用于限制（或容许）该列中存储的数据。
关系模式（Relation Scheme）：表头，关系模式是型（Type），关系是值（Value），关系模式是对关系的描述。关系模式是静态的、稳定的，关系是动态的、随时间不断变化的。
关系数据库（Relation Database）：所有关系的集合，构成一个关系数据库。以关系模型作为数据的逻辑模型，并采用关系作为数据组织方式的一类数据库，其数据库操作建立在关系代数的基础上。
关系数据库对关系的限定/要求：
 每一个属性都是不可分解的（不允许表中有表）； 每一个关系仅仅有一种关系模式； 每一个关系模式中的属性必须命名，属性名不同； 同一个关系中不允许出现候选码或候选键值完全相同的元组； 在关系中元组的顺序（行序）是无关紧要的，可以任意交换； 在关系中属性的顺序（列序）是无关紧要的，可以任意交换。  1.2 基本的关系操作  查询（Query） 插入（Insert）：更新操作 删除（Delete）：更新操作 修改（Update）：更新操作  关系数据语言的分类：
  关系代数语言
  结构化查询语言（SQL）
  关系演算语言
  关系代数的运算符，任何一种操作都包含三大要素：操作对象、操作符、操作结果。
传统的集合运算：并、差、交、笛卡尔积
 并（UNION）：度和属性都相同的数据会合并（两个关系必须有相同的属性个数）； 差（DIFFRENCE）：以左侧为基础，减去共同拥有的部分（两个关系必须有相同的属性个数）； 交（INTERSECTION）：求出两个关系的公共部分（两个关系必须有相同的属性个数）； 笛卡尔积（CARTESIAN PRODUCT）：两关系元组个数相乘为结果元组个数，结果属性个数为两关系属性之和。  专门的关系运算：选择、投影、连接、除
 选择（SELECT，1个关系）：根据条件表达式选出来的行 投影（PROJECTION，1个关系）：根据属性序列选出来的列 连接（JOIN，2个关系）：笛卡尔积后，只留两关系中指定属性值相等的元组，去掉重复列  1.3 关系的完整性约束 数据库的数据完整性是指数据库中数据的正确性、相容性、一致性。
分类：
 实体完整性约束：主码的组成不能为空，主属性不能是空值（NULL） 参照完整性约束：定义外码和主码之间的引用原则，检验外码为空值（NULL）或已经存在 用户定义完整性约束：域完整性约束（针对某一应用环境的完整性约束）  执行插入操作，需要对以上三种都进行检验；
执行删除操作，需要检查是否被引用，一般只需要对被参照关系检查参照完整性约束；
执行更新操作，插入和删除两种情况的综合。
2. 关系数据库的规范化理论 不好的关系模式中可能存在的冗余和异常问题：
 数据冗余：指同一数据被反复存储的情况 更新异常：输入冗余造成的，多个内容更改使操作错误 插入异常 删除异常  2.1 函数依赖与关键字 函数依赖：在关系中，根据 X 的属性值能决定 Y 的属性值，Y 依赖于 X，记作 X-&gt;Y，X 称为决定因素。
分类：
 完全函数依赖: (X, Y)-&gt;Z 部分函数依赖: (X, Y)，X-&gt;Z 传递函数依赖: X-&gt;Y,Y-&gt;Z  2.2 范式与关系规范化过程 一个低一级范式的关系模式通过模式分解可以转换为若干个高一级范式的关系模式的集合，这种过程叫做规范化。
第一范式（1NF）：表中每一列的属性都不可再分；
第二范式（2NF）：表中每一列的属性都不可再分，且非主属性完全函数依赖于主属性；
第三范式（3NF）：表中每一列的属性都不可再分，且非主属性完全函数依赖于主属性，且每个非主属性都不传递函数依赖于主属性；
第三范式的改进形式（BCNF）
三、数据库设计 1. 数据库设计概述 数据库的生命周期 数据库分析与设计阶段：需求分析、概念设计、逻辑设计、物理设计
数据库实现与操作阶段：实现、操作与监督、修改与调整
数据库设计的目标  满足应用的功能需求：增删改查 良好的数据库性能：高效率存取和空间的节省  数据库设计的内容  数据库结构设计（静态的）：概念结构设计、逻辑结构设计、物理结构设计 数据库行为设计（动态的）：功能设计、事务设计、程序设计  数据库设计的方法  直观设计法：最原始的设计方法 规范设计法：基于第三范式的设计方法 计算机辅助设计法：辅助软件工程工具  2. 数据库设计的基本步骤 2.1 需求分析 数据库设计的起点。需求分析的步骤：
  确定数据库范围
  应用过程分析（的结果是数据库结构设计的重要依据）
  收集与分析数据
 静态结构：数据分类表、数据元素表 动态结构：任务分类表、数据特征操作表 数据约束：数据的安全保密性、数据的完整性、响应时间、数据恢复    编写需求分析报告
  2.2 概念结构设计 概念模型
 实体分析法（自顶向下法） 属性综合法（自底向上法）  2.3 逻辑结构设计 目标是将概念模型转换为等价的、且对特定 DBMS 所支持的数据模型的结构。
步骤：
 模型转换 子模式设计 编制应用程序设计说明 设计评价的任务  2.4 物理设计 任务是确定数据库在存储设备上的存储结构及存取方法，因 DBMS 的不同还可能包括建立索引和聚集，以及物理块大小、缓冲区个数和大小、数据压缩的选择。
2.5 数据库实施  加载数据：收集、分类、整理、校验、输入等 应用程序设计：应用编程 数据库试运行：工作人员熟悉并掌握系统，避免误操作  2.6 数据库运行与维护 目的是保证数据库的正常运行，系统维护中最困难的工作是：数据库重组与重构。
3. 关系数据库设计方法 3.1 关系数据库设计过程与各级模式 ]]></content></entry><entry><title>Andorid - Oppo安装Apk规避手机验证码</title><url>/tech/andorid/oppo%E5%AE%89%E8%A3%85apk%E8%A7%84%E9%81%BF%E6%89%8B%E6%9C%BA%E9%AA%8C%E8%AF%81%E7%A0%81/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">使用测试机安装开发版应用包时，会弹出密码弹框。测试机多人使用，不知道密码，该怎么绕过弹窗，从而装上包呢？
安装软件需要密码怎么关闭？经常使用OPPO 手机 的用户都知道，在安装第三方下载的软件时，需要输入密码进行验证身份，那安装软件需要密码怎么关闭呢，下面就和小编一起来看看吧！
　OPPO手机第三方软件下载的软件，在安装前需要先进性身份验证，也就是输入OPPO账户的登录密码，输入密码正确才可以验证成功，且此功能无法解除，因为系统设定就是如此，不能关闭和取消。
　如果不想要身份验证直接进行安装，只有在软件商店中下载软件，这样无需进行身份验证和安全检测就可以直接安装，还可以设置指纹验证，在进行身份验证时，直接是使用录入的指纹进行验证。
【使用指纹验证身份】
　1、首先我们需要手机有指纹模块，才可以设置指纹，如果没有指纹模块，那么只能使用密码或者手势密码验证。打开手机中的【设置】；
　2、找到【指纹、面部与密码】，点击进入；
　3、选择【指纹】进入设置指纹；
　4、如果设置了锁屏密码，需要先输入锁屏密码，再进入指纹设置，选择【指纹用于】选项；
　5、将【安装与短信扣费验证】选项开启，这样在进行软件安装时可以直接使用指纹验证。</content></entry><entry><title>Booknotes - 《C++程序设计》个人笔记</title><url>/tech/booknotes/c++%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html"><![CDATA[一、C++ 简介 程序设计语言分为：
 低级语言（机器语言、汇编语言） 中级语言 高级语言（C、C++等）  C++ 语言的主要特点：
 兼容 C 语言 面向对象（继承和多态） 引进了类和对象的概念  C++ 的基本数据类型
 bool：布尔值 char：字符型 int：整型 float：浮点型 double：双精度浮点型  注释的两种方式：
 单行注释（//） 多行注释（/*..*/）  编写 C++ 程序一般需要经过四个步骤，依次是：编辑、编译、连接、运行。
1. 头文件和命名空间 包含头文件需要使用 # include 指令，一条指令仅可以包含一个头文件，多个头文件需要使用多条指令。
通常使用尖括号 &lt;&gt; 包含系统头文件，会首先在系统设定的目录中寻找要包含的头文件；
使用双引号 &quot;&quot; 包含自定义的头文件，会在当前用户目录下或指令中指定的目录下寻找要包含的头文件。
# include &lt;iostream&gt; # include &#34;myCustom.h&#34; 常用的头文件：
 标准输入/输出流：&lt;iostream&gt; 标准文件流：&lt;fstream&gt; 标准字符串处理函数：&lt;string&gt; 标准数学函数：&lt;cmath&gt;  文件后缀 .cpp 是源程序文件，文件后缀 .h 是头文件。
命名空间的作用是消除同名引起的歧义。
using namespace std; // 自定义命名空间 namespace work { // work 为命名空间名  // 各种声明  class Foo {...}; func() {...}; }; // 使用方式一 using work::func(); // 使用方式二 推荐 using namespace work; Foo f; // 文件头声明后后面可以直接使用 func(); 2. 基本的输入/输出 当程序需要进行输入/输出信息时，需要包含头文件 
  cin：使用流提取运算符 &raquo; 从标准输入设备键盘取得数据；
  cout：使用流插入运算符 &laquo; 向标准输入设备屏幕输出信息。
  # include &lt;iostream&gt; using namespace std; int main() { int a, b; cin&gt;&gt;a&gt;&gt;b; cout&lt;&lt;&#34;a=&#34;&lt;&lt;a&lt;&lt;&#34;\tb=&#34;&lt;&lt;b&lt;&lt;endl; return 0; } 3. 强制类型转换运算符 static_cast 把表达式类型转换为类型名所指定的类型，static_cast 也可以省略。
double num = 3.12; n1 = static_cast&lt;int&gt;(num); // 强制类型转换 n2 = int(num); // 强制类型转换运算符的新形式 n3 = (int) num; // 强制类型转换运算符的旧形式 n4 = num; // 自动类型转换 4. 函数参数的默认值 C++ 语言规定，提供默认值必须按从右至左的顺序提供，有默认值的形参必须在最后。
void func(int a, int b=2, int c=3); // 正确 void func(int a=1, int b); // 错误，a 有默认值形参应该放在最后 void func(int a, int b=2, int c); // 错误，b 有默认形参应该放在最后 调用函数时，主调函数的实参与被调函数的形参按从左至右的顺序进行匹配对应。
int func(float x, char y=&#39;$&#39;, int a=9, char b=&#39;@&#39;); // 函数调用判断 func(3.14); // 正确，仅匹配 x，其他都有默认值 func(3.14, &#39;#&#39;); // 正确，匹配 x、y func(3.14, &#39;%&#39;, &#39;@&#39;); // 错误，第三个参数类型不对应，预期 int，实际是 char func(3.14, &#39;&amp;&#39;, 5, &#39;*&#39;); // 正确 func(3.14, , 5, &#39;*&#39;); // 错误，调用时的实参应该是连续排列的 5. 引用 引用相当于给变量起了个别名，对应于某个内存地址。如果给某个变量起了别名（不需要给它另开辟内存单元），相当于变量和这个引用都对应到同一地址。
// 在程序中定义变量的引用 // 类型名 &amp;引用名 = 同类型的某变量名; # include &lt;iostream&gt; using namespace std; int main() { int foo = 1; int &amp;ref = foo; // ref 是 foo 的引用，等价于 foo 	const int &amp;ref2 = foo; // 定义常引用  ref = 2; // foo=2; ref=2; ref2=2;  foo = 3; // foo=3; ref=3; ref2=3;  // ref2 = 4; 错误，不能使用常引用对所引用的变量进行修改  return 0; } 引用还可以用在函数中，既可以作为函数的参数使用，也可以作为函数的返回值使用。函数调用时参数的传递方式有两种：传值和传引用。
传值，传递对象的值。将实参的值拷贝给形参，函数执行过程中，都是对这个拷贝进行操作的，执行完毕后，形参的值并不拷贝回实参。也就是函数内部对形参的改变不会影响到函数外实参的值。
传引用，传递对象的首地址值。函数调用时，实参对象名传递给形参对象名，形参就成为实参的引用，他们是等价的，代表同一个对象。也可以看作是将实参的地址传递给了形参，函数内部对形参进行的改变，会影响到函数外实参的值。引用调用形参必须是引用。
// 函数中使用引用  /* 例 1：引用作为参数传递 */ # include &lt;iostream&gt; using namespace std; void func(int x, int y) { // 传值  int tmp; tmp = x; x = y; y = tmp; cout&lt;&lt;&#34;func(): &#34;&lt;&lt;&#34;a=&#34;&lt;&lt;x&lt;&lt;&#34; b=&#34;&lt;&lt;y&lt;&lt;endl; } void func_ref(int &amp;x, int &amp;y) { // 传引用  int tmp; tmp = x; x = y; y = tmp; cout&lt;&lt;&#34;func_ref(): &#34;&lt;&lt;&#34;a=&#34;&lt;&lt;x&lt;&lt;&#34; b=&#34;&lt;&lt;y&lt;&lt;endl; } int main() { int a = 10, b = 20; func(a, b); cout&lt;&lt;&#34;调用 func() 后: a=&#34;&lt;&lt;a&lt;&lt;&#34; b=&#34;&lt;&lt;b&lt;&lt;endl; // func(): a=20 b=10  // 调用 func() 后: a=10 b=20  // 形参的改变没有影响函数外实参的值  func_ref(a, b); cout&lt;&lt;&#34;调用 func_ref() 后: a=&#34;&lt;&lt;a&lt;&lt;&#34; b=&#34;&lt;&lt;b&lt;&lt;endl; // func_ref(): a=20 b=10  // 调用 func_ref() 后: a=20 b=10  // 形参的改变影响了函数外实参的值  return 0; } /* 例 2：引用作为返回值 */ # include &lt;iostream&gt; using namespace std; int a = 10, b = 20; int &amp;ref(int &amp;x) { // 返回值是引用  return x; } int main() { ref(a) = 30; cout&lt;&lt;&#34;a=&#34;&lt;&lt;a&lt;&lt;&#34; b=&#34;&lt;&lt;b&lt;&lt;endl; // a=30 b=20  ref(b) = 40; cout&lt;&lt;&#34;a=&#34;&lt;&lt;a&lt;&lt;&#34; b=&#34;&lt;&lt;b&lt;&lt;endl; // a=30 b=40  return 0; } 6. const 与指针共同使用  const 用于约束某值不变，在 C++ 中是用来修饰内置类型变量，自定义对象，成员函数，返回值，函数参数。
 // const 修饰普通变量 const int a = 10; int b = a; // 正确 a = 8; // 错误 不能改变 // a 被定义为一个常量 // 可以将 a 赋值给 b，但是不能对 a 再次赋值，不允许对常量重新赋值 const 修饰指针变量
 情况一：左定值，const 修饰指针指向的内容，则内容为不可变量。
 const int *p = 8;
如果唯一的 const 位于符号 * 的左侧，表示指针所指数据是常量，数据不能通过本指针改变，但可以通过其他方式修改。指针本身是变量，可以指向其他的内存单元。
 情况二：右定向，const 指针指向的内存地址不能被改变，但其内容可以改变。
 int a = 8; int *const p = &amp;a; *p = 9; // 正确，内容可改变 int b = 7; p = &amp;b; // 错误，指针地址不能被改变 如果唯一的 const 位于符号 * 的右侧，表示指针本身是常量，不能让该指针指向其他内存地址。指针所指的数据可以通过本指针进行修改。
 情况三：内容和指针内存地址都固定，不可改变。
 int a = 8; const int *const p = &amp;a; int const *const p = &amp;a; 如果在 * 的左右各有一个 const 时，表示指针和指针所指的数据都是常量，既不能让指针指向其他地址，也不能通过指针修改所指向的内容。
7. 内联函数 为避免频繁的函数调用，使用内联函数，在编译时不生成函数调用，而是将程序中出现的每一个内联函数表达式替换为该内联函数的函数体。使用内联函数会使最终可执行程序的体积增大，以空间消耗节省时间开销。
定义内联函数需要在函数头加上关键字 inline，定义在前，调用在后。内联函数主要应用于代码量少且频繁调用的函数，通常不建议内联函数体中包含循环语句或 switch 语句。
# include &lt;iostream&gt; using namespace std; inline int Max(int x, int y) { return x &gt; y ? x : y; } int main() { cout&lt;&lt;Max(20, 10)&lt;&lt;endl; cout&lt;&lt;Max(100, 500)&lt;&lt;endl; } 如果函数成员定义在类体内，则默认是内联函数。也可以在类体内部声明函数，并加上 inline 关键字，然后在类体外给出定义，这样也是内联函数。
# include &lt;iostream&gt; using namespace std; class A { public: inline void print1(); // 类体外定义需要加 inline 关键字  void print2() { // 默认内联函数  cout&lt;&lt;&#34;print inline 2&#34;&lt;&lt;endl; } }; void A::print1() { cout&lt;&lt;&#34;print inline 1&#34;&lt;&lt;endl; } int main() { A a; a.print1(); a.print2(); } 8. 函数重载 函数重载是指在程序的同一范围内声明几个功能类似的同名函数，提高代码可读性。必须要满足条件之一：
 参数表中参数类型不同（顺序不同也可） 参数表中参数个数不同  # include &lt;iostream&gt; using namespace std; int max(int x, int y) { return x &gt; y ? x : y; } int max(float x, float y) { return x &gt; y ? x : y; } int main() { cout&lt;&lt;max(5, 8)&lt;&lt;endl; cout&lt;&lt;max(3.14, 5.67)&lt;&lt;endl; } 如果两个函数的名字和参数表都是一样的，仅仅是返回值类型不同，则不符合函数重载的条件，编译报错。
// 错误的函数重载 float max(float x, float y); int max (float x, float y); 采用引用参数也不符合函数重载。
// 错误的函数重载 void print(double); void print(&amp;double); 避免产生二义性。
// 错误的函数重载 int sum(int a, int b, int c=0); int sum(int a, int b); sum(1, 2); // 编译错误，不知道调用哪个函数 9. 指针和动态内存分配 C++ 中使用 new 运算符实现动态内存分配。指针变量中保存的是一个地址，也称指针指向一个地址。
int *p; p = new int; // 动态分配 4 字节的内存空间 *p = 5; 使用 new 运算符也可以动态分配一个任意大小的数组。数组的长度是声明数组时指定的，不允许定义元素个数不明确的数组。
int pArr; int n; pArr = new int[n]; // 错误，元素个数不明确 pArr = new int[5]; // 分配了 5 个元素的整型数组 pArr[0] = 10; // 数组的第一个值 pArr[4] = 20; // 数组的最后一个值 使用 pArr[-1] 或者 pArr[5]时，下标会越界。不过在编译时，对于数组越界的错误不会提示，运行时报错。
使用 new 运算符动态申请的内存空间，需要在使用完毕后释放。使用 delete 运算符，用来释放动态分配的内存空间。
/* 释放指针变量动态内存 */ int foo = 6; int *p = &amp;foo; delete p; // 错误，delete 后面的指针必须是指向动态分配的内存空间（new）  int *q = new int; *q = 8; delete q; // 正确，q 指向动态分配的空间  /* 释放数组动态内存 */ int *p = new int[100]; delete []p; 10. string 对象 C++ 标准模板库中提供了 string 数据类型，专门处理字符串。string 是一个类，这个类型的变量称为 string 对象。
# include &lt;string&gt; // 需包含头文件  // 使用 string 类型初始化变量 string str = &#34;hello&#34;; string str2 = &#34;world&#34;; // 使用字符数组对 string 变量初始化 char name[] = &#34;hello, world.&#34;; string str = name; // 声明 string 对象数组 string citys[] = {&#34;beijing&#34;, &#34;shenzhen&#34;, &#34;shanghai&#34;}; str.empty() // 判断字符串是否为空 true false str.length() // 返回字符串长度 str.size() // 返回字符串占用空间字节数 str.append(&#34;haha&#34;) // 向字符串后面追加内容 str.insert(4, &#34;123&#34;) // 从字符串第四个位置插入内容 string 对象间可以相互赋值，不需要考虑空间是否足够的问题。
11. C++ 语言的程序结构 C++程序以 .cpp 作为文件扩展名，文件中包含若干个类和若干个函数。程序中必须有且仅有一个主函数 main()，这是程序执行的总入口。程序从主函数的开始处执行，直到结束。主函数可以出现在任何地方。
程序的结束通常是遇到了以下两种情况：
 主函数中遇到了 return 语句 执行到了主函数最后的括号  主函数可以调用其他函数，但其他函数不能调用主函数。主函数仅是系统执行程序时调用的。
二、面向对象的基本概念 结构化程序设计方法采用自顶向下、逐步求精及模块化思想，大问题化小问题。
编写程序时使用 3 种基本控制结构：顺序、选择、循环，强调程序的易读性。
面向对象程序设计方法就是使分析、设计和实现一个系统的方法 尽可能地接近 人们认识一个系统的方法。通常包括三方面：面向对象的分析、面向对象的设计、面向对象的程序设计。
对象具有两个特性：
 状态，指对象本身的信息（属性）； 行为，指对对象的操作。  通过对实物的抽象找出同一类对象的共同属性（静态特征）和行为（动态特征），从而得到类的概念。对象是类的一个具象，类是对象的一个抽象。C++ 中使用 对象名、属性、操作 三要素来描述对象。
面向对象的程序设计有四个基本特点：
  抽象：对象的属性和操作；
  封装：通过自定义类来支持数据封装和信息隐藏；
  继承：在已有类的基础上加上特殊的数据和函数构成新类，原来的类是基类（父类或超类），新类是派生类（子类）；
  多态 ：不同种类的对象具有名称相同的行为，但具体的实现方式却不同。通过函数重载及运算符重载实现的多态。
  1. 类的定义 类是具有唯一标识符的实体，类名不能重复。
标识符命名规则：字母、数字、下划线 的组合，但不能以数字开头，大小写敏感，不能和系统中的关键字重名。类定义以 ; 结束，大括号中的部分称为类体。
定义类时系统并不为类分配存储空间，类中声明的任何成员不能使用 auto、extern、register 关键字进行修饰。
类中的成员按功能划分：
 成员变量：对象的属性，个数不限，也称为数据成员。成员变量的声明方式与普通变量的声明方式相同； 成员函数：对象的操作，个数不限，声明方式与普通函数相同。  类中的成员按访问权限划分：
 公有成员(public)：公有的，可以在程序任何地方访问； 私有成员(private) ：私有的，仅能在本类内访问；未定义则默认为私有； 保护成员(protected)：保护的，能在本类内及子类中被访问。  成员函数可以定义在类体内，也可以定义在类体外。可以定义不是任何类的成员的函数，称为全局函数。
如果成员函数定义在类体外，则类体内必须要有函数原型声明，类体外定义函数必须使用类作用域运算符 ::。成员函数在内存中只有一份，可以作用于不同的对象，为类中各对象共享。
#include &lt;iostream&gt;using namespace std; class A { int foo = 1; // 定义成员变量，默认为私有成员  public: // 共有成员  void print(); // 类体内声明成员函数  A a; // 错误，不能定义本类的成员变量 }; // 注意类定义最后要加引号  void A::print() {}; // 类体外定义成员函数 2. 创建类对象的基本形式 class Test { public: Test(); Test(int x); }; /* 方法一 */ Test t1; // 类名 对象名; Test t2(5); // 类名 对象名(参数); Test t3 = Test(6); // 类名 对象名 = 类名(参数); Test t4, t5, t6(7), t7(10); // 扩展多个对象  /* 方法二 */ Test *p1 = new Test; // 类名 *对象指针名 = new 类名; Test *p2 = new Test(); // 类名 *对象指针名 = new 类名(); Test *p3 = new Test(5); // 类名 *对象指针名 = new 类名(参数); 用 new 创建对象时返回的是一个对象指针，指向创建的对象。创建的对象必须用 delete 来撤销。
// 声明对象的引用 Test t1, t2; // 定义对象 Test &amp;t = t1; // 声明对象的引用 ==&gt; 类名 &amp;对象引用名 = 对象; Test *p = &amp;t2; // 声明对象指针 ==&gt; 类名 *对象指针名 = 对象的地址; Test ts[3]; // 声明对象数组 ==&gt; 类名 对象数组名[数组大小]; 3. 访问对象的成员 定义了类对象后，就可以访问对象的成员。
#include &lt;iostream&gt;using namespace std; class Student { int age; public: char msg[40] = &#34;该学生年龄为：&#34;; int getAge(); void setAge(int); }; int Student::getAge() { return age; } void Student::setAge(int x) { age = x; } 3.1 通过对象访问  对象名.成员变量名 对象名.成员函数名(参数表)  int main() { Student s; s.setAge(18); // 成员函数  cout&lt;&lt;s.msg; // 成员变量  cout&lt;&lt;s.getAge()&lt;&lt;endl; return 0; } 3.2 通过指针访问 还可以使用指针或引用的方式来访问类成员，运算符 . 需要更换为 -&gt;。
int main() { Student s; Student *p = &amp;s; p -&gt; setAge(19); cout&lt;&lt;p-&gt;msg; cout&lt;&lt;p-&gt;getAge()&lt;&lt;endl; return 0; } 3.3 通过引用访问 // 与通过对象访问方式一样 int main() { Student s; Student &amp;sr = s; sr.setAge(20); cout&lt;&lt;sr.msg; cout&lt;&lt;sr.getAge()&lt;&lt;endl; return 0; } 4. 标识符的作用域与可见性 标识符是组成程序的最小成分之一。类名、函数名、变量名、常量名和枚举类型的取值等都是标识符。
标识符的作用域有：
 函数原型作用域：函数声明时的形参，这是最小的作用域； 局部作用域(块作用域)：代码块内，比如循环语句内变量； 类作用域 命名空间作用域  类作用域有三种访问方式：
 该类内的成员函数可以直接访问 在类外，通过类.成员或类::成员访问 在类外，通过类指针名-&gt;成员访问  具有命名空间作用域的变量称为全局变量。命名空间作用域有两种访问方式：
 命名空间名::成员; using 命名空间名::成员; using namespace 命名空间名;  作用域的隐藏规则如下：
  标识符声明在前，引用在后；
  同一作用域中，不能声明同名标识符；
  不同作用域中，可以声明同名标识符；
  在具有包含关系的两个作用域中，外层声明的标识符：
 如果没有在内层重新声明，外层标识符依然在内层可见； 如果在内层重新声明，则内层标识符隐藏外层同名标识符，这种机制称为隐藏规则。    类和对象进阶 1. 构造函数 基本数据类型的变量初始化：
 全局变量：声明时没有初始化，则系统自动为其初始化为 0； 局部变量：声明时没有初始化，则是一个随机值。  构造函数的作用 对象的初始化，需要通过构造函数机制，来为对象成员变量赋初值。构造函数是类中的特殊成员函数，给出类定义时，需要编写构造函数，如果没有，则默认由系统添加一个不带参数的构造函数。
声明对象后，使用 new 运算符为对象进行初始化，此时系统自动调用构造函数，完成对象的初始化工作，保证对象的初始状态是确定的。
构造函数的定义 定义一个类时，需要为类定义相应的构造函数。构造函数的函数名与类名相同，没有返回值。
一个类的构造函数可以有多个，允许重载，参数表一定不能完全相同。
当类中没有定义任何构造函数时，系统会自动添加一个参数表和函数体都为空的默认构造函数。因此，任何类都保证至少有一个构造函数。
class myDate {}; // 定义构造函数 方式一 无参数 myDate::myDate() { year = 1970; month = 1; day = 1; } // 方式二 有参数 函数体内赋值 myDate::myDate(int y, int m, int d) { year = y; month = m; day = d; } // 方式三 另一种写法 myDate::myDate(): year(1970), month(1), day(1) {} // 赋初始值 myDate::myDate(int y, int m, int d): year(y), month(m), day(d) {} // 从参数列表取值 构造函数的使用 创建类的任何对象时都一定会调用构造函数进行初始化。如果程序中声明了对象数组，那么数组的每个元素都是一个对象，每个元素都要调用构造函数进行初始化。如果通过类仅声明了指针，并未与对象相关，则不会调用构造函数。
// Test 是类 // 调用 4 次构造函数，声明指针不会调用 Test a(4), b[3], *p; 复制构造函数 复制构造函数是构造函数的一种，也称为拷贝构造函数。作用是使用一个已存在的对象去初始化另一个正在创建的对象。
例如：类对象间的赋值是由复制构造函数实现的。
复制构造函数只有一个参数，参数类型是本类的引用。一个类中可以写两个复制构造函数，函数的参数分别为 const 引用和非 const 引用。
以下三种情况会自动调用复制构造函数：
 用一个对象去初始化另一个对象 作为函数形参的对象 作为函数返回值的对象  class A{ public: int x; A(int t) {x = t;} // 有参构造函数  A(A &amp;t) {x = t.x;} // 复制构造函数一  A(const A &amp;t) {x = t.x;}; // 复制构造函数二 }; int main() { A a(10); cout&lt;&lt;a.x&lt;&lt;endl; // 10  A b(a); cout&lt;&lt;b.x&lt;&lt;endl; // 10  return 0; } 2. 析构函数 析构函数也是成员函数的一种，名字与类名相同，但要在类名前加一个 ~ 符号，以区别构造函数。
析构函数没有参数，也没有返回值。一个类中有且仅有一个析构函数。如果未定义，则系统自动生成函数体为空的默认析构函数。
析构函数的作用是做一些善后处理的工作，当对象消亡时自动调用析构函数。比如通过 new 创建的对象，使用 delete 释放空间时，首先调用对象的析构函数，然后再释放对象占用的空间。
对于对象数组，要为它的每个元素调用一个构造函数和析构函数。析构函数的调用执行顺序与构造函数正好相反。
#include &lt;iostream&gt;using namespace std; class Test { public: Test(); ~Test(); private: int *p; }; Test::Test() { cout&lt;&lt;&#34;Test 构造函数&#34;&lt;&lt;endl; p = new int[10]; // 指针指向堆空间 } Test::~Test() { cout&lt;&lt;&#34;Test 析构函数&#34;&lt;&lt;endl; delete p; // 必须显式的声明析构函数，释放空间，避免内存泄漏 } int main() { Test t; return 0; } 3. 变量及对象的生存期和作用域 全局变量
 未赋初值默认为 0，字符型变量为空字符 作用域：定义在函数外，可被所有文件的函数使用，其他文件使用需 extern 声明（外部链接） 生存期：整个程序执行期 不同文件的全局变量不可以重名  局部变量
 未赋初值，内容为随机 作用域：程序块内 生存期：程序块执行期 同一文件中全局变量和局部变量可以重名，在局部变量作用域内，全局变量不起作用  静态全局变量
 值只初始化一次，未赋初值默认为 0，字符型变量为空字符 作用域：本文件内，存储在全局数据区 生存期：整个程序执行期 不同文件的静态全局变量可以重名  静态局部变量
 值只初始化一次，未赋初值默认为 0，字符型变量为空字符 作用域：程序块内，存储在全局数据区 生存期：整个程序执行期  使用 new 创建的变量具有动态生存期，从声明处开始，直到用 delete 释放存储空间或程序结束。
类对象的生存期为调用构造函数开始到消亡时调用析构函数。
4. 类的静态成员 类的静态成员分为：
 静态成员变量 静态成员函数  类的静态成员只有一份保存在公用内存中，被类的所有对象共享。静态成员定义时，需要在前面添加 static 关键字。必须在类体外赋静态成员变量的初值。
#include &lt;iostream&gt;using namespace std; class Book { public: static int page_num; // 静态数据成员  static void print() { // 静态函数才能调用静态变量  cout&lt;&lt;&#34;已阅读到的页码为：&#34;&lt;&lt;page_num&lt;&lt;endl; } }; int Book::page_num = 100; // 静态数据成员的初值只能在类体外定义，不需要加 static 关键字  int main() { Book b1, b2, *b3; b1.print(); // 100  b2.print(); // 100 该类的所有对象公用一个静态数据成员  // 静态成员访问的三种方法  cout&lt;&lt;Book::page_num&lt;&lt;endl; // 类名.静态成员名  cout&lt;&lt;b1.page_num&lt;&lt;endl; // 对象.静态成员名  cout&lt;&lt;b3-&gt;page_num&lt;&lt;endl; // 对象指针-&gt;静态成员名  return 0; } 类的静态函数只能处理类的静态成员变量。静态函数与静态函数之间、非静态函数与非静态函数之间是可以相互调用的，非静态成员函数内可以调用静态成员函数，但静态成员函数内不能调用非静态成员函数。
5. 常量成员和常引用成员 在类中，可以使用关键字 const 定义成员变量、成员函数、类的对象。
类的常量成员变量必须进行初始化，且只能通过构造函数的成员初始化列表的方式进行。
定义常量成员变量或常量对象：const 数据类型 常量名 = 表达式;
定义常量函数：类型说明符 函数名(参数表) const;
对象被创建以后，常量成员变量的值不允许被修改，只可以读其值。对于常量对象，只能调用常量函数。
class A { public: void test() {} // 非常量成员函数  void demo() const {} // 常量成员函数 }; int main() { const A a; a.test(); // 错误 常量对象不能调用非常量成员函数  a.demo(); // 正确 } 6. 成员对象和封闭类 一个类的成员变量如果是另一个类的对象，则该成员变量称为成员对象。这两个类为包含关系，包含成员对象的类叫做封闭类。
#include &lt;iostream&gt;using namespace std; class Tyres { private: int radius, width; public: Tyres(int r, int w): radius(r), width(w) { cout&lt;&lt;&#34;Tyres(radius=&#34;&lt;&lt;radius&lt;&lt;&#34;, width=&#34;&lt;&lt;width&lt;&lt;&#34;)&#34;&lt;&lt;endl; }; }; class Car { private: int prices; Tyres tyres; public: Car(int p, int tr, int td); }; // 定义封闭类构造函数中，需要指明调用成员对象的哪个构造函数 如：Tyres(int, int) Car::Car(int p, int tr, int td): prices(p), tyres(tr, td) { cout&lt;&lt;&#34;Gogogo!&#34;&lt;&lt;endl; // 先调用成员对象的构造函数，在调用封闭类对象的构造函数 } int main() { Car car(100, 3, 6); return 0; } // Tyres(radius=3, width=6) // Gogogo! 7. 友元函数 设置私有成员的机制叫做隐藏。修改私有属性需要通过公有函数，函数内可以避免对对象的不正确操作或做一些其他修改。私有类型的成员在类外不能访问，通过类内公有函数可以访问但是比直接访问的效率低，所以提供了友元访问方式。
友元函数内部可以直接访问本类对象的私有成员，友元函数不是类的成员函数，但允许访问类中的所有成员。不受类中的访问权限关键字限制，可以把它放在类的公有、私有、保护部分，结果是一样的。友元的概念破坏了类的封装性和信息隐藏，但有助于数据共享，能够提高程序执行的效率。
友元函数使用关键字 friend 标识，定义方式 ：
  friend 返回值类型 函数名(参数表);
  friend 返回值类型 类名::函数名(参数表);
  一个函数可以声明为多个类的友元函数，一个类中也可以有多个友元函数。
友元类 如果将一个类 B 说明为类 A 的友元类，则类 B 中的所有函数都是类 A 的友元函数，在类 B 的所有成员函数中都可以访问类 A 中的所有成员。
声明格式为：friend class 类名;
友元类的关系是单向的，友元类的关系不能传递。一般不把整个类说明为友元类。
8. this 指针 当调用一个成员函数时，系统自动向它传递一个隐含的参数，该参数是一个指向调用该函数的对象的指针，称为 this 指针，从而使成员函数知道对哪个对象进行操作。
  非静态成员函数内部可以直接使用 this 关键字，代表指向该函数所作用的对象的指针
  静态成员函数没有 this 指针
  一般情况下，可以省略 this-&gt;，系统采用默认设置
  运算符重载 运算符重载的概念 算术运算符包括：+ - * / %，通常只能用于对基本数据类型的常量或变量进行运算，而不能用于对象之间的运算。运算符重载可以使运算符也能用来操作对象。
重载运算符有一个返回类型和一个参数列表，这样的函数称为运算符函数。运算符可以被重载为全局函数，也可以被重载为类的成员函数。声明为全局函数时，通常应是类的友元。运算符函数是一种特殊的友元函数或成员函数。
重载运算符的规则  符合原有的用法习惯 不能改变运算符原有的语义 不能改变运算符操作数的个数及语法结构 不能创建新的运算符 重载运算符() [] -&gt; = 时，只能重载为成员函数，不能为全局函数 不能改变运算符用于基本数据类型对象的含义  myComplex operator+(const myComplex &amp; c1, const myComplex &amp; c2) { return myComplex(c1.real + c2.real, c1.imag + c2.imag); } myComplex operator+(const myComplex&amp; c1, double r) { return myComplex(c1.real + r, c1.imag); } myComplex operator+(double r, const myComplex&amp; c1) { return myComplex(r + c1.real, c1.imag); } myComplex operator-(const myComplex&amp; c1, const myComplex&amp; c2) { return myComplex(c1.real - c2.real, c1.imag - c2.imag); } myComplex operator-(const myComplex&amp; c1, double r) { return myComplex(c1.real - r, c1.imag); } myComplex operator-(double r, const myComplex&amp; c1) { return myComplex(r - c1.real, -c1.imag); } 重载赋值运算符 赋值运算符 = 只能重载为成员函数。
myComplex&amp; myComplex::operator=(const myComplex&amp; c1) { this-&gt;real = c1.real; this-&gt;imag = c1.imag; return *this; } myComplex&amp; myComplex::operator=(double r) { this-&gt;real = r; this-&gt;imag = 0; return *this; } 同类对象之间可以通过赋值运算符进行赋值。如果没有经过重载，= 的作用就是将赋值号右侧对象的值一一赋值给左侧的对象。这相当于值的拷贝，称为浅拷贝。重载赋值运算符后，赋值语句的功能是将一个对象中指针成员变量指向的内容复制到另一个对象指针成员变量指向的地方，这样的拷贝叫深拷贝。
重载流插入运算符和流提取运算符  流插入运算符(cout) &lt;&lt; 流提取运算符(cin) &gt;&gt;  只能采用友元函数重载的方式。
#include &lt;iostream.h&gt;  class Test { private: int i; float f; char ch; public: test(int a=0, float b=0, char c=&#39;\0&#39;) {i=a; f=b; ch=c;} friend ostream &amp;operator&lt;&lt;(ostream &amp;, test); // 必须重载为类的友元  friend istream &amp;operator&gt;&gt;(istream &amp;, test &amp;); // 必须重载为类的友元 }; ostream &amp;operator&lt;&lt;(ostream &amp;stream, test obj) { stream&lt;&lt;obj.i&lt;&lt;&#34;,&#34;; // stream 是 cout 的别名  stream&lt;&lt;obj.f&lt;&lt;&#34;,&#34;; stream&lt;&lt;obj.ch&lt;&lt;endl; return stream; } istream &amp;operator&gt;&gt;(istream &amp;t_stream, test &amp;obj) { t_stream&gt;&gt;obj.i; // t_stream 是 cin 的别名  t_stream&gt;&gt;obj.f; t_stream&gt;&gt;obj.ch; return t_stream; } void main() { test A; operator&lt;&lt;(cout, &#34;Input as i f ch:&#34;); operator&gt;&gt;(cin, A); // 45,8.5,&#39;W’  operator&lt;&lt;(cout,A); // 45,8.5,&#39;W’  return 0; } 重载自增、自减运算符   自增运算符：++k k++
  自减运算符：--k k--
  按照定义，++k 返回被修改后的值，k++ 返回被修改前的值。
# include &lt;iostream&gt; using namespace std; class Demo { private: int n; public: Demo(int i=0): n(i) {} operator int() {return n;} Demo &amp; operator++(); // 用于前置形式  Demo operator++(int); // 用于后置形式 }; Demo &amp;Demo::operator++() { n++; return *this; } Demo Demo::operator++(int k) { Demo tmp(*this); // 记录修改前的对象  n++; return tmp; // 返回修改前的对象 } int main() { Demo d(10); // 后置形式两种写法  cout&lt;&lt;(d++)&lt;&lt;endl; // 10  cout&lt;&lt;d&lt;&lt;endl; // 11  d.operator++(0); // 11 不输出 有参代表后置形式  cout&lt;&lt;d&lt;&lt;endl; // 12  // 前置形式两种写法  cout&lt;&lt;(++d)&lt;&lt;endl; // 13  d.operator++(); // 14 不输出 无参代表前置形式  cout&lt;&lt;d&lt;&lt;endl; // 14  return 0; } 类的继承与派生 通过已有的类建立新类的过程，叫做类的派生。
 原来的类称为基类、父类、一般类； 新类称为派生类、子类、特殊类。  派生类继承于基类，基类派生了派生类，派生类可以作为基类再次派生新的派生类，这种集合称作类继承层次结构。
使用基类派生新类时，除构造函数和析构函数外，基类的所有成员自动成为派生类的成员，包括基类的成员变量和成员函数。派生类中需要定义自己的构造函数和析构函数，可以增加基类中没有的成员，还可以重新定义或修改基类中已有的成员，包括可以改变基类中成员的访问权限。
// 基类与派生类的定义 class Base { int a, b; }; class Derived: public Base { int c; }; 派生类占用的存储空间大小，等于基类成员变量占用存储空间大小 加上 派生类对象自身成员变量占用的存储空间大小。对象占用的存储空间包含对象中各成员变量占用的存储空间。可以使用 sizeof() 计算对象占用的字节数。
基类有友元，派生类不会继承友元类或友元函数。如果基类是某类的友元，那么这种友元关系是继承的。如果基类中的成员是静态的，在派生类中静态属性随静态成员被继承。如果基类的静态成员是公有的或者保护的，则他们被其派生类继承为派生类的静态成员。
C++ 允许从多个类派生一个类，即一个派生类可以同时有多个基类。这称为多重继承。相应地，从一个基类派生一个派生类的情况，称为单继承或单重继承。
#include &lt;iostream&gt;using namespace std; class C1 {}; class C2 {}; class C3: public C1, public C2 { cout&lt;&lt;&#34;多重继承&#34;&lt;&lt;endl; };  如果派生类中新增了同名成员，则派生类成员将隐藏所有基类的同名成员，使用派生类对象名.成员名 或 派生类对象指针-&gt;成员名 的方式可以唯一标识和访问派生类的新增成员。这种情况下，不会产生二义性。 如果派生类中没有新增同名成员，使用上面的方式访问成员时，系统无法判断到底调用哪个基类的成员，产生二义性，为避免这种情况，必须通过 基类名和作用域分辨符 来标识成员。当访问派生类对象中某个变量时，添加 基类:: 作为前缀，指明访问从哪个基类集成来的成员。  访问控制  public：共有继承 private：私有继承 protected：保护继承  类的共有继承
   各成员 派生类中 基类与派生类外     基类的公有成员 直接访问 直接访问   基类的保护成员 直接访问 调用公有函数访问   基类的私有成员 调用公有函数访问 调用公有函数访问   从基类继承的公有成员 直接访问 直接访问   从基类继承的保护成员 直接访问 调用公有函数访问   从基类继承的私有成员 调用公有函数访问 调用公有函数访问   派生类中定义的公有成员 直接访问 直接访问   派生类中定义的保护成员 直接访问 调用公有函数访问   派生类中定义的私有成员 直接访问 调用公有函数访问    类的私有继承
    第一级派生类中 第二级派生类中 基类与派生类外     基类的共有成员 直接访问 不可访问 不可访问   基类的保护成员 直接访问 不可访问 不可访问   基类的私有成员 通过公有函数访问 不可访问 不可访问    类型兼容规则 在公有派生的情况下，有以下三条兼容规则：
 派生类的对象可以赋值给基类对象； 派生类的对象可以用来初始化基类引用； 派生类对象的地址可以赋值给基类指针，即派生类的指针可以赋值给基类的指针。  派生类的构造函数与析构函数 在执行一个派生类构造函数之前，总是先执行基类的构造函数。派生类对象消亡是时，先执行派生类的析构函数，在执行基类的析构函数。
#include &lt;iostream&gt; using namespace std; //基类 class BaseClass { protected: int v1,v2; public: BaseClass(); BaseClass(int,int); ~BaseClass(); }; BaseClass::BaseClass() { cout&lt;&lt;&#34;BaseClass 无参构造函数&#34;&lt;&lt;endl; } BaseClass::BaseClass(int m, int n) { v1=m; v2=n; cout&lt;&lt;&#34;BaseClass 无参构造函数&#34;&lt;&lt;endl; } BaseClass::~BaseClass() { cout&lt;&lt;&#34;BaseClass 析构函数&#34;&lt;&lt;endl; } // 派生类 class DerivedClass:public BaseClass { private: int v3; public: DerivedClass(); DerivedClass(int); DerivedClass(int,int,int); ~DerivedClass(); }; DerivedClass::DerivedClass() { cout&lt;&lt;&#34;DerivedClass 无参构造函数&#34;&lt;&lt;endl; } DerivedClass::DerivedClass(int k):v3(k) { cout&lt;&lt;&#34;DerivedClass 带1个参数构造函数&#34;&lt;&lt;endl; } DerivedClass::DerivedClass(int m, int n, int k):BaseClass(m, n), v3(k) { cout&lt;&lt;&#34;DerivedClass 带3个参数构造函数&#34;&lt;&lt;endl; } DerivedClass::~DerivedClass() { cout&lt;&lt;&#34;DerivedClass 析构函数&#34;&lt;&lt;endl; } int main() { cout&lt;&lt;&#34;无参对象的创建&#34;&lt;&lt;endl; BaseClass b; DerivedClass d; return 0; } /* 输出内容： 无参对象的创建 BaseClass 无参构造函数 BaseClass 无参构造函数 DerivedClass 无参构造函数 DerivedClass 析构函数 BaseClass 析构函数 BaseClass 析构函数 */ 派生类构造函数执行顺序一般次序如下：
 调用基类构造函数，调用顺序按照它们被继承时声明的顺序（从左向右） 对派生类新增的成员变量初始化，调用顺序按照它们在类中声明的顺序 执行派生类的构造函数体重的内容  在派生类构造函数执行之前，要先执行两个基类的构造函数，执行次序依据定义派生类时所列基类的次序而定。
类之间的关系 使用已有类编写新的类有两种方式：
 继承关系：也称为 is a 关系或 是 关系 组合关系：也称为 has a 关系或 有 关系，表现为封闭类  封闭类：如果一个类的成员变量是另一个类的对象，则为封闭类。
如果基类为封闭类，函数调用顺序如下：
 构造函数：对象成员构造函数 - 基类构造函数 - 派生类构造函数 析构函数：派生类析构函数 - 基类析构函数 - 对象成员析构函数  互包含关系的类，两个类相互引用，这种情况称为循环依赖。
多层次的派生  派生类沿着类的层次自动向上继承它所有的直接和间接基类的成员，类之间的继承关系具有传递性 派生类的成员包括派生类自己定义的成员、直接基类中定义的成员及所有间接基类中定义的全部成员 当生成派生类的对象时，会从最顶层的基类开始逐层往下执行所有基类的构造函数，最后执行派生类自身的构造函数；当派生类对象消亡时，会先执行自身的析构函数，然后自底向上依次执行各个基类的析构函数  一个类不能被多次说明为某个派生类的直接基类，可以不止一次地称为间接基类。
基类与派生类指针的相互转换 在公有派生的情况下，因为派生类对象也是基类对象，所以派生类对象可以赋给基类对象。
对于指针类型，可以使用基类指针指向派生类对象，也可以将派生类的指针直接赋值给基类指针。但即使基类指针指向的是一个派生类的对象，也不能通过基类指针访问基类中没有而仅在派生类中定义的成员函数。
多态与虚函数 多态的基本概念 多态 多态分为：
 编译时多态：函数的重载（包括运算符重载）。编译时根据实参确定应该调用哪个函数，编译阶段的多态称为静态多态，一个对象调用同名函数； 运行时多态：和继承、虚函数等概念有关，主要指运行时多态，运行阶段的多态称为动态多态，不同对象调用同名函数。  在类直接满足 赋值兼容的前提下，实现动态绑定必须满足两个条件：
 必须声明虚函数 通过基类类型的引用或指针调用虚函数  多态实现原理：多态的关键在于通过基类指针或引用调用一个虚函数时，编译阶段不能确定到底调用的是基类还是派生类的函数，运行时才能确定。
派生类对象占用的存储空间大小，等于基类成员变量占用的存储空间大小加上派生类对象自身成员变量占用的存储孔家你大小。
虚函数  在函数声明前加了 virtual 关键字的成员函数 只能在类定义中的成员函数声明处使用，类体外编写函数体时不加该关键字 不能声明为虚函数的有：全局函数（非成员函数）、静态成员函数、内联函数、构造函数和友元函数 不要在构造函数和析构函数中调用虚函数 最好将基类的析构函数声明为虚函数 包含虚函数的类称为 多态类 派生类重写基类的虚函数实现多态，要求函数名、参数列表和返回值类型要完全相同 基类中定义了虚函数，在派生类中该函数始终保持虚函数的特性  #include &lt;iostream&gt;using namespace std; class Base1 { public: void show() { cout&lt;&lt;&#34;Base1::show()&#34;&lt;&lt;endl; } }; class Base2: public Base1 { public: void show() { cout&lt;&lt;&#34;Base2::show()&#34;&lt;&lt;endl; } }; class Derived: public Base2 { public: void show() { cout&lt;&lt;&#34;Derived::show()&#34;&lt;&lt;endl; } }; // 通过基类类型的指针或引用调用 void func(Base1 *p) { p -&gt; show(); } int main() { // b1 是基类，b2 继承自 b1，d 继承自 b2  // 通过子类对象赋值给基类时，调用同名方法都会变成基类的方法  // 没有实现多态  Base1 b1; Base2 b2; Derived d; func(&amp;b1); func(&amp;b2); func(&amp;d); return 0; } /* Base1::show() Base1::show() Base1::show() */ 通过虚函数实现多态
class Base1 { public: virtual void show() { cout&lt;&lt;&#34;Base1::show()&#34;&lt;&lt;endl; } }; /* 只需要修改基类的同名方法为虚函数，派生类中自然继承 再次执行，输出结果为：实现多态 Base1::show() Base2::show() Derived::show() */ 虚析构函数 如果一个基类指针指向的对象是用 new 运算符动态生成的派生类对象，那么释放该对象所占用的空间时，如果仅调用基类的析构函数，则只会完成该析构函数内的空间释放，不会涉及派生类析构函数内的空间释放，容易造成内存泄漏。
使用虚析构函数的目的是为了在对象消亡时实现多态。
声明虚析构函数格式：virtual ~类名();
 虚析构函数没有返回值类型，没有参数 如果一个类的析构函数是虚函数，那么由它派生的所有子类的析构函数都是虚析构函数  #include&lt;iostream&gt;using namespace std; class Base { public: Base() { cout&lt;&lt;&#34;Base::构造函数&#34;&lt;&lt;endl; } // 虚析构函数，子类自动也变为虚析构函数  virtual ~Base() { cout&lt;&lt;&#34;Base::析构函数&#34;&lt;&lt;endl; } }; class Derived: public Base { public: int w,h; //两个成员  Derived() { cout&lt;&lt;&#34;Derived::构造函数&#34;&lt;&lt;endl; w=4; h=7; } ~Derived() { cout&lt;&lt;&#34;Derived::析构函数&#34;&lt;&lt;endl; } }; int main() { Base *p = new Derived(); //使用基类指针指向new创建的派生类对象  delete p; return 0; } /* 输出： Base::构造函数 Derived::构造函数 Derived::析构函数 // 如果声明虚析构函数的话，就不会调用派生类的析构函数了 Base::析构函数 */ 纯虚函数 纯虚函数的作用相当于一个统一的接口形式，表明在基类的各派生类中应该有这样的一个操作，然后在各派生类中具体实现与本派生类相关的操作。
纯虚函数是声明在基类中的虚函数，没有具体定义。
声明格式：virtual 函数类型 函数名(参数表) = 0;
抽象类 包含纯虚函数的类称为抽象类。因为抽象类中含有未完成的函数定义，所以不能实例化一个对象。
抽象类的派生类中，如果没有给出全部纯虚函数的定义，则该派生类继续是抽象类。
虽然不能创建抽象类对象，但是可以定义抽象类的指针和引用。
// 假设 Foo 为抽象类 Foo *p; 虚基类 #include &lt;iostream&gt; using namespace std; class A { public: int a; void showa() { cout&lt;&lt;&#34;a=&#34;&lt;&lt;a&lt;&lt;endl; } }; class B: virtual public A { // 对类 A 进行了虚继承 public: int b; }; class C: virtual public A { //对类 A 进行了虚继承 public: int c; }; class D: public B, public C { // 派生类 D 的两个基类 B、C 具有共同的基类 A, // 采用了虚继承，从而使类 D 的对象中只包含着类 A 的 1 个实例 public: int d; }; int main() { D d; // 说明派生类D的对象  d.a = 11; // 若不是虚继承，此行会出错!因为&#34;D::showa&#34;具有二义性  d.b = 22; d.showa(); // 输出 11，若不是虚继承，D::showa 具有二义性  cout&lt;&lt;&#34;d.b=&#34;&lt;&lt;d.b&lt;&lt;endl; //输出Dobj.b=22 } 消除二义性。
输入/输出流 流类简介 C++中凡是数据从一个地方传输到另一个地方的操作都是流的操作。
 读操作：被称为(从流中)“提取” 写操作：被称为(向流中)“插入”  为了避免多重继承的二义性，从 ios 派生 istream 和 ostream 时，均使用了 virtual 关键字（虚继承）。
 istream：提供了流的大部分输入操作，对系统预定义的所有输入流重载提取运算符 &gt;&gt; ostream：对系统定义的所有输出流重载插入运算符 &lt;&lt;  iostream 类库 常见的头文件：
 iostream：包含操作所有输入/输出流所需要的基本信息 iomanip：setw()、setprecision()、setfill()、setbase() 等 fstream：包含处理文件的有关信息，童工建立文件、读/写文件的各种操作接口  iostream 头文件 iostream 包含操作所有输入/输出流所需的基本信息，含有 4 个标准流对象：
 cout：标准输出流，与标准输出设备（显示器）相关联，可以被重定向为向文件里写入数据； cin：标准输入流，与标准输入设备（键盘）相关联，可以被重定向为从文件中读取数据； cerr：输出错误信息，与标准错误信息输出设备（显示器）相关联（非缓冲），不能被重定向； clog：输出错误信息，与标准错误信息输出设备（显示器）相关联（缓冲），不能被重定向。  // 将标准输出cout重定向到文件 #include &lt;iostream&gt;using namespace std; int main() { int x,y; cin&gt;&gt;x&gt;&gt;y; freopen(&#34;test.txt&#34;, &#34;w&#34;, stdout); // 将标准输出重定向到文件test.txt  if(y==0) // 除数为0, 则输出错误信息 	cerr&lt;&lt;&#34;error.&#34;&lt;&lt;endl; else cout&lt;&lt;x&lt;&lt;&#34;/&#34;&lt;&lt;y&lt;&lt;&#34;=&#34;&lt;&lt;x/y&lt;&lt;endl; return 0; } 函数 freopen() 的功能是将 stream 按 mode 指定的模式重定向到路径 path 指向的文件。
iomanip C++ 进行 I/O 格式控制的方式一般有使用流操纵符、设置标志字和调用成员函数。
流操纵符 不带参数的流操纵符：
 endl（O）：换行符，输入一个换行符，清空流 ends（O）：输出字符串结束，清空流 flush（O）：清空流缓冲区 dec（I/O，默认）：十进制形式 hex（I/O）：十六进制形式 oct（I/O）：八进制形式 ws（O）：提取空白字符  包含格式化 I/O 的带参数流操纵符，可用于指定数据输入/输出的格式。例如：
 setw(int w)：指定输出宽度为 w 个字符，或输入字符串时读入 w 个字符，一次有效 setprecision()：设置有效数字位数，全部数字个数 setfill()：指定输出宽度，宽度不足时用空格填充 setbase()：输入表示数值进制的前缀 setiosflags()：设置标志字  进制标识：
 十六进制常量——前缀0x，0~9、a~f 十进制常量——无前后缀，0~9 八进制常量——前缀0，0~7；080就是非法数 长整型常量——后缀L或l  标志字 #include&lt;iostream&gt; #include&lt;iomanip&gt; using namespace std; int main() { double x=12.34; cout&lt;&lt;&#34;1)&#34;&lt;&lt;setiosflags(ios::scientific|ios::showpos)&lt;&lt;x&lt;&lt;endl; // ios::scientific 科学计数法 showpos 正数前加 “+” 号  // 输出：+1.234000e+001  cout&lt;&lt;&#34;2)&#34;&lt;&lt;setiosflags(ios::fixed)&lt;&lt;x&lt;&lt;endl; // fixed 定点形式表示浮点数  // +12.34  cout&lt;&lt;&#34;3)&#34;&lt;&lt;resetiosflags(ios::fixed)&lt;&lt;setiosflags(ios::scientific|ios::showpos)&lt;&lt;x&lt;&lt;endl; // +1.2340003+001  cout&lt;&lt;&#34;4)&#34;&lt;&lt;resetiosflags(ios::showpos)&lt;&lt;x&lt;&lt;endl; // 清除要输出正号的标志  // 1.234000e+001  return 0; } 调用 cout 的成员函数    成员函数 作用相同的流操纵符     precision(int np) setprecision(np)   width(int nw) setw(nw)   fill(char cFill) setfill(cFill)   setf(long iFlags) setiosflags(iFlags)   unsetf(long iFlags) resetiosflags(iFIags)    cout.put(&#39;d&#39;); // cout&lt;&lt;&#39;d&#39;，向输入流中插入一个字符 cout.write(); // 向输出流汇总插入 数据块 调用 cin 的成员函数 // get() 函数 while((ch=cin.get()) != EOF) //当文件没有结束时继续进行循环 { cout.put(ch); } // getline() 函数，从输入流中读取一行字符 // 函数原型 istream &amp; getline(char * buf, int bufSize); // 读取 size-1 个字符到缓冲区 或到 \n 截止 istream &amp; getline(char * buf, int bufSize, char delim); // 或到 delim 截止  // eof() 函数，用于判断输入流是否已经结束，返回 true 表示输入结束 // 测试是否到文件尾，到文件返回 1，否则返回 0 bool eof( ); // ignore() 函数，跳过输入流中的 n 个字符 或 delim 及其之前的所有字符 // cin.ignore() == cin.ignore(1, EOF) 默认值，即跳过一个字符 istream &amp; ignore(int n=1, int delim=EOF); // peek() 函数，返回输入流中的当前字符，只看一眼 // 输入流已经结束的情况下，cin.peek() 返回 EOF int peek( ); 文件和操作 文件基本概念和文件流类 根据文件数据的编码方式不同分为：
  文本文件
  二进制文件
  根据存取方式不同分为：
 顺序存取文件：按照文件中数据存储次序进行顺序操作，访问第 i 个数据，首先得访问 i-1 随机存取文件：根据应用需要，通过命令移动位置指针直接定位到文件位置  对文件的基本操作分为：
 读文件：将文件中的数据读入内存之中，也称为输入 写文件：将内存中的数据存入文件之中，也称为输出  C++ 标准类库中有 3 个流类可以用于文件操作，统称为文件流类，分别如下：
 ifstream：用于从文件中读取数据 ofstream：用于向文件中写入数据 fstream：即可用于读取数据，也可用于写入数据  使用这 3 个流类，需要包含 fstream 头文件。
在程序中，要使用一个文件，必须包含3个基本步骤：
 打开(open)文件 操作文件：对文件进行读/写 关闭(close)文件  C++ 文件流类有相应的成员函数来实现打开、读、写、关闭等文件操作。
打开和关闭文件 打开文件的方式有以下两种:
 先建立流对象，然后调用 open() 函数连接外部文件。格式如下: 流类名 对象名; 对象名.open(文件名, 模式); 调用流类带参数的构造函数，建立流对象同时连接外部文件，格式如下： 流类名 对象名(文件名，模式);  // 输入：方式一 ifstream inFile; //建立输入文件流对象 inFile.open(&#34;data.txt&#34;, ios::in); //连接文件，指定打开模式，默认为 in // 输入：方式二 ifstream inFile(&#34;data.txt&#34;, ios::in); // 输出：方式一 ofstream outFile; //建立输入文件流对象 outFile.open(&#34;c:\\c2019\\newfile&#34;,ios::out | ios::binary); // 二进制文件 // 输出：方式二 ofstream outFile(&#34;c:\\c2019\\newfile&#34;,ios::out | ios::binary); 使用 fstream 中的成员函数 close() 关闭文件。
inFile.close(); outFile.close(); 文件读写操作 读写文本文件 /* 键盘输入学生的学号、姓名和成绩，存入 score.txt 中 每行保存一名学生的成绩信息，各项数据之间用空格分隔 */ #include &lt;iostream&gt;#include &lt;fstream&gt;using namespace std; int main() { char id[11], name[21]; int score; // 写文件  ofstream outFile; outFile.open(&#34;score.txt&#34;, ios::out); // 写方式打开文件  if (!outFile) { cout&lt;&lt;&#34;创建文件失败！&#34;&lt;&lt;endl; return 0; } cout&lt;&lt;&#34;请输入：学号 姓名 成绩（以 Ctrl+Z 结束！）&#34;; while(cin&gt;&gt;id&gt;&gt;name&gt;&gt;score) outFile&lt;&lt;id&lt;&lt;&#34; &#34;&lt;&lt;name&lt;&lt;&#34; &#34;&lt;&lt;score&lt;&lt;endl; //向流中插入数据  outFile.close(); // 读文件  iftream inFile(&#34;score.txt&#34;, ios:in); // 读方式打开文件  if (!inFile) { cout&lt;&lt;&#34;打开文件失败！&#34;&lt;&lt;endl; return 0; } cout&lt;&lt;&#34;学生学号 姓名\t\t\t成绩\n&#34;; while(inFile&gt;&gt;id&gt;&gt;name&gt;&gt;score) // 读入文件 	cout&lt;&lt;left&lt;&lt;setw(10)&lt;&lt;id&lt;&lt;&#34; &#34;; cout&lt;&lt;setw(20)&lt;&lt;name&lt;&lt;&#34; &#34;; cout&lt;&lt;setw(3)&lt;&lt;right&lt;&lt;score&lt;&lt;endl; inFile.close( ); return 0; } 读写二进制文件 需要用 binary 方式打开二进制文件。
// 用 ostream::write() 成员函数写文件 ostream &amp; write(char * buffer, int nCount); // e.g. ofstream outFile(&#34;students.dat&#34;,ios::out|ios::binary); outFile.write((char*)&amp;stu, sizeof(stu)); // 用 istream::read() 成员函数读文件 istream &amp;read(char * buffer, int nCount); // 用 ostream::gcount() 成员函数得到读取字节数 int gcount(); 用成员函数 put() 和 get() 读写文件 // 不带参数，提取一个字符并返回，当遇到文件结束符，返回 EOF int get(); // 从指定输入流中提取一个字符 istream&amp; get(char &amp;rch); // 从流的当前字符开始，读取 nCount-1 个字符，到 delim 结束 istream&amp; get(char *pch, int nCount, char delim=’\n’); // put 向输出流中插入一个字节 ostream&amp; put(char ch); 文本文件与二进制文件异同 在输入/输出过程中，系统要对内外存的数据格式进行相应转换。
  文本文件：以文本形式存储数据
 优点：具有较高的兼容性 缺点：1.存储一批纯数值信息时，要人为地添加分隔符；2.不便于对数据进行随机访问。    二进制文件：以二进制形式存储数据
 优点：便于对数据实行随机访问 (相同数据类型的数据所占空间的大小均是相同的，不必在数据之间人为地添加分隔符)，在输入/输出过程中，系统不需要对数据进行任何转换。 缺点：数据兼容性差    通常纯文本信息(如字符串)以文本文件形式存储，而将数值信息以二进制文件形式存储。
随机访问文件 顺序文件：如果一个文件只能进行顺序存取操作，则称为顺序文件。
 典型的顺序文件 (设备)是键盘、显示器和保存在磁带上的文件 在访问文件的过程中，若严格按照数据保存的次序从头到尾访问文件，则称为顺序访问 只能进行顺序访问  随机文件：如果一个文件可以在文件的任意位置进行存取操作，则称为随机文件。
  磁盘文件就是典型的随机文件
  在访问文件的过程中，若不必按照数据的存储次序访问文件，而是要根据需要在文件的不同位置进行访问，则称为随机访问
  既可以进行顺序访问，也可以进行随机访问
  **类 istream **中与位置指针相关的函数如下:
/* 1. 移动读指针函数 */ // 该函数的功能是将读指针设置为 pos，即将读指针移动到文件的 pos 字节处 istream &amp; seekg(long pos); // 将读指针按照 seek_dir 的指示(方向)移动offset个字节 // 其中seek_dir 是在类ios中定义的一个枚举类型 enum seek_dir {beg=0, cur, end}; // ios::beg 流的开始位置。此时，offset 应为非负整数 // ios::cur 表示流的当前位置。offset 为正数则表示向后(文件尾)移动，为负数则表示向前(文件头)移动。 // ios::end 表示流的结束位置。此时 offset 应为非正整数 istream &amp; seekg(long offset, ios::seek_dir dir); /* 2. 返回写指针当前位置的函数 */ // 函数返回值为流中读指针的当前位置。 long tellg(); **类 ostream **中与位置指针相关的函数如下:
/* 1. 移动写指针函数 */ // 该函数的功能是将写指针设置为 pos，即将写指针移动到文件的 pos 字节处 ostream &amp; seekp(long pos); // 该函数的功能是将写指针按 seek_dir 指示的方向移动 offset 个字节 ostream &amp; seekp(long offset, ios::seek_dir dir); /* 2. 返回写指针当前位置的函数 */ // 函数的返回值为流中写指针的当前位置 long tellp(); 函数模板与类模板 函数模板 设计程序中的函数时，可能会遇到函数中参数的类型有差异，但需要实现的功能类似的情形。函数重载可以处理这种情形。重载函数的参数表中，可以写不同类型的参数，从而可以处理不同的情形。
为了提高效率，实现代码复用，C++ 提供了一种处理机制，即使用函数模板。函数在设计时并不使用实际的类型，而是使用虚拟的类型参数。
当用实际的类型来实例化这种函数时，将函数模板与某个具体数据类型连用。**编译器将以函数模板为样板，生成一个函数，即产生了模板函数，这个过程称为函数模板实例化。**函数模板实例化的过程由编译器完成。程序设计时并不给出相应数据的类型，编译时，由编译器根据实际的类型进行实例化。
#include &lt;iostream&gt;using namespace std; template&lt;typename T&gt; T abs(T x) { return x&lt;0?-x:x; } int main() { int n=-5; int m=10; double d=-.5; float f=3.2; cout&lt;&lt;n&lt;&lt;&#34;的绝对值是:&#34;&lt;&lt;abs(n)&lt;&lt;endl; cout&lt;&lt;m&lt;&lt;&#34;的绝对值是:&#34;&lt;&lt;abs(m)&lt;&lt;endl; cout&lt;&lt;d&lt;&lt;&#34;的绝对值是:&#34;&lt;&lt;abs(d)&lt;&lt;endl; cout&lt;&lt;f&lt;&lt;&#34;的绝对值是:&#34;&lt;&lt;abs(f )&lt;&lt;endl; return 0; } 函数与函数模板也是允许重载的。在函数和函数模板名字相同的情况下，一条函数调用语句到底应该被匹配成对哪个函数或哪个模板的调用呢?
C++ 编译器遵循以下先后顺序：
 先找参数完全匹配的普通函数(不是由模板实例化得到的模板函数)； 再找参数完全匹配的模板函数； 然后找实参经过自动类型转换后能够匹配的普通函数； 如果上面的都找不到，则报错。  类模板 通过类模板，可以实例化一个个的类。
 继承机制也是在一系列的类之间建立某种联系，类是相同类型事物的抽象，有继承关系的类可以具有不同的操作。 模板是不同类型的事物具有相同的操作，实例化后的类之间没有联系，相互独立。  不能使用类模板来直接生成对象，因为类型参数是不确定的，必须先为模板参数指定“实参”，即模板要“实例化”后，才可以创建对象。也就是说，当使用类模板创建对象时，要随类模板名给出对应于类型形参或普通形参的具体实参。
格式如下:
  类模板名 &lt;模板参数表&gt; 对象名1,...,对象名n;
  类模板名 &lt;模板参数表&gt; 对象名1(构造函数实参),...,对象名构造函数实参);
  类模板中的成员函数全部都是模板函数。
#include&lt;iostream&gt;using namespace std; template&lt;class T&gt; class TestClass { public: T buffer[10]; T getData(int j); }; template&lt;class T&gt; T TestClass&lt;T&gt;::getData(int j) { return *(buffer+j); }; int main() { // char 取代 T，从而实例化为一个具体的类  TestClass&lt;char&gt; ClassInstA; int i; char cArr[6]=&#34;abcde&#34;; for(i=0; i&lt;5; i++) { ClassInstA.buffer[i]=cArr[i]; } for(i=0; i&lt;5; i++) { char res = ClassInstA.getData(i); cout&lt;&lt;res&lt;&lt;&#34; &#34;; } cout&lt;&lt;endl; // 实例化为另外一个具体的类 double  TestClass&lt;double&gt; ClassInstF; fArr[6]={12.1,23.2,34.3,45.4,56.5,67.6}; for(i=0; i&lt;6; i++) { ClassInstF.buffer[i]=fArr[i]-10; } for(i=0; i&lt;6; i++) { double res = ClassInstF.getData(i); cout&lt;&lt;res&lt;&lt;&#34; &#34;; } cout&lt;&lt;endl; return 0; } 类之间允许继承，类模板之间也允许继承。具体来说，类模板和类模板之间、类模板和类之间可以互相继承，它们之间的常见派生关系有以下4种情况:
 普通类继承模板类 类模板继承普通类 类模板继承类模板 类模板继承模板类。  根据类模板实例化的类即是模板类。
#include &lt;iostream&gt; using namespace std; template&lt;class T&gt; class TBase { // 类模板，基类 	T data; public: void print() { cout&lt;&lt;data&lt;&lt;endl; } }; class Derived:public TBase&lt;int&gt; {}; //从模板继承，普通类  int main() { Derived d; // 普通派生类的对象  d.print(); // 调用类模板中的成员函数  return 0; } ]]></content></entry><entry><title>Database - Mysql 常用命令汇总</title><url>/tech/database/mysql-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</url><categories><category>Database</category></categories><tags><tag>Database</tag></tags><content type="html"><![CDATA[简介 **数据（Data）**是描述事物的符号记录，是指利用物理符号记录下来的、可以鉴别的信息。
**数据库（Database, DB）**是指长期储存在计算机中的有组织、可共享的数据集合。
**数据库管理系统（DBMS）**是专门用于建立和管理数据库的一套软件，介于应用程序和操作系统之间。
数据库分类  关系型数据库（RDB - Relationship Database）  Mysql、Oracle、Postgres、SQLLite、SQLServer 使用场景：数据处理较复杂、数据量不是特别大、对安全性要求比较高、数据格式单一   非关系型数据库（NoSQL - Not only sql）  MongoDB、Redis、HBase、Neo4j（图分析数据库） 数据模型比较简单、需要灵活性更强的 IT 系统、对数据库性能要求较高、不需要高度的数据一致性    MySQL 安装与配置 登录数据库服务器
登录方式
 远程连接（ssh） 本地服务器（本地搭建）  我这里通过本地 docker 的方式，启动数据库服务，登录命令：
# 设为 % 使得所有客户端均可连 $ docker run --name=mysql -it -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -e MYSQL_ROOT_HOST=% -d mysql $ docker exec -it mysql /bin/bash 查看数据库版本信息
$ mysql --version $ mysql -V mysql&gt; select version(); PostgreSQL 10.7 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36), 64-bit 登录数据库
$ mysql -h localhost -u root -p # -h：指连接的主机名 # -u：用户名 # -p：密码 root # 然后输入密码，进入数据库 # 修改密码 $ alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;新密码&#39;; # 退出数据库 $ exit 查看数据库版本
mysql&gt; SELECT VERSION(); 正常会出现数据库的版本号，环境准备完成！
数据库客户端工具   workBench；下载地址：https://dev.mysql.com/downloads/workbench/
  Navicat（付费）
  表  包含数据库中所有数据的数据库对象
 表名：每个表的唯一标识
模式：schema，关于数据库和表的布局及特性的信息
列：表中每列称为一个字段
行：表中的一条记录
SQL SQL 是什么？
 结构化查询语言，简称 SQL 一种特殊目的的编程语言 一种数据库查询和程序设计语言 用于存取数据以及查询、更新和管理关系数据库系统  语法规范 通用语法
 命令中间用逗号分隔，可以单行或者多行书写，以分号结尾 可以使用空格和缩进来增加语句的可读性 命令不区分大小写，建议 关键字大写，数据库名、表名、列名小写 注释方式：--、#（仅 MySQL） 单行注释；/* */ 多行注释  分类
 数据定义语言（DDL）：用来定义数据库对象，比如数据库、表、列等 数据操作语言（DML）：用来对数据库中表的记录进行更新 数据查询语言（DQL）：用来查询数据库中表的记录 数据控制语言（DCL）：用来定义数据库的访问权限和安全级别及创建用户  DDL 数据库操作 创建 # 创建数据库语法 # {} 必选项；｜ 或；[] 可选项 CREATE {DATABASE|SCHEMA} [IF NOT EXISTS] 数据库名 CHARACTER SET [=] 字符集; 创建数据库注意事项：
 不能与其他数据库重名 名称可以由任意字母、阿拉伯数字、下划线和 $ 组成，但不能使用单独的数字 名称最长可为 64 个字符，别名最长为 256 个字符 不能使用 MySQL 关键字作为数据库名 建议采用小写来定义数据库名  -- 创建数据库 CREATE DATABASE test_db; -- 指定字符集为 utf-8 CREATE DATABASE test_db2 CHARACTER SET utf8; -- 创建数据库前判断是否存在同名数据库 CREATE DATABASE IF NOT EXISTS test_db3 CHARACTER SET utf8; 查看 -- 查看所有数据库 SHOW DATABASES; -- 指定为当前数据库 USE 数据库名; -- 查看数据库定义信息 SHOW CREATE DATABASE 数据库名; 修改 -- 修改数据库相关参数，如果不指定数据库名则表示修改当前的数据库 ALTER {DATABASE} [数据库名] CHARACTER SET [=] 字符集; -- 实例 CREATE DATABASE db1 CHARACTER SET gbk; ALTER DATABASE db1 CHARACTER SET utf8; 删除 -- 删除数据库; 删除后数据结构和数据都没了 DROP DATABASE [IF EXISTS] 数据库名; DDL 表操作 MySQL 的数据类型
 数字类型（大概下面三种，长短整型、双精度浮点型等不详细列了）  INT 整型 FLOAT 浮点型 BOOLEAN 布尔值   字符串类型  CHAR 固定长度（1-255） VARCHAR 长度可变，不超过 255 个字符 TEXT 最大长度为 64K 的变长文本   日期和时间类型  DATE 日期 TIME 时间 DATETIME 日期和时间 TIMESTAMP 时间戳 YEAR 年份    创建 -- 创建表；列名在表中唯一 CREATE TABLE 数据表名 ( 列名 数据类型 [NOT NULL | NULL] [DEFAULT 默认值] [AUTO_INCREMENT] [PRIMARY KEY] [注释], ... ); -- AUTO_INCREMENT 是否自动编号 -- PRIMARY KEY 是否为主键  -- 复制表(结构) CREATE TABLE 数据表名 {LIKE 源数据表名 | (LIKE 源数据表名)}; 实例
-- 切换到数据库 USE db1; -- 创建学员表 CREATE TABLE student ( id INT, name VARCHAR(20) ); -- 复制学员表 CREATE TABLE student_cpy LIKE student; 查看 -- 查看表名 SHOW TABLES; -- 查看表结构 DESCRIBE 数据表名; -- 简写 DESC 数据表名; DESC 数据表名 列名; 修改 -- 添加新列 ALTER TABLE 表名 ADD 列名 列属性; -- 修改列定义 ALTER TABLE 表名 MODIFY 列名 列属性; -- 修改列名 ALTER TABLE 表名 CHANGE 旧列名 新列名 类型; 实例
-- 切换数据库 USE db1; -- 添加列 ALTER TABLE student ADD email VARCHAR(50) NOT NULL; -- 修改列定义 ALTER TABLE student ADD score VARCHAR(10) NOT NULL; ALTER TABLE student MODIFY score INT; -- 修改列名 ALTER TABLE student CHANGE COLUMN name stu_name VARCHAR(30) DEFAULT NULL; -- 查看表结构，验证修改生效 DESC student; 删除列 ALTER TABLE 表名 DROP 列名; ALTER TABLE student DROP score; 修改表名 -- 方式一 ALTER TABLE 旧表名 RENAME AS 新表名; -- 方式二 RENAME TABLE 旧表名 TO 新表名; 删除表 DROP TABLE [IF EXISTS] 数据表名; DML 表数据操作 插入 -- 插入数据 列名和值一一对应 INSERT INTO 数据表名 (列名1, 列名2, ...) VALUES (值1, 值2, ...); 注意事项：
 值与字段必须对应，个数相同且数据类型相同 值的数据大小，必须在字段指定的长度范围内 VARCHAR、CHAR、DATE 类型的值，必须使用单引号括起来 如果要插入空值，可以忽略不写，或者插入 NULL 如果插入指定字段的值，必须写上列名  修改 UPDATE 数据表名 SET 列名1=值1 [, 列名2=值2, ...] [WHERE 条件表达式]; 删除 -- 通过 delete 语句; 未指定条件则删除表中全部数据 DELETE FROM 表名 [WHERE 条件表达式]; -- 通过 truncate table 语句删除表中全部数据 TRUNCATE TABLE 表名; 如果需要删除整张表，推荐使用 TRUNCATE 语句：
 DELETE：每条数据都会执行一次删除，效率低 TRUNCATE：删除整张表，然后重新创建空表，效率高  实例
-- 切换数据库 USE db1; -- 创建 user 表 CREATE TABLE user( id INT, name VARCHAR(20), age INT, sex CHAR(1), address VARCHAR(40) ); /* 插入 */ -- 插入一条完整的数据 INSERT INTO user (id, name, age, sex, address) VALUES (1, &#39;张三&#39;, 20, &#39;男&#39;, &#39;北京&#39;); -- 插入一条完整的数据，可以不用写列名，值按照表的列的顺序插入 INSERT INTO user VALUES (2, &#39;李四&#39;, 19, &#39;女&#39;, &#39;上海&#39;); -- 插入表中某几列的值，没有值的列自动为 NULL INSERT INTO user (id, name, address) VALUES (3, &#39;王五&#39;, &#39;深圳&#39;); -- 插入多条数据 INSERT INTO user (id, name, address) VALUES (4, &#39;赵六&#39;, &#39;天津&#39;), (5, &#39;周七&#39;, &#39;杭州&#39;); /* 修改 */ -- 不带条件修改，将所有的性别改为女 UPDATE user SET sex=&#39;女&#39;; -- 带条件修改，id=3 的用户：性别修改为男 UPDATE user SET sex=&#39;男&#39; WHERE id=3; -- 修改多个列的数据，id=2 的用户：年龄修改为 30，地址修改为 北京 UPDATE user SET age=30, adress=&#39;北京&#39; WHERE id=2; /* 删除 */ -- 删除 id=1 的用户数据 DELETE FROM user WHERE id=1; -- 删除表中所有的数据 DELETE FROM user; TRUNCATE TABLE user; DQL 表查询操作 在进行查询前，先进行数据准备工作，使用开源的数据示例。
  https://github.com/datacharmer/test_db  
该数据库包含大约 300,000 条员工记录和 280 万条工资条目。导出数据为 167 MB，对于测试来说足够。
 # 这里通过 docker 启动 mysql:5.7 的容器进行测试 # 1、下载数据文件 $ cd workspace/github $ git clone git@github.com:datacharmer/test_db.git # 2、启动 mysql 容器，挂载数据文件到容器内 $ docker pull mysql:5.7 $ docker run --name=mysql -it -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -e MYSQL_ROOT_HOST=% -v /workspace/github/test_db:/opt -d mysql:5.7 # 3、导入数据库 $ docker exec -it mysql /bin/bash $ mysql -h 127.0.0.1 -u root -p &lt; /opt/employees.sql Enter password: root # 等待导入完成，大概 1 分钟+ 单表查询  从一张表中查询所需要的数据。
 -- 查询全部数据 SELECT * FROM 表名; -- 实例：查询部门表中的信息 SELECT * FROM departments; -- 查询多个字段（列）, 多个列中间用逗号分隔 SELECT 列名 FROM 表名; -- 实例：查询部门名称 SELECT dept_name FROM departments; /* 起别名 */ -- 为表起别名 SELECT 列名 FROM 表名 表别名; -- 为字段起别名 SELECT 列名 AS 别名 FROM 表名; -- 实例：查询员工信息，并将列名改为中文，表名改为 emp SELECT emp_no AS &#39;编号&#39;, first_name AS &#39;名&#39;, last_name AS &#39;姓&#39;, gender AS &#39;性别&#39;, hire_date AS &#39;入职时间&#39; FROM employees emp; -- 去重 SELECT DISTINCT 列名 FROM 表名; -- 实例：去掉重复职级信息 SELECT DISTINCT title FROM titles; -- 查询结果参与运算 SELECT (列名 运算表达式) FROM 表名; -- 实例：所有员工的工资 +1000 进行显示 SELECT emp_no, salary + 1000 FROM salaries; 条件查询 -- 条件查询 SELECT 列名 FROM 表名 WHERE 条件表达式; 比较运算法  大于（&gt;）、小于（&lt;）、&gt;=、&lt;= 等于（=）如果是字符，则比较 ASCII 码 不等于（&lt;&gt;、!=） 范围限定（BETWEEN&hellip;AND&hellip;） 子集限定（IN） 模糊查询（LIKE &lsquo;%or%'） 为空（IS NULL）  -- 实例：比较大小，查询出生日期晚于 1965-01-01 的员工编号、姓名和生日 SELECT emp_no, first_name, birth_date FROM employees WHERE birth_date &gt; &#39;1965-01-01&#39;; -- 使用 BETWEEN 进行模糊查询 WHERE 列名 [NOT] BETWEEN 起始表达式 AND 结束表达式 -- 实例：查询年薪介于 70000 到 70003 之间的员工编号和年薪 SELECT emp_no, salary FROM salaries WHERE salary BETWEEN 70000 AND 70003; -- 使用 IN 进行模糊查询, 常量列表使用逗号隔开 WHERE 列名 IN (常量列表) -- 实例：查询入职日期为 1995-01-27 和 1995-03-20 的员工信息 SELECT * FROM employees WHERE hire_date IN (&#39;1995-01-27&#39;, &#39;1995-03-20&#39;); -- 判断是否为空 WHERE &lt;列名&gt; IS [NOT] NULL -- 实例：查询性别为空的员工信息 SELECT * FROM employees WHERE gender IS NULL; -- 没有为空的数据 SELECT * FROM employees WHERE gender IS NOT NULL; -- 全部员工数据 逻辑运算法  AND 或 &amp;&amp;：多个条件同时成立 OR 或 ||：多个条件任一成立 NOT：不成立  -- 查询名字为 Lillian 并且姓氏为 Haddadi 的员工信息 SELECT * FROM employees WHERE first_name = &#39;Lillian&#39; AND last_name = &#39;Haddadi&#39;; -- 查询名字为 Lillian 或者姓氏为 Terkki 的员工信息 SELECT * FROM employees WHERE first_name = &#39;Lillian&#39; OR last_name = &#39;Terkki&#39;; -- 查询名字为 Lillian 并且性别不是女的员工信息 SELECT * FROM employees WHERE first_name = &#39;Lillian&#39; AND NOT gender = &#39;F&#39;; 通配符  %：匹配任意多个字符 _：匹配一个字符  -- 查询名字中包含 fai 的员工信息 SELECT * FROM employees WHERE first_name LIKE &#39;%fai%&#39;; -- 查询名字中 fa 开头的且长度为 3 位的员工信息 SELECT * FROM employees WHERE first_name LIKE &#39;fa_&#39;; 排序 排序语法
 ASC：升序（默认） DESC：降序  -- 对查询结果进行排序 SELECT 列名 FROM 表名 [WHERE 条件表达式] ORDER BY 列名1 [ASC | DESC], 列名2 [ASC | DESC]; 单列排序 -- 使用 salary 字段，对 salaraies 表数据进行 升序/降序 排序 SELECT * FROM salaries ORDER BY salary; SELECT * FROM salaries ORDER BY salary DESC; -- 查询员工的编号和入职日期，按照员工入职日期从晚到早排序 SELECT emp_no, hire_date FROM employees ORDER BY hire_date DESC; 组合排序 同时对多个字段进行排序，如果第一个字段相同，就按照第二个字段进行排序。
-- 在入职时间排序的基础上，再使用 emp_no 进行降序排序 SELECT emp_no, hire_date FROM employees ORDER BY hire_date DESC, emp_no DESC; 聚合函数  COUNT()：统计指定列不为 NULL 的记录行数 MAX()：计算指定列的最大值 MIN()：计算指定列的最小值 SUM()：计算指定列的数值和 AVG()：计算指定列的平均值  -- 聚合查询语法 SELECT 聚合函数(列名) FROM 表名; -- 实例 -- 查询职级名称为 Senior Engineer 的员工数量 SELECT COUNT(title) FROM titles WHERE title = &#39;Senior Engineer&#39;; SELECT COUNT(*) FROM titles WHERE title = &#39;Senior Engineer&#39;; -- 查询员工编号为 10002 的员工的最高年薪 SELECT MAX(salary) FROM salaries WHERE emp_no = 10002; -- 查询最低年薪 SELECT MIN(salary) FROM salaries WHERE emp_no = 10002; -- 查询薪资总和 SELECT SUM(salary) FROM salaries WHERE emp_no = 10002; -- 计算平均薪资 SELECT AVG(salary) FROM salaries WHERE emp_no = 10002; 分组 分组查询语法
 分组列：按哪些列进行分组 HAVING：对分组结果再次过滤  -- 分组查询语法 SELECT (分组列 ｜ 聚合函数) FROM 表名 GROUP BY 分组列 [HAVING 条件]; 实例
-- 查询每个员工的薪资和 SELECT emp_no, SUM(salary) FROM salaries GROUP BY emp_no; -- 查询员工编号小于 10010 且薪资和小于 400000 的员工的薪资和 SELECT emp_no, SUM(salary) FROM salaries WHERE emp_no &lt; 10010 GROUP BY emp_no HAVING SUM(salary) &lt; 400000; 子句区别
 WHERE 子句：从数据源中去掉不符合搜索条件的数据 GROUP BY 子句：搜集数据行到各个组中，统计函数为各个组计算统计值 HAVING 子句：去掉不符合其组搜索条件的各行数据行  LIMIT 关键字 限制查询结果的数量
-- 限制查询结果行数 SELECT 列名1, 列名2 FROM 表名 LIMIT [开始的行数], &lt;查询记录的条数&gt;; -- 使用 OFFSET 关键自指定开始的行数 SELECT 列名1, 列名2 FROM 表名 LIMIT &lt;查询记录的条数&gt; OFFSET &lt;开始的行数&gt;; -- 开始的行数：从 0 开始，默认为 0 -- 查询记录的条数：返回的行数 实例
-- 展示前 10 条员工信息 SELECT * FROM employees LIMIT 10; SELECT * FROM employees LIMIT 0, 10; SELECT * FROM employees LIMIT 10 OFFSET 0; -- 显示年薪从高到低排序，第 15 位到第 20 员工的编号和年薪 SELECT emp_no, salary FROM salaries ORDER BY salary DESC LIMIT 14, 6; SELECT emp_no, salary FROM salaries ORDER BY salary DESC LIMIT 6 OFFSET 14; 单表查询总结 SELECT DISTINCT 列名 FROM 表名 WHERE 查询条件表达式 GROUP BY 分组的列名 HAVING 分组后的查询条件表达式 ORDER BY 排序的列名 [ASC | DESC] LIMIT 开始的行数, 查询记录的条数; SQL 约束 对表中的数据进行进一步的限制，保证数据的正确性、有效性、完整性。违反约束的不正确数据无法插入到表中。常见的约束：
 主键：PRIMARY KEY 非空：NOT NULL 唯一：UNIQUE 默认：DEFAULT 外键：FOREIGN KEY  主键约束 主键：一列（或一组列），其值能够唯一标识表中的每一行
特点：不可重复，唯一，非空
语法：列名 字段类型 PRIMARY KEY
创建带有主键的表 -- 创建一个带有主键的表 CREATE TABLE emp1( -- 设为主键后自动非空 	eid INT PRIMARY KEY, ename VARCHAR(20), gender CHAR(1) ); -- 向已有的表中添加主键 CREATE TABLE emp2( eid INT, ename VARCHAR(20), gender CHAR(1) ); ALTER TABLE emp2 ADD PRIMARY KEY(eid); -- 向 emp1 中添加数据，验证主键非空和不能重复的特性 INSERT INTO emp1 VALUES(1, &#39;zhangsan&#39;, &#39;M&#39;); -- 插入空值插入报错，主键不能为空 -- INSERT INTO emp1 VALUES(NULL, &#39;lisi&#39;, &#39;W&#39;); -- 插入重复数据报错，主键不能重复 -- INSERT INTO emp1 VALUES(1, &#39;lisi&#39;, &#39;F&#39;); 主键自增 由于主键的特性，每次人为按顺序添加难免出错，可以使用自增的属性。
-- 创建主键自增 -- AUTO_INCREMENT: 表示自动增长（必须整数类型的字段），默认从 1 开始 CREATE TABLE emp3( eid INT PRIMARY KEY AUTO_INCREMENT, ename VARCHAR(20), gender CHAR(1) ); INSERT INTO emp3 VALUEs(1, &#39;zhangsan&#39;, &#39;M&#39;); -- 只需要添加名字和性别即可，id 会自增 INSERT INTO emp3(ename, gender) VALUES(&#39;lisi&#39;, &#39;M&#39;), (&#39;wangwu&#39;, &#39;F&#39;); -- 修改主键自增起始值为 100 CREATE TABLE emp4( eid INT PRIMARY KEY AUTO_INCREMENT, ename VARCHAR(20), gender CHAR(1) )AUTO_INCREMENT=100; # DELETE FROM emp4; 删除表后，添加数据会继续之前的编号往上自增 # TRUNCATE TABLE emp4; 先删除整表后重新创建，自增会从起始值开始 删除主键约束 -- 删除表中的主键 ALTER TABLE 表名 DROP PRIMARY KEY; -- 实例：删除表2 的主键 ALTER TABLE emp2 DROP PRIMARY KEY; 选择主键原则  针对业务设计主键，建议每张表都设计一个主键 主键可以没有业务意义，只需保证不重复  非空约束 特点：某一列不允许为空
语法：列名 字段类型 NOT NULL
-- 创建非空约束的表 CREATE TABLE emp5 ( eid INT PRIMARY KEY AUTO_INCREMENT, ename VARCHAR(20) NOT NULL, gender CHAR(1) ); INSERT INTO emp5(ename, gender) VALUES(&#39;zhangsan&#39;, &#39;F&#39;); -- 报错：Field &#39;ename&#39; doesn&#39;t have a default value, Time: 0.001000s INSERT INTO emp5(gender) VALUES(&#39;F&#39;); 唯一约束  表中的某一列的值不能重复 对 NULL 不做唯一的判断 语法：列名 字段类型 UNIQUE  -- 创建带有唯一约束的表 CREATE TABLE emp6 ( eid INT PRIMARY KEY AUTO_INCREMENT, ename VARCHAR(20) UNIQUE, gender CHAR(1) ); INSERT INTO emp6(ename, gender) VALUES(&#39;zhangsan&#39;, &#39;F&#39;); -- 报错：Duplicate entry &#39;zhangsan&#39; for key &#39;ename&#39;, Time: 0.004000s INSERT INTO emp6(ename, gender) VALUES(&#39;zhangsan&#39;, &#39;F&#39;); 主键约束与唯一约束的区别：
 主键约束：唯一且不能为空 唯一约束：唯一但可以为空 一个表中只能有一个主键，但是可以有多个唯一约束  默认值约束 默认值约束：用来指定某列的默认值
语法：列名 字段类型 DEFAULT 默认值
-- 创建带有默认值的表 CREATE TABLE emp7 ( eid INT PRIMARY KEY AUTO_INCREMENT, ename VARCHAR(20), gender CHAR(1) DEFAULT &#39;F&#39; ); -- 使用默认值，可以通过 DEFAULT 指定，也可以不写 INSERT INTO emp7(ename, gender) VALUES(&#39;zhangsan&#39;, DEFAULT); INSERT INTO emp7(ename) VALUES(&#39;lisi&#39;); -- 不使用默认值 INSERT INTO emp7(ename, gender) VALUES(&#39;wangwu&#39;, &#39;M&#39;); 外键约束 课程名称： SQL 约束 - 外键约束
TODO 不理解，等查阅完基础资料再来。
创建表的同时创建外键约束 -- 创建主表 CREATE TABLE tester ( id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(20), team_id INT, -- 添加外键及外键约束 	CONSTRAINT tester_team FOREIGN KEY(team_id) REFERENCES tester(id) ); 修改外键约束
删除外键约束
级联删除
多表  在数据库设计中使用多张表格来实现数据存储的要求，在实际的项目中，数据量大且复杂，需要分库分表。
 分表：按照一定的规则，对原有的数据库和表进行拆分，表与表之间可以通过外键建立连接。
实例：创建一张员工信息表，包含字段：
 eid：员工 ID（自增主键） ename：员工姓名 age：年龄 gender：性别 dept_name：部门名称 dept_id：部门 ID dept_manager：部门主管 dept_location：所在地点  -- 创建单表 CREATE TABLE emp( eid INT PRIMARY KEY AUTO_INCREMENT, ename VARCHAR(20), age INT, gender VARCHAR(5), dept_name VARCHAR(10), dept_id INT, dept_manager VARCHAR(10), dept_location VARCHAR(10) ); INSERT INTO emp VALUES(1, &#39;zhangsan&#39;, 20, &#39;&#39;, &#39;qa&#39;, 1, &#39;qa_leader&#39;, &#39;beijing&#39;); 当插入数据时，所有的数据都需要添加部门名称、部门经理等重复性信息，所以需要使用多表设计模式。
 将数据拆分为员工信息表table_emp和部门信息表table_dept 两个表之间通过部门 IDdept_id字段连接  CREATE TABLE table_emp( id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(20), age INT, gender VARCHAR(5), dept_id INT ); CREATE TABLE table_dept( id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(10), manager VARCHAR(10), location VARCHAR(10)	); INSERT INTO table_emp VALUES(1, &#39;zhangsan&#39;, 18, &#39;M&#39;, 1); INSERT INTO table_emp VALUES(2, &#39;lisi&#39;, 19, &#39;F&#39;, 2); INSERT INTO table_dept VALUES(1, &#39;qa&#39;, &#39;leader&#39;, &#39;beijing&#39;); INSERT INTO table_dept VALUES(2, &#39;rd&#39;, &#39;rd_leader&#39;, &#39;beijing&#39;); 多表的优点：
 简化数据 提高复用性 方便权限控制 提高系统的稳定性和负载能力  多表关系简介 一对多 定义：主表的一条记录可以对应从表的多条记录。在一对多关系中，多的表定为从表，设置外键指向主表。
比如：部门表、员工表，一个部门可以对应多个员工。建表时，员工表就应作为从表，设置外键指向部门表的主键。
多对多 定义：主表的多条记录可以对应从表的多条记录。需要创建第三张表作为中间表，中间表需要包含两种表的主键。
比如：商品信息表、客户表、订单表。
一对一 定义：从表的一条记录对应主表的一条记录，这种对应关系的数据，通常放在单表里。
比如：员工信息表与身份证、联系方式。
多表查询 笛卡尔积查询 通过查询多张表格获取数据，至少涉及两张表
-- 创建部门表，插入三条数据 CREATE TABLE dept( id INT PRIMARY KEY AUTO_INCREMENT, dept_name VARCHAR(20), dept_manager VARCHAR(20), dept_location VARCHAR(20) ); INSERT INTO dept VALUES (1, &#39;研发部&#39;, &#39;研发小张&#39;, &#39;北京&#39;); INSERT INTO dept VALUES (2, &#39;运营部&#39;, &#39;运营小李&#39;, &#39;上海&#39;); INSERT INTO dept VALUES (3, &#39;销售部&#39;, &#39;销售小王&#39;, &#39;深圳&#39;); -- 创建员工信息表，添加外键约束，允许级联删除，并对三个部门插入对应的员工信息 CREATE TABLE worker( id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(20), gender VARCHAR(10), dept_id INT, salary INT, -- 添加外键约束，级联删除 	CONSTRAINT FK FOREIGN KEY(dept_id) REFERENCES dept(id) ON DELETE CASCADE ); INSERT INTO worker VALUES (1, &#39;虞姬&#39;, &#39;女&#39;, 2, 10000); INSERT INTO worker VALUES (2, &#39;项羽&#39;, &#39;男&#39;, 1, 18000); INSERT INTO worker VALUES (3, &#39;后羿&#39;, &#39;男&#39;, 3, 28000); -- 查询表 SELECT * FROM dept; SELECT * FROM worker; -- 笛卡尔积查询，会出现很多无效数据 SELECT * FROM dept, worker; -- 正确查询 SELECT * FROM dept, worker WHERE dept.id=worker.dept_id; -- 查询出运营部的部门信息及该部门下的员工信息 SELECT * FROM dept, worker WHERE dept.id=worker.dept_id AND dept.id=2; 内连接查询 内连接（INNER JOIN）：使用比较运算符进行表间某（些）列数据的比较操作，并列出这些表中与连接条件相匹配的数据行，组成新的记录。匹配上显示，匹配不上不显示。按语法结构分为：隐式内连接和显式内连接。
  隐式内连接：使用 where 条件过滤无用数据，没有出现 inner join 关键字
  显式内连接：添加 inner join 关键字
  -- 隐式内连接 SELECT [字段名称] FROM [表名] WHERE [条件]; -- 显示内连接 SELECT [字段名称] FROM [主表名] INNER JOIN [从表名] ON [条件]; SELECT worker.id, name, dept_location FROM worker, dept WHERE worker.dept_id=dept.id AND dept_name=&#34;运营部&#34;; SELECT worker.id, name, dept_location FROM dept INNER JOIN worker ON dept.id=worker.dept_id AND dept_name=&#34;运营部&#34;; 外连接查询 外连接：查询多个表中相关联的行，有时候需要包含没有关联的行中数据，即返回查询结果集合中不仅包含符合连接条件的行，还包括左表（左连接）、右表（右连接）中的所有数据行。
 左外连接（LEFT OUTER JOIN），OUTER 可以省略，以左表为基准匹配右表的数据，确保左表数据都展示，右表中没有的项，显示为空。 右外连接（RIGHT OUTER JOIN），OUTER 可以省略，以右表为基准匹配左表的数据，确保右表数据都展示，左表中没有的项，显示为空。  -- 左连接 SELECT [字段名称] FROM [左表] LEFT JOIN [右表] ON [条件]; -- 右连接 SELECT [字段名称] FROM [左表] RIGHT JOIN [右表] ON [条件]; 子查询 子查询指一个查询语句嵌套在另一个查询语句内部，在 SELECT 子句中先计算子查询，子查询的结果作为外层另一个查询的过滤条件，查询可以基于一个表或者多个表。
子查询作为过滤条件时需要用小括号包裹。
常见的三类子查询如下：
from 型
将子查询的结果作为父查询的表来使用。子查询是一张多行多列的表，将子查询作为父查询的表来嵌套查询，子查询必须用小括号包裹且有别名。
-- 计算出各部门男性员工的人数 -- 最终查询字段部门名称、男性员工人数 -- 子查询：查询公司所有性别为男的员工信息 SELECT * FROM worker WHERE gender=&#34;男&#34;; SELECT dept_name AS &#39;部门名称&#39;, COUNT(dept_id) AS &#39;部门人数&#39; FROM (SELECT * FROM worker WHERE gender=&#34;男&#34;) AS male_worker INNER JOIN dept ON male_worker.dept_id=dept.id GROUP BY dept_name; in/not in 型：子查询的结果是单列多行，作为 where 的过滤条件
-- 带 IN 关键字的子查询 -- 查询出北京地区所有的员工信息 SELECT id FROM dept WHERE dept_location=&#34;北京&#34;; SELECT * FROM worker WHERE dept_id IN (SELECT id FROM dept WHERE dept_location=&#34;北京&#34;); SELECT * FROM worker WHERE dept_id NOT IN (SELECT id FROM dept WHERE dept_location=&#34;北京&#34;); where 型：查询结果作为过滤条件出现在比较运算符的一端，常用于子查询结果为单个的情况。
-- 查询出薪资大于公司平均薪资的员工 ID、姓名、薪资 SELECT AVG(salary) FROM worker; SELECT id, name, salary FROM worker WHERE salary &gt; (SELECT AVG(salary) FROM worker); with&hellip;as&hellip;型：如果一整句查询语句中，某个子查询的结果会被多个父查询引用，通常建议将公用的子查询用简写表示出来。
-- WITH [表名] AS (SELECT ...) -- 查询出部门平均薪资大于公司平均薪资的部门名称、部门主管、所在地，及其平均薪资 WITH dept_avg AS (SELECT dept_id, AVG(salary) AS avg_salary FROM worker GROUP BY dept_id) SELECT dept_name, dept_manager, dept_location, avg_salary FROM dept INNER JOIN dept_avg ON id=dept_id AND avg_salary &gt; (SELECT AVG(avg_salary) FROM dept_avg); 视图 视图是一种虚拟的表，它并不会在存储空间复制一份数据，而是对原有数据的一种引用。可以将视图理解为一种存储起来的 sql 语句。
 视图可以简化多表查询 视图可以用于控制用户权限  CREATE VIEW [视图名称] AS SELECT ... ]]></content></entry><entry><title>Booknotes - 《数据结构导论》线性表</title><url>/tech/booknotes/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AF%BC%E8%AE%BA%E7%BA%BF%E6%80%A7%E8%A1%A8/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html"><![CDATA[概论 2. 线性表 ![image-20220407200207639](/Users/lan/Library/Application Support/typora-user-images/image-20220407200207639.png)
2.1 线性表的基本概念 2.2 线性表的顺序存储 2.2.1 线性表顺序存储的类型定义 2.2.2 线性表的基本运算在顺序表上的实现 定义数据结构
const int MaxSize = 100; typedef struct { int id; char name[10]; char sex; float score; } DataType; typedef struct { DataType data[10]; int length; } SeqList; 插入 void InsertSeqList(SeqList L, DataType x, int i) /* 元素插入 一般情况下，需要移动 n-i+1 次 最坏的情况下，插入队首元素，需要移动 n 次； 最好的情况下，插入队尾元素，需要移动 0 次； 平均移动 n/2 次，时间复杂度为 O(n). */ { // 表是否满  if (L.length == MaxSize) exit(&#34;表已满！&#34;); // 位置非法  if (i &lt; 1 || i &gt; L.length + 1) exit(&#34;位置非法!&#34;); // 从后开始，元素移动  for (int j = L.length; j &gt;= i; j--) { L.data[j] = L.data[j - 1]; } // 把元素放在 i-1 的位置上  L.data[i-1] = x; L.length++; } 删除 void DeleteSeqList(SeqList L, int i) /* 删除元素 一般情况下，需要移动 n-i 次 最坏的情况下，删除队首元素，需要移动 n-1 次； 最好的情况下，删除队尾元素，需要移动 0 次； 平均移动 (n-1)/2 次，时间复杂度为 O(n). */ { // 非法位置  if (i &lt; 1 || i &gt; L.length) exit(&#34;非法位置！&#34;); // 删除是从前往后遍历，元素向前移动  for (int j = i; j &lt; L.length; j++) L.data[j-1] = L.data[j]; L.length--; } 定位 int LocateSeqList(SeqList L, DataType x) /* 定位元素 时间复杂度为 O(n) 求表长和读取表元素算法的时间复杂度为 O(1) */ { int i = 0; while (i &lt; L.length &amp;&amp; L.data[i] != x) i++; if (i &lt; L.length) return i + 1; else return 0; } 2.2.3 顺序表实现算法的分析 优点  无需为表示结点间的逻辑关系而增加额外的存储空间 可以方便的随机存取表中的任一结点  缺点  插入和删除运算不方便，必须移动大量结点 顺序表要求占用连续空间，存储分配职能预先进行，当表长变化较大时，难以确定合适的存储规模  2.3 线性表的链接存储 2.3.1 单链表的类型定义 ![image-20220407201405246](/Users/lan/Library/Application Support/typora-user-images/image-20220407201405246.png)
所有的结点通过指针链接组成单链表
 data：存放结点值的数据域 next：存放结点的直接后继地址（位置）的指针域（链域） NULL：空指针，尾结点通常指向空指针，代表链表结束 Head：头指针变量，存放链表中第一个结点地址，一般不存放数据  不带头节点的空链表：head == NULL 带头节点的空链表：head -&gt; next == NULL，增加头节点的目的是为了==方便运算==    ![image-20220411110632674](/Users/lan/Library/Application Support/typora-user-images/image-20220411110632674.png)
2.3.2 线性表的基本运算在单链表上的实现 初始化 // 空表由一个头指针和一个头结点组成 LinkList InitiateLinkList(){ LinkList head; // 头指针  head = malloc(sizeof(Node)); // 动态构建一个结点，作为头结点  head -&gt; next = NULL; return head; } 在算法中，变量head是链表的头指针，它指向新创建的结点，即头结点。一个空链表仅有一个头结点，它的指针域为NULL
求表长 int LengthLinkList(LinkList head) { Node *p; p = head; j = 0; while (p -&gt; next != NULL) { p = p -&gt; next; // 结点不断后移  j++; } return j; } 读表元素 // 给定元素的位置，返回这个元素 Node *GetLinkList(LinkList head, int i) { Node *p; p = head -&gt; next; int c = 1; // 数到第 i 个结点  while (c &lt; i &amp;&amp; p != NULL) { p = p -&gt; next; c++; } if (i == c) return p; else return NULL; } 定位 // 给定表元素的值，找出元素的位置 int LocateLinkList(LinkList head, DataType x) { Node *p = head; // p 是工作指针  p = p -&gt; next; // 初始时 p 指向首结点  int i = 0; // 代表结点的序号，初始为 0  while (p != NULL &amp;&amp; p -&gt; data != x) // 访问链表  { i++; p = p -&gt; next; } if (p != NULL) return i+1; else return 0; } 插入 void InsertLinkList(LinkList head, DataType x, int i) { Node *p, *q; if (i == 1) q = head; else q = GetLinkList(head, i-1); // 查找第 i 个数据元素结点  if (q == NULL) exit(&#34;找不到插入位置！&#34;); else { p = malloc(sizeof(Node)); // 开辟新结点的空间  p -&gt; data = x; // 填入数据  p -&gt; next = q -&gt; next; q -&gt; next = p; } } 删除 // 找到线性表中第 i-1 个结点，修改其指向后继的指针 void DeleteLinkList(LinkList head, int i) { Node *p; // 找到待删结点的直接前驱  if (i == 1) p = head; else p = GetLinkList(head, i-1); if (p != NULL &amp;&amp; p -&gt; next != NULL) // 直接前驱存在且待删结点存在  { q = p -&gt; next; // q 指向待删结点  p -&gt; next = q -&gt; next; free(q); // 释放结点  } else exit(&#34;找不到待删结点！&#34;) } free() 是必不可少的，当一个结点从链表移出后，如果不释放它的空间，它将变成一个无用的结点，会一直占着系统的内存空间，其他程序无法使用。
]]></content></entry><entry><title>Booknotes - 《数据结构导论》排序</title><url>/tech/booknotes/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AF%BC%E8%AE%BA%E6%8E%92%E5%BA%8F/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html"><![CDATA[排序 概述 数据排序：将一个文件的记录按关键字不减（或不增）次序排列，使文件成为有序文件
稳定排序：排序后，相同关键字的记录保持它们原来的相对次序
不稳定排序：排序后，相同关键字的记录相对次序发生变更
排序类型
 内部排序：全部数据存于内存 外部排序：需要对外存进行访问  比较算法的好坏，主要看空间复杂度和时间复杂度。通过代码来实现各种排序
定义数据结构体
typedef struct { int key; // 关键字项  ItemType otherItem; // 其他数据项 } RecordType; typedef RecordType list[n+1]; // list R; 定义数据 // R[i].key 代表第 i 个记录的关键字 插入排序 直接插入排序 稳定性：稳定排序
void StraightInsertSort(list R, int n) {	for (i = 2; i &lt;= n; i++) { // R[0] 保存 R[i] 的值，第一是方便互换；  // 第二是岗哨作用，相等后就跳出循环体，可以少写一个j为负数的判断  R[0] = R[i]; j = j - 1; while (R[0].key &lt; R[j]) { R[j+1] = R[j]; // 记录后移  j--; } R[j+1] = R[0]; } } 交换排序 冒泡排序  通过多次重复比较，交换相邻记录
 时间复杂度：O(n^2)
空间复杂度：O(1)
稳定性：稳定排序
void BubbleSort(List R, int n) { int i, j, temp, endSort; for (i = 1; i &lt;= n - 1; i++) { endSort = 0; // 若未记录交换，则说明已经有序  for (j = 1; j &lt;= n - i; j++) { if (R[j].key &gt; R(j+1).key) { temp = R[j]; R[j] = R[j+1]; R[j+1] = temp; endSort = 1; } } if (endSort == 0) break; } } 快速排序  通过分部排序完成整个表的排序。首先取第一个记录，与表中其余记录比较并交换，使记录表左边的关键字均小于它，右边的关键字均大于它，然后对这两部分重新执行上述过程，直至排序完毕。
 时间复杂度：O(log2n)
选择排序 直接选择排序 堆排序 归并排序 有序序列的合并 二路归并排序 ]]></content></entry><entry><title>Booknotes - 《数据结构导论》查找表</title><url>/tech/booknotes/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AF%BC%E8%AE%BA%E6%9F%A5%E6%89%BE%E8%A1%A8/</url><categories><category>Booknotes</category></categories><tags><tag>Booknotes</tag></tags><content type="html">查找表 基本概念 查找表：由同一类型的数据元素构成的集合 关键字：用来标识数据元素的数据项，简称键，其值称为键值 主关键字：可唯一标识各个数据元素的关键字 查找：根据给定的某个 k 值，在查找表寻找一个其键值等于 k 的数据元素
静态查找表：进行的是引用型运算，操作为：建表、查找、读取表中元素。
动态查找表：进行的是加工型运算，操作为：初始化、查找、读表中元素、插入、删除
静态查找表 静态查找表的实现：
顺序查找 有序表上的查找（二分查找） 索引表上的查找（分块查找） 1. 顺序查找 首先，从表中最后一个记录开始顺序查找，若当前记录的关键字等于给定值，则查找成功；
否则，继续查找上一记录；
直至到第一个记录还未查找到，则查找失败。
// 静态查找表长度 const int maxsize = 20; // 定义数据结构体 typedef struct { keytype key; // 关键字域 ... // 其他域 } TableElem; typedef struct { // 定义一维数组，0 号元素留空 TableElem elem[maxsize + 1]; // 最后一个元素的下标，即表长 int n; } SeqTable; 算法实现：使用一种设计技巧，设立岗哨
int SearchSeqTable(SeqTable T, KeyType key) { // 将要查找的元素放到 0 的位置 T.elem[0].key = key; i = T.n; // 表长度 // 从最后一个值开始查找，当前值不等于预期值时，i--，继续查找 // 找到时返回下标，没有找到就返回 0 // 0 是岗哨，就不用每次在循环内判断 i-- 是否小于 0，节省了一半的时间 // 空间（T.elem[0]）换时间 while (T.elem[i].key != key) i--; return i; } 算法分析
成功查找：==ASL=(n+1)/2==，平均次数
不成功查找：==ASL=n+1==，n 个元素查找 n 次，再加上 0 号元素的那次
优点：简单，对表无要求
缺点：比较次数多，时间复杂度是 ==O(n)==
2. 有序表上的查找 - 二分查找 关键点，每次找中项，可使下次查找范围缩小一半。
每次将处于查找区间中间位置的数据元素与给定值 K 进行比较，若不等则缩小查找区间，在新的区间内重复上述过程，直到查找成功或查找区间为 0（查找不成功）截止。
顺序方式存储，且元素按关键字有序
算法实现
int SearchBin (SeqTable T, KeyType k) { int low, mid, high; low = 1; hign = T.n; while (low &amp;lt;= high) { mid = (low + high) / 2; if (key == T.elem[mid].key) return mid; else if (key &amp;lt; T.elem[mid].key) high = mid - 1; else low = mid + 1; } return 0; } 算法分析
查找成功或不成功时，比较次数最多都为: $$ \lfloor{log_2{n}}\rfloor + 1 $$ 平均查找长度为: $$ (\frac{n+1}{n} {log_2{(n+1)}}) - 1 $$ 由此可见，二分查找的时间复杂度比顺序查找要好，但是相比而言，二分查找要求表元素是排好序的。非顺序表存储结构或顺序表元素未按键值排序（递增或递减）时，不能进行二分查找。
3. 索引表上的查找 - 分块查找 首先建立索引表，将数据分块，把每块中最大（或最小）关键字及指针依次存入一张表中，此表称为索引表；
查找索引表，将预期关键字 k 与索引表中每块元素进行比较，确定预期查找元素所在块号；
在相应块中按顺序查找关键字为 k 的记录
平均查找长度为： $$ \frac{1}{2}(\frac{n}{s}+s)+1 $$
4. 算法分析 静态查找表的上述三种不同实现各有优缺点，其中：
顺序查找效率最低，但限制最少 二分查找效率最高，但限制最强 分块查找介于二者之间 实际应用中根据需要选择。
动态查找 1. 二叉排序树 又称二叉查找树，具有以下性质：
若左子树不空，则左子树上所有结点的键值均小于它的根结点键值； 若右子树不空，则右子树上所有结点的键值均大于它的根结点键值； 根的左、右子树也分别为二叉排序树。 空二叉树也是二叉排序树的一种。 中序遍历一颗二叉排序树所得的结点访问序列是键值的递增序列。
查找分析：二叉排序树的平均查找长度是介于 O(n) 和 O(log 以 2 为底 n 的对数) 之间，其查找效率与树的形态有关。
理想情况，树左右对称，每次在一半的元素里查找，时间复杂度为 O(log 以 2 为底 n 的对数) 最坏情况，单枝树（从大到小或从小到大），需要遍历树的全部元素，时间复杂度为 O(n) 平均查找长度为：sum(层数 * 该层结点数) / 总结点数
2. 散列表（哈希表） 为了使数据元素的存储位置和键值之间建立某种联系，以减少比较次数，可以用散列技术实现动态查找表。
散列函数（哈希函数）决定关键字在表中地址，Addr(a) = H(k)
散列地址：由散列函数决定数据元素的存储位置，该位置称为散列地址
散列查找：给定关键字，通过散列函数转换，得到在表中的地址，如果查找到该元素则输出信息，反之将它填到此位置上
散列表：通过散列法建立的表称为散列表
==冲突==：不同的关键字映射到同一存储单元，这些关键字称为==同义词==
常用散列法
数字分析法：若一组数据前面 n 位都一样，则排除这些重复位 ==除留余数法==：取关键字被某个数 p 除后所得余数作为散列地址，p 不取偶数，一般为最接近表长的==质数== 平方取中法：以键值平方的中间几位作为散列地址 基数转换法：转换进制，根据散列表的长度从中选取几位作为散列地址 散列表解决冲突的方法
线性探测法：取余作为表中地址，被占用后就往后移，超出表长就从头开始 二次探测法：取余作为表中地址，被占用后先加1的平方，还被占用就减1的平方，再被占用就加2的平方，直到有空位 链地址法：取余作为指针，指向所有取余后等于指针的键值链表，每个单链表都是一个同义词表 多重散列法：设立多个散列函数，优点是不易产生==堆积== 公共溢出区法：由两个一维数组组成，一个是散列表，一个是溢出表，同义词存入溢出表</content></entry><entry><title>Mac - 安装Android Sdk</title><url>/tech/mac/%E5%AE%89%E8%A3%85android-sdk/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">方式一 下载地址：http://tools.android-studio.org/index.php/sdk
下载完成后运行 tools -&amp;gt; android，安装 platform-tools
配置环境变量
完成安装！
方式二 $ brew install android-sdk $ brew install android-platform-tools 方式三：推荐 使用 Android studio 管理。</content></entry><entry><title>Docker - 搭建Sonic云真机平台记录</title><url>/tech/docker/%E6%90%AD%E5%BB%BAsonic%E4%BA%91%E7%9C%9F%E6%9C%BA%E5%B9%B3%E5%8F%B0%E8%AE%B0%E5%BD%95/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[本文通过 docker 在服务器上搭建 sonic 真机平台 simple 版本。
部署文档：https://sonic-cloud.gitee.io/#/Deploy
搭建服务 该版本更新很快，官方的部署文件也越来越完善，去官方找最新，这里就提供个模板参考。
# .env ################################################ # Do you need any help? # # Visit https://sonic-cloud.cn/deploy # ################################################ ################## # Service Config # ################## SONIC_SERVER_HOST=192.168.1.222 SONIC_SERVER_PORT=3000 SONIC_EUREKA_USERNAME=sonic SONIC_EUREKA_PASSWORD=sonic SONIC_EUREKA_PORT=8761 ################ # MySQL Config # ################ MYSQL_HOST=sonic-mysql MYSQL_PORT=3306 MYSQL_DATABASE=sonic MYSQL_USERNAME=root MYSQL_PASSWORD=sonic ################ # User Config # ################ SECRET_KEY=sonic EXPIRE_DAY=14 PERMISSION_ENABLE=true PERMISSION_SUPER_ADMIN=sonic REGISTER_ENABLE=true NORMAL_USER_ENABLE=true LDAP_USER_ENABLE=false LDAP_USER_ID=cn LDAP_BASE_DN=ou=users LDAP_BASE=ou=system LDAP_USERNAME=uid=admin,ou=system LDAP_PASSWORD=sonic LDAP_URL=ldap://192.168.1.1:10389 LDAP_OBJECT_CLASS=person # docker-compose.yml version: &#39;3&#39; services: sonic-server-eureka: image: &#34;dockerproxy.com/sonicorg/sonic-server-eureka:v2.4.1&#34; hostname: sonic-server-eureka environment: - SONIC_EUREKA_USERNAME - SONIC_EUREKA_PASSWORD - SONIC_EUREKA_PORT - SONIC_EUREKA_HOST=sonic-server-eureka volumes: - ./logs/:/logs/ depends_on: - sonic-mysql networks: - sonic-network ports: - &#34;${SONIC_EUREKA_PORT}:${SONIC_EUREKA_PORT}&#34; sonic-server-gateway: image: &#34;dockerproxy.com/sonicorg/sonic-server-gateway:v2.4.1&#34; hostname: sonic-server-gateway environment: - SONIC_EUREKA_USERNAME - SONIC_EUREKA_PASSWORD - SONIC_EUREKA_PORT - SONIC_EUREKA_HOST=sonic-server-eureka - SECRET_KEY - EXPIRE_DAY volumes: - ./logs/:/logs/ depends_on: - sonic-server-eureka networks: - sonic-network restart: on-failure sonic-server-controller: image: &#34;dockerproxy.com/sonicorg/sonic-server-controller:v2.4.1&#34; environment: - SONIC_EUREKA_USERNAME - SONIC_EUREKA_PASSWORD - SONIC_EUREKA_PORT - SONIC_EUREKA_HOST=sonic-server-eureka - MYSQL_HOST 1,6 Top - EXPIRE_DAY networks: - sonic-network volumes: - ./keepFiles/:/keepFiles/ - ./imageFiles/:/imageFiles/ - ./recordFiles/:/recordFiles/ - ./packageFiles/:/packageFiles/ - ./logs/:/logs/ depends_on: - sonic-server-eureka restart: on-failure sonic-client-web: image: &#34;dockerproxy.com/sonicorg/sonic-client-web:v2.4.1&#34; environment: - SONIC_SERVER_HOST - SONIC_SERVER_PORT networks: - sonic-network depends_on: - sonic-server-gateway restart: on-failure ports: - &#34;${SONIC_SERVER_PORT}:80&#34; sonic-mysql: image: &#34;mysql:5.7&#34; hostname: sonic-mysql command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci environment: - MYSQL_ROOT_PASSWORD=${MYSQL_PASSWORD} - MYSQL_DATABASE volumes: - ./mysql/log:/var/log/mysql - ./mysql/data:/var/lib/mysql #- ./mysql/conf:/etc/mysql ports: - &#34;3306:3306&#34; networks: - sonic-network networks: sonic-network: driver: bridge 配置节点 仅 Ubuntu 支持节点以 docker 部署。
访问前端服务 IP:3000，注册后自动登录。
进入 设备中心 - Agent 中心 - 新增 Agent，复制 Agent Key
我这里是 Ubunt，所以直接使用 docker-compose 部署节点，jar 包部署方式移步官网。
$ mkdir /data/sonic-agent &amp;&amp; cd /data/sonic-agent $ wget 节点部署文件下载地址 &amp;&amp; unzip sonic-* 按照注释修改
# docker-compose.yml version: &#39;3&#39; services: sonic-agent: image: &#34;sonicorg/sonic-agent-linux:v2.4.1&#34; environment: # Change to SONIC_SERVER_HOST and SONIC_SERVER_PORT of server | 改成server的SONIC_SERVER_HOST和SONIC_SERVER_PORT - SONIC_SERVER_HOST=192.168.1.222 - SONIC_SERVER_PORT=3000 # Replace with ipv4 of the agent machine | 替换为部署Agent机器的ipv4 - AGENT_HOST=192.168.1.222 # Replace with the port of the agent service, which can be changed by yourself | 替换为Agent服务的端口，可以自行更改 - AGENT_PORT=7777 # Replace with the key of agent generated by the new front-end | 替换为前端新增Agent生成的key - AGENT_KEY=191b38a7-464f-418e-8697-cbd9a843992b # Whether to enable Android module | 是否开启安卓模块 - ANDROID_ENABLE=true # Whether to enable sonic-android-supply module | 是否开启sonic-android-supply功能 - USE_SAS=true # Whether to turn on the iOS module. | 是否开启iOS模块 - IOS_ENABLE=true # Replace with the bundleId of wda. If there is no. xcrunner suffix, it will be automatically completed. | 替换为wda的bundleId，如果没有.xctrunner后缀会自动补全 - WDA_BUNDLE_ID=com.facebook.WebDriverAgentRunner.xctrunner # Whether to enable the sonic-go-mitmproxy module | 是否开启sonic-go-mitmproxy功能 - SGM_ENABLE=true network_mode: &#34;host&#34; privileged: true volumes: - /dev/bus/usb:/dev/bus/usb - /var/run/usbmuxd:/var/run/usbmuxd 启动 docker-compose 即可。
]]></content></entry><entry><title>Andorid - 启动时间分析</title><url>/tech/andorid/%E5%90%AF%E5%8A%A8%E6%97%B6%E9%97%B4%E5%88%86%E6%9E%90/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html">APP 启动首屏基本上都是以颜色来标识，而不是图片，目的是为了适配更多分辨率不同的机型。
APP 启动方式 COLD（冷启动）：杀死应用进程后启动 WARM（暖启动）：BACK 退出应用后启动 HOT（热启动）：应用置为后台再启动 冷启动流程 第一阶段
加载并启动 APP 启动后立即显示一个空白的窗口 创建 APP 进程 第二阶段
创建 APP 对象 启动主进程 创建 Activity 加载布局，绘制 APP 启动时间 获取启动时间的方法有三种，以下均为冷启动。
1、代码打印日志获取
这种方式需要开发自行添加代码。
attachBaseContext onCreate 1、系统日志
$ adb logcat | grep -i displayed ActivityTaskManager: Displayed com.esbook.reader/.activity.ActLoading: +932ms 3、adb 启动
# -S 杀死应用后启动 $ adb shell am start -S -W com.esbook.reader/com.esbook.reader.activity.ActLoading Stopping: com.esbook.reader Starting: Intent { act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] cmp=com.esbook.reader/.activity.ActLoading } Status: ok LaunchState: COLD Activity: com.esbook.reader/.activity.ActLoading TotalTime: 932 WaitTime: 935 Complete Status：命令执行状态 LaunchState：应用启动状态，分为冷、暖、热启动，还有一种 UNKNOWN (0) 的状态，测试当前应用在前台，执行启动命令会出现。 TotalTime：代表所有 Activity 启动时间 WaitTime：当前应用进程的创建过程 + TotalTime ThisTime：代表最后一个 Activity 启动时间（Android 10 上面没有这个时间）</content></entry><entry><title>Mac - 安装Jdk17</title><url>/tech/mac/%E5%AE%89%E8%A3%85jdk17/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html"><![CDATA[下载地址：https://www.oracle.com/java/technologies/downloads/#jdk17-mac
选择 x64 DMG Installer 下载完成后，一路下一步完成安装。
查看当前机器安装的所有 Java 版本
$ /usr/libexec/java_home -V 17.0.2 (x86_64) &#34;Oracle Corporation&#34; - &#34;Java SE 17.0.2&#34; /Library/Java/JavaVirtualMachines/jdk-17.0.2.jdk/Contents/Home 11.0.2 (x86_64) &#34;Oracle Corporation&#34; - &#34;Java SE 11.0.2&#34; /Library/Java/JavaVirtualMachines/jdk-11.0.2.jdk/Contents/Home 1.8.231.11 (x86_64) &#34;Oracle Corporation&#34; - &#34;Java&#34; /Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home # JRE 1.8.0_231 (x86_64) &#34;Oracle Corporation&#34; - &#34;Java SE 8&#34; /Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home 修改 bash_profile 内的 JAVA_HOME 路径
# JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-17.0.2.jdk/Contents/Home PATH=$JAVA_HOME/bin:$PATH:. CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:. export JAVA_HOME export PATH export CLASSPATH ]]></content></entry><entry><title>Bookmarks - 测开面试经验</title><url>/tech/bookmarks/%E6%B5%8B%E5%BC%80%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C/</url><categories><category>Bookmarks</category></categories><tags><tag>Bookmarks</tag></tags><content type="html"><![CDATA[ 文章来源：测试人社区 ling_tianxia 的分享。
原文地址： https://ceshiren.com/t/topic/3505  
 这里归纳总结了一些测试工程师常见的面试题，包含网络收集（完善）、个人遇到的、日常讨论等部分，总结为以下十个部分，供大家参考。如有错误的地方，欢迎指正。有更多的面试题或面试中遇到的坑，也希望补充分享。希望大家都能找到满意的工作，共勉之！~
软件测试工程师面试的过程中，一些常见的、印象比较深的题目 一、测试常见问题和流程篇  介绍一下测试流程（重点，常见！）  需求评审、测试计划、测试用例、用例评审、冒烟测试、测试执行、验收测试、风险评估、上线\观察、问题跟进、测试报告、复盘会议； 根据自己的日常经验来回答，每个点的工作内容都需要清晰掌握，有可能就某个点如何工作进行提问。   介绍一下测试方法  按阶段：单元测试、集成测试、系统测试、验收测试 按手段：黑盒测试、白盒测试、灰盒测试 其他：冒烟测试、回归测试   介绍一下测试用例设计方法（用例设计方法&amp;测试方法需分清楚）  黑盒测试用例设计：等价类划分法、边界值分析法、错误推测法、因果图法、正交试验分析法、流程分析法 白盒测试：语句覆盖、判定覆盖、条件覆盖、条件组合覆盖、判定/条件覆盖、路径覆盖   设计一个登录页面的用例（提供某个场景设计用例，重点！）  功能测试：正确输入、为空输入、字符类型校验、长度校验、密码是否加密显示、大写提示、跳转页面是否成功、登出后用另一个账号登录 UI：界面布局合理、风格统一、界面文字简洁好理解、没有错别字 性能测试：打开登录页面需要几秒、点击登录跳转首页需要几秒、多次点击、多人点击 安全性：用户名和密码是否加密发送给服务器、错误登录的次数限制（防止暴力破解）、一台机器登录多个用户、一个用户多方登录、检查元素能否看到密码 兼容性测试：不同浏览器、不同的平台（Windows Mac）、移动设备能否工作 易用性：输入框可否tab键切换、回车能否登录等   举例说明项目推进的能力（针对个人评价的举例说明）  （例）推动开发解决菜单权限需退出登录才可应用的问题。描述：XX项目上线后，由于权限更新导致用户无法使用旧界面+用户不懂得自己退出登录以应用新菜单权限，线上多个用户反馈平台相关功能无法使用。处理：远程操作+线上指导出现问题的用户退出登录，凌晨脚本批量强制用户退出登录。推进：在下一次版本中，推动开发处理菜单权限更新问题，以防每次更新菜单都出现用户使用不了功能的问题。结果：处理为用户登录期间仍可使用旧界面，直到用户退出重新登录后，才应用新菜单权限 推动冒烟：冒烟不通，测试召开会议罗列项目不通的模块、存在的问题，一一对应到每个人去跟进，得到解决的时间，后续项目群说明并艾特每个人跟进。测试准时验收 推动文档质量：在日常工作中遇到需求文档、设计文档、接口文档不规范或不详细的在绝大多数，这个时候就要通过沟通或以bug的形式，促使各个岗位将各自的文档完善 结合自己的个人经验，从问题描述+处理过程+推进表现+结果，一一说明   测试中遇到的比较难的一个项目是？（掌握自己简历上的项目）  XX项目：这个项目是一个新项目、需要对接第三方、从协助测试产品模块到转手负责整个项目加强了一定的需求理解难度、订单逻辑不熟悉、其中需求的问题推进比较困难。针对这些困难，测试方面：先快速了解需求，并与原先的测试负责人了解具体的进度和需要注意的测试点。开发方面：迅速与开发人员了解订单逻辑，以及与第三方对接的过程。产品方面：遇到某个需求问题产品不接受、最后汇报领导+开会讨论了较好的处理方案。虽然过程问题比较多，但是通过项目组的集体努力，最后项目得以按时上线 说明项目（最好是简历上的项目方便面试官进一步提问）。描述有难度的地方+如何处理+结果   印象深刻的一个bug？  隐藏得比较深的bug、影响比较大的bug、处理过程比较曲折的bug。根据自己的经验描述：如何发现的、如何处理、影响、结果、反思。 举例说明：如升级版本兼容性问题、接口安全性问题、数据库安全性问题、服务器资源占用溢出问题、代码逻辑问题等   你们公司是不是敏捷开发？介绍一下敏捷开发？  是，敏捷快速迭代、多版本同时迭代 敏捷开发属于增量式开发，对于需求范围不明确、需求变更较多的项目而言可以很大程度上响应和拥抱变化、主张简单、拥抱变化、可持续性、递增的变化、高质量的工作、快速反馈、软件是你的主要目标   复盘会议的主要内容有哪些？  这点需要结合自己平时参与的项目会议举例说明。如线上bug分析、优化改进策略、bug优先级等等   app的兼容性怎么测，app的接口测试怎么测？  系统兼容(ios、安卓)、机型兼容（iPhone、华为、小米、三星、vivo、OPPO）、分辨率兼容、软件本身向前向后兼容 接口测试：获取接口文档，使用fiddler抓包工具获取接口的请求方式、url、请求参数、返回参数，然后使用postman、jmeter进行测试   web端测试和app端测试有何不同（常见）  系统结构方面  web项目，b/s架构，基于浏览器的；web测试只要更新了服务器端，客户端就会同步会更新 app项目，c/s结构的，必须要有客户端；app 修改了服务端，则客户端用户所有核心版本都需要进行回归测试一遍   兼容方面  web项目：a. 浏览器（火狐、谷歌、IE等）b. 操作系统（Windows7、Windows10、Linux等） app项目：a. 设备系统: iOS（ipad、iphone）、Android（三星、华为、联想等） 、Windows（Win7、Win8）、OSX（Mac）b. 手机设备可根据 手机型号、分辨率不同   性能方面  web项目 需监测 响应时间、CPU、Memory app项目 除了监测 响应时间、CPU、Memory外，还需监测流量、电量等   相对于 Web 项目，APP有专项测试  干扰测试：中断，来电，短信，关机，重启等 弱网络测试（模拟2g、3g、4g，wifi网络状态以及丢包情况）；网络切换测试（网络断开后重连、3g切换到4g/wifi 等） 安装、更新、卸载  安装：需考虑安装时的中断、弱网、安装后删除安装文件等情况 卸载：需考虑 卸载后是否删除app相关的文件 更新：分强制更新、非强制更新、增量包更新、断点续传、弱网状态下更新     界面操作：关于手机端测试，需注意手势，横竖屏切换，多点触控，前后台切换 安全测试：安装包是否可反编译代码、安装包是否签名、权限设置，例如访问通讯录等 边界测试：可用存储空间少、没有SD卡/双SD卡、飞行模式、系统时间有误、第三方依赖（QQ、微信登录）等 权限测试：设置某个App是否可以获取该权限，例如是否可访问通讯录、相册、照相机等    二、测试工具篇  介绍一下测试中常用的工具（基础，掌握！）  需求问题跟进、测试计划、风险评估登记、测试报告、复盘会议：wiki 测试用例：Xmind编写，testlink管理 测试执行：elk、Xshell等 bug管理：Jira、bugfree、禅道等 接口相关：charles、fiddler、postman、jmeter等 自动化相关：selenium、appium、pytest、locust、jmeter等   用什么工具对用例进行管理  testlink管理用例的一般步骤：新建计划、新建版本、上传xml文件、添加测试用例到测试计划中、分配测试用例给开发、查看用例执行报告 xmind：xxxxxx excel：xxxxxxx   怎么使用elk定位日志  查看产品推送是否成功。产品从A平台推送到B平台，根据A平台的链接id，搜索对应的日志。搜索不到，则为A平台推送失败。搜索到了，查看推送的状态，进一步判断问题所在。 使用官方文档，可以进一步了解elk日志查看   Xshell如何登录，如何切换目录  使用ssh密钥登录：生成密钥公钥和私钥-上传公钥到服务器-配置Xshell使用密钥认证方式登录到服务器（参考： https://www.cnblogs.com/Black-rainbow/articles/9418713.html） 39   使用账号密码登录：配置中输入被连接服务器的账号、密码、ip及端口连接   埋点测试怎么测试，使用什么工具，数据要不要入库  使用charles、fiddler抓包，查看对应的来源记录、事件等必要参数是否正确，查看数据库记录是否正确   介绍fiddler和postman的区别  fiddler主要是抓包，postman主要进行接口请求   怎么使用postman进行多个接口请求？  将多个接口请求归纳到一个集合里，在集合的右上角点击展开箭头，点击run   日常工作中jmeter是怎么用的？  接口测试：通过对指定接口进行请求访问，验证数据出入的准确性与安全性 性能测试：编写对应的测试集，通过脚本控制线程数，实现逐步加压等 结合自己项目经验，没有经验千万不能盲目举例乱说，避免坑自己   例举熟悉的自动化测试工具，并说明其实现原理  selenium 过程如下：  运行用python写好的selenium脚本，它会像web service中发送一个http请求 浏览器驱动中的web service 会根据这个请求生成对应的js脚本，因为不同的浏览器，相同的操作生成的js脚本会有所不同，因此不同的浏览器要有不同的驱动 js脚本驱动浏览器，产生各种操作，并返回给web service web service将结果通过http响应的形式返回给客户端   appium的加载过程  调用Android adb完成基本的系统操作 向Android上部署bootstrap.jar bootstrap.jar Forward Android的4723端口到PC机器上 PC上监听端口接收请求，使用webdriver协议 分析命令并通过forward 端口发给bootstrap.jar bootstrap.jar接收请求并把命令发给uiautomator uiautomator执行命令      三、计算机网络 常识篇  擅长哪些开发语言  学习过Java，C等 半精通python   输入url到网页显示出来的全过程  输入网址 DNS解析 建立tcp连接 客户端发送HTTP请求 服务器处理请求 服务器响应请求 浏览器展示HTML 浏览器发送请求获取其他在HTML中的资源。   http和https的区别  https里面是要有证书的，http并没有证书，证书的作用是证明你是这个网站的拥有者，谁去证明，最顶级的CA去帮你证明，这些顶级的CA都是浏览器、操作系统本身就自动帮你集成，而且自动添加到设置信任里面去 https要兼顾安全+性能的方面，由于对称式加密虽然速度很快，但是安全性特别的低，因为双方要规定对称式加密的秘钥，别人都无法知道，但你怎么能确保别人不知道你的秘钥呢，因此需要有非对称式加密去保证安全，但非对称式加密速度又很慢，如果客户端和服务器端都用非对称式加密，网络得卡死了。所以当双方建立好了非对称加密后，再约定一个随机数，等大家都非对称解密了之后呢，就拿到只有对方知道的唯一随机数（秘钥），就可以用秘钥来进行对称式加密和解密了   HTTP的报文结构  HTTP请求报文：一个HTTP请求报文由请求行、请求头部、空行和请求数据4个部分组成 HTTP响应报文：HTTP响应也由三个部分组成，分别是：状态行、消息报头、响应正文   http常见的响应状态码  200 请求已成功，请求所希望的响应头或数据体将随此响应返回。 201 请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随 Location 头信息返回 202 服务器已接受请求，但尚未处理 301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。 302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。 304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。  305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。 307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 401 当前请求需要用户验证。如果当前请求已经包含了 Authorization 证书，那么 401 响应代表着服务器验证已经拒绝了那些证书 403 服务器已经理解请求，但是拒绝执行它。与 401 响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交 404 请求失败，请求所希望得到的资源未被在服务器上发现 500 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。 501 服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。 502 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 503 由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。   cookie和session机制的区别  cookies 数据保存在客户端，session 数据保存在服务器端； cookies 可以减轻服务器压力，但是不安全，容易进行 cookies 欺骗； session 较安全，但占用服务器资源   TCP和UDP的区别  TCP：面向连接，可靠的，速度慢，效率低 UDP：无连接、不可靠、速度快、效率高   TCP为什么是三次握手和四次挥手  三次握手能保证数据可靠传输又能提高传输效率。若握手是两次：如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认。 要保证双方都关闭了连接。因为TCP是全双工的，就是要等到两边都发送fin包确认双方都没有数据传输后才关闭   TCP为什么最后挥手后会有time_wait  为了保证可靠的断开TCP的双向连接，确保足够的时间让对方收到ACK包。若客户端回复的ACK丢失，server会在超时时间到来时，重传最后一个fin包，处于TIME_WAIT状态的client可以继续回复Fin包，发送ACK。 保证让迟来的TCP报文段有足够的时间被识别和丢弃，避免新旧连接混淆。有些路由器会缓存没有收到的数据包，如果新的连接开启，这些数据包可能就会和新的连接中的数据包混在一起。连接结束了，网络中的延迟报文也应该被丢弃掉，以免影响立刻建立的新连接。   简要说明http请求中的post和get有哪些区别的地方  请求头多了content-length和content-type字段 post可以附加body，可以支持form、json、xml、binary等各种数据格式 行业通用规范 无状态变化的建议使用get 数据的写入与状态的修改建议使用post 基于http协议：都是请求返回数据，get将请求体放在头上，只发一次请求，post将请求体放在内部，需要发送两次请求 GET 在浏览器回退时是无害的，而 POST 会再次提交请求。 GET 请求会被浏览器主动 cache，而 POST 不会，除非手动设置。 GET 请求只能进行 url 编码，而 POST 支持多种编码方式。 GET 请求在 URL 中传送的参数是有长度限制的，而 POST 么有。 对参数的数据类型，GET 只接受 ASCII 字符，而 POST 没有限制。 GET 比 POST 更不安全，因为参数直接暴露在 URL 上，所以不能用来传递敏感信息。   如果一个请求，返回的状态码是200，但是没有内容，可能发生了什么？  请求头缺失或错误 参数length不符 以上为个人了解，有误请补充   http 与 https 的区别  端口号不同，http 是 80， https 是 443 http 是超文本传输协议，明文传输；https 是具有安全性的 ssl 加密传输协议 连接方式不同，http 是三次握手，https 多了一个安全握手过程 https 需要申请 ca 证书，会产生一定的费用    四、数据库篇   工作中常使用的SQL语法有哪些？
 create table、create view、 select from where、insert into、update set values、delete、alter、order by、having    数据库存储过程
 一组数据库操作命令，当作是自己写的一个方法，一系列步骤自己去封装（个人理解）    SQL常见查询语句编写（此处仅举例常见的查询语句，如有更多坑，希望补充）
查询所有学生的数学成绩，显示学生姓名 name, 分数， 由高到低。
SELECT a.name, b.score FROM student a, grade b WHERE a.id = b.id AND kemu = ‘数学’ ORDER BY score DESC； 统计每个学生的总成绩（由于学生可能有重复名字）,显示字段：学生 id，姓名，总成绩。
SELECT a.id, a.name, c.sum_score from student a, (SELECT b.id, sum(b.score) as sum_score FROM grade b GROUP BY id) c WHERE a.id = c.id ORDER BY sum_score DESC； 列出各门课程成绩最好的学生， 要求显示字段: 学号，姓名，科目，成绩。
SELECT c.id , a.name, c.kemu, c.score FROM grade c, student a, (SELECT b.kemu, MAX(b.score) as max_score FROM grade b GROUP BY kemu) t WHERE c.kemu = t.kemu AND c.score = t.max_score AND a.id = c.id   慢查询是什么意思？
 开启慢查询日志，可以让MySQL记录下查询超过指定时间的语句，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能。    导致数据库性能差的可能原因有哪些？
 硬件环境问题，如磁盘IO 查询语句问题，如join、子查询、没建索引 索引失效，建了索引，查询的时候没用上 查询关联了太多的join 服务器关联缓存，线程数等 表中存在冗余字段，在生成笛卡尔积时耗费多余的时间    redis缓存应用场景
 需要将数据缓存在内存中，提升查询效率 本人没经验，希望补充    怎么定位redis缓存失效问题（缓存坏了）
 不知道，看不懂    五、Linux篇  工作中常用的Linux命令有哪些？  awk、sed、vim、iotop、dstat、cp、top、ifconfig、pwd、cd、ll、ls、cat、tail、grep、mv、rm、mkdir、df、du   什么命令可以帮助Linux执行Windows上传的脚本  改变编码格式 vim test.sh :set ff?// 显示dos的话 :set ff=unix:wq   简述linux三剑客  grep命令：根据用户指定的模式pattern对目标文本进行过滤，显示被模式匹配到的行，grep [options] pattern [file]，常用参数：  -v 显示不被pattern匹配到的行 -i 忽略字符的大小写 -n 显示匹配的行号 -c 统计匹配的行数 -o 仅显示匹配到的字符串 -E 使用ERE，相当于egrep（可以识别更多的正则表达式规则）   sed：流编辑器，用来处理一行数据。将一行数据存储在模式空间中-&gt;用sed命令处理-&gt;送入屏幕-&gt;清空空间，常用参数：  -h 显示帮助 -n 仅显示script处理后的结果 -e 指定的脚本来处理输入的文本文件 -f 以指定的脚本文件来处理 常用动作  a: 新增 sed -e ‘4 a newline’ c: 取代 sed -e ‘2,5c No 2-5 number’ d: 删除 sed -e ‘2,5d’ i: 插入 sed -ed ‘2i newline’ p: 打印 sed -n ‘/root/p’ s: 取代 sed -e ‘s/old/new/g’ g: 代表全局     awk：把文件逐行的读入，以空格为默认分隔符将每行切片。 把行作为输入，并赋值给$0-&gt;将行切段，从$1开始-&gt;对行匹配正则/执行动作-&gt;打印内容，awk ‘pattern + action’ [filenames]，常用语法：  filename awk浏览的文件名 begin 处理文本前要执行的操作 end 处理文本之后要执行的操作 fs 设置输入域分隔符，等价于命令行-F选项 nf 浏览记录的域的个数（列数） nr 已读的记录数（行数） 常用参数  ofs 输出域分隔符 ors 输出记录分隔符 rs 控制记录分隔符，换行标志 $0 整条记录 $1 第一条分隔后的记录       如何通命令定位Linux服务器下的日志？  如果要监控日志，那么使用tail -f | grep xxx命令，过滤需要的字段 如果在完整日志中查看内容，使用cat xxx.log | grep xxxx | awk &lsquo;{print $1}&lsquo;等命令过滤自己需要的内容   简述项目中的环境搭建和维护  结合自身经验先从系统安装开始，如常用的centos和Ubuntu说起，系统安装主要是磁盘分区和磁盘阵列问题 基础环境依赖，如MySQL、Redis、jenkins、docker、项目中用到的其他依赖环境等 维护方便主要从遇到的错误说起，如无法远程连接、服务器加固等    六、 python编程篇   python中类方法，类实例方法，静态方法的区别
 实例方法：由对象调用；至少一个self参数；执行普通方法时，自动将调用该方法的对象赋值给self； 类方法：由类调用； 至少一个cls参数；执行类方法时，自动将调用该方法的类复制给cls； 静态方法：由类调用；无默认参数；    dict和tuple及list的区别（这里列的是主要区别，面试足够）
 tuple是不可变对象，list和dict都是可变对象，这里的不可变指的是指向地址不可变 list是有序的，dict是无序的，不可存放有序集合 dict查找速度快，不管有多少个元素时间都一样，list查找速度慢，需要有序查找 dict的key为不可变对象，且不可重复，list则可以重复，存放任意对象    json和dict的区别
 json是一种数据格式，纯字符串。dict是一种完整的数据结构 dict是一个完整的数据结构，是对Hash Table这一数据结构的一种实现，是一套从存储到提取都封装好了的方案。它使用内置的哈希函数来规划key对应value的存储位置，从而获得O（1）的数据读取速度。 json的key只能是字符串，python的dict可以是任何可hash对象（不可变对象） json的key可以是有序、可重复的；dict的key不可重复，且无序。 json任意key存在默认值undefined，dict默认没有默认值 json访问方式可以是[],也可以是.，遍历方式分in、of；dict的value仅可以下标访问 dict可以嵌套tuple，json里只有数组    python会不会出现内存泄漏，为什么
 当对象之间互相引用的时候再删除的时候，可能会造成无法释放对象的情况，出现泄漏 上面为个人了解，如有其它请补充    python的同步和异步
 直接得到最终结果的结果，就是同步调用。 不直接得到的最终的结果，就是异步调用。 同步与异步区别在于：调用者是否得到了想要的最终结果。    常见手撕代码题
 两个列表提取作为字典  dict(zip(list1, list2))  字符串反转输出  str = &#39;1234567890&#39; print(str[::-1]) l.reverse() print(&#39;&#39;.join(l))  实现斐波那契数列  def Fibonacci(loop): if loop == 0: return &#39;无效参数&#39; elif loop == 1: return 0 l = [0, 1] for i in range(2, loop): l.append(l[i - 1] + l[i - 2]) return l  找出驼峰数组的最大值  li = [1, 2, 10, 10, 2, 1] print([v for v in li if v == max(li)])  水仙花数  sxh = [] for i in range(100, 1000): s = 0 for j in str(i): s += int(j)**3 if i == int(j)**3: sxh.append(i) print(sxh)  完全数  a = [] for i in range(1, 1000): s = 0 for j in range(1, i): if i % j == 0 and j &lt; i: s += j if s == i: a.append(i)  幂的递归  def mi(a, n): if n == 0: return 1 else: return a * mi(a, n - 1)  目录遍历  import os files = [] for fpath, dirs, fs in os.walk(path): for f in fs: if os.path.join(fpath, f).endswith(rule): files.append(f) return files   七、自动化相关（包含selenium、appium和接口）  自动化代码中，用到了哪些设计模式  单例模式 工厂模式 PO模式 数据驱动模式   什么是断言  检查一个条件，如果它为真，就不做任何事，用例通过。如果它为假，则会抛出AssertError并且包含错误信息。   UI自动化中，如何做集群  selenium grid，分布式执行用例 appium 使用stf管理多设备 docker+k8s管理集群   怎么对含有验证码的功能进行自动化测试  万能验证码 测试环境屏蔽验证 其他操作不推荐   如何优化和提高selenium脚本的执行速度  尽量使用by_css_selector()方法：by_css_selector()方法的执行速度比by_id()方法的更快，因为源码中by_id()方法会被自动转成by_css_selector()方法处理 使用等待时，尽量使用显示等待，少用sleep()，尽量不用隐式等待 尽量减少不必要的操作：可以直接访问页面的，不要通过点击操作访问 并发执行测试用例：同时执行多条测试用例，降低用例间的耦合 有些页面加载时间长，可以中断加载   接口测试能发现哪些问题  可以发现很多在页面上操作发现不了的 bug 检查系统的异常处理能力 检查系统的安全性、稳定性 前端随便变，接口测好了，后端不用变 可以测试并发情况，一个账号，同时（大于 2 个请求）对最后一个商品下单，或不同账号，对最后一个商品下单 可以修改请求参数，突破前端页面输入限制（如金额）   selenium 中隐藏元素如何定位？  如果单纯的定位的话，隐藏元素和普通不隐藏元素定位没啥区别，用正常定位方法就行了，这个很多面试官也搞不清楚 元素的属性隐藏和显示，主要是 type=&ldquo;hidden&quot;和 style=&ldquo;display: none;&ldquo;属性来控制的，接下来在元素属性里面让它隐藏，隐藏元素可以正常定位到，只是不能操作（定位元素和操作元素是两码事，很多初学者傻傻分不清楚），操作元素是 click,clear,send_keys 这些方法 JS 操作隐藏元素   如何判断一个页面上元素是否存在？  方法一：用 try…except… 方法二：用 elements 定义一组元素方法，判断元素是否存在,存在返回 True,不存返回 False 方法三：结合 WebDriverWait 和 expected_conditions 判断（推荐）   如何提高脚本的稳定性  不要右键复制 xpath(十万八千里那种路径，肯定不稳定)，自己写相对路径，多用 id 为节点查找 定位没问题，第二个影响因素那就是等待了，sleep 等待尽量少用（影响执行时间） 定位元素方法重新封装，结合 WebDriverWait 和 expected_conditions 判断元素方法，自己封装一套定位元素方法   如何定位动态元素  动态元素有 2 种情况，一个是属性动态，比如 id 是动态的，定位时候，那就不要用 id 定位就是了 还有一种情况动态的，那就是这个元素一会在页面上方，一会在下方，飘忽不定的动态元素，定位方法也是一样，按 f12，根据元素属性定位（元素的 tag、name的步伐属性是不会变的，动的只是 class 属性和 styles 属性）   如何通过子元素定位父元素  使用element.parent方法   平常遇到过哪些问题? ?如何解决的  可以把平常遇到的元素定位的一些坑说下，然后说下为什么没定位到，比如动态id、有 iframe、没加等待等因素   一个元素明明定位到了，点击无效（也没报错），如果解决？  使用 js 点击，selenium 有时候点击元素是会失效   **测试的数据你放在哪? **  对于账号密码，这种管全局的参数，可以用命令行参数，单独抽出来，写的配置文件里（如 ini） 对于一些一次性消耗的数据，比如注册，每次注册不一样的数，可以用随机函数生成 对于一个接口有多组测试的参数，可以参数化，数据放 yaml,text,json,excel都可以 对于可以反复使用的数据，比如订单的各种状态需要造数据的情况，可以放到数据库，每次数据初始化，用完后再清理 对于邮箱配置的一些参数，可以用 ini 配置文件 对于全部是独立的接口项目，可以用数据驱动方式，用 excel/csv 管理测试的接口数据 对于少量的静态数据，比如一个接口的测试数据，也就 2-3 组，可以写到 py脚本的开头，十年八年都不会变更的   什么是数据驱动，如何参数化？  参数化的思想是代码用例写好了后，不需要改代码，只需维护测试数据就可以了，并且根据不同的测试数据生成多个用例   其他接口都需要登录接口的信息，怎么去让这个登录的接口只在其他接口调用一次  使用单例模式 使用自定义缓存机制 使用测试框架中的setup机制 pytest中fixture机制   接口产生的垃圾数据如何清理  造数据和数据清理，需用 python 连数据库了，做增删改查的操作测试用例前置操作，setUp 做数据准备后置操作，tearDown 做数据清理   怎么用接口案例去覆盖业务逻辑？  考虑不同的业务场景，一个接口走过的流程是什么样的，流程的逻辑是什么样的，什么样的参数会有什么样的结果，多场景覆盖    八、性能篇  性能测试指标包括哪些  最大并发用户数，HPS（点击率）、事务响应时间、每秒事务数、每秒点击量、吞吐量、CPU使用率、物理内存使用、网络流量使用等。 前端需主要关注的点是：  响应时间：用户从客户端发出请求，并得到响应，以及展示出来的整个过程的时间。 加载速度：通俗的理解为页面内容显示的快慢。 流量：所消耗的网络流量。   后端需主要关注的是：  响应时间：接口从请求到响应、返回的时间。 并发用户数：同一时间点请求服务器的用户数，支持的最大并发数。 内存占用：也就是内存开销。 吞吐量（TPS）：Transaction Per Second, 每秒事务数。在没有遇到性能瓶颈时：TPS=并发用户数*事务数/响应时间。 错误率：失败的事务数/事务总数。 资源使用率：CPU占用率、内存使用率、磁盘I/O、网络I/O。 从性能测试分析度量的度角来看，主要可以从如下几个大的维度来收集考察性能指标： 系统性能指标、资源性能指标、稳定性指标     如果一个需求没有明确的性能指标，要如何开始进行性能测试？  先输出业务数据，如pv、pu、时间段等，计算出大概的值，然后不断加压测到峰值   介绍JMeter聚合报告包括哪些内容  请求名、线程数、响应时间（50 95 99 最小 最大）错误率、吞吐量   如果有一个页面特别卡顿，设想一下可能的原因  后台：接口返回数据慢，查询性能等各种问题 前端：使用chrome工具调试，判断js执行久或是其他问题 网络问题   说一说项目中的实际测试内容  根据自己项目中的经验实话实说，有没有经验很容易露馅   介绍一下JMeter进行性能测试的过程   www.baidu.com 116     介绍一下JMeter和LoadRunner的区别   www.baidu.com 116      九、10大灵魂拷问  自己的优点和缺点  避开岗位的核心技能 把缺点放在场景中描述 对缺点进行合理化解释 优点随便说，主要方向还是在岗位上   是否能接受加班，建议分情况作答：  第一种情况：假设公司有重要的项目要赶。示范回答：贵公司现在正处于发展上升期，也在官网上有看到公司的重要项目成果，我觉得有时候因为赶项目进度、工作需要等忙起来是非常正常的，面对这种情况，我是非常愿意配合公司和团队的工作，让工作能够更顺利地完成，此外，我也相信自己一定能在公司安排的工作中获得到锻炼，获得更快地成长。 第二种情况：假设自己作为新人，对业务不熟悉。示范回答：我作为公司刚进去的新人，可能刚开始进入公司接触业务时不太熟练，会出现需要加班的情况，但我更愿意提高工作效率，并积极向公司的前辈请教学习，在一定的时间内完成工作而不是拖到下班之后。当然， 如果有紧急的事情，忙起来需要加班也是可以接受的。   薪酬的要求  薪资并不是我求职的唯一标准，我上家公司基本在A~B 之间（建议合理提高，避免部分HR压价） 我来贵司求职的主要动机是兴趣，这份工作是我喜欢做的，也相信自己可以胜任，更相信公司会给出一个合理的薪酬。 相比薪酬，我更在意的是收入，所以，我很愿意了解贵司的薪酬架构，可以简单介绍下吗？ 我希望薪资可以达到**，据我了解，贵司这个岗位薪资范围是A~B ，而结合岗位职责及任职要求，我对自己也进行了相应评估，也愿意接受贵司的下一步考核。   未来5年的职业规划  自我认知。对自己是否了解，了解是不是靠谱。 动机和价值观。你是否能接受我们并不一定能给你公平的职业发展机会这个现实？ 组织承诺。你到底能在我们这踏实的干几年？   我们为什么要聘用你  描述应聘岗位的胜任条件，强调自己的工作能力和工作经验跟岗位的匹配度，岗位要求的工作技能是否自己掌握了，掌握的程度是怎样的，最好在面试中说出来。因此，在面试前最好是要针对应聘岗位，把自己胜任的条件一一列出来，做到知己知彼。可以谈论一下自己之前的工作情况，用成绩、用数据来说明自己的成就。 描述自己能为公司做出什么贡献，公司是一个讲究利益的地方，聘用你肯定要你为公司做出贡献。那么你在回答这个问题时，就需要说出你的加入可以为公司带来什么，这非常重要。因此，一定要明确你的工作目标和职业规划，表明你的立场和专业程度，让HR信任你。 描述出自身的优势。公司为何要聘用你，而不聘用别人，肯定是你有比别人优秀的地方。那么在回答这个问题时，就一定要说出自己与众不同的地方，最好是要举一个例子，来支持你的观点。 建立个人和公司的联系，HR想要得到一个怎样的答案呢？无非就是想通过这个问题，来进一步了解你各方面的信息，以及看看你为这次面试做了多少功课。那么在面试前，你最好是要尽可能获取有关公司可行业的资料信息。在回答的时候，结合自己所做的功课，建立个人和公司的联系，说明自己在哪一方面能够匹配公司的要求。HR看到你对应聘岗位这么了解，肯定会对你有好感。 说出你对这份工作的兴趣以及热情   对我们公司有多少了解  实时回答就好，知道多少就说多少，一般去面试对这个公司的了解都是从网上查到的，不会太深入   为什么愿意到我们公司  有所准备，了解公司 个人目标要与公司目标一致 强调你能如何为公司提高价值   与领导意见不一致时，该如何处理  不要假设我已经完全的掌握了对这件事的认知。向领导询问确认自己有可能缺失的信息。要寻找对领导没有告知的信息，和领导不能透露的信息。 不要假设领导已经完全的掌握了我对这件事的认知。检查一下，是否已经将事情的前因后果，自己对事情的理解，明确清晰的传达给了领导，以及，他是否真的已经明确了解。 在进行有效的认知沟通后，重新思考整件事情。如果意见还是有不一致，那么：  按领导要求执行。不理解，也执行，在执行中理解。 执行过程中，收集反馈，不断调整，提升认知。 执行完成后，及时复盘，回顾决策和行动过程，沉淀知识。     缺乏工作经验，如何胜任这份工作  承认工作经验的重要性。这样能带给面试官的印象是：该位候选人认知能力较强，具有理性思维与客观公正的处事态度及判断能力，尤其是对于自己也能客观公正地看待，勇于承认自己的缺失。 突显个人优势。用自己的其他优势特长来补足经验上的不足，比如说记忆力好、动手能力强、语言能力强、学习能力强等。 强调自己会不断提高工作能力。切忌用假大空的话，要用具体的与工作相关的事例或是数据来说明自己的学习力。   工作中与同事发生争执，如何处理  在沟通之前，做好充分的准备 学会认知倾听，让别人把话说完 借用一些工具，来解决交流障碍    十、反问面试官  职责  团队中初级和高级人眼如何平衡 针对员工有哪些培训和提升计划   技术  公司内部的技术栈 产品的架构 版本控制及迭代速度 服务器管理权限，本机家算计管理权限   团队  团队内和团队之间如何沟通 遇到了分歧如何解决 团队正在经历的尚未解决的挑战是什么 绩效考核是如何算的   公司  晋升机会 是否有自己的学习资源 假期，加班工资等 过去半年最糟糕的一天是怎么样的 是什么让你来到并留在这里 是否能够平衡工作与生活    ]]></content></entry><entry><title>Python - Requests Html解析网页</title><url>/tech/python/requests-html%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ requests-html API 使用示例。
 官方文档  
 Github  
 移动端混合应用，除 API 接口外，还包含大量的 web 页面需要校验，进行自动化测试。
在 GitHub 上找到一个解析 HTML 页面的库，与 requests 库是同作者，大神出品，必属精品。哈哈，研究一下。
安装 仅支持 Python 3.6 及以上版本。
$ pip install requests-html 使用 请求数据的方法：
 发送 web 请求，获取 HTML 响应 发送异步请求，异步获取 HTML 响应 解析本地 HTML 文件  解析数据的方法：
 links/absolute_links：获取网页链接 find：基于 CSS 选择器提取 xpath：基于 xpath 语法提取 search/search_all：正则获取文本内容  JavaScript 渲染：
 render() arender()：异步渲染  1、请求数据 请求方法与 requests 一样，因为他们是继承的关系。
# 发送请求 from requests_html import HTMLSession session = HTMLSession() r = session.get(&#39;https://python.org/&#39;) html = r.html # 异步请求 from requests_html import AsyncHTMLSession asession = AsyncHTMLSession() r = await asession.get(&#39;https://python.org/&#39;) html = r.html # 本地 HTML 文件 from requests_html import HTML doc = &#34;&#34;&#34;&lt;a href=&#39;https://httpbin.org&#39;&gt;&#34;&#34;&#34; html = HTML(html=doc) 以上三种方式都会得到一个 HTML 对象，后面的数据操作都是基于这个 HTML 对象进行的。
2、提取数据 简单了解下 API 的使用方法。
Links 获取页面上所有的链接（href 标签）。
from requests_html import HTMLSession session = HTMLSession() r = session.get(&#34;https://www.baidu.com/&#34;) html = r.html &#34;&#34;&#34; 相对链接：&lt;a href=&#34;/index.html&#34;&gt;Home&lt;/a&gt; 绝对链接：&lt;a href=&#34;https://www.navegabem.com/index.html&#34;&gt;Home&lt;/a&gt; &#34;&#34;&#34; # 获取全部链接，包含相对链接 html.links # 获取绝对链接，自动拼接前缀 html.absolute_links Text 获取页面上所有的文本内容。
session = HTMLSession() r = session.get(&#34;https://www.baidu.com/&#34;) html = r.html # 元素内和 HTML 标签内的文本内容 html.text # 包含链接文本内容 html.full_text 获取整个页面的文本内容，数据量往往非常大，且不好清洗，所以一般都是对单个元素使用。当对某一个元素使用时，就获取该元素内的文本内容，后面会用到。
XPATH 通过 XPATH 语法   获取数据。
# 获取页面中的书名和作者 # ==&gt; 后面跟的是输出 session = HTMLSession() r = session.get(&#34;https://book.easou.com/ta/index.m&#34;) html = r.html # 获取第一条匹配的数据，上文中 text 的好处在这里就体现出来了 element = html.xpath(&#34;//div[@class=&#39;text&#39;]&#34;, first=True) element.text # 获取所有匹配的数据，elements 是一个组 elements = html.xpath(&#34;//div[@class=&#39;text&#39;]&#34;) # 找到一本下标为 5 的书籍，获取该元素内的全部文本信息 elements[5].text.split(&#34;\n&#34;) ==&gt; [&#39;遮天&#39;, &#39;辰东&#39;, &#39;古典仙侠&#39;, &#39;冰冷与黑暗并存的宇宙深处，九具...&#39;, &#39;630.6万字&#39;, &#39;古典仙侠&#39;] CSS 通过 CSS 选择器   获取数据。
# 获取页面上的 tab 名称 session = HTMLSession() r = session.get(&#34;https://book.easou.com/ta/index.m&#34;) html = r.html # 获取第一个 tab 的名称 element = html.find(&#34;div.banner li&#34;, first=True) element.text ==&gt; &#39;精选&#39; # 获取全部 tab 名，这是 css selector 的另一种写法 elements = html.find(&#34;div[class=&#39;banner&#39;] li&#34;) tabs = [ele.text for ele in elements] ==&gt; [&#39;精选&#39;, &#39;分类&#39;, &#39;免费&#39;, &#39;书架&#39;] # 获取包含关键字的 tab 名 elements = html.find(&#34;div[class=&#39;banner&#39;] li&#34;, containing=&#34;书&#34;) elements[0].text ==&gt; &#39;书架&#39; re 基于正则获取数据。
# 获取排行榜第一页的书名 session = HTMLSession() r = session.get(&#34;https://book.easou.com/ta/rank.m?pageName=排行&#34;) html = r.html &#34;&#34;&#34; 1. search() 返回第一条匹配的数据 &#34;&#34;&#34; # 使用大括号匹配文本，类似 (.*?) element1 = html.search(&#39;&lt;div class=&#34;title&#34;&gt;{}&lt;/div&gt;&#39;) element2 = html.search(&#39;&lt;div class=&#34;desc&#34;&gt;{desc}&lt;/div&gt;&#39;) # 返回的是一个对象，包含一个元组，一个字典 # 大括号内为空，未对数据命名，数据放在元组内，通过下标取值 # 大括号内对数据命名，数据放在字典内，仅能通过 dict[key] 取值，不支持 get() element1 ==&gt; &lt;Result (&#39;深空彼岸&#39;,) {}&gt; element2 ==&gt; &lt;Result () {&#39;desc&#39;: &#39;浩瀚的宇宙中，一片星系的生灭，也不过是...&#39;}&gt; element1[0] ==&gt; &#39;深空彼岸&#39; element2[&#34;desc&#34;] ==&gt; &#39;浩瀚的宇宙中，一片星系的生灭，也不过是...&#39; &#34;&#34;&#34; 2. search_all() 返回全部数据 &#34;&#34;&#34; elements = html.search_all(&#39;&lt;div class=&#34;title&#34;&gt;{}&lt;/div&gt;&#39;) books = [ele[0] for ele in elements] len(books) ==&gt; 20 3、JavaScript 渲染 简单说下 JavaScript 渲染。
在浏览器访问一个链接，中间过程省略，浏览器会得到服务器返回的响应内容，开始生成 HTML DOM 树、渲染树，当遇到 JavaScript 脚本，也就是 &lt;script&gt; 标签时，会阻塞，等待 js 脚本执行，完成最终页面渲染。
使用代码直接发送页面请求时，无法获取利用 JavaScript 生成的页面，必须借助浏览器内核实现。这里实现渲染能力借助的是 Chromium 无头浏览器，页面渲染时是无感的。
 引用作者描述
Reloads the response in Chromium, and replaces HTML content with an updated version, with JavaScript executed.
 通过百度主页的热搜模块，演示该功能。
# 百度热搜 模块就是通过 js 渲染的 session = HTMLSession() r = session.get( url=&#34;https://www.baidu.com/&#34;, headers={&#34;user-agent&#34;: &#34;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Mobile Safari/537.36&#34;} ) html = r.html # 查看页面数据 html.html ==&gt; 输出的文本内容里没有包含「百度热搜」关键词 # 进行页面渲染后，再次打印 html.render() html.html ==&gt; 输出文本中包含「百度热搜」关键词 # 拿到热搜数据 hot_items = html.find(&#34;span[class=&#39;title-content-title&#39;]&#34;) hot_news = [e.text for e in hot_items] hot_news ==&gt; [ &#39;讲好冬奥故事 共赴冰雪之约&#39;, &#39;天津出现45起家庭聚集疫情&#39;, &#39;春节返乡31省份防疫要求汇总来了&#39;, ... ] 仅第一次运行 render() 方法时，会下载 Chromium。可能会下载失败：
 受网络影响（下载需要访问外网服务器，不稳定）; urllib3 版本号需要小于 1.25，我报错后通过下面命令回退版本后解决。  # pyppeteer.errors.NetworkError: Execution context was destroyed, most likely because of a navigation. $ pip install -U &#34;urllib3&lt;1.25&#34; 4、异步请求 from requests_html import AsyncHTMLSession, HTML urls = [ &#34;https://www.baidu.com/&#34;, &#34;https://python.org/&#34;, &#34;https://www.bilibili.com/&#34; ] asession = AsyncHTMLSession() async def async_html(url) -&gt; HTML: r = await asession.get(url, headers=headers) html = r.html # 异步渲染页面 await html.arender() return html task = [lambda url=url: async_html(url) for url in urls] html_list: [HTML, ...] = asession.run(*task) ==&gt; [ &lt;HTML url=&#39;https://www.python.org/&#39;&gt;, &lt;HTML url=&#39;https://www.baidu.com/&#39;&gt;, &lt;HTML url=&#39;https://www.bilibili.com/&#39;&gt; ] 小技巧 1、选择器语法调试 通过 XPATH 或 CSS 选择器获取数据时，放在代码里面验证表达式的正确性，刚开始不熟悉，要多次修改表达式，效率很低。
这种情况下可以使用 Chrome 开发者工具的搜索功能，快速验证表达式结果。
使用方法：选中 Elementstab 项，调出搜索框（Ctrl + F），支持 XPATH 和 CSS 选择器搜索，写入表达式查看命中结果即可。
2、如何查看当前页面是否是由 JavaScript 渲染而成的？ 设置 Chrome 开启/禁用 JavaScript，直达链接如下：
chrome://settings/content/javascript 禁用后，访问页面，通过 JavaScript 渲染的页面或者模块是不会展示的。
]]></content></entry><entry><title>Jenkins - K8S 整套工具集记录</title><url>/tech/jenkins/k8s-%E6%95%B4%E5%A5%97%E5%B7%A5%E5%85%B7%E9%9B%86%E8%AE%B0%E5%BD%95/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[Gogo - 一款极易搭建的自助 Git 服务。 官网：https://gogs.io/
地址：http://gogs.ieasou.cn/
账号：lanyangbi｜lanyangbi@6666
CI 平台 官网：https://www.drone.io/
地址：http://drone2.ieasou.cn/
账号：同上
私有镜像仓库 地址：http://hub.evbj.easou.com
账号：查看 .drone.yml 配置文件
Lens - Kubernetes runs Desktop 下载地址（Mac）：https://k8slens.dev
配置文件找管理员生成，填入即可。
查看当前运行的服务
查看服务访问地址
搭建 Nextcloud（未成功） 1、在 gogs 上先创建 nextcloud-mariadb 项目，然后需要写入四个文件：
 .drone.yml：流水想项目配置文件 Dockerfile：项目镜像构建 deploy-tmp.yaml：项目部署配置文件 README.md：非必需，一般用来写项目介绍  # .drone.yml kind: pipeline type: kubernetes name: nextcloud-mariadb  # 【QA】项目名称 clone: disable: true metadata: namespace: drone steps: - name: clone image: hub.evbj.easou.com/dev/alpine-git:20200622 commands: - git clone $DRONE_GIT_HTTP_URL . - name: build image: plugins/docker settings: username: admin password: Easou2)1* insecure: true mirror: https://ci7pm4nx.mirror.aliyuncs.com registry: hub.evbj.easou.com repo: hub.evbj.easou.com/tech-qa/${DRONE_REPO_NAME}  # 【QA】repo 路径修改为 tech-qa tag: v1.0.0  # 【QA】版本号可自定义 - name: deployment image: hub.evbj.easou.com/dev/drone-agent:v2.0.0 pull: always # privileged: true environment: JNLP_ENV: tech-qa JNLP_REPLICAS: 1 JNLP_TAG: v1.0.0  # 【QA】版本号可自定义 JNLP_VERSION: v1  # default v1, v2 for canary DEPLOY_ENV: k8s-2 # 可以选择把应用部署到集群:k8s-1 or k8s-2 JNLP_REPO: hub.evbj.easou.com JNLP_CONTAINER_PORT: 3306 # 【QA】端口号需要修改 JNLP_INGRESS: nginx JNLP_SVC_MODE: http JNLP_STORAGE_CLASS: rbd JNLP_DOMAIN: .ieasou.cn JNLP_CONTROL: StatefulSet JNLP_STORAGE_CAPACITY: 20Gi JNLP_MOUNT_PATH: /data JNLP_LIVENESS_INIT: 30 JNLP_LIVENESS_PER: 15 JNLP_READINESS_INIT: 30 JNLP_READINESS_PER: 15 JNLP_INGRESS_PUB: yes commands: # 切换目标集群 - kubecm s $DEPLOY_ENV # 生成配置YAML文件 - python3 /root/tools.py -b # 部署服务到kubernetes上 - python3 /root/tools.py -a # 检查服务部署状态 - python3 /root/tools.py -c # 添加dns解析记录,生成访问域名 - python3 /root/tools.py -d - name: success image: hub.evbj.easou.com/dev/drone-wechat:20200622 settings: corpid: ww419ee4063735e1c0 corp_secret: zpiRBLETH9eLwIMQ4eJ_r_dcm3BPSGeLHvTcft8Ot-M agent_id: 1000004 title: &#34;Pipeline ${DRONE_REPO_NAME} Success&#34; description: &#34;${DRONE_BUILD_LINK} 部署完成&#34; msg_url: ${DRONE_BUILD_LINK} btn_txt: &#34;否&#34; when: status: - success - name: failure image: hub.evbj.easou.com/dev/drone-wechat:20200622 settings: corpid: ww419ee4063735e1c0 corp_secret: zpiRBLETH9eLwIMQ4eJ_r_dcm3BPSGeLHvTcft8Ot-M agent_id: 1000004 title: &#34;Pipeline ${DRONE_REPO_NAME} Failure&#34; description: &#34;${DRONE_BUILD_LINK} 部署失败，请检查配置！&#34; msg_url: ${DRONE_BUILD_LINK} btn_txt: &#34;否&#34; when: status: - failure # DockerfileFROMmariadbENV MYSQL_DATABASE=nextcloud ENV MYSQL_USER=nextcloud # deploy-tmp.yaml # 不需要动 apiVersion: v1 kind: Service metadata: name: $DRONE_REPO_NAME-svc namespace: $JNLP_ENV labels: app: $DRONE_REPO_NAME-svc spec: type: NodePort ports: - port: $JNLP_CONTAINER_PORT targetPort: $JNLP_CONTAINER_PORT selector: app: $DRONE_REPO_NAME --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: $DRONE_REPO_NAME-ingress namespace: $JNLP_ENV annotations: kubernetes.io/ingress.class: $JNLP_INGRESS spec: rules: - host: $JNLP_ENV-$DRONE_REPO_NAME$JNLP_DOMAIN http: paths: - path: / backend: serviceName: $DRONE_REPO_NAME-svc servicePort: $JNLP_CONTAINER_PORT 2、进入 http://drone2.ieasou.cn/   查看创建的项目并进行激活，激活后就可以通过提交项目来触发 webhook 进行构建了。
3、构建了一次，失败了，哈哈哈。明天来了在看吧。
]]></content></entry><entry><title>Docker - 搭建Android打包环境</title><url>/tech/docker/%E6%90%AD%E5%BB%BAandroid%E6%89%93%E5%8C%85%E7%8E%AF%E5%A2%83/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[  https://github.com/budtmo/docker-android  
 首先检查服务器是否支持虚拟化技术:https://linux.cn/article-9516-1.html
$ egrep --color -i &#34;svm|vmx&#34; /proc/cpuinfo 如果出现红字就代表机器支持，否则不支持。
windows 项目地址：https://github.com/budtmo/docker-android
$ docker run --privileged \ 	-d -p 6080:6080 -p 5554:5554 -p 5555:5555 \ 	-e DEVICE=&#34;Samsung Galaxy S6&#34; \ 	--name android-container \ 	budtmo/docker-android-real-device # 镜像需要找支持全部平台的，仅支持 linux 的在 window 上就显示个默认图，无设备 镜像下载完成后，启动容器。
查看画面
访问：localhost:6080
验证设备
$ docker exec -it {container} \bin\bash $ adb --version $ adb devices # 无设备，搁置 ]]></content></entry><entry><title>Bookmarks - Ycwdaaaa发帖整理</title><url>/tech/bookmarks/ycwdaaaa%E5%8F%91%E5%B8%96%E6%95%B4%E7%90%86/</url><categories><category>Bookmarks</category></categories><tags><tag>Bookmarks</tag></tags><content type="html"><![CDATA[ ycwdaaaa (孙高飞) 在 TesterHome 的发帖整理。
 更新日志：
  【2022.01.12】create：创建该帖。
  【2022.07.07】update：增加各模块发帖数量；新增最近 5 篇发帖；总贴数：141。
  【2023.03.27】update：总帖数：145。
  【2024.01.30】update：总帖数：157。
   花两天时间终于认真看完一遍大佬的帖子，是看完不是看懂。。。字都认识，连一块就懵了。
浏览过程中按帖子相关性顺手整理了下：
 模块化 贴出发帖时间线 平台精华贴使用 🌟 标注；个人觉得非常有帮助的帖子使用 👍 标注 标题后增加当前模块发帖数  学习大佬的做事态度，趁热打铁，专注只搞一件事！
一、自动化测试（23） UI 自动化 【2016.05.01】 测试开发之路 - 概要  
【2016.05.01】 测试开发之路 - 框架中数据的管理策略  ：共享数据、隔离数据
【2016.05.03】 测试开发之路 - 数据驱动及其变种  ：XML 维护数据
【2016.05.11】🌟 测试开发之路 - 可读性，可维护性，可扩展性  
【2016.05.13】🌟 测试开发之路 - 可读性，可维护性，可扩展性 (续)  
【2018.08.12】🌟 测试开发之路 - UI 自动化设计军规  
【2018.08.23】🌟 测试开发之路 - UI 自动化常用设计模式  
【2018.09.07】 测试开发之路 - UI 自动化常用设计模式 (二)  
【2021.11.07】 UI 自动化中的分层设计  
【2021.11.09】 在 UI 自动化中调用浏览器 API 的方法与使用场景  
接口自动化 【2016.04.29】 NO_CODE 接口自动化测试框架  ：java 接口；第一篇帖子
代码覆盖率 【2016.06.20】 测试开发之路 - 代码覆盖率 (EMMA)  
【2016.07.05】 linux 下 jacoco 动态统计覆盖率  
框架 【2016.05.22】🌟 测试开发之路 - 一切为了效率 (简易监控)  
【2016.05.31】 测试开发之路 - 一切为了效率 (数据恢复&ndash;AssertJ 的另类用法)  
【2016.05.24】 [求助] AssertJ-DB 断言神器在遇到表名和关键字冲突的时候报错  
【2016.07.11】🌟 Jmeter 二次封装  
【2016.08.14】🌟 Selenide 阶段性总结介绍  
【2016.08.20】👍 allure&ndash;开源 report 框架阶段性总结介绍  
【2016.12.02】🌟 测试开发之路 (工具篇) - assertJ-db 科普  
【2017.02.08】 [求助] python 的各个单元测试框架选择  
【2017.02.14】👍 测试开发之路 (工具篇) - pytest and pytest-allure-adaptor  
【2020.07.03】 使用 cypress 之前需要知道的  
二、平台开发（5） 【2017.03.02】 测试开发之路 - Flask 之旅 (一)  
【2017.03.04】 测试开发之路 - Flask 之旅 (二)：表单  
【2017.03.08】 测试开发之路 - Flask 之旅 (三):数据库  
【2017.03.09】 测试开发之路 - Flask 之旅 (四):登录与权限控制  
【2017.03.11】 测试开发之路 - Flask 之旅 (五):后台管理  
三、DevOps（44） 【2016.05.19】 关于监控的讨论  
【2016.06.30】 测试开发之路 - CI (开发部分的持续集成)  
【2016.10.06】 测试开发之路 - 环境管理  
【2016.10.17】🌟 测试开发之路 (工具篇) - Docker  
【2016.10.18】 测试开发之路 (工具篇) - Docker compose  
【2016.11.03】🌟 测试开发之路 - 持续集成  
【2016.11.26】 测试开发之路 - 持续集成 (分支模型补充)  
【2016.11.26】👍 测试开发之路 (工具篇) - docker 网络  
【2016.11.27】🌟 测试开发之路&ndash;分布式用例执行  
【2016.12.27】🌟 测试开发之路 (工具篇) - docker 1.12 的 swarm mode  
【2017.02.04】🌟 测试开发之路 - 聊聊自动化的打开方式  
【2017.05.15】 测试开发之路 - kubeadm 搭建 kubernetes 集群踩坑记  
【2017.07.23】🌟 测试开发之路 - devops (一):序  
【2017.07.28】👍 测试开发之路 - devops (二):docker 的文件系统  
【2017.08.02】👍 测试开发之路 - devops (三):docker 的网络原理  
【2017.08.29】👍 测试开发之路 - devops (四):docker 的 4 种网络模式  
【2017.12.19】 测试开发之路 - devops (五): salt 的安装与配置  
【2017.12.27】 测试开发之路 - devops (六): salt state 基础  
【2018.01.28】👍 测试开发之路 - devops (七):使用 salt 搭建 docker 和 k8s  
【2018.07.16】🌟 测试开发之路 - k8s 下的大规模持续集成与环境治理  
【2018.11.17】 测试开发之路 - 系统稳定性评测  
【2019.01.12】 测试开发之路 - k8s 之 POD 详解 (一)  
【2019.01.12】 测试开发之路 - k8s 之 POD 详解 (二)  
【2019.02.07】 测试开发之路 - k8s 之 POD 详解 (三)  
【2019.03.11】 测试开发之路 - 衍生知识 (cgroups)  
【2019.12.22】 测试开发之路 - 混沌工程的秘密 (一)  
【2019.12.29】 测试开发之路 - 混沌工程的秘密 (二)  
【2020.02.11】 持续集成的开源方案攻略 (一) 概述  
【2020.02.16】 持续集成的开源方案攻略 (二) jenkins pipeline  
【2020.02.22】 持续集成的开源方案攻略 (三) jenkins pipeline 与 k8s 集成  
【2020.02.24】 持续集成的开源方案攻略 (四) jenkins 与 k8s 集成的通信原理与配置记录  
【2020.03.11】 持续集成的开源方案攻略 (五) 多分支 pipeline 与可视化  
【2020.12.02】🌟 mock server 实践  
【2021.11.01】 k8s 详解之资源管理  
【2021.11.10】 普罗米修斯 &ndash; 基本使用  
【2021.11.25】 普罗米修斯 &ndash; 初识 PromQL  
【2021.12.07】 普罗米修斯 &ndash; PromQL 进阶  
【2022.01.07】 普罗米修斯 &ndash; HTTP API 调用 PromQL  
【2022.02.16】 普罗米修斯 &ndash; 自定义 exporter  
【2022.02.26】 k8s 集群监控平台的实现  
【2022.04.25】🌟 混沌工程理论知识记录 &ndash; CAP  
【2022.05.11】 混沌工程理论知识记录 &ndash; 数据同步设计  
【2023.03.27】 记录一次 K8S 性能问题排查  
【2023.04.10】 记录一次 K8S Pod 启动异常问题排查  
四、大数据测试 &amp; 人工智能测试（16） 【2017.03.16】 测试开发之路 - Spark 之旅 (一)：大数据介绍  
【2017.03.19】🌟 测试开发之路 - Spark 之旅 (二)：基础操作  
【2017.03.27】 测试开发之路 - Spark 之旅 (三)：Shuffle 以及性能测试初探  
【2018.11.30】 测试开发之路 - Spark 之旅 (四)：大数据产品的一种测试方法与实现  
【2020.12.17】🌟 大数据测试场景科普 &ndash; 流计算篇 (上)  
【2020.12.22】🌟 大数据测试场景科普 &ndash; 流计算篇 (下)  
【2021.10.26】 大数据测试场景科普 &ndash; 离线造数场景  
【2023.02.07】 分布式存储系统测试基础（一）块存储，文件存储与对象存储  
【2023.10.12】 云原生测试是什么样子的  
【2023.12.19】 我们是如何测试人工智能的（一）基础效果篇（内含大模型的测试内容）  
【2023.12.29】 我们是如何测试人工智能的（二）数据挖掘篇  
【2023.12.29】 人工智能产品测试的学习路线  
【2024.01.05】 我们是如何测试人工智能的（三）数据构造与性能测试篇  
【2024.01.09】 我们是如何测试人工智能的（四）补充：模型全生命周期流程与测试图  
【2024.01.16】 我们是如何测试人工智能的（五）案例介绍：ASR 效果测试介绍  
【2024.01.30】 我们是如何测试人工智能的（六）推荐系统拆解  
五、深度学习基础（26） 【2017.10.22】 深度学习基础(一) - 二分类  
【2017.10.29】 深度学习基础 (二) - 浅层神经网络  
【2017.11.05】 深度学习基础 (三) - 深层神经网络  
【2017.11.12】 深度学习基础 (四) - 拟合与梯度  
【2017.11.17】 深度学习基础 (五) - 超参数：mini batch  
【2017.11.26】 深度学习基础 (六) - 超参数：指数加权平均  
【2017.12.03】 深度学习基础 (七) - 特征工程  
【2017.12.10】 深度学习基础 (八) - 二分类模型的评估指标  
【2017.12.17】 深度学习基础 (九) - Softmax (多分类与评估指标)  
【2017.12.27】 深度学习基础 (十) - 训练集，验证集和测试集  
【2018.01.07】 深度学习基础 (十一) - 测试模型时的注意事项  
【2018.01.07】🌟 深度学习基础文章合集  
【2018.01.14】 深度学习基础 (十二) - 测试模型时的注意事项 (补充)  
【2018.01.26】🌟 深度学习基础 (十三) - 演讲稿: 机器学习服务的测试探索  
【2018.02.04】 深度学习基础 (十四) - 计算机视觉与卷积神经网络  
【2018.03.18】 深度学习基础 (十五) - padding，卷积步长与简单卷积神经网络示例  
【2018.03.25】 深度学习基础 (十六) - TensorFlow 概览  
【2018.04.01】 深度学习基础 (十七) - TensorFlow 中的变量  
【2018.04.06】 深度学习基础 (十八) - 使用 tensorflow 构建一个简单神经网络  
【2018.04.16】 深度学习基础 (十九) - 使用 tensorflow 构建一个卷积神经网络 (上)  
【2018.04.21】 深度学习基础 (二十) - 使用 tensorflow 构建一个卷积神经网络 (下)  
【2018.05.07】 深度学习基础 (二十一) - 科普：深度学习业务场景与原理概览 (一)  
【2018.05.11】 深度学习基础 (二十二) - 科普：深度学习业务场景与原理概览 (二)  
【2018.05.20】 深度学习基础 (二十三) - 科普：深度学习业务场景与原理概览 (三)  
【2018.06.10】 深度学习基础 (二十四) - tensorflow 中的数据流  
【2018.06.17】 深度学习基础 (二十五) - tensorflow serving  
六、职业经验（18） 【2016.05.02】🌟 作为一个面试官，我想说点什么  
【2016.05.25】👍 还是面试那点事 - 薪资  
【2016.06.12】🌟 论自动化测试脚本的质量与效率  
【2016.09.26】🌟 测试开发之路 - QA 的能力  
【2016.12.03】👍 测试开发之路&ndash;让我们把产品质量变得更好 (测试人的转型探索)  
【2017.02.25】🌟 测试开发之路 - 英雄迟暮，我心未老  
【2017.04.09】🌟 测试开发之路 - 测试沙龙演讲稿：docker 搭建测试环境的实践  
【2017.07.16】🌟 MTSC-2017 演讲稿 &ndash; 人工智能产品的测试探索  
【2017.10.28】👍 全国大学生软件测试参加有感  
【2017.05.25】🌟 测试开发之路 - 那些年总结出的学习经验  
【2018.02.27】😱 暂时停更  : 合理用眼，保重身体
【2018.12.09】👍 测试开发之路 - 不要成为你曾经最讨厌的人  
【2020.08.01】🌟 演讲稿 &mdash;- 10 年 测试开发  
【2020.11.26】🌟 菜鸟的成长之路  
【2021.07.05】🌟 大厂面试总结  
【2022.09.16】 聊一些对测试技术的看法  
【2023.03.12】👍 编写简历的方法  
【2023.06.21】 有点感慨 &ndash; 强者越强，弱者越弱  
七、随笔（14） 【2016.06.13】 趣谈我眼中测试发展  
【2016.06.13】 新项目的质量保障流程探讨  
【2016.07.17】 测试总结，感悟与职业选择  
【2016.09.06】🌟 喷喷埋雷的事，吵吵代码的情  
【2016.10.05】👍 我也聊聊测试团队的考核吧  ：讨论很精彩
【2016.11.29】 跑偏了的测试开发之路和之后的想法  
【2017.06.20】🌟 对那篇测试无用论我想实名说点什么  
【2017.11.11】 测试开发之路 - 请不要打着人工智能的旗号在测试圈子骗人  
【2018.06.05】 玩儿  ：备忘贴手滑发线上了
【2018.07.01】👍 测试开发之路 - 每一次发布都是一次成长  
【2018.09.25】🌟 测试开发之路 - 希望你们在新家过的更好  
【2019.12.17】 测试开发之路 - 深圳大会记  
【2020.10.05】 我们真的知道测试行业的内卷是什么吗？  
【2021.02.28】 如果测试行业没门槛了，你开心么  
八、个人总结（7） 【2017.01.02】🌟 测试开发之路 - 一个小小工程师的回首  ：2016 年终总结
【2018.01.02】🌟 测试开发之路 - 一个小小工程师的再回首  ：2017 年终总结
【2019.10.23】 测试开发之路 - 在社区与范式的 4 年  ：回顾第四范式工作历程
【2020.05.17】 一个小小工程师魔幻的 10 年  ：回顾整体工作历程
【2020.01.17】 进击的 2019 (一个小小工程师的又一次回首)   ：2018 年终总结
【2022.03.22】 迟来的总结与回顾  ：2021 年终总结
【2023.01.02】 2022 年终总结 &ndash; 一个小小工程师的再回首  
九、招聘&amp;广告（4） 【2016.05.11】 第四范式招聘测试开发工程师  
【2016.08.18】 第四范式招聘业务测试工程师  
【2018.11.02】 第四范式 招聘 测试开发工程师  
【2023.08.28】 给自己的书打个广告 &ndash; 云原生测试实战  
高钙鸡汤 摘自作者文章。
 我们之前把太多的失败因素都归结于需求，归结于产品，归结于没有文档，归结于开发不配合甚至归结于自动化根本没用等等等等。 该醒醒了 老实承认吧，你就是不懂代码 老实承认吧，你就是懒的学习 老实承认吧，你就是懒的思考 老实承认吧，你就是自以为是 老实承认吧，你就是 low
知道自己 low 是好事，因为它激励着你前进。2 年前我承认我自己 low，所以我才能努力的变成今天这样不那么 low 了。
  人总要先有用处，才会有机会，所以有时候利用二字，并没有你想象的可怕。
机会不会砸到你脑袋上，你要主动把脑袋凑过去。
  我们到底是否相信天道酬勤这四个字，如果相信了，人就会陷入一个盲目的自信中，认为成功都是自己努力而来的结果。而事实上这世上 95% 的事是我们自己无法决定的。但是呢，我们依然要努力，要用那 5% 来撬动 95% 的可能性。只不过我们仍然能接受失败的结果。
&ndash; 罗翔老师
 最后，共勉！  种一棵树最好的时间是十年前，其次是现在。 ——《dead aid》
 ]]></content></entry><entry><title>随笔 - 2021年终总结</title><url>/tech/%E9%9A%8F%E7%AC%94/2021%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html"> 写篇文记录过去的一年。
工作 这是在宜搜的第五个年头，是变化最大的一年，变化分两个方面讲讲。
裁员 团队的小伙伴被优化掉一半左右。公司的决定，不好多说什么。团队的工作氛围一直很好，小伙伴相处的其乐融融，没有太大的绩效压力，但相对也不会有可观的发展空间，出去的小伙伴不见得就是坏事。新的一年，有合适的机会我也会跳出这个舒适圈，老话说得好，不逼自己一把，都不知道自己能吃几碗干饭，哈哈。
技术 受人事变动影响，我增加了一些工作量。
领导计划让我接手配置管理和测试组相关服务的维护工作，由于还得继续功能测试，所以配置管理转交运维组，只剩下服务维护工作。现在有更多的时间跟服务器打交道，这段时间提升了 Linux 基本功，学习了 Docker 容器、Web 服务部署及原理，原来东拼西凑的知识碎片突然就可以连接起来了，虽然还是很菜，好在持续进步。工作上还是要尽量多的扩展自己的知识面，让自己「冒头」，这样机会来了，才能把握的住。
聊聊功能测试。
今年测试广告 SDK 比较多，经常需要 mock 数据，修改代理，所以 Charles 玩的是比较多的。随着测试工作的增加，遇到越来越多的场景是 Charles 搞不定的，于是学习了 mitmproxy，通过代码可以高度定制化，以前一些苦逼的测试场景通过脚本就轻松完成了。但是这样还是不能离开手工点点点，毕竟广告是需要展示才算钱的。我又尝试写了一个广告 UI 自动化测试项目，遍历目前集成的所有 SDK，以截图的方式作为测试报告。用了几次，很多广告不出物料，数据也无法抓取，目前还是人工测试，比较痛苦。后续继续找方法，对能抓包的 SDK 使用 mock server + UI 点击的方式继续搞一搞。
做测试的小伙伴都知道，测试数据的构造是非常苦逼的，打开测试平台一顿操作，测完后切换下一个测试场景，继续打开测试平台一顿操作&amp;hellip;重复性的工作就需要自动化实现，常用的场景都封装成测试脚本，用起来还是比较爽的。
再说说自动化测试吧。
今年的接口自动化测试算是完全落地了，经过了几个版本的迭代，目前总算是跑起来了，用例不多，但是已经初步发挥了作用。比如服务迁移，原来好几个人的工作量，现在一两个人轻松搞定；线上接口监控，设置定时任务，把报告体现的问题，及时反馈给相关人员，提升了处理问题的响应速度，不然以前都是等用户反馈或者随缘发现。当然，更开心的是，在组内的技术分享，问题答疑，能促进大家共同成长，这让我很有成就感。
最后说下测试服务。
独立完成了测试用例平台迁移，数据备份相关工作；使用 Docker 搭建接口管理平台，完成 API 和 WEBVIEW 的简单校验；搭建 Jenkins 平台，完成接口自动化测试的持续构建；使用 Nginx 搭建发布目录。这些在我过去的文章中都有提及，并不是什么高深的技术，只是去用心做了。
总体来说，这一年工作上的进步还是很大的，因为以前太懒了，欠下的技术债太多。相信只要肯下功夫，所有的事情通通都能搞定，哈哈。
个人 阅读 今年花费了大量的时间阅读技术文章（Github、官方文档、CSDN、TesterHome、测试人论坛等），带给我的好处就是解决问题的速度大大提高，百分之八十的问题都能从官方文档找到解决办法， 剩下的百分之二十再去技术论坛查找。
多看多读开源项目的源码，无形中可以提升自己的代码水平，源码是不会骗人的，别人再怎么说不如自己沉下心来去捋一捋代码逻辑。我看了大概 3 遍 HttpRunner 的源码，这是一个非常优秀的接口测试开源项目，学习过程中也抄了很多代码到自己的项目，并学着去模仿。现在仍然有看不明白的地方，继续补充欠缺的知识。
那本厚厚的《Python 核心编程》今年终于看完了，买到家已经有 3 年了。。。
公众号 公众号很早就注册了，基本是不怎么登录的。今年文章更新的比较频繁，因为想要记录的东西太多了，也说明我开始学习了哈哈。
当时注册了公众号但是没有去开通留言功能，后来微信不开放留言功能了，挺遗憾的。在别的公众号上找到了可以留言的小程序，放在文末测试一下，小伙伴们可以留言看看。
现在的总用户数是 231 位，像我这样语文从来不及格的人，写出来的文章你们能忍住不取关，这是对我最大的支持，感谢。有一部分同学是因为抢购茅台的开源项目而关注我的，京东一刀切掉 WEB 端抢购，导致项目无法使用，我也无能为力，抱歉哈。我这个号主要还是以发布工作日常记录为主，不感兴趣的同学也可以取消关注啦，再次感谢支持哈。
新的一年，公众号还是会继续发文，记录工作上成长的点滴。
还是太懒了，立个 flag 督促一下：今年完成原创 50 篇，奖励自己一趟重庆游不过分吧。媳妇想去很久了，借此机会满足她。。。哈哈。
理财 今年开始学习理财，注册了股票账号，买了基金。一顿操作，应了那句老话：你不理财，财就不会离开你。
跟着理财大 V 做价值投资，左手互联网右手医疗，中间别个白酒，现在亏了小三千块。新的一年还接着投，慢慢来，折腾呗。
千万不要盲目跟风，理性投资。
家庭 孩子马上三岁了，正是淘气、闹腾的时候。我父母，老丈人、丈母娘轮班来北京给我们带孩子，非常辛苦，感谢他们的付出，我跟媳妇才能安心上班，没有被孩子绑定的“痛苦”。随着年龄越来越大，这种能每天共处的机会也不会很多了，珍惜当下。
非常荣幸能够参与到孩子的成长过程，看着他一天天长大，品尝不同味道的美食，学习各种各样的技能，心里说不出的高兴。也开始能体会到作为一名父亲的那种无法言语的感觉，还有责任。小朋友在新的一年能够开心快乐的成长就是我最大的心愿。
年中疫情不太严重的时候，跟媳妇去厦门玩了一周，景色很美，人间值得呀，希望疫情早点结束吧！
最后 过去的一年好像什么都没做，又好像做了点什么。
二十多岁的我，心态仿佛已经四五十岁，年轻人还是要多折腾折腾。换一份满意的工作，带家人来一趟美美的旅行。
最后的最后，送上新年的祝福。
凡是过往，皆为序章。新的一年，愿日子如熹光，温柔又安详。</content></entry><entry><title>Docker - 搭建Sonarqube静态代码扫描</title><url>/tech/docker/%E6%90%AD%E5%BB%BAsonarqube%E9%9D%99%E6%80%81%E4%BB%A3%E7%A0%81%E6%89%AB%E6%8F%8F/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html">启动容器
$ docker run -d --name sonarqube -e SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true -p 9000:9000 sonarqube:latest</content></entry><entry><title>Docker - 构建镜像命令</title><url>/tech/docker/docker-%E6%9E%84%E5%BB%BA%E9%95%9C%E5%83%8F%E5%91%BD%E4%BB%A4/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html">容器更新为镜像 如果容器中安装的新包需要更新为镜像，请执行以下步骤：
确保容器中安装的包已保存到容器的镜像层中。可以通过执行以下命令来检查容器的更改： # 将显示容器中进行的任何更改，例如添加，删除或修改的文件 $ docker diff &amp;lt;container-id&amp;gt; 在容器运行时，使用 docker commit 命令将容器转换为新的镜像，此命令将使用容器的当前状态创建一个新的镜像层，并将其添加到现有的镜像中。 $ docker commit my-container my-image 使用 docker images 命令来检查新的镜像是否已添加到本地 Docker 镜像列表中： $ docker images # 应该能够看到 my-image 已添加到列表中。 将新的镜像上传到 Docker 仓库，以便其他人可以使用： $ docker push my-image 这将将 my-image 推送到默认Docker仓库中（即 Docker Hub）。可以在 docker push 命令中指定仓库名称，以将新镜像推送到仓库中。</content></entry><entry><title>Jenkins - Jenkins Docker Slave</title><url>/tech/jenkins/%E9%80%9A%E8%BF%87docker%E9%83%A8%E7%BD%B2%E8%8A%82%E7%82%B9/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"> 新建一个 docker slave 节点，并注册到 jenkins 上。
TODO：没有成功，直接在 pipeline 使用 docker 镜像运行
下载 docker 插件 Manage Jenkins：管理 Manage Plugins：插件管理 选中 Available 可用插件栏，搜索 docker 下载插件 Docker 下载插件 docker pipline 修改 docker 配置 开放外部连接
$ vim /lib/systemd/system/docker.service # ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375 # 重启服务 $ systemctl daemon-reload $ systemctl restart docker.service 配置云 Manage Jenkins：管理
configuration System：系统设置
页面最底部 Cloud，进入设置云页面
Docker Cloud details&amp;hellip;
Docker host uri 是宿主机的 IP 地址，格式要与上图保持一致。
接下来点击 Docker Agent templates 继续配置
记录 apline 配置 ssh：将来放在 dockfile 中构建https://blog.csdn.net/catcher92/article/details/116030171</content></entry><entry><title>Docker - Dockerfile基础</title><url>/tech/docker/dockerfile-%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ Dockerfile 是由一系列指令和参数构成的脚本，一个 Dockerfile 里面包含了构建整个镜像的完整命令。
 工作中，由于业务水平与技术选型不同，在使用 Docker 起服务时，需要定制项目镜像。通过两种方式：
 Docker commit Dockerfile  Docker commit   基于一个运行状态的容器，在容器内安装项目运行所需要的环境依赖，再创建出一个新的镜像。
$ docker commit \ 	-a &#34;author&#34; \ 	-m &#34;commit info&#34; \ 	container_id \ 	image_name:tag 使用这种方式制作的镜像，对外不可解释，不知道镜像内的环境组成，不方便排查问题，可维护性差。
Dockerfile   Dockerfile 是一个文本文档，通过 docker build 可以执行 Dockerfile 中的一系列指令自动构建镜像。Dockerfile 的目录最好不要放其他文件，因为构建时会将该目录下的文件内容全部传输到 docker daemon，影响构建性能。
# -t 指定镜像名称和标签 # -f 指定 Dockerfile 文件路径 # . 代表当前路径，千万别忘记写 $ docker build -t pytest:v1 -f Dockerfile . 详细的说明请参考官方文档，推荐直接去看官方文档。下面记录 Dockerfile 常用的指令及其用法。
常用指令 指令不区分大小写，为方便区分指令和参数，约定指令统一大写。
FROM# 指定基础镜像，Dockerfile 必须以 FROM 指令开始（除 ARG）LABEL # 标签信息，作者、版本等；&lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...ENV # 容器启动的环境变量；&lt;key&gt;=&lt;value&gt; ...ARG # 仅作用于 Dockerfile 的环境变量，可以出现在 FROM 指令之前USER# 指定运行容器时的用户名或 UID，默认管理员用户，后续 RUN 也会使用指定用户WORKDIR# 设置工作目录，作用于 RUN、CMD、ENTRYPOINT、ADD 指令ADD # 添加压缩文件到镜像中，自动解压缩COPY # 复制文件到镜像中VOLUME# 挂载目录RUN # 运行命令，每条 RUN 指令在当前基础镜像上执行，并且会提交一个新的镜像层EXPOSE# 对外暴漏端口号，可以被容器运行时的 -p 参数覆盖掉CMD # 容器启动时执行的默认命令ENTRYPOINT # 容器启动时指定参数HEALTHCHECK # 容器健康状态检查编写 Dockerfile 的最佳实践移步官方文档，写的非常详细了。
 Best practices for writing Dockerfiles  
列出几点：
  多行参数使用换行符
  不要安装非必要的包
  每个容器只干一件事，解耦应用程序
  尽量减少镜像层数
  充分利用构建缓存
  镜像制作过程中，每个指令代表一层，镜像是由多层镜像累加起来的。指令会产生缓存，构建过程中会优先使用缓存，所以当开发镜像时，可以使用多个 RUN 命令，充分利用缓存，提高调试的效率。通过 --no-cache 可以人为避免使用缓存。
Dockerfile 开发完成后，用 &amp;&amp; 符号把 RUN 指令合并，作为同一层镜像进行构建。因为镜像的分层原理，每多一层就会多一次 IO 开销，当指令过多，可能会影响系统性能。
AS 关键字 在 Dockerfile 中使用 AS（或 as）关键字可以创建一个多阶段构建（multi-stage build）。
多阶段构建是一种将应用程序的构建过程分解为多个阶段（stage）的技术，每个阶段使用不同的基础镜像和指令来完成特定的任务。
在多阶段构建中，可以使用 AS 关键字指定构建阶段的名称，然后在后续阶段中引用它们。
例如，以下是一个包含两个构建阶段的 Dockerfile：
# 第一阶段：构建应用程序FROMnode:14-alpine AS builderWORKDIR/appCOPY package*.json ./RUN npm installCOPY . .RUN npm run build# 第二阶段：运行应用程序FROMnginx:1.21-alpineCOPY --from=builder /app/dist /usr/share/nginx/html在这个 Dockerfile 中，第一阶段使用 node:14-alpine 镜像作为基础镜像，创建了一个名为 builder 的构建阶段。在该阶段中，执行了一系列指令来构建应用程序，并生成了编译后的代码。
第二阶段使用 nginx:1.21-alpine 镜像作为基础镜像，并使用 COPY --from=builder 指令从第一阶段中拷贝编译后的代码到 nginx 容器中，从而运行应用程序。
在这个例子中，AS 关键字用于给第一阶段命名为 builder，以便在第二阶段中使用 COPY --from=builder 来引用该阶段中的构建结果。
演示 使用 Dockerfile 构建 nginx 容器，添加容器健康检查。
# index.html &lt;h1&gt;Hello Nginx!&lt;/h1&gt; # Dockerfile# 导入基础镜像FROMnginx:latest# 指定信息LABEL Description=&#34;Nginx Testing services.&#34;# 设置环境变量ENV WELCOME &#34;hello, nginx!&#34;# ARG 设置的环境变量只在 dockerfile 生效ARG dir=/usr/share/nginx# 设置工作目录WORKDIR$dir/html# 切换用户USERroot# 执行安装命令RUN apt-get -y update &amp;&amp; apt-get install -y curl# 复制 index.html 文件到 workdir 目录下COPY index.html .# 映射 80 端口EXPOSE80# 此处 CMD 作为 ENTRYPOINT 的参数CMD [&#34;nginx&#34;, &#34;-g&#34;, &#34;daemon off;&#34;]# 检查容器健康，通过访问 Nginx 服务 80 端口，来判断容器是否正常运行HEALTHCHECK --interval=5s --timeout=3s \ CMD curl -fs http://localhost/ || exit 1构建后验证
# 构建镜像 $ docker build -t nginx:test . ... # 启动容器 $ docker run -d --name demo nginx:test ... # 进入容器内 $ docker exec -it demo bash # 用户为 root # 执行 env 命令，出现设置的环境变量 # 当前目录为设置的工作目录 root@*:/usr/share/nginx/html $ env WELCOME=hello, nginx! # 查看容器日志;健康检查生效 $ docker logs -f demo 127.0.0.1 - - [07/Jan/2022:09:52:12 +0000] &#34;GET / HTTP/1.1&#34; 200 615 &#34;-&#34; &#34;curl/7.74.0&#34; &#34;-&#34; ]]></content></entry><entry><title>Docker - 搭建私有镜像仓库</title><url>/tech/docker/%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[Docker registry 简介 Docker Registry 是存储 Dcoker Image 的仓库，运行 push、pull、search 时，是通过 Docker daemon 与 docker registry 通信。有时候使用 Docker Hub 这样的公共仓库可能不方便，我们可以通过 registry 创建一个本地仓库。
运行 # 搭建仓库的主机运行 $ docker run -d -p 5000:5000 -v ${PWD}/registry:/var/lib/registry --restart always --name registry registry:2.7.1 # 其他机配置下镜像仓库 $ vim /etc/docker/daemon.json { &#34;insecure-registries&#34;:[&#34;{仓库主机的IP地址和端口号}&#34;] } $ systemctl restart docker # 重启下docker 演示 # 搭建仓库的主机：先从 docker hub 上随便下载一个镜像 $ docker pull nginx:1.18.0 # 打上带主机 IP 地址的标签 $ docker tag nginx:1.18.0 {仓库地址}/nginx:1.18.0 # 推送到内网仓库下 $ docker push {仓库IP:port}/nginx:1.18.0 # 其他机器 $ docker pull {仓库IP:port}/nginx:1.18.0 # 查看下载的镜像，就是本地仓库的镜像 $ docker image # 构建镜像并推送到本地仓库上 $ docker build -t {仓库IP:port}/flask-web:1.0 . 通过搭建本地仓库，下载镜像后 push 到本地仓库，其他内网机器 pull 的话速度会有所提升。
一般公司业务不方便放到 docker hub 上，可以通过内网仓库提高隐私性。
merge todo $ docker pull registry:2 $ docker run -d -p 5000:5000 -v /usr/local/registry:/var/lib/registry --restart=always --name registry registry:2 # --restart=always 代表容器万一挂掉，docker 会永远重启容器 # DEMO # 先下载一个小镜像 $ docker pull busybox # 上传镜像前需要更新名字，命名规范 ==&gt; IP地址:端口号/名称:版本号； # 上面 pull busybox，其实应该是 library/busybox:latest # library 是docker默认仓库地址，版本号不写默认是latest，代表最新版本 $ docker tag busybox localhost:5000/busybox:v1.0 $ docker push localhost:5000/busybox:v1.0 # 通过命令查看镜像仓库 $ curl http://localhost:5000/v2/_catalog # 从一个运行的容器制作镜像 $ docker commit registry localhost:5000/myimage:v1.0 $ docker images | grep myimage $ docker push localhost:5000/myimage:v1.0 $ curl http://localhost:5000/v2/_catalog # 这种方法不推荐，别人拿到这个镜像，如果要做一些扩展，不知道安装了什么软件、设置权限、配置等等 # 为了解决上面的问题，推荐使用 dockerfile # 将制作镜像的过程脚本化 ]]></content></entry><entry><title>Docker - 搭建Testlink缺陷管理平台</title><url>/tech/docker/%E6%90%AD%E5%BB%BAtestlink%E7%BC%BA%E9%99%B7%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[搭建测试用例管理平台 Testlink Testlink 简介 Testlink 基于 WEB 的测试用例管理系统，主要功能是测试项目管理、产品需求管理、测试用例管理、测试计划管理、测试用例的创建、管理和执行，并且还提供了统计功能。
部署数据库 # 创建一个名为 testlink 的容器网络 $ docker network create testlink # 查看当前存在的容器网络 $ docker network ls NETWORK ID NAME DRIVER SCOPE 备注（自己加的） 4deb334c55f6 bridge bridge local 桥接网络 cf4fbaac0160 host host local 主机网络 50027393c74d none null local 6ac9853f1eab testlink bridge local 刚才新建的网络 # 运行数据库，如果本地没有该镜像的话会自动去下载 $ docker run -d --name mariadb -e MARIADB_ROOT_PASSWORD=mariadb -e MARIADB_USER=bn_testlink -e MARIADB_PASSWORD=bn_testlink -e MARIADB_DATABASE=bitnami_testlink --net testlink -v ${PWD}/mariadb:/bitnami bitnami/mariadb:10.3.22 Unable to find image &#39;bitnami/mariadb:10.3.22&#39; locally 10.3.22: Pulling from bitnami/mariadb ... 74dbf92d3ddca4d241f2b9022890445820f7e26e5324c352c90983515379bd65 部署 Testlink # 运行 testlink $ docker run -d -p 80:8080 -p 443:8443 --name testlink -e TESTLINK_DATABASE_USER=bn_testlink -e TESTLINK_DATABASE_PASSWORD=bn_testlink -e TESTLINK_DATABASE_NAME=bitnami_testlink --net testlink -v ${PWD}/testlink:/bitnami bitnami/testlink:1.9.20 Unable to find image &#39;bitnami/testlink:1.9.20&#39; locally 1.9.20: Pulling from bitnami/testlink ... 5e766b7f386db5c0bdb3adcb14c1daea6f5f9517f56dfc9af556fbcb4c6e1bc9 在浏览器访问本地 IP 地址，即可正常浏览网页。
默认用户名：user；默认密码：bitnami。
]]></content></entry><entry><title>Docker - Docker Compose常用命令</title><url>/tech/docker/docker-compose%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[Dcoekr-compose 简介 Docker-compose 是用于定义和运行多容器的 Docker 应用程序的工具。通过 compose，可以使用 yaml 文件来配置应用程序的服务。compose 的使用一般分为三步：
 使用 Dockerfile 定义应用程序的环境，以便可以在任何地方复制它； 在 docker-compose.yml 中定义组成应用程序的服务，以便他们可以在隔离的环境中一起运行； 运行 docker-compose up，然后 compose 启动并运行您的整个应用程序。  安装 macOS、windwos 上的 Desktop 版本，默认已经安装
# 验证 $ docker-compose version docker-compose version 1.23.2, build 1110ad01 docker-py version: 3.6.0 CPython version: 3.6.6 OpenSSL version: OpenSSL 1.1.0h 27 Mar 2018 CentOS 安装
# 根据服务器型号安装稳定版本 # -L 跟随链接重定向 $ curl -L &#34;https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)&#34; -o /usr/local/bin/docker-compose # 更改权限 $ chmod +x /usr/local/bin/docker-compose # 查看版本 $ docker-compose version Docker Compose version v2.2.2 常用命令 # 查看配置 $ docker-compose config # -d 表示在后台运行 $ docker-compose up -d # 指定名称 $ docker-compose -p &#34;selenium-grid&#34; up -d # 指定配置文件启动 $ docker-compose -f docker-compose.yml up -d # --build 选项表示强制重新构建所有镜像 # --force-recreate选项表示强制重新创建所有容器 $ docker-compose up --build --force-recreate -d # 构建镜像；仅构建，不启动容器 $ docker-compose build # 下载镜像，仅拉取镜像 $ docker-compose pull # 查看运行状态 $ docker-compose ps # 查看容器内运行的进程 $ docker-compose top # 启动/停止/重启/暂停/恢复 $ docker-compose start $ docker-compose stop $ docker-compose restart $ docker-compose pause $ docker-compose unpause # 停止并删除已创建的容器网络及容器 $ docker-compose down 演示 创建一个 web 服务，统计当前服务被访问的次数。项目文件目录如下：
 docker-compose.yml .env dockerfile app.py  1、创建 docker-compose 配置文件
# 指定 docker-compose API 版本 version: &#39;3&#39; services: web: build: context: . depends_on: - redis ports: - &#34;5000:5000&#34; redis: image: ${REDIS_VERSION} restart: always 2、创建环境配置文件
# .env REDIS_VERSION=redis:alpine 验证配置文件
$ docker-compose config # context：. 会变成实际工作目录 # 镜像变量也会自动替换为 env 文件内配置的值 3、创建 dockerfile
# Dockerfile FROM python:3.7-alpine LABEL maintainer=&#34;test&#34; # 工作路径设定为 /code WORKDIR /code # 创建环境变量给 Flask 使用 ENV FLASK_APP app.py ENV FLASK_RUN_HOST 0.0.0.0 # 复制 app.py 到容器内的 /code 目录 COPY app.py /code # 安装 python 库 RUN pip install flask &amp;&amp; pip install redis # 映射端口 EXPOSE 5000 STOPSIGNAL SIGTERM # 为容器设置默认启动命令 CMD [&#34;flask&#34;, &#34;run&#34;] 4、创建业务代码文件
# app.py # 实现统计访问次数 import time import redis from flask import Flask app = Flask(__name__) cache = redis.Redis(host=&#39;redis&#39;, port=6379) def get_hit_count(): retries = 5 while True: try: return cache.incr(&#34;hits&#34;) except redis.exceptions.ConnectionError as e: if retries == 0: raise e retries -= 1 time.sleep(0.5) @app.route(&#39;/&#39;) def hello(): count = get_hit_count() return f&#34;Hello World! I have been seen {count}times.\n&#34; 启动 $ docker-compose up -d $ docker-compose logs -f ]]></content></entry><entry><title>Docker - 搭建Jenkins</title><url>/tech/docker/%E6%90%AD%E5%BB%BAjenkins/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ Docker 搭建 Jenkins 服务
 从零搭建服务 历史服务迁移至 docker   一、从零搭建服务 拉取镜像 # lts: Long Term Support $ docker pull jenkins/jenkins:lts 注意注意注意！！！
默认镜像 jenkins:latest 版本已经废弃，拉取时手动指定 lts 长期维护版本。 启动容器 需要挂载的内容太多，将容器启动命令封装为 shell 脚本，方便使用。
#!/bin/bash  name=jenkins if [[ -n $(docker ps -q -f &#34;name=^$name$&#34;) ]]; then docker rm -f $name; fi # 将宿主机 docker 挂载进来，否则 Jenkinsfile agent docker # 报错：docker: not found docker run -d --name $name \  -p 8080:8080 -p 50000:50000 \  --restart=always \  -u root \  --privileged=true \  -v $(pwd)/volumes/jenkins_home:/var/jenkins_home \  -v /var/run/docker.sock:/var/run/docker.sock \  -v $(which docker):/bin/docker \  -v /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7 \  -v /var/lib/docker/tmp:/var/lib/docker/tmp \  -e JAVA_OPTS=-Duser.timezone=Asia/Shanghai \  jenkins/jenkins:lts 运行脚本
# 添加脚本可执行权限 $ chmod +x jenkins.sh $ sh jenkins.sh 02e3239e020a98acd74af4a59b7ca53bb6e6e0fe6a135608056f7130edb5fe09 执行docker ps命令，发现容器并没有启动起来，查看容器运行日志。
$ docker logs -f jenkins touch: cannot touch &#39;/var/jenkins_home/copy_reference_file.log&#39;: Permission denied Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions? 原因是jenkins用户创建文件失败，没有写入权限，添加权限后重试。
# 添加挂载目录的可操作权限 # 方法一：添加 jenkins 用户的可读写权限，jenkins uid = 1000 $ chown -R 1000 ./volumes/jenkins_home # 方法二：允许所有用户可读写挂载目录 $ chmod 777 ./volumes/jenkins_home $ sh jenkins.sh 6b0c20ed3dd952dff85b4da2207267c597ce4851b13727059d6b807c70bcc340 浏览器输入服务器 IP:8080 即可访问服务，等待初始化完成，来到解锁服务页面，需要输入管理员密码。
密码获取方法一：查看容器日志
$ docker logs -f jenkins ... # 管理员密码 ************************************************************* Jenkins initial setup is required. An admin user has been created and a password generated. Please use the following password to proceed to installation: 48fa9c4cd9f24745a87dc19a44df5796 This may also be found at: /var/jenkins_home/secrets/initialAdminPassword ************************************************************* 密码获取方法二：查看初始化密码文件
因为 jenkins_home 被挂载到宿主机上，所以在容器内或宿主机挂载目录里都是可以查看密码文件的。
# 容器内查看默认密码 $ docker exec -it jenkins cat /var/jenkins_home/secrets/initialAdminPassword 48fa9c4cd9f24745a87dc19a44df5796 # 宿主机挂载目录查看默认密码 $ cat $(pwd)/volumes/jenkins_home/secrets/initialAdminPassword 48fa9c4cd9f24745a87dc19a44df5796 界面按照提示一步一步来，重设管理员密码，跳过插件安装，完成服务搭建。
二、历史版本迁移 复制原服务下的 jenkins_home 目录，压缩后上传到新服务器，在新服务器上解压到自定义位置，修改容器启动脚本内的挂载目录，启动容器。
服务启动后出现报错：
java.nio.file.AccessDeniedException: /var/jenkins_home/secret.key ... Failed to fully read /var/jenkins_home/secret.key 权限问题，解决办法：
$ chown -R 1000 jenkins_home 重启容器，正常访问，原历史数据全部恢复。
]]></content></entry><entry><title>Docker - 搭建Nginx提供服务器目录对外访问</title><url>/tech/docker/%E6%90%AD%E5%BB%BAnginx%E6%8F%90%E4%BE%9B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%AE%E5%BD%95%E5%AF%B9%E5%A4%96%E8%AE%BF%E9%97%AE/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ 使用 Nginx 搭建 Web 服务
 Nginx 简介 Nginx (engine x) 是一个高性能的 HTTP 和反向代理 WEB 服务器，通过简单的配置文件即可快速提供服务，性能稳定，系统资源占用少，并发能力强。
 反向代理：服务器将收到的请求分发到其他服务器 负载均衡：流量均匀的分布到后端的服务器上 HTTP 缓存：缓存服务器，提高用户访问速度  DEMO 拉取镜像 $ docker pull nginx:latest 启动容器 $ vim nginx.sh # -d 在后台运行 # -p 将容器的 80 端口映射到本机的 80 端口 # -v 挂载目录；必须使用绝对路径（/开头的地址） docker run -d --name nginx -p 80:80 \ 	-v /data/nginx/volumes/html:/usr/share/nginx/html \ 	-v /data/nginx/volumes/log:/var/log/nginx \ 	nginx:latest $ chmod +x nginx.sh $ sh nginx.sh 891e09a6bbb5e131f99cd3fe60dfb2687b0939c28ad614d017408ce74478b1a1 # 查看容器状态；status Up $ docker ps 容器起来后，打开浏览器访问服务器 IP 地址，就可以看到 nginx 的欢迎页！
由于启动命令通过 -v 参数挂载了主页面，所以修改本地 index.html 文件可以实时同步到容器内。
$ echo &#34;&lt;h1&gt;Everythin will be ok.&lt;/h1&gt;&#34; &gt; /data/nginx/volumes/html/index.html 刷新页面，看看效果。
Nginx 显示目录文件列表 工作中有时会分发安装包、配置文件、测试数据、测试报告等给其他同事，文件上传到服务器发布目录，通过分享链接即可一对多进行文件分发。之前使用 Apache 服务来完成这项工作，正好这几天旧机器回收，借此机会，在新机器上使用 Nginx 搭建该服务，在此记录。
为了安全起见，Nginx 默认不允许展示目录文件列表，通过 Fancy Index 模块可以开启此功能，就像内置的 autoindex 模块一样，同时允许对页面进行定制，会更加美观。
 自定义页头 自定义页脚 添加自定义 CSS 样式 允许按名称（默认）、修改时间或文件大小对文件进行排序；升序（默认）或降序  登录到服务器，切换为自定义工作目录：/data1/docker/nginx，尽量不要放在系统盘，防止系统盘损坏导致数据丢失。
1、下载 fancyindex   # $ wget -O fancyindex.zip https://github.com/aperezdc/ngx-fancyindex/archive/refs/tags/v0.5.2.zip # 地址已失效替换 $ wget -O fancyindex.zip https://github.com/aperezdc/ngx-fancyindex/releases/download/v0.5.2/ngx-fancyindex-0.5.2.tar.xz $ unzip fancyindex.zip &amp;&amp; rm -f nginx-1.21.4.tar.gz ngx-fancyindex-0.5.2 2、下载 Nginx-Fancyindex-Theme   开源的 fancyindex 主题，支持搜索，界面美化，有白色/黑色两种风格。
$ wget -O fancytheme.zip https://github.com/Naereen/Nginx-Fancyindex-Theme/archive/master.zip $ unzip fancytheme.zip &amp;&amp; rm -f fancytheme.zip Nginx-Fancyindex-Theme-master $ mv Nginx-Fancyindex-Theme-master Nginx-Fancyindex-Theme 3、下载 Nginx 可以自定义版本，1.21.4 是当前最新版本
$ wget http://nginx.org/download/nginx-1.21.4.tar.gz $ tar xvf nginx-1.21.4.tar.gz &amp;&amp; rm -f nginx-1.21.4.tar.gz # 将 fancyindex 放到 nginx 目录内，方便后续编译安装 $ mv ngx-fancyindex-0.5.2/ nginx-1.21.4/model/ngx-fancyindex-0.5.2 4、Dockerfile 添加 FancyIndex 模块需要重新编译 Nginx，因此没有使用官方现成的 Nginx 镜像，编写 Dockerfile，基于 apline 镜像重新构建新的镜像。
# Dockerfile# apline 面向安全的轻型 Linux 发型版；包管理工具为 apkFROMalpine:latestLABEL author=&#34;lan&#34;WORKDIR/rootCOPY ./nginx-1.21.4 /usr/local/nginx-1.21.4# 配置阿里云下载源RUN echo &#34;http://mirrors.aliyun.com/alpine/latest-stable/main/&#34; &gt; /etc/apk/repositories \  &amp;&amp; echo &#34;http://mirrors.aliyun.com/alpine/latest-stable/community/&#34; &gt;&gt; /etc/apk/repositories \  # 更新 &amp; 安装依赖 &amp;&amp; apk update \  &amp;&amp; apk add --no-cache gcc libc-dev make openssl-dev pcre-dev zlib-dev linux-headers curl \  &amp;&amp; cd /usr/local/nginx-1.21.4/ \  # 执行编译安装 Nginx &amp;&amp; ./configure --prefix=/etc/nginx \  --sbin-path=/usr/sbin/nginx \  --modules-path=/usr/lib/nginx/modules \  --conf-path=/etc/nginx/nginx.conf \  --error-log-path=/var/log/nginx/error.log \  --http-log-path=/var/log/nginx/access.log \  --pid-path=/var/run/nginx.pid \  --lock-path=/var/run/nginx.lock \  --http-client-body-temp-path=/var/cache/nginx/client_temp \  --http-proxy-temp-path=/var/cache/nginx/proxy_temp \  --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \  --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \  --http-scgi-temp-path=/var/cache/nginx/scgi_temp \  --conf-path=/etc/nginx/nginx.conf \  --with-http_ssl_module \  # 指定安装扩展模块路径 --add-module=/usr/local/nginx-1.21.4/model/ngx-fancyindex-0.5.2 \  --with-compat \  --with-file-aio \  --with-threads \  --with-http_addition_module \  --with-http_auth_request_module \  --with-http_dav_module \  --with-http_flv_module \  --with-http_gunzip_module \  --with-http_gzip_static_module \  --with-http_mp4_module \  --with-http_random_index_module \  --with-http_realip_module \  --with-http_secure_link_module \  --with-http_slice_module \  --with-http_ssl_module \  --with-http_stub_status_module \  --with-http_sub_module \  --with-http_v2_module \  --with-mail \  --with-mail_ssl_module \  --with-stream --with-stream_realip_module \  --with-stream_ssl_module \  --with-stream_ssl_preread_module \  &amp;&amp; make \  &amp;&amp; make install \  &amp;&amp; mkdir -p /var/cache/nginx/client_temp \  &amp;&amp; rm -rf /usr/local/nginx-1.21.4 \  # 修改系统时区为东八区 &amp;&amp; rm -rf /etc/localtime \  &amp;&amp; ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeEXPOSE80CMD [&#34;/bin/sh&#34;,&#34;-c&#34;,&#34;nginx -g &#39;daemon off;&#39;&#34;]构建镜像
# 命令记不住可以直接放到 sh 文件 $ docker build -t nginx-apline:pub -f Dockerfile . ... Successfully built 93d160ece5d8 Successfully tagged nginx-apline:pub $ docker images nginx-apline pub 93d160ece5d8 41 seconds ago 161MB 5、编写 nginx.conf 配置文件 worker_processes auto; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; fancyindex on; fancyindex_localtime on; fancyindex_exact_size off; fancyindex_header &#34;/Nginx-Fancyindex-Theme-light/header.html&#34;; fancyindex_footer &#34;/Nginx-Fancyindex-Theme-light/footer.html&#34;; fancyindex_ignore &#34;examplefile.html&#34;; fancyindex_ignore &#34;Nginx-Fancyindex-Theme-light&#34;; fancyindex_name_length 255; server { # 代理 80 端口；将 location 里面配置的内容反向代理到 80 端口供外部访问 listen 80; server_name localhost; # 支持中文显示 charset utf-8; location / { autoindex on; # 对外访问目录设置 root /etc/nginx/html; } } } 6、启动容器 直接封装 sh 脚本，方便执行。
#!/bin/bash # 判断容器存在就删除 if [[ -n $(docker ps -q -f &#34;name=^nginx$&#34;) ]]; then docker rm -f nginx; fi # 设置主题；把主题文件放到挂载的主页即可 /bin/cp -rf /data1/docker/nginx/Nginx-Fancyindex-Theme/Nginx-Fancyindex-Theme-light/ /data1/pub/ &amp;&amp; \  # 挂载目录 docker run -id --name nginx -p 80:80 \  -v /data1/pub/:/etc/nginx/html/ \  -v /data1/docker/nginx/volumes/nginx.conf:/etc/nginx/nginx.conf \  -v /data1/docker/nginx/volumes/log:/var/log/nginx \  --restart=always \  nginx-apline:pub 最后附上效果图，页面支持排序、搜索功能，比之前 Apache 的发布目录好多了。
]]></content></entry><entry><title>Jenkins - Jenkinsfile</title><url>/tech/jenkins/jenkinsfile-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[Jenkins Pipeline 一、概念 将整个持续集成的过程用解释性代码 jenkinsfile 来描述。
二、Jenkinsfile 使用方法  Pipeline script Pipeline script from SCM  1、Pipeline script 创建第一个 pipeline 项目
 新建项目 输入项目名称 选择流水线项目 点击确定 进入配置页面，配置 pipeline  下拉到页面最底部，定义流水线脚本有两种方式，默认是在配置页面编辑脚本，也就是 Pipeline script，点击输入框右上角的
try simple Pipeline...
就可以自动生成一个 demo 脚本。
pipeline { // 构建节点，any 代表任意节点  agent any // 构建阶段，可以有多个阶段  stages { // 构建阶段一  stage(&#34;Hello&#34;) { // 阶段一执行的步骤一  // 可以有多个步骤  steps { // 步骤内构建脚本  echo &#34;Hello World!&#34; } } } // 构建后置操作  post { // always 代表总是触发  always { echo &#34;Say goodbye!&#34; } } } 保存配置后，进行构建，第一个流水线任务就建立完成了。
2、Pipeline script from SCM 远程仓库检出脚本构建
在配置页面上编写 jenkinsfile 有个缺点，如果内容有变更的话，需要登录 Jenkins 平台修改，比较麻烦。所以流水线项目提供从远程仓库检出 jenkiinsfile 的方式构建。
 新建一个 Jenkins file，填入上面的脚本内容，提交远程代码仓库。 回到配置页面，流水线定义选中 Pipeline script form SCM，配置远程代码仓库 选择 SVN（Git 类似） 填写仓库地址（Repository URL） 配置验证信息，有代码仓库访问权限的账号（Credentials） 填写 Jenkinsfile 脚本路径，就是远程仓库脚本的存放目录 eg： ./ci/jenkinsfile 保存后进行构建  三、Jenkinsfile 语法  Declarative pipeline（结构化方式） Scripts pipeline（groovy 语法）  Declarative pipeline 1、所有内容必须包含在一个 pipeline 代码块内：pipeline {}
pipeline { ... } 2、agent（必填指令）：执行节点
 any：可以在任意节点上执行 pipeline 的构建 none：pipeline 不分配全局节点，每个 stage 自己分配 label：指定运行节点的 label node：自定义运行节点配置  指定 label 指定 自定义工作目录   docker：控制目标节点上的 docker 运行相关内容  pipeline { agent { node { label &#34;myslave&#34; customWorkspace &#34;myWorkSpace&#34; } } } 3、stages（必填指令）：包含一个或者多个 stage 的序列，pipeline 大部分工作在此执行。
 无参数 唯一  4、stage（必填指令）：包含在 stages 中，pipeline 完成的所有工作都需要包含到 stage 中
 无参数 需要定义 stage 名字 可以写多个  5、steps（必填指令）：包含在 stage 中，具体执行步骤
 无参数 可以写多个  6、post（非必填指令）：定义 stages 运行结束后的操作
 always：无论 stages 运行结果如何，都会执行 changed：只有当运行结果与上次运行结果不同时，才会执行 failure：仅当运行结果为失败时，才会执行 sucess：仅当运行结果为成功时，才会执行 unstable：仅当运行结果不稳定时，才会执行 aborted：仅当运行中止状态时，才会执行  post { always { echo &#34;always&#34; } success { echo &#34;success&#34; sleep 2 } unstable { echo &#34;unstable&#34; } } 7、environment（非必填指令）：定义运行时环境变量，无参数
environment { test = &#39;hello world&#39; } stages { stage(&#34;print environment&#34;) { steps { echo test } } } 8、options（非必填指令）：定义 pipeline 的专有属性，配置页内的其他自定义项
 buildDiscarder：保持构建的最大个数 disabelConcurrentBuilds：不允许并行执行 pipeline 任务 timeout：pipeline 超时时间 retry：重试次数 timestamps：预定义由 pipeline 生成的所有控制台输出时间 skipStagesAfterUnstable：一旦构建进入不稳定状态，就跳过此 stage  options { timeout(time: 30, unit: &#34;SECONDS&#34;) buildDiscarder(logRotator(numToKeepStr: &#39;2&#39;)) retry(5) } 9、parameters（非必填指令）：定义 pipeline 的专有参数列表
 支持的数据类型  booleanParam choice credentials：证书 file text password run string   类似参数化构建的选项  parameters { string(name: &#34;PERSON&#34;, defaultValue: &#34;jenkins&#34;, description: &#34;输入的文本参数&#34;) } stages { stage(&#34;Test Parameters&#34;) { steps { echo &#34;Hello, ${params.PERSON}!&#34; } } } 10、triggers（非必填指令）：定义了 piplien 自动化触发的方式
 cron：接收一个 cron 风格的字符串来定义 pipeline 触发的常规间隔 pollSCM：接收一个 cron 风格的字符串来定义 Jenjkins 检查 SCM 源更改的常规间隔；如果存在更改，则 pipeline 被重新触发。  triggers { pollSCM(&#39;H */4 * * 1-5&#39;) } 11、parallel（非必填指令）：并行构建
pipeline { agent none stages { stage(&#34;并行构建&#34;) { parallel { stage(&#34;stage - 001&#34;) { agent { label &#34;slave1&#34; } steps { echo &#34;在 slave1 节点上执行 stage - 001.&#34; sh &#34;ifconfig&#34; sleep 10 } } stage(&#34;stage -002&#34;) { agent { label &#34;slave2&#34; } steps { echo &#34;在 slave2 节点上执行 stage - 002.&#34; sh &#34;ifconfig&#34; sleep 10 } } } } } } 2、Scripts pipeline 基于 groovy 语法定制的一种领域专用语言（DSL）
 DSL (Domain Specific Language)
A specialized computer language designed for a specific task.
为了解决某一类任务而专门设计的计算机语言。
 优点：
 灵活性高 可扩展性更好 与 Declarative pipeline 语法类型  流程控制 - if/else
node { stage(&#34;if/else demo&#34;){ if (env.BRANCH_NAME == &#34;master&#34;) { echo &#34;master branch&#34; } else { echo &#34;else branch&#34; } } } 流程控制 - try/carch
node { echo &#34;This is test stage which run on the slave agent.&#34; try { echo &#34;try block.&#34; } catch (exc) { echo &#34;catch block.&#34; } finally { // 兜底执行 	echo &#34;finally block.&#34; } } 控制全局工具设置的环境变量与运行命令
 定义 maven Name &amp; MAVEN_HOME 定义 java Name &amp; JAVA_HOME 定义 allure Name &amp; ALLURE_HOME &hellip;  stage(&#34;maven deploy&#34;) { node(&#34;master&#34;) { sh &#34;. ~/.bash_profile&#34; // 定义 maven 工具，工具在全局工具设置添加好，这里去获取 	// 全局工具设置（Manager Jenkins - Global Tools Configuration） 	def mvnHome = tool &#34;maven_3.6.0_master&#34; def jdkHome = tool &#34;jdk_1.8_master&#34; env.PATH = &#34;${mvnHome}/bin:${env.PATH}&#34; env.PATH = &#34;${jdkHome}/bin:${env.PATH}&#34; sh &#34;mvn clean install&#34; sh &#34;mv target/iWeb.war target/ROOT.war&#34; } } 以上就是 jenkinsfile 的基本用法，先有一个大概的认识，了解了解语法，编写过程中随用随查。
]]></content></entry><entry><title>Python - Jmespath基本操作</title><url>/tech/python/jmespath%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[ JMESPath is a query language for JSON.
 JMESPath 是 JSON 查询语言，可以从 JSON 文档中提取和转换元素。在做接口自动化测试项目时，最基础的一步就是从响应中获取各种待验证字段值，掌握 jmespath 语法，能达到事半功倍的效果。撸了一天官方文档，趁热记录下所学所得。
 Try it Out!  
 jmesath.py  
 JMESPath Examples  
安装 $ pip install jemspath jmespath.py 库提供了两个接口：
def compile(expression): return parser.Parser().parse(expression) def search(expression, data, options=None): return parser.Parser().parse(expression).search(data, options=options) # options 可以通过创建实例来控制 jmespath 表达式的计算方式。  compile：与 re 模块类似，使用 compile 函数编译表达式，并使用解析后的表达式执行重复搜索 search：接收表达式和数据，返回提取结果  基本表达式 1. 对象取值 根据键取值，如果键不存在，则返回一个 null，或该语言中与 null 等效的值。
&gt;&gt;&gt; from jmespath import search &gt;&gt;&gt; search(&#34;a&#34;, {&#34;a&#34;: &#34;foo&#34;, &#34;b&#34;: &#34;bar&#34;, &#34;c&#34;: &#34;baz&#34;}) &#39;foo&#39; &gt;&gt;&gt; search(&#34;d&#34;, {&#34;a&#34;: &#34;foo&#34;, &#34;b&#34;: &#34;bar&#34;, &#34;c&#34;: &#34;baz&#34;}) None 使用子表达式获取值，如果键不存在，则返回一个 null。
&gt;&gt;&gt; search(&#34;a.b.c&#34;, {&#34;a&#34;: {&#34;b&#34;: {&#34;c&#34;: &#34;value&#34;}}}) value &gt;&gt;&gt; search(&#34;a.b.c.d&#34;, {&#34;a&#34;: {&#34;b&#34;: {&#34;c&#34;: &#34;value&#34;}}}) None 2. 列表取值 索引表达式，从 0 开始，索引越界，则返回 null；索引可以为负数，-1 为列表中最后一个元素。
&gt;&gt;&gt; search(&#34;[1]&#34;, [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;]) &#34;b&#34; &gt;&gt;&gt; search(&#34;[3]&#34;, [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;]) None &gt;&gt;&gt; search(&#34;[-1]&#34;, [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;]) &#34;c&#34; 3. 对象嵌套列表 &gt;&gt;&gt; search(&#34;a.b[0].c&#34;, {&#34;a&#34;: {&#34;b&#34;: [{&#34;c&#34;: 3}, {&#34;d&#34;: 4}]}}) 3 4. 切片 与 python 列表切片相同，[start：end：step]，留头掐尾
&gt;&gt;&gt; search(&#34;[0:5]&#34;, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) [0, 1, 2, 3, 4] &gt;&gt;&gt; search(&#34;[5:10]&#34;, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) [5, 6, 7, 8, 9] # 步长为 2，为 -1 时翻转列表 &gt;&gt;&gt; search(&#34;[::2]&#34;, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) [0, 2, 4, 6, 8] 5. 投影 # 创建数据 data = { &#34;student&#34;: [ {&#34;name&#34;: &#34;james&#34;, &#34;age&#34;: 32}, {&#34;name&#34;: &#34;harden&#34;, &#34;age&#34;: 18}, {&#34;name&#34;: &#34;curry&#34;, &#34;age&#34;: 13}, {&#34;test&#34;: &#34;ok&#34;} ] }  列表投影  &gt;&gt;&gt; search(&#34;student[*].name&#34;, data) [&#39;james&#39;, &#39;harden&#39;, &#39;curry&#39;] student 中的每个元素被收集到数组中，给到后续的表达式，这成为投影（名词来自翻译软件，我不是很懂 😂）。我理解的意思就是每一步获取到的数据结果。 通配符 *，表示返回列表中的全部元素。当单组元素的结果表达式为 null，则该值从收集的 结果集 中忽略。
所以，在最终的输出结果内没有 {&quot;test&quot;: &quot;ok&quot;} 的值。
 切片投影  &gt;&gt;&gt; search(&#34;student[:2].name&#34;, data) [&#39;james&#39;, &#39;harden&#39;]  对象投影  data = { &#34;test&#34;: { &#34;funcA&#34;: {&#34;num&#34;: 1}, &#34;funcB&#34;: {&#34;num&#34;: 2}, &#34;funcC&#34;: {&#34;miss&#34;: 3}, } } &gt;&gt;&gt; search(&#34;test.*.num&#34;, data) [1, 2] 对象投影可以分解为两个部分，左侧和右侧：
 左侧创建要投影的初始数组：  evaluate(test, inputData) -&gt; [ {&#34;num&#34;: 1}, {&#34;num&#34;: 2}, {&#34;miss&#34;: 3} ] 右侧作用于数组中的每个元素  evaluate(num, {num: 1}) -&gt; 1 evaluate(num, {num: 2}) -&gt; 2 evaluate(num, {miss: 3}) -&gt; null 第三条不符合，最终结果过滤空值，所以最终表达式结果为 [1, 2]。
 展平投影  列表/对象投影，在投影中创建投影时会保留原始文档的结构。
data = { &#34;a&#34;: [ { &#34;b&#34;: [ {&#34;name&#34;: &#34;a&#34;}, {&#34;name&#34;: &#34;b&#34;} ] }, { &#34;b&#34;: [ {&#34;name&#34;: &#34;c&#34;}, {&#34;name&#34;: &#34;d&#34;} ] } ] } &gt;&gt;&gt; search(&#34;a[*].b[*].name&#34;, data) [ [&#39;a&#39;, &#39;b&#39;], [&#39;c&#39;, &#39;d&#39;] ] 如果只要列表下的所有值，不关心所谓的层级结构，那么就需要通过展平投影来获取结果。
&gt;&gt;&gt; search(&#34;a[].b[].name&#34;, data) [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;] 只需要将 [*] -&gt; [] 就可以扁平化列表。它将子列表展平到父列表，并不是递归的关系，下面例子能很好的说明。
data = [ [0, 1], 2, [3], 4, [5, [6, 7]] ] # 展平一层 &gt;&gt;&gt; search(&#34;[]&#34;, data) [0, 1, 2, 3, 4, 5, [6, 7]] # 展平第二层 &gt;&gt;&gt; search(&#34;[][]&#34;, data) [0, 1, 2, 3, 4, 5, 6, 7]  过滤投影  data = { &#34;book&#34;: [ {&#34;name&#34;: &#34;a1&#34;, &#34;author&#34;: &#34;aa&#34;}, {&#34;name&#34;: &#34;a2&#34;, &#34;author&#34;: &#34;aa&#34;}, {&#34;name&#34;: &#34;b&#34;, &#34;author&#34;: &#34;bb&#34;} ] } # 获取 aa 写的两本书 &gt;&gt;&gt; search(&#34;book[?author==&#39;aa&#39;].name&#34;, data) [&#39;a1&#39;, &#39;a2&#39;] 过滤器表达式是为数组定义的，一般形式为 左侧投影 [? &lt;表达式&gt; &lt;比较器&gt; &lt;表达式&gt;] 右侧投影。
条件表达式支持如下：
 ==, tests for equality. !=, tests for inequality. &lt;, less than. &lt;=, less than or equal to. &gt;, greater than. &gt;=, greater than or equal to.  6. 管道表达式 管道表达式 &lt;expression&gt; | &lt;expression&gt;，表示必须停止投影。将当前节点的结果传递到管道符右侧继续投影。
&gt;&gt;&gt; search(&#34;book[*].name | [0]&#34;, data) &#34;a1&#34; # 管道符左侧结果为 [&#39;a1&#39;, &#39;a2&#39;, &#39;b&#39;]  # [0] 取该结果下标为 0 的数据，得到 a1 7. 多选 多选列表示例
data = { &#34;people&#34;: [ { &#34;name&#34;: &#34;a&#34;, &#34;state&#34;: {&#34;name&#34;: &#34;up&#34;} }, { &#34;name&#34;: &#34;b&#34;, &#34;state&#34;: {&#34;name&#34;: &#34;down&#34;} }, { &#34;name&#34;: &#34;c&#34;, &#34;state&#34;: {&#34;name&#34;: &#34;up&#34;} } ] } &gt;&gt;&gt; search(&#34;people[].[name, state.name]&#34;, data) [ [&#39;a&#39;, &#39;up&#39;], [&#39;b&#39;, &#39;down&#39;], [&#39;c&#39;, &#39;up&#39;] ] 从 json 文档中提取所需要的内容，精简结构。
[name, state.name] 表达式的意思是创建一个包含两个元素的列表：
 第一个元素是计算 name 表达式得到的结果 第二个元素是计算 state.name 表达式的结果  因此，每个列表元素都会创建一个双元素列表，整个表达式的最终结果是一个包含两个元素列表的列表。
多选对象示例
与多选列表思想相同，创建的是一个散列而不是数组。
&gt;&gt;&gt; search(&#34;people[].{name: name, state: state.name}&#34;, data) [ {&#39;name&#39;: &#39;a&#39;, &#39;state&#39;: &#39;up&#39;}, {&#39;name&#39;: &#39;b&#39;, &#39;state&#39;: &#39;down&#39;}, {&#39;name&#39;: &#39;c&#39;, &#39;state&#39;: &#39;up&#39;} ] 8. 函数 部分函数的使用，直接通过 test 更直观一些，见名知义，没什么好解释的。
import jmespath import pytest class TestJmesPath: def setup_class(self): self.data = { &#34;book&#34;: [ {&#34;name&#34;: &#34;平凡的世界&#34;, &#34;author&#34;: &#34;路遥&#34;, &#34;sort&#34;: 3}, {&#34;name&#34;: &#34;围城&#34;, &#34;author&#34;: &#34;钱钟书&#34;, &#34;sort&#34;: 2}, {&#34;name&#34;: &#34;围城&#34;, &#34;author&#34;: &#34;钱钟书&#34;, &#34;sort&#34;: 2}, {&#34;name&#34;: &#34;活着&#34;, &#34;author&#34;: &#34;余华&#34;, &#34;sort&#34;: 1}, {&#34;name&#34;: &#34;麦田里的守望者&#34;, &#34;author&#34;: &#34;塞林格&#34;, &#34;sort&#34;: 4}, {&#34;name&#34;: &#34;挪威的森林&#34;, &#34;author&#34;: &#34;村上春树&#34;, &#34;sort&#34;: 5} ] } def test_keys(self): &#34;&#34;&#34;提取对象的 key 注意：管道符前面是一个对象，所以需要指定下标，不能通过 * 号提取数组后获取 key，否则报错 jmespath.exceptions.JMESPathTypeError: In function keys(), expected one of: [&#39;object&#39;], received: &#34;array&#34; &#34;&#34;&#34; result = jmespath.search(&#34;book[0].test&#34;, self.data) assert result == [&#39;name&#39;, &#39;author&#39;] def test_values(self): &#34;&#34;&#34;提取对象的 value，不接受数组&#34;&#34;&#34; result = jmespath.search(&#34;book[0] | values(@)&#34;, self.data) assert result == [&#39;平凡的世界&#39;, &#39;路遥&#39;] def test_sort(self): &#34;&#34;&#34;根据 sort 进行排序&#34;&#34;&#34; result = jmespath.search(&#34;book[*].sort | sort(@)&#34;, self.data) assert result == [1, 2, 2, 3, 4, 5] result = jmespath.search(&#34;book[*].author | sort(@) | [join(&#39;, &#39;, @)]&#34;, self.data) assert result == [&#39;余华, 塞林格, 村上春树, 路遥, 钱钟书, 钱钟书&#39;] def test_type(self): result = jmespath.search(&#34;book[*].sort | type(@)&#34;, self.data) assert result == &#34;array&#34; result = jmespath.search(&#34;book[0].name | type(@)&#34;, self.data) assert result == &#34;string&#34; def test_to_string(self): result = jmespath.search(&#39;[].to_string(@)&#39;, [1, 2, 3, &#34;number&#34;, True]) assert result == [&#34;1&#34;, &#34;2&#34;, &#34;3&#34;, &#39;number&#39;, &#39;true&#39;] def test_to_number(self): result = jmespath.search(&#39;[].to_number(@)&#39;, [&#34;1&#34;, &#34;2&#34;, &#34;3&#34;, &#34;number&#34;, True]) assert result == [1, 2, 3] def test_avg(self): result = jmespath.search(&#34;avg(@)&#34;, [10, 15, 20]) assert result == 15.0 with pytest.raises(jmespath.exceptions.JMESPathTypeError): jmespath.search(&#34;avg(@)&#34;, [10, False, 20]) def test_contains(self): result = jmespath.search(&#34;contains(`foobar`, `foo`)&#34;, {}) assert result is True result = jmespath.search(&#34;contains(`foobar`, `f123`)&#34;, {}) assert result is False def test_join(self): # expected one of: [&#39;array-string&#39;] # @ 为当前节点，得到的结果用逗号加空格分隔，然后放在当前节点下 result = jmespath.search(&#34;join(`, `, @)&#34;, [&#34;a&#34;, &#34;b&#34;]) assert result == &#34;a, b&#34; result = jmespath.search(&#34;join(``, @)&#34;, [&#34;a&#34;, &#34;b&#34;]) assert result == &#34;ab&#34; def test_length(self): result = jmespath.search(&#34;length(@)&#34;, [&#34;a&#34;, &#34;b&#34;]) assert result == 2 def test_max(self): result = jmespath.search(&#34;max(@)&#34;, [10, 3, 5, 5, 8]) assert result == 10 def test_min(self): result = jmespath.search(&#34;min(@)&#34;, [10, 3, 5, 5, 8]) assert result == 3 9. 自定义函数 接口测试项目中，有个获取列表数据后去重的需求，在官方文档上始终没有找到相关表达式或函数的使用，倒是在项目 issues 中找到这个问题，但也仅仅是一个提问&hellip;
继续查找资料，在 jmespath.py 项目中，找到用户自定义函数的方法，根据文档，自定义排序加去重的方法实现如下：
from jmespath import search from jmespath import functions class CustomFunctions(functions.Functions): &#34;&#34;&#34; https://github.com/jmespath/jmespath.py &#34;&#34;&#34; @functions.signature({&#39;types&#39;: [&#39;string&#39;, &#34;array&#34;]}) def _func_uniq(self, arg): if isinstance(arg, str): # string of unique return &#39;&#39;.join(sorted(set(arg))) if isinstance(arg, list): # array of unique return sorted(set(arg)) options = jmespath.Options(custom_functions=CustomFunctions()) &gt;&gt;&gt; search(&#34;foo.bar | uniq(@)&#34;, {&#39;foo&#39;: {&#39;bar&#39;: &#39;banana&#39;}}, options=options) abn &gt;&gt;&gt; search(&#34;foo.bar | uniq(@)&#34;, {&#39;foo&#39;: {&#39;bar&#39;: [5, 5, 2, 1]}}, options=options) [1, 2, 5]  掌握上面的基础语法后，再回过头看官方提供的多重提取表达式示例就非常容易了，配合使用，可以满足项目中需要的大部分数据提取，特殊需求还可以通过自定义函数来实现，非常好用。
]]></content></entry><entry><title>Jenkins - Jenkins Pipline Esbook</title><url>/tech/jenkins/%E6%8E%A5%E5%8F%A3%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%9E%E6%88%98pipeline/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[1、安装 Jenkins 插件  Extended Choice Parameter：参数化 stage view：用于展示流水线进度视图 groovy postbuild：执行 groovy 脚本请求 allure：报告展示  2、安装 allure 安装 node 先安装 node，未安装 node 直接启动 allure 会报错：/usr/bin/env: node: No such file or directory
# 创建安装目录 $ mkdir node &amp;&amp; cd node # 下载安装包 $ wget https://npm.taobao.org/mirrors/node/v15.8.0/node-v15.8.0-linux-x64.tar.gz # 解压缩安装包 $ tar -zxvf node-v15.8.0-linux-x64.tar.gz # 创建软链 $ ln -s /data/node/node-v15.8.0-linux-x64/bin/npm /usr/bin/npm $ ln -s /data/node/node-v15.8.0-linux-x64/bin/node /usr/bin/node 安装 allure 方法一
$ npm install -g allure-commandline --save-dev 方法二
下载包推送到服务器上解压
下载地址：https://registry.npmjs.org/allure-commandline/-/allure-commandline-2.13.0.tgz
# 上传到服务器上，-be 是防止乱码卡死 $ rz -be $ tar -zxvf allure-commandline-2.13.0.tgz $ ln -s /data/allure/package/bin/allure /usr/bin/allure 3、创建流水线任务 3.1、 创建项目
3.2、 配置项目
 参数化构建过程：用于选择脚本执行环境   添加流水线脚本  pipeline { agent any stages { stage(&#39;拉取代码&#39;){ steps { // 拉取代码，可选 svn、git 等，通过 pipline 语法生成  // 只需要添加仓库 URL 和 证书 即可，其他默认就行  } } stage(&#39;验证环境&#39;){ steps { // 安装运行环境  sh &#34;pip3 install -r requirements.txt&#34; // 验证测试环境  sh &#34;chmod 777 ./ci/env.sh&#34; sh &#34;sh ci/env.sh&#34; } } stage(&#39;运行测试&#39;){ steps{ sh &#34;python3 run.py ${env.choice}&#34; } } stage(&#39;生成报告&#39;){ steps{ script{ // 集成allure  allure includeProperties: false, jdk: &#39;&#39;, report: &#39;reports/allure-report&#39;, results: [[path: &#39;reports/allure-result&#39;]] } } } } } 3.3、 配置 allure 插件
Dashboard - 系统管理 - 全局工具配置 - Allure Commandline
构建后效果图 ![image-20211129102413817](/Users/lan/Library/Application Support/typora-user-images/image-20211129102413817.png)
]]></content></entry><entry><title>Jenkins - 接口自动化Ci全流程搭建记录</title><url>/tech/jenkins/%E6%8E%A5%E5%8F%A3%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%9E%E6%88%98pipeline+dockerfile/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[ 每日构建自动化测试任务，搭建流程记录。
 项目依赖
 Docker Jenkins SVN Pytest Allure  准备工作 1、环境安装   Docker 安装    Docker 搭建 Jenkins 服务    2、插件安装 按下面路径进入插件市场，搜索插件名，勾选后安装即可。
Jenkins -&gt; Manage Jenkins -&gt; Manage Plugins -&gt; 选中 Available 栏 # Install without restart 所需插件列表：
 Pipeline 流水线任务 Docker Docker Pipeline Subversion 代码管理仓库 Extended Choice Parameter 参数化构建 Allure：生成及展示 Allure 报告 Blue Ocean：美化 UI  3、配置全局凭证 使用 SVN 拉取项目代码，提前配置好用户名密码。仅填写用户名、密码即可，其他默认就好。
Jenkins -&gt; Manage Jenkins -&gt; Manage Credentials -&gt; Credentials -&gt; 选择作用范围 Jenkins -&gt; 全局凭据 (unrestricted) -&gt; Add Credentials 如果使用 Git 管理项目代码，同理。
4、配置 allure 工具 配置路径如下，填写 Name，勾选自动安装，点击保存。
Jenkins -&gt; Manage Jenkins -&gt; Global Tool Configuration -&gt; Allure Commandline -&gt; Add Allure Commandline 注意：
 如果不填写 Name，自动安装时会出现空指针错误； 勾选自动安装后，运行 job 会检查工具目录是否存在 allure，如果不存在才进行下载安装，如果存在，直接使用，不会重复下载。  Unpacking https://repo1.maven.org/maven2/io/qameta/allure/allure-commandline/2.17.2/allure-commandline-2.17.2.zip to /var/jenkins_home/tools/ru.yandex.qatools.allure.jenkins.tools.AllureCommandlineInstallation/allure on Jenkins Pipeline 以上准备工作完成后，接下来开始配置流水线项目。
1、新建 Pipeline 项目 创建成功后，进入配置页面。
2、配置项目：参数化构建 接口自动化测试项目需要传入一个环境参数，根据参数值判断执行环境为测试还是线上；如果这里没有该选项，检查下插件是否安装成功，或尝试重启 Jenkins。
3、配置项目：Pipeline script 两种方式：
 直接在配置页面文本框编写； 从代码仓库检出。   详情点击查看历史文章  
一般是在项目内创建 Jenkinsfile 文件，跟随项目代码一起维护，变更会在下一次项目构建时自动生效。且代码编辑器可安装插件，便于脚本编写和语法检查。
Jenkins 配置完成，先保存。
4、构建执行脚本的镜像 在代码项目内编写 Dockerfile  ，把项目依赖的工具包全部打到镜像内，构建为新的镜像。
# API AUTO TEST image v2: Pytest、JDK 8、allureFROMpython:3.7-alpineLABEL author=&#34;lanzy.nice@gmail.com&#34;WORKDIR/varCOPY requirements.txt .# 更新包管理工具RUN echo &#34;http://mirrors.aliyun.com/alpine/latest-stable/main/&#34; &gt; /etc/apk/repositories \  &amp;&amp; echo &#34;http://mirrors.aliyun.com/alpine/latest-stable/community/&#34; &gt;&gt; /etc/apk/repositories \  &amp;&amp; apk update \  &amp;&amp; apk add --no-cache openjdk8 nodejs curl wget tar \  # 安装 Python 第三方库 &amp;&amp; pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple/ \  &amp;&amp; pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/ \  # 修改系统时区为上海 &amp;&amp; rm -rf /etc/localtime \  &amp;&amp; ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \  # 安装 allure &amp;&amp; wget https://registry.npmjs.org/allure-commandline/-/allure-commandline-2.13.0.tgz \  &amp;&amp; tar -zxvf allure-commandline-2.13.0.tgz \  &amp;&amp; rm -f allure-commandline-2.13.0.tgz \  &amp;&amp; mv package allure \  &amp;&amp; chmod -R 777 allure \  &amp;&amp; ln -s $(pwd)/allure/dist/bin/allure /usr/bin/allureSTOPSIGNALSIGRTMAX执行一下 job，把代码拉取到服务器上，进入 Dockerfile 所在的目录，构建镜像。
# pytest:v2 为镜像名跟标签，可自定义 # requirements.txt 放在该目录内 $ docker build -t pytest:v2 -f Dockerfile . 5、定义流水线任务 编写 Jenkinsfile   自定义工作流程，大概长这个样子，根据需求稍加修改即可。
pipeline { agent { docker { image &#39;pytest:v2&#39; // 把测试结果挂载到 Jenkins 容器，生成报告 args &#39;-v ${WORKSPACE}/reports/allure-result:${WORKSPACE}/reports/allure-result&#39; } } // 定时任务；工作日每天上午下午各跑一次 // 注意：设置定时任务后需要手动构建一次加载配置 triggers { cron(&#39;H 10,18 * * 1-5&#39;) } stages { stage(&#39;拉取代码&#39;){ steps { // 具体的代码使用流水线语法生成 checkout(...) } } stage(&#39;验证环境&#39;){ steps { sh &#34;chmod 777 ./ci/env.sh&#34; sh &#34;sh ci/env.sh ${env.choice}&#34; } } stage(&#39;运行测试&#39;){ steps{ // 注意 allure 报告路径需要与下方生成报告内配置的路径一致 sh &#34;pytest test/test_demo.py ${env.choice} --alluredir=./reports/allure-result&#34; } } stage(&#39;生成报告&#39;){ steps{ script{ // Allure 插件：工作目录可省略不写，自动拼接 allure includeProperties: false, jdk: &#39;&#39;, report: &#39;reports/allure-report&#39;, results: [[path: &#39;reports/allure-result&#39;]] } } } } } 由于执行接口自动化测试的环境基本不会变更，所以这里直接使用固定的镜像。如果镜像变动频率较高，就需要添加步骤，每次运行项目时先基于 Dockerfile 构建镜像，镜像构建成功后供后面的步骤使用，会更加灵活。
6、进行构建 在 Jenkins job 主页进行构建，就会展示流水线任务的执行进度及工作日志。多次构建后，右上角还会展示项目整体运行结果的趋势图。
当 Jeknins 的执行报告要让其他人访问时，可以切换为 Blue Ocean 视图，页面会相对美观。
]]></content></entry><entry><title>功能测试 - 软件测试方法与理论</title><url>/tech/%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95%E4%B8%8E%E7%90%86%E8%AE%BA/</url><categories><category>功能测试</category></categories><tags><tag>功能测试</tag></tags><content type="html">1. 软件开发流程 软件包含：程序、文件、文档、数据
软件开发流程演变：传统瀑布模型 → 敏捷开发模型 → DevOps 模型
瀑布模型 瀑布模型流程：需求分析 → 设计 → 编码 → 实现 → 软件测试 → 完成 → 维护
瀑布模型特点：线性
瀑布模型优点：阶段清晰、强调早期计划和需求调查、适合需求稳定产品
瀑布模型缺点：增加开发风险、错误发现晚
敏捷开发模型 敏捷开发模型：XP、SCRUM
1、极限编程-XP：分多个周期
编程方法：简单设计、结对编程、测试驱动开发、重构
小组实践：代码集体所有、编码标准、稳定高速的步伐、持续集成、隐喻
交付和管理：小规模发布、计划游戏、完整的团队、现场客户
2、SCRUM：产品backlog、sprint计划会议、sprint backlog→2-4周sprint、潜在交付产品增量
敏捷模型特点：增量迭代、小步快跑
Devops DevOps：开发、测试、运维
DevOps生命周期：持续开发、持续测试、持续集成、持续部署、持续监控
DevOps特点：减少变更范围、加强发布协调、自动化
持续集成（CI） 持续交付（CD）
2. 系统架构与数据流 理解公司产品的整体架构-测试架构思维
1．业务架构
商业模式
业务流程：角色、资源、数据
系统架构：角色、行为、数据集成关系
2．系统架构
架构角色与技术栈
部署架构
3．使用统一建模语言UML（梳理业务逻辑关系）
用例图-梳理业务流程：商业模式、业务角色
时序图-分析数据流：业务流程、调用关系
部署图：系统架构与集成关系
活动图-分析测试用例：业务逻辑分析
思维导图（活动图）-分析功能点（流程、分类）
3. 软件测试概念 3.1 软件测试原则 测试显示缺陷的存在 穷尽测试是不可能的 测试尽早介入 缺陷集群性（2/8原则） 杀虫剂悖论 测试活动依赖于测试内容 没有错误是好事谬论 3.2 软件测试模型 3.2.1 V模型 V模型：需求分析 → 概要设计 → 详细设计 → 编码 → 单元测试 → 集成测试 → 系统测试 → 验收测试
优点：既有底层测试又有高层测试、开发阶段清晰
缺点：误解为测试是在开发后进行的阶段
3.2.2 W模型 W模型：测试开发并行、测试伴随整个软件开发周期（包括需求、设计）
用户需求 → 需求分析 → 概要设计 → 详细设计 → 编码 → 集成 → 实施 → 交付
验收测试设计 → 确认与系统测试设计 → 集成测试设计 → 单元测试设计 → 单元测试 → 集成测试 → 确认测试系统测试 → 验收测试
优点：测试贯穿整个项目周期、更早介入早发现问题、测试开发并行
缺点：无法支持迭代的开发模型、有些项目无文档产出、对需求和设计的测试技术要求高
3.2.3 H模型 H模型：把测试活动完全独立出来
测试准备→测试就绪点→测试执行→测试流程
优点：完全独立并发进行、尽早准备执行灵活
缺点：测试就绪点分析困难、对人员要求高
4. 测试流程体系（软件项目管理） 项目流程：开发→单元测试→集成测试→持续集成→冒烟测试→系统测试→验收测试→发布→持续监控
测试流程：需求分析→测试计划（计划评审）→测试用例（用例评审）→集成测试（准备测试数据、准备自动化测试用例）→搭建测试环境（补充测试数据、功能测试、自动化测试）→系统测试报告（缺陷报告）
软件测试范围：传统测试流程、测试左移（开发）和测试右移（运维）
4.1 传统测试流程 完整测试流程：单元测试→集成测试→冒烟测试→系统测试→回归测试→验收测试
系统测试流程：需求分析→测试计划→测试设计（用例）→用例评审→测试执行→bug管理→发布维护
Bug管理流程：
提交缺陷→指派缺陷→确认缺陷（是）→推迟处理（是）→遗留缺陷（后续版本处理）→处理缺陷→回归缺陷（通过）→关闭缺陷
确认缺陷（是）→推迟处理（否）→处理缺陷→回归缺陷（通过）→关闭缺陷
确认缺陷（否）→回归缺陷（通过）→关闭缺陷
回归缺陷（未通过）→重新打开→确认缺陷
4.2 测试左移（开发） 测试左移：开发早期介入、代码测试、预防bug
质量保障手段：代码评审、代码审计、单元测试、自动化冒烟测试、研发自测
4.3 测试右移（运维） 测试右移：发布之后、线上监控
质量保障手段：闭环的线上问题反馈检查解决更新流程、查看日志、log 快速定位
5. 需求分析 查看需求文档-模拟宣讲-需求评审
5.1 需求评审 业务场景角度：
用户故事（站在用户使用角度）
业务流程图（业务整体流程逻辑）
功能点角度：
数据约束是否全面、合理
存在分支的逻辑、描述是否覆盖所有路径
多状态流程，状态流转描述是否合理且完整
权限描述是否明确
5.2 需求分析 明确测试范围
明确功能点
明确业务流程
明确输出结果
分析异常流程
预估测试需要的时间和资源
6. 测试技术体系 6.1 软件测试分类 按开发阶段分类
单元测试 集成测试 系统测试（功能测试、兼容性测试、性能测试、安全测试） 验收测试（α测试、β测试） 按是否查看代码分类
黑盒测试 白盒测试 灰盒测试 按测试执行方式分类
静态测试（查看代码文档） 动态测试（运行程序） 按是否手工执行分类
手工测试 自动化测试 其他分类
冒烟测试 回归测试 随机测试 探索性测试 6.2 分层测试体系 70%单元测试、20%服务测试（接口）、10%用户界面测试（UI）
单元测试方法（白盒，开发人员自己编写）
java（JUnit、TestNG） python（unittest、pytest） 接口测试（API，灰盒，测试编写）
抓包工具：Charles、Fiddler 自动化测试：postman、python（Requests、HttpRunner）、java（HttpClient、RestAssured） 性能测试：Jmeter、loadRunner 用户界面测试（UI）
人工测试 自动化方式（web：selenium、app：appium） 7. 常用测试平台 测试用例管理与bug管理平台：jira、redmine、testlink、tapd、云效、禅道、gitlab
代码管理平台：gitlab、subversion、github、bitbucket
持续集成管理平台：jenkins、gitlab runner、github action、自建 devops 平台
JIRA基本功能模块
Project 项目（产品、用例管理、bug管理）
Issue 问题（任务）
Field 字段（任务的属性）
Workflow 工作流（任务状态）
Screen 视图（字段的合集）
8. 测试用例设计 1、测试用例概念：测什么？怎么测？
2、测试用例组成：用例编号、测试模块、测试点、前提条件、测试步骤、预期结果、实际结果
3、测试用例等级
P0（核心-冒烟） P1（高优先级-基本功能） P2（中优先级-异常、边界、中断、网络、容错、UI） P3（低优先级-性能、压力、兼容性、安全性、可用性） 4、测试用例设计工具
思维导图 excel 测试用例设计方法
8.1 白盒测试方法论 根据待测产品的内部实现细节来设计测试用例
白盒测试手段：涵盖单元测试、集成测试
白盒测试度量：代码覆盖率
代码覆盖率常见概念：
语句覆盖：每行代码都要覆盖至少一次
判定覆盖：判定表达式的真假至少覆盖一次
判定/条件覆盖：判定覆盖与条件覆盖都必须覆盖
条件组合覆盖：判定表达式中的所有条件组合都需要覆盖
分支覆盖：控制流中的每条分支都要被覆盖一次
路径覆盖：所有的路径都要尽量覆盖
指令覆盖：一行代码会被编译为多条指令，尽可能的覆盖所有指令
方法覆盖：每个方法至少被覆盖一次
类覆盖：每个类至少被覆盖一次
文件覆盖、模块覆盖等等扩展覆盖
覆盖率统计工具：emma、cobertura、jacoco
流程覆盖
利用代码执行流代表流程
流程覆盖用路径覆盖率表达
对流程进行裁剪获得一个适合业务的小规模的业务子集
流程覆盖率=测试经过的路径/业务子集路径
精准化测试（控制流延申）
代码调用链与黑盒测试用例的关联
根据代码变更自动分析影响范围
黑盒测试过程中借助代码流程覆盖数据指导探索式测试
利用线上数据推导有效测试用例
代码流程分析与覆盖率统计
8.2 黑盒测试方法论 常用测试方法：等价类划分、边界值分析、因果图与判定表（决策树-流程图）、场景法
8.2.1 等价类划分法 等价类划分设计步骤：先划分等价类、有效等价类、无效等价类，挑选测试用例数据
可能数据：整数、小数、字母、汉字、符号、空格、回车、不输入
示例
需求：1～100 加法测试
1-100 整数 两个输入框 有效等价类：[1，100] 整数
无效等价类：负数、0、小数、字母、汉字、特殊符号、空
边界值： 0、1、2、99、100、101
8.2.2 边界值分析法 等价类划分的补充方法，通常同时使用
编号 所属等价类 输入框1 输入框2 预期结果 1 有效 1 100 101 2 有效 2 99 101 3 有效 99 2 101 4 有效 100 100 200 5 无效 0 40 给出错误提示 6 无效 40 0 给出错误提示 7 无效 101 50 给出错误提示 8 无效 50 101 给出错误提示 9 无效 3.23 45 给出错误提示 10 无效 45 3.23 给出错误提示 11 无效 ab 11 给出错误提示 12 无效 11 ab 给出错误提示 13 无效 我 34 给出错误提示 14 无效 34 我 给出错误提示 15 无效 % 56 给出错误提示 16 无效 56 % 给出错误提示 17 无效 78 给出错误提示 18 无效 78 给出错误提示 8.2.3 因果图 利用图解法分析输入的各种组合情况，从而设计测试用例的方法，适合检查程序输入条件的各种组合情况。
因 - 输入条件 果 - 输出结果 基本符号
c1-e1 恒等 c1~e1 非 c1/c2/c3ve1或 c1/c2^e1 与 约束条件
E 互斥（至多 1 个） I 包含（至少 1 个） O 唯一（有且只有 1 个） M 屏蔽（有 a 无 b） R 要求（有 a 必有 b） 因果图设计步骤
找出所有输入条件（因） 找出所有输出条件（果） 输入条件之间的制约和组合关系 输出条件之间的制约和组合关系 输入条件组合产生的输出结果 因果图转化为判定表 设计测试用例
充值条件：投币50/100，充值50/100
输入条件 输出条件 1、投币50 a、完成充值，退卡 2、投币100 b、提示充值成功 3、充值50 c、找零（退钱） 4、充值100 d、提示错误 输入条件：1 和 2 互斥、3 和 4 互斥，共 8 种情况：1、2、3、4、13、14、23、24
输出条件：a 和 d 互斥、b 和 d 互斥，共 4 种情况：ab、abc、cd、d
1、2→cd；3、4→d；13、24→ab；14→cd；23→abc
编号 1 2 3 4 5 6 7 8 输入 1. 投币50元 1 1 1 2. 投币100元 1 1 1 3. 充值50元 1 1 1 4. 充值100元 1 1 1 输出 a. 完成充值退卡 1 1 1 b. 提示充值成功 1 1 1 c. 找零（退钱） 1 1 1 1 d. 提示错误 1 1 1 1 1 8.2.4 判定表组成 条件桩 - 问题的所有条件 动作桩 - 问题的所有输出 条件项 - 针对条件桩的取值 动作项 - 条件项的各种取值情况下的输出结果 判定表设计步骤：列出所有的条件桩和动作桩、确定规则数-每个条件桩的取值个数^条件桩个数、填入条件项、填入动作项得到初始判定表、简化判定表。
示例
判断三角形：三条边a、b、c，判断是否构成三角形、三角形的类型
条件桩 条件项2^4
C1：a、b、c是否构成三角形 1、0
C2：a=b？ 1、0
C3：a=c？ 1、0
C4：b=c？ 1、0
动作桩 动作项
A1：不是三角形 1
A2：普通三角形 1
A3：等腰三角形 1
A4：等边三角形 1
A5：不可能出现 1
条件桩 C1：a、b、c是否构成三角形 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 C2：a=b？ 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 C3：a=c？ 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 C4：b=c？ 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 动作桩 A1：不是三角形 1 1 1 1 1 1 1 1 A2：普通三角形 1 A3：等腰三角形 1 1 1 A4：等边三角形 1 A5：不可能出现 1 1 1 简化后的判定表为：
条件桩 C1：a、b、c是否构成三角形 0 1 1 1 1 1 C2：a=b？ - 0 0 1 1 1 C3：a=c？ - 0 1 0 1 1 C4：b=c？ - 0 1 1 0 1 动作桩 A1：不是三角形 1 A2：普通三角形 1 A3：等腰三角形 A4：等边三角形 1 A5：不可能出现 1 1 1 8.2.5 场景法 模拟用户操作软件时的场景，主要用于测试系统的业务流程。
用例场景定义
基本流-按照正确的业务流程来实现的一条操作路径 备选流-导致程序出现错误的操作流程 场景法用例设计步骤
根据需求规格说明画出功能模块流程图 根据流程图描述程序的基本流和备选流 根据基本流备选流生成不同场景构造场景列表 每个场景生成测试用例 生成的测试用例复审去掉多余用例 为测试用例确定测试数值 示例
淘宝网购物流程：流程图
确定基本流和备选流
基本流
进入淘宝网、不注册、浏览物品、选择物品购买、直接购买、是会员、填写验证码、付款到支付宝、等待收货、确认收货 备选流
注册，填写注册信息，验证通过
注册，填写注册信息，验证未通过
加入购物车，直接购买
加入购物车，继续选购
不是会员，填写注册信息，验证通过
不是会员，填写注册信息，未通过验证
8.3 测试方法的选择 需要输入数据的地方，考虑使用等价类划分法，将无限测试变成有限测试
任何情况下都必须采用边界值分析法
关注程序的主要功能、业务流程和业务逻辑是否正确实现，考虑使用场景法
如果含有输入条件的组合情况，考虑因果图判定表
采用错误推断法再追加测试用例
8.4 测试用例的编写 测试用例的粒度
掌握好用例复杂和简单的程度。
过于简单失去测试用例意义，过于复杂会降低效率、增加维护成本
测试用例的作用
指导测试的实施、规划测试数据的准备、编写测试脚本的“设计规格说明书”、测试结果的度量基准、分析缺陷的标准
测试用例编写步骤
1.步骤：划分功能模块→正向功能验证→单个功能项验证→功能之间交互验证→隐形需求
2.数据约束：数据长度验证、数据类型验证、是否必填验证、限制约束验证
3.面试测试用例设计思路：需求分析、界面、功能、易用性、兼容性、性能、安全性
9. 测试策略概念 在特定环境约束下，描述软件开发周期中关于测试原则、方法、方式的纲要，并阐述了它们之间如何配合，以高效地减少缺陷、提升质量。测试策略关注重点：
测试的目的
测试可能存在的风险
测试对象和范围
如何安排测试活动
如何评价测试效果
BUG 定位方法
1、常见 BUG 分类
功能：业务流程是否正确
性能：业务流程是否顺畅
安全：是否符合安全标准与规范
专项质量：用户体验 UX 兼容性 稳定性 可靠性
2、BUG 定位能力
明确bug问题的现象与复现步骤
分层分析关键过程的数据与问题特征
积累bug特征与问题根源特性，丰富测试经验，提高发现 bug 能力
10. 测试环境搭建 被测系统AUT
1、常见被测系统类型：UI、service、code
2、部署方法
打包部署：apk、app、ipa、jar、war
脚本部署：自动化脚本与自动化平台
容器部署：基于容器镜像 docker k8s（自动化构建-bash 容器构建-docker 容器编排-k8s 持续集成-jenkins）</content></entry><entry><title>安全测试 - 记录一个验证码暴力破解的案例</title><url>/tech/%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95/%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E9%AA%8C%E8%AF%81%E7%A0%81%E6%9A%B4%E5%8A%9B%E7%A0%B4%E8%A7%A3%E7%9A%84%E6%A1%88%E4%BE%8B/</url><categories><category>安全测试</category></categories><tags><tag>安全测试</tag></tags><content type="html">记录一个验证码暴力破解的案例。
背景 某公司接到用户反馈，应用存在安全漏洞，通过技术手段可以在无手机情况下，获取验证码，直接修改密码成功。如果用户密码被他人修改成功，直接涉及到资产损失问题，无疑是一个非常严重的漏洞。
通过跟用户交流，他是通过暴力撞库的手段，去匹配正确验证码，由于后端服务没有做请求次数限制，所以可多次试错，通过程序不断发送请求，很容易就得到正确的验证码，从而修改用户密码。这也是测试容易疏漏的地方。
回过头，看看正常的密码重置流程：
进入用户手机号登录页面 点击「忘记密码」 ，输入手机号 接收四位数验证码，填写验证码 后端对验证码进行校验 校验通过后，设置新密码 使用新密码登录账号 漏洞复现 先去注册账号，如果手机号已存在，会提示当前用户已经注册，通过随机生成手机号的方式，去测试是否注册过当前应用，如果已注册，就进入忘记密码页面，通过手机号验证码方式找回账号。
忘记密码页面，输入上面的手机号，点击发送验证码后，后端会下发验证码到该手机号上，这个验证码现在只有两个人知道：
手机号主本人 后端服务 当然是不可能直接打电话给号主本人要验证码的，所以从后端服务下手。
随便输入四位数验证码，点击重置密码，会发送校验验证码的接口，请求内附带上客户端输入的验证码，抓包该请求，通过人为构造验证码的方式，进行撞库，直到成功。
由于验证码是四位数字，所以范围锁定在 0000～9999 内，不断请求，消耗数字就可以了，直到响应内返回成功的状态及 token 字符串。
将 token 字符串、新密码、手机号作为参数传递给更改密码的接口，请求成功后，密码修改成功。
问题分析
1、接口验证码参数为什么没有加密？
这个验证码参数其实是做了加密处理，但是由于在非常老的历史版本上，使用明文传输，为了兼容，所以在低版本的请求上，通过明文传参后端是正常接收并处理的。
2、验证码校验接口，次数没有限制？
这才是根本原因，用户账号是非常重要和基础的业务，后端在更改密码的接口上没有次数限制和风控，应该在试错 N 次后，直接取消本次验证码校验，直接认为失败。
该问题属于安全范畴，日常工作根本不会去注意。这也反映出测试同学在日常工作中，需要通过各种复杂的业务问题，来提高预知风险的能力，丰富项目测试的经验，这才是真正的工作经验。
我认为上述是一个比较好的案例，分享给大家，共同学习。
另外，安利一个好用的接口测试工具 &amp;ndash; burp suite。</content></entry><entry><title>Database - 数据库基础</title><url>/tech/database/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80/</url><categories><category>Database</category></categories><tags><tag>Database</tag></tags><content type="html"><![CDATA[@ TOC 
一、登录数据库服务器 登录方式
 远程连接（ssh） 本地服务器（本地搭建）  我这里通过本地 docker 的方式，启动数据库服务，登录命令：
$ docker exec -it mysql /bin/bash 查看数据库版本信息
$ mysql --version $ mysql -V 登录数据库
$ mysql -h localhost -u root -p # -h：指连接的主机名 # -u：用户名 # -p：密码 # 然后输入密码，进入数据库 查看数据库版本
mysql&gt; SELECT VERSION(); 正常会出现数据库的版本号，环境准备完成！
二、语法规范 开始数据库操作之前， 先了解一下基本的 SQL 规范：
 命令不区分大小写，建议 关键字大写； 命令中间用逗号分隔，以 分号 结尾； 命令根据需要可缩进或换行； 注释方法  # 单行注释 -- 单行注释  /* 多行 注释 */ 三、数据库操作 创建数据库
mysql&gt; CREATE DATABASE [数据库名]; # 还可以使用条件判断语句，当数据库不存在才创建 mysql&gt; CREATE DATABASE if not exists demo; 查看当前所有数据库
mysql&gt; SHOW DATABASES; 打开指定库
mysql&gt; USE &lt;数据库名&gt;; 查看当前库的所有表
mysql&gt; SHOW TABLES; 查看其他库的所有表
mysql&gt; SHOW TABLES FROM &lt;数据库名&gt;; 删除数据库
mysql&gt; DROP DATABASE &lt;数据库名&gt;; # 还可以使用条件判断语句，当数据库存在才进行删除命令 mysql&gt; DROP DATABASE IF EXISTS &lt;数据库名&gt;; 四、表操作 创建表
mysql&gt; CREATE TABLE 表名 ( 属性名 数据类型 [完整约束条件], 属性名 数据类型 [完整约束条件], ... ... 属性名 数据类型 [完整约束条件] ); 上面创建表的时候涉及到一个完整性约束条件，如下表：
   约束条件 说明     PRIMARY KEY 标识该属性为该表的主键，可以唯一的标识对应的元组   FOREIGN KEY 标识该属性为该表的外键，是与之联系某表的主键   NOT NULL 标识该属性不能为空   UNIQUE 标识该属性的值是唯一的   AUTO_INCREMENT 标识该属性的值是自动增加，MySQL 语句的特色   DEFAULT 为该属性设置默认值    示例：
# 创建学生表 mysql&gt; CREATE TABLE student( sid INT PRIMARY KEY AUTO_INCREMENT UNIQUE, sname varchar(20) NOT NULL, sage INT NOT NULL, sgender varchar(2) NOT NULL DEFAULT &#39;男&#39; )charset=&#39;utf8&#39;; Query OK, 0 rows affected (0.01 sec) 查看表结构
mysql&gt; DESC &lt;表名&gt;; mysql&gt; DESCRIBE &lt;表名&gt;; 复制表
# 方法一 mysql&gt; CREATE TABLE &lt;new_table_name&gt; LIKE &lt;old_table_name&gt;; # 方法二 2=1、1=0、1&lt;&gt;1 表示恒假，只为了获取表结构使用 mysql&gt; CREATE TABLE &lt;new_table_name&gt; AS (SELECT * FROM &lt;old_table_name&gt; WHERE 2=1); # eg. mysql&gt; CREATE TABLE student_1 LIKE student; # 1&lt;&gt;1 表示 1 不等于 1，也是恒假 mysql&gt; CREATE TABLE student_1 AS (SELECT * FROM student WHERE 1&lt;&gt;1); 修改表名
mysql&gt; ALTER TABLE [旧表名] RENAME [新表名]; # eg. mysql&gt; ALTER TABLE student RENAME new_student; 删除表
mysql&gt; DROP TABLE [表名]; mysql&gt; DROP TABLE [表名1], [表名2]; 删除被关联的父表：
 方法 1 : 先删除子表，再删除父表； 方法 2 : 删除父表的外键约束，再删除该表。  增加列
mysql&gt; ALTER TABLE [表名] ADD COLUMN [新增字段名] [数据类型] [完整性约束条件] [FIRST | AFTER [已有字段名]]; # FIRST：为可选参数，作用是将新增字段设置为表的第一个字段 # AFTER：作用是将新增字段添加到“已有字段名”后面 # eg. mysql&gt; ALTER TABLE student ADD COLUMN age INT(3) NOT NULL FIRST; mysql&gt; ALTER TABLE student ADD COLUMN age INT(3) NOT NULL AFTER id; 删除列
mysql&gt; ALTER TABLE [表名] DROP [属性名]; # eg. mysql&gt; ALTER TABLE student DROP name; 修改列名
mysql&gt; ALTER TABLE [表名] CHANGE [旧属性名] [新属性名] [新数据类型]; # eg mysql&gt; ALTER TABLE student CHANGE name new_name varchar(20); 修改列数据类型
mysql&gt; ALTER TABLE [表名] MODIFY [属性名] [数据类型]; # eg. mysql&gt; ALTER TABLE student MODIFY name varchar(30); 五、数据操作 增 插入数据/新增数据
mysql&gt; INSERT INTO [表名] (field1, field2, field3) VALUES (value1, value2, value3); # eg. 插入测试数据 mysql&gt; INSERT INTO student (sname, sage, sgender) VALUES (&#39;周杰伦&#39;, 20, &#39;男&#39;); mysql&gt; INSERT INTO student (sname, sage, sgender) VALUES (&#39;高圆圆&#39;, 18, &#39;女&#39;); 查 1. 列数据查询 查询指定列数据
mysql&gt; SELECT sname FROM student; mysql&gt; SELECT sname, sgender FROM student; 查询所有列数据
mysql&gt; SELECT * FROM student; # 如果数据量过大，使用 `*` 通配符，会降低检索和应用程序的性能 使用完全限定的表名
# 表关系如下：school 数据库中存在表 student，student 表中存在 sname 列 mysql&gt; SELECT sname FROM student;　mysql&gt; SELECT student.sname FROM student; mysql&gt; SELECT student.sname FROM school.student; # 其实这三条语句是等同的，这就是完全限定名的语法，在一些特定的情景中使用。 2. 关键字 DISTINCT - 查询数据按列去重 # 按性别查询，默认查询全部符合的结果 mysql&gt; SELECT sgender FROM student; 男 男 女 女 ... # 使用 DISTINCT 按性别去重，因为只有男或女，所以查询结果仅为两个 mysql&gt; SELECT DISTINCT sgender FROM student; 男 女 DISTINCT 关键字可添加多列，当添加多列时，仅去重多列数据同时重复，某一列没有重复，剩余列重复也不会被去重；那么，如果为检索的列为 * 的话，所有行都将被检索出来。
3. 关键字 LIMIT - 限制结果 检索返回数据的前 5 行
# 查询 student 表中返回数据的前 5 行 mysql&gt; SELECT * FROM student LIMIT 5; 检索返回数据的行数区间
# 查询学生表中 从第 5 行开始，后面 5 行的数据 mysql&gt; SELECT * FROM student LIMIT 5, 5; 第一个数为开始位置，第二个数为要检索的行数，检索出来的第一行为 行 0，而不是行 1，因此，LIMIT 1,1 将检索出第二行，而不是第一行。
行数不够时，只返回它能返回的行数。例如：LIMIT 10，5 在只有 12 条数据的情况下只返回 2 条数据。
MYSQL 5 还有一种用法：OFFSET
# 查询学生表中 从第 3 行开始，后面 5 行的数据 mysql&gt; SELECT * FROM student LIMIT 5 OFFSET 3; 4. 关键字 ORDER BY - 检索数据排序  关系数据库设计理论认为：如果不明确规定排序顺序，则不应该假定检索出的数据的顺序有意义。 按单列排序
 # 按照姓名排序(A-Z) mysql&gt; SELECT sname FROM student ORDER BY sname; 按多列排序
# 首先按照年龄排序，然后再按照姓名排序 mysql&gt; SELECT sname, sage FROM student ORDER BY sage, sname; 这里需要注意，如果第一个排序列中的值都是唯一，则不会按照第二个排序列去排序。
降序排序 - DESC
# 按照姓名排序（Z-A） mysql&gt; SELECT sname FROM student ORDER BY sname DESC; # 按照年龄倒叙排列，姓名依然正序排列 # 得出结果是大龄在前 mysql&gt; SELECT sname, sage FROM student ORDER BY sage DESC, sname; 如果需要对多个列进行降序排列，必须对每个列指定 DESC 关键字。
正序排列 - ASC
升序排序时可以指定关键字 ASC，但实际上，很少会使用，因为默认就是升序排序。
5. 组合使用：ORDER BY + LIMIT # 如何找出年龄最大的同学 mysql&gt; SELECT * FROM student ORDER BY sage DESC LIMIT 1; 6. WHERE 语句 - 过滤数据 使用 WHERE 子句
数据根据 WHERE 子句指定的搜索条件进行过滤，WHERE 子句在 FROM 子句之后，
# 查找姓名为周杰伦的同学的所有信息 mysql&gt; SELECT * FROM student WHERE sname = &#34;周杰伦&#34;; WHERE 子句操作符
   操作符 说明     = 等于   &lt;&gt; 不等于   != 不等于   &lt; 小于   &lt;= 小于等于   &gt; 大于   &gt;= 大于等于   BETWEEN 在指定两个值之间    在使用BETWEEN时，必须指定两个值——所需范围的低端值和高端值，这两个值必须用AND关键字分隔。BETWEEN匹配范围中所有的值，包括指定的开始值和结束值。举例如下：
# 检索年龄小于 19 的所有同学的信息 mysql&gt; SELECT * FROM student WHERE sage &lt; 19; # 检索年龄不等于 15 的所有同学的信息 mysql&gt; SELECT * FROM student WHERE sage &lt;&gt; 15; SELECT * FROM student WHERE sage != 15; # 检索年龄在 19-20 区间的所有同学的信息(包含 19 和 20) mysql&gt; SELECT * FROM student WHERE sage BETWEEN 19 AND 20; 空值检查
# 添加一项电话列 mysql&gt; ALTER TABLE student ADD COLUMN sphone varchar(20) AFTER sgender; # 查找所有电话为空的学生信息 mysql&gt; SELECT * FROM student WHERE sphone IS NULL; 7. 聚集函数   AVG()：计算某列平均值，忽略值为 null 的行
  SUM()：计算某列值之和，忽略值为 null 的行
  MAX()：返回某列最大值，忽略值为 null 的行
  MIN()：返回某列最小值，忽略值为 null 的行
  COUNT()：对所有行计数，忽略值为 null 的行
  mysql&gt; SELECT AVG(sage) FROM student; # 19.0000 mysql&gt; SELECT SUM(sage) FROM student; # 133 mysql&gt; SELECT MAX(sage) FROM student; # 20 mysql&gt; SELECT MIN(sage) FROM student; # 18 mysql&gt; SELECT COUNT(sname) FROM student WHERE sname = &#39;高圆圆&#39;; # 2 删 删除所有数据
mysql&gt; DELETE FROM &lt;表名&gt;; 删除单个数据
mysql&gt; DELETE FROM student [WHERE 子句] [ORDER BY 子句] [LIMIT 子句] 改 修改整列数据
mysql&gt; UPDATE student SET sphone=123; 按条件修改单条数据
# 修改年龄最大的 名为高圆圆的学生 电话号码 mysql&gt; UPDATE student SET sphone=1234567 WHERE sname=&#39;高圆圆&#39; ORDER BY sage DESC LIMIT 1; 六、多表查询 交叉连接 # 学生表和课程表 # 课程表包含 id 和 科目名称两个列 # 写法一；官方建议写法 mysql&gt; SELECT * FROM student CROSS JOIN course; # 写法二 mysql&gt; SELECT * FROM studen, course; 交叉连接返回结果为两表的笛卡尔积，当数据量庞大时，返回结果也非常大。应该尽量避改这种查询。
多表按条件交叉连接
# 可以添加 WHERE 子句; 查询两个表中学生的课程 ID 相等的数据 mysql&gt; SELECT * FROM student CROSS JOIN course WHERE student.course_id = course.id; 交叉连接使用 WHERE 语句，会先生成两个表的笛卡尔积，然后再筛选满足条件的记录。
因此，表的数量越多，交叉连接会越慢。一般情况下不建议使用交叉连接。
内连接 两个表用 INNER JOIN 连接，条件子句用 ON 连接
# 查询学生对应的课程名称 mysql&gt; SELECT s.sname, c.cname FROM student s INNER JOIN course c ON s.course_id = c.cid; 外连接 左外连接
mysql&gt; SELECT s.sname, c.cname FROM student s LEFT JOIN course c on s.course_id = c.cid; 根据表 1 的返回记录来展示结果，如果表 1 的数据在表 2 中没有结果，那么显示为 NULL
右外连接
mysql&gt; SELECT s.sname, c.cname FROM student s RIGHT JOIN course c on s.course_id = c.cid; 同左外连接原理，显示右表的全部记录。
 使用外连接查询时，根据需要是否显示那边的全部记录，来选择是用左连接还是右连接。
 子查询 条件语句嵌套，套娃需要根据实际的题来进行练习。
]]></content></entry><entry><title>Jenkins - K8S</title><url>/tech/jenkins/k8s-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[K8s 一切皆资源
 pod service deployment &hellip;  集群部署工具：kubeadm（官方）
参考链接：https://www.kubernetes.org.cn/7189.html
 kubectl -&gt; 运行命令，操控集群 kubelet -&gt; 与集群通信、鉴权、认证等等，一般在 kubeadm 内自动安装 kubeadm -&gt; 部署工具  机器低于两核会直接报错，部署不起来。
kubectl $ kubectl 动作(get/describe/delete) 资源(pod/deployment/svc) -n 名称空间(不加就跟默认) # 获取命名空间，默认是 defaule $ kubectl get namespace $ kubectl get ns # 查看日志 $ kubectl log -f # 登录到容器内 # kubectl exec -it {name} bash # 创建 # create 如果存在该配置文件会报错，需要先删除再创建 $ kubectl create -f {config 配置文件} # apply 不需要删除，直接更新，推荐使用 $ kubectl apply -f {config 配置文件} ]]></content></entry><entry><title>Docker - 搭建Gitlab</title><url>/tech/docker/%E6%90%AD%E5%BB%BAgitlab/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ docker 部署 Gitlab
 拉取镜像 $ docker pull gitlab/gitlab-ce:latest 启动容器 #!/bin/bash  NAME=gitlab VOLUMES=/data1/docker/gitlab/volumes HOST=`ifconfig eth1 | grep &#39;inet&#39; | awk &#39;{print $2}&#39;` if [[ -n $(docker ps -a -q -f &#34;name=^$NAME$&#34;) ]]; then docker rm -f $NAME; fi docker run -d --name $NAME \  --hostname $HOST \  --publish 4433:443 \  --publish 8880:80 \  --publish 222:22 \  --restart always \  -v $VOLUMES/config:/etc/gitlab \  -v $VOLUMES/logs:/var/log/gitlab \  -v $VOLUMES/data:/var/opt/gitlab \  gitlab/gitlab-ce:latest 启动后，初始化非常慢，耐心等待
$ docker logs -f gitlab ... 查看初始化登录密码
$ docker exec -it gitlab bash $ cat /etc/gitlab/initial_root_password Password: GVmOPy613BipQ38T5xdEpjS/Q/yWCgnHq7KQJJyhHpI= # 重置初始化密码 $ gitlab-rails console Loading production environment (Rails 6.1.4.1) irb(main):001:0&gt; user=User.where(id:1).first =&gt; #&lt;User id:1 @root&gt; irb(main):002:0&gt; user.password=&#39;12345678&#39; =&gt; &#34;12345678&#34; irb(main):003:0&gt; user.password_confirmation=&#39;12345678&#39; =&gt; &#34;12345678&#34; irb(main):007:0&gt; user.save =&gt; true gitlab 创建新项目 New project -&gt; Create blank project
 设置项目名称 公开访问  创建成功后，根据提示初始化代码目录
$ git init $ git clone http://10.26.20.117:8880/root/tmp.git Cloning into &#39;tmp&#39;... warning: You appear to have cloned an empty repository. 删除项目 仓库 -&gt; Settings -&gt; General -&gt; Advanced -&gt; Expand -&gt; Delete project
与 Jenkins 打通 Jenkins 需要下载 gitlab 插件；
Dashboard -&gt; Manage jenkins -&gt; Configure System -&gt; Gitlab，进行配置：
1、配置名称：自定义
2、Gitlab host URL：gitlab 的访问地址
3、credentials：全局凭证
  在 gitlab 生成 token 填入，gitlab token 生成：gitlab -&gt; 用户头像 -&gt; edit profile -&gt; Access Token -&gt; 填写 token 名称、日期、权限 -&gt; 创建
  添加认证 -&gt; kind（GitLab API token）-&gt; 填入 API token
  4、保存配置
5、项目配置内，构建触发器选择 gitlab webhooks
6、gitlab 进入项目内，Settings -&gt; Webhooks -&gt; 填写上面 Jenkins 构建触发器上面显示的地址
通过 Push events可以精确的控制触发分支名称，支持正则。
Jenkins 和 gitlab 一直链接不上！  通过指定容器网络，网络可以互相 ping 通  mysql 启动脚本
]]></content></entry><entry><title>Jenkins - Jenkins Apk Build</title><url>/tech/jenkins/%E5%AE%89%E5%8D%93%E6%89%93%E5%8C%85%E6%B5%81%E7%A8%8B%E5%AE%9E%E6%88%98/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[测试 APP 构建、打包过程 准备 安卓源码
# https://github.com/princeqjzh/AndroidSampleApp.git $ git clone git@github.com:princeqjzh/AndroidSampleApp.git 安卓打包命令
# clean 清空 build 目录下的构建文件 # assemble 打包；比如 assembleRealese 或者渠道包 $ gradlew clean assembleDebug # APK 输出路径 # /app/build/outputs/apk/debug/app-debug.apk 打包环境要求
 JDK Android SDK Gradle  编译完成后安装包
$ adb install app-debug.apk Success 总结 配置 job 1 用于构建 APP；
配置 job 2 用于构建 自动化测试（子节点 - 模拟器运行）；
父子关联（job 1 添加稳定构建后执行 job 2）
遇到的报错 # 执行编译命令时出现报错 Required by: project : &gt; Could not resolve com.android.tools.build:gradle:3.4.1. &gt; Could not get resource &#39;https://dl.google.com/dl/android/maven2/com/android/tools/build/gradle/3.4.1/gradle-3.4.1.pom&#39;. &gt; Could not GET &#39;https://dl.google.com/dl/android/maven2/com/android/tools/build/gradle/3.4.1/gradle-3.4.1.pom&#39;. &gt; Connect to dl.google.com:443 [dl.google.com/203.208.43.97] failed: Read timed out 显示无法请求 dl.google.com，本地 ping 这个域名网络链接是正常的呀，不知道什么原因。
一顿折腾都没用，就在要放弃的时候，再次执行了一下，好了。。。
BUILD SUCCESSFUL in 1m 37s
]]></content></entry><entry><title>Jenkins - Jenkins 接口压力实战</title><url>/tech/jenkins/%E6%8E%A5%E5%8F%A3%E5%8E%8B%E5%8A%9B%E5%AE%9E%E6%88%98jmx/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[接口压力测试实战，集成到 jenkins 项目。
创建一个自由风格的新项目。
配置 git 项目上拉取代码，git 不稳定，直接拷贝项目到 workspace/weather_stress 目录下
配置 build -&gt; execute shell
$ cd iInterface_python/jmx $ sh auto_stress_test.sh 下载 Groovy Postbuild 插件，目的是解除 jenkins 对于 js 渲染的限制。Groovy Script 添加如下代码。
System.setProperty(&#34;hudson.model.DirectoryBrowserSupport.CSP&#34;,&#34;&#34;) 增加 publish html report 用于展示报告，增加三个，分别对应 10、20、30
 安装 jmeter 环境 $ cd iInterface_python/jmx $ sh auto_stress_test.sh auto_stress_test.sh: 15: auto_stress_test.sh: Syntax error: &#34;(&#34; unexpected # 出现报错 # 代码对于标准bash而言没有错，Debian为了加快开机速度，用dash代替了传统的bash $ sudo dpkg-reconfigure dash # 输入 n，继续运行 # 安装 jmeter # $ wget https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.4.1.tgz # 下载的太慢了，直接从宿主机拷贝过去 $ docker cp Downloads/jmeter-5.3.zip jenkins:/opt $ cd /opt &amp;&amp; unzip jmeter-5.3.zip # 修改 auto_stess_test.sh # 需要在系统变量中定义jmeter根目录的位置，如下 # export jmeter_path=&#34;/your jmeter path/&#34; # 放开上面的注释 export jmeter_path=&#34;/opt/jmeter-5.3/&#34; 构建，即可搞定。
接口性能参考标准（百分之90，参考，十几年前的标准）：
 2秒：良好 8秒：可忍受 12秒：不可忍受  吞吐量
 随着流量增大，TPS 会显著增大，继续增加流量，TPS 会呈现下滑趋势，这个拐点就是性能瓶颈。 可以根据每天的访问量去换算（TPS 12 的话，大概一天可以承受一百万的访问量）  也需要监控 server 物理的值，比如 CPU、内存、网络等等。
]]></content></entry><entry><title>Jenkins - Jenkins 接口功能实战</title><url>/tech/jenkins/%E6%8E%A5%E5%8F%A3%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%9E%E6%88%98pytest-allure/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[接口功能自动化测试项目集成到 jenkins 实战。
安装 python 在 jenkins 容器内安装 python 执行环境
$ docker exec -it -u root jenkins /bin/bash $ cat /etc/issue Debian GNU/Linux 1 # 根据 debian 版本更新下载源 # https://blog.csdn.net/lan_yangbi/article/details/86720257 $ apt-get update # 下载安装包 $ apt-get install wget $ wget https://www.python.org/ftp/python/3.6.8/Python-3.6.8.tgz $ tar -zxvf Python-3.6.8.tgz # 编译安装 $ cd Python-3.6.8 $ ./configure --prefix=/opt/python3 --with-ssl $ apt-get -y install gcc automake autoconf libtool make $ apt-get -y install make* $ apt-get -y install zlib* $ apt-get -y install openssl libssl-dev $ apt-get install sudo $ make &amp;&amp; make install # 软链 $ ln -s /opt/python3/bin/python3.6 /usr/bin/python $ ln -s /opt/python3/bin/pip3 /usr/bin/pip 配置从 git 拉取项目 在 Source Code Management 内选择 Git，添加仓库地址；
# 仓库地址 $ https://github.com/princeqjzh/iInterface_python.git 在 Additional Behaviours 内增加 check out to a sub-directory，目的是在工作目录创建一个项目地址
构建命令 在 Bulid 内添加 Execute shell，写入构建要执行的命令
$ cd iInterface_python $ sudo pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple $ python -m pytest -sv test/weather_test.py 由于执行命令的是 jenkins 用户，无法执行 sudo 命令，这里还需要设置一下 jenkins 用户免密使用 sudo。
# root 用户 $ sudo vi /etc/sudoers $ echo &#39;jenkins ALL=(ALL) NOPASSWD:ALL&#39; &gt;&gt; /etc/sudoers 直接运行 pytest 会提示：bash: pytest: command not found
因为系统存在默认的 python2 和 pip2 版本，所以
配置 allure 报告 容器环境内安装 allure commandline $ cd /opt/python3 $ wget https://registry.npmjs.org/allure-commandline/-/allure-commandline-2.13.0.tgz $ mkdir allure $ tar -zxvf allure-commandline-2.13.0.tgz -C ./allure/ # 软链 $ find / -name allure /opt/python3/allure # 自己创建的目录 /opt/python3/allure/package/bin/allure /opt/python3/allure/package/dist/bin/allure # 软链这个 $ ln -s /opt/python3/allure/package/dist/bin/allure /usr/bin/allure $ allure --version 2.13.0 jenkins 安装 allure 插件 在 插件市场进行下载安装： Allure Jenkins Plugin  
step 1：在项目构建后添加步骤 Post-build Actions - Allure Report
step 2：添加 allure 到 jenkins 的全局环境变量内，这里直接添加 allure/package/bin目录下的allure 会报找不到node 的错误，换成dist/bin 目录下的就可以成功运行，所以在环境变量这里填写 dist 目录。
上面软链成 dist 目录也是因为这个原因。
step 3：还需要修改一下 execute shell 内的 pytest 命令
# 添加 allure 报告地址，必须与上面配置的 path 一致 $ python -m pytest -sv test/weather_test.py --alluredir ./allure-results 构建项目 进行构建项目，即可看到 allure 报告展示。
]]></content></entry><entry><title>Jenkins - Jenkins 基础</title><url>/tech/jenkins/%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0/</url><categories><category>Jenkins</category></categories><tags><tag>Jenkins</tag></tags><content type="html"><![CDATA[持续集成测试流程记录。
 jenkins_pipeline_快速入门 38  
 jenkins_pipeline_语法详解 19  
 jenkins_pipeline_Sharedlib 8  
 jenkins_pipeline与k8s集成 8  
 jenkins_pipeline_jenkins集成k8s的原理和配置总结 8  
 jenkins_pipeline_多分支pipeline 10  
jenkins 搭建 # 创建或者映射 docker 文件映射卷；二选一 $ docker volume create jenkins # 创建新的映射卷 $ docker volume inspect jenkins # 本地文件映射 # 创建容器;lts 长期维护版本，稳定版本 $ docker run -d --name jenkins -p 8080:8080 -p 5000:5000 -v {本地目录}/jenkins:/var/jenkins_home jenkins/jenkins:lts # 获得管理员密码 $ docker exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword 插件 可以先配置代理，然后再下载插件。
 email extension email extension template blue ocean  job 管理 修改系统配置 默认shell：bash
默认邮箱：邮箱地址与账户
默认地址：服务器域名
安全：设置安全制度
时区：时区修改
插件：设置代理、安装插件、更新插件
节点管理   jenkins 的任务可以分布在不同的节点上运行
  节点上需要配置 java 运行环境：Java version &gt; 1.5
  节点支持 windows、linux、mac
  jenkins 运行的主机在逻辑上是 master 节点
  设置：Manage Jenkins &ndash;&gt; System configuration &ndash;&gt; mange Nodes and Clouds &ndash;&gt; New Node
节点连接方式：
 8080 端口：jenkins 服务器对外 URL 地址 50000 端口：slave 节点与 Jenkins 的通讯端口  用户权限控制  初始化过程会先注册一个管理员用户 管理员用户登录后再创建后续的一般用户 启用用户安全配置：Manage Jenkins &ndash;&gt; Configure Global Security  报警机制 # 模版配置 # 通过 Jenkins 的参数定制自己的 Email 模版 # 常用的 key 值 $BUILD_STATUS:构建结果 $PROJECT_NAME:构建脚本名称 $BUILD_NUMBER:构建脚本编号 $JOB_DESCRIPTION:构建项目描述 $CAUSE:脚本启动原因 $BUILD_URL:脚本构建详情URL地址 用户在 jenkins 构建任何之后发送 email 通知
 需要下载插件：Email Extension、Email Extension Template 配置邮件发送规则 配置邮件模版  在系统设置内，设置管理员邮箱地址。
 https://blog.csdn.net/weixin_35688430/article/details/119599712  
定时构建 在 Jenkins 中设置定时构建可以使用 Jenkins 的“构建触发器”功能。具体步骤如下：
进入 Jenkins 任务的配置页面。
找到“构建触发器”部分，勾选“构建周期性地触发构建”。
在“构建触发器”中输入定时构建的表达式，例如：每周一到周五晚上 8 点构建 H 20 * * 1-5
表达式中的 H 表示随机的分钟数，以避免所有任务在同一时间触发。您可以根据需要修改表达式中的参数。
保存 Jenkins 任务的配置。
父子 job 父子多任务运行，任务启动的触发条件，是其他任务的运行结果，有以下触发条件：
 前驱任务成功 前驱任务失败 前驱任务不稳定  使用场景：有先后次序关系的任务，比如：部署环境 -&gt; 验收测试任务
cli 命令行 需要本地先下载 jenkins-cli.jar
Manage Jenkins - Jenkins CLI，然后点击下载链接进行下载。
# 执行重启命令 $ java -jar jenkins-cli.jar -s http://localhost:8081/jenkins/ restart ERROR: anonymous is missing the Overall/Administer permission
# 加上 -auth 管理员账号就可以了 $ java -jar jenkins-cli.jar -s http://localhost:8081/jenkins/ -auth admin:password restart ]]></content></entry><entry><title>Docker - K8S 基础</title><url>/tech/docker/k8s-%E5%9F%BA%E7%A1%80/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[一切皆资源
 pod service deployment &hellip;  集群部署工具：kubeadm（官方）
参考链接：https://www.kubernetes.org.cn/7189.html
 kubectl -&gt; 运行命令，操控集群 kubelet -&gt; 与集群通信、鉴权、认证等等，一般在 kubeadm 内自动安装 kubeadm -&gt; 部署工具  机器低于两核会直接报错，部署不起来。
kubectl $ kubectl 动作(get/describe/delete) 资源(pod/deployment/svc) -n 名称空间(不加就跟默认) # 获取命名空间，默认是 defaule $ kubectl get namespace $ kubectl get ns # 查看日志 $ kubectl log -f # 登录到容器内 # kubectl exec -it {name} bash # 创建 # create 如果存在该配置文件会报错，需要先删除再创建 $ kubectl create -f {config 配置文件} # apply 不需要删除，直接更新，推荐使用 $ kubectl apply -f {config 配置文件} ]]></content></entry><entry><title>Docker - 搭建Yapi及使用记录</title><url>/tech/docker/%E6%90%AD%E5%BB%BAyapi%E5%8F%8A%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ YApi 是比较好用的接口管理平台，通过 docker-compose 搭建记录。
  CentOS Linux release 7.9.2009 (Core)
  Docker 20.10.8
   先编写 Dockerfile
RUN yarn &amp;&amp; yarn buildWORKDIR/yapi/vendors# 拉取 YApi 源码RUN git clone \  --branch &#34;v${YAPI_VERSION}&#34; \  --single-branch \  --depth 1 \  https://github.com/YMFE/yapi.git .# 拷贝启动脚本RUN cp /yapi/scripts/start.js ./start.js# 执行一些准备工作RUN node /yapi/scripts/prepare.js $(pwd)# 安装依赖RUN yarn# 清理文件RUN node /yapi/scripts/clean.js $(pwd)# 构建应用RUN yarn build-client# 再次清理以删除构建缓存文件RUN node /yapi/scripts/clean.js $(pwd)# 删除脚本RUN rm -rf /yapi/scripts######## 镜像 ########FROMnode:12.16.3-alpine3.11WORKDIR/yapiCOPY --from=builder /yapi .EXPOSE3000CMD [&#34;node&#34;, &#34;/yapi/vendors/start.js&#34;]&#34;Dockerfile&#34; 56L, 1092B 56,38 BotRUN yarn &amp;&amp; yarn buildWORKDIR/yapi/vendors# 拉取 YApi 源码RUN git clone \  --branch &#34;v${YAPI_VERSION}&#34; \  --single-branch \  --depth 1 \  https://github.com/YMFE/yapi.git .# 拷贝启动脚本RUN cp /yapi/scripts/start.js ./start.js# 执行一些准备工作RUN node /yapi/scripts/prepare.js $(pwd)# 安装依赖RUN yarn# 清理文件RUN node /yapi/scripts/clean.js $(pwd)# 构建应用RUN yarn build-client# 再次清理以删除构建缓存文件RUN node /yapi/scripts/clean.js $(pwd)# 删除脚本RUN rm -rf /yapi/scripts######## 镜像 ########FROMnode:12.16.3-alpine3.11WORKDIR/yapiCOPY --from=builder /yapi .EXPOSE3000CMD [&#34;node&#34;, &#34;/yapi/vendors/start.js&#34;]然后直接用 docker-compose 启动
version: &#39;3&#39; services: yapi-web: image: jayfong/yapi:latest container_name: yapi-web ports: - 4000:3000 environment: - YAPI_ADMIN_ACCOUNT=admin@joyame.com - YAPI_ADMIN_PASSWORD=admin - YAPI_CLOSE_REGISTER=true - YAPI_DB_SERVERNAME=yapi-mongo - YAPI_DB_PORT=27017 - YAPI_DB_DATABASE=yapi - YAPI_MAIL_ENABLE=false - YAPI_LDAP_LOGIN_ENABLE=false - YAPI_PLUGINS=[] depends_on: - yapi-mongo links: - yapi-mongo restart: unless-stopped yapi-mongo: image: mongo:4.4.4 container_name: yapi-mongo volumes: - ./mongo/db:/data/db expose: - 27017 restart: unless-stopped  下面是一开始搭建的时候从头到尾的记录，比较麻烦。
搭建 创建容器网络 $ docker network create --driver bridge --subnet=10.10.0.0/16 --agteway=10.10.0.1 mynet 目的是保证 mangodb 和 yapi 两个容器间可以互相通信。
# 创建工作目录并进入 $ mkdir yapi-compose &amp;&amp; cd yapi-compose 创建 mongodb-compose $ vim mongodb-compose.yml version: &#39;3&#39;services: mongodb: image: mongo:4.4.4 # 镜像名 container_name: mongodb # 容器名 volumes: # 数据挂载目录；本地目录:容器目录  - /opt/docker/mongodb:/data/db  ports: - 27017:27017 # 端口，宿主机:容器 # environment:  # - COMPOSE_PROJECT_NAME=yapi restart: always# 设置默认网络networks: default: external: name: mynet # 创建的容器网络名# ESC =&gt; :wq ==&gt; Enter创建 yapi-compose $ vim yapi-compose.yml version: &#39;3&#39;services: yapi: image: jayfong/yapi:latest # 镜像名 container_name: yapi # 容器名 privileged: true # 赋予root权限 ports: - 3000:3000 # 端口，宿主机:容器 environment: - YAPI_ADMIN_ACCOUNT=admin@easou.com # 登入账号 - YAPI_ADMIN_PASSWORD=admin # 登入密码 - YAPI_CLOSE_REGISTER=true # 关闭注册功能 - YAPI_DB_SERVERNAME=mongodb # mongodb 数据库地址 - YAPI_DB_PORT=27017 # mongodb 端口 - YAPI_DB_DATABASE=yapi # mongodb 数据库名 - YAPI_MAIL_ENABLE=false # 不启用邮箱 - YAPI_LDAP_LOGIN_ENABLE=false # 不启用 loap 登入 - YAPI_PLUGINS=[] # 插件 # - COMPOSE_PROJECT_NAME=yapi restart: always# 设置默认网络networks: default: external: name: mynet构建容器 $ docker-compose -p mongodb -f mongodb-compose.yml up -d $ docker-compose -p yapi -f yapi-compose.yml up -d 访问 浏览器输入：http://{ip}:3000
报错记录 如果遇到问题，可以通过查看日志的方式定位到问题。
$ docker logs -f {container_id} 错误 1:
MongoDB 5.0+ requires a CPU with AVX support 问题：mongo 镜像如果不指定版本，会自动下载 latest 版本（5.0+）会出现上面的报错，且容器一直是 restarting 的状态。
解决：理论安装上 5.0 以下的版本都可以，我这里使用 4.4.4 版本安装成功。
错误 2：
Error [ValidationError]: user validation failed: username: Path `username` is required. yapi-compose.yml 文件内，账号必须为邮箱格式，我刚开始图方便设置账号为 admin，一直无法登录，查看日志后发现用户名写入 db 失败，由于没有指定 emailAddress，默认使用用户名代替，报校验失败的错误。
如果成功的话，构建后，日志内会出现如下提示：
始化管理员账号成功,账号名：&#34;admin@easou.cn&#34;，密码：&#34;admin&#34; 错误 3:
$ mv mongodb-compose.yml docker-compose.yml $ docker-compose -d up $ mv docker-compose.yml mongodb-compose.yml $ mv yapi-compose.yml docker-compose.yml $ docker-compose -d up $ mv docker-compose.yml yapi-compose.yml WARNING: Found orphan containers (name1, name2) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up. 注意：刚开始我使用这种方式构建，报错后网上搜索了下，通过 -p 指定项目名称的方式解决。
后来查文档，发现 -p 通过环境变量来指定也行，理论上将 COMPOSE_PROJECT_NAME=xx 放在 conpose 文件内，应该也可以，由于服务已经部署成功，没有再测试，参数我补充在上面的 compose 文件中了，已注释。
错误 4:
Error: EACCES: permission denied, mkdir &#39;/sys/fs/cgroup/memory/safeify&#39; 无创建文件权限，需要以 root 用户启动容器，使用该参数，container内的root拥有真正的root权限，否则， container 内的 root 只是外部的一个普通用户权限。
# yapi 的 compose 内添加如下设置privileged: true# 或者启动容器时加上这个参数--privileged=true本篇文章，记录下使用过程中遇到的问题。
YAPI 安全漏洞解决方法 Yapi 使用的脚本执行沙箱存在安全漏洞问题，需要更换为更安全的沙箱 safeify。详情参考 yapi 安全漏洞详解 
也可以一并解决，断言脚本报错问题：Error: assert.equal is not a function。
// sandbox.js 脚本需要更新如下 const Safeify = require(&#39;safeify&#39;).default; module.exports = async function sandboxFn(context, script) { // 创建 safeify 实例  const safeVm = new Safeify({ timeout: 3000, asyncTimeout: 60000, // quantity: 4, //沙箱进程数量，默认同 CPU 核数  // memoryQuota: 500, //沙箱最大能使用的内存（单位 m），默认 500m  // cpuQuota: 0.5,  // true 表示不受 CPU 限制，解决 Docker 启动问题  unrestricted: true, unsafe: { modules: { // 引入assert断言库  assert: &#39;assert&#39; } } }); safeVm.preset(&#39;const assert = require(&#34;assert&#34;);&#39;); script += &#34;; return this;&#34;; // 执行动态代码  const result = await safeVm.run(script, context); // 释放资源  safeVm.destroy(); return result }; 操作步骤
# rz 命令将 sandbox.js 传入服务器 $ rz -be # 服务器上执行 cp 命令，覆盖原文件 $ docker cp sandbox.js yapi:/yapi/vendors/server/utils/sandbox.js $ docker restart yapi 单个接口调试的请求参数怎么看？ 根据提示文档安装 cross-request，开发者栏 network 处查看跨域请求。
console.log() 方法输出的日志去哪里看？ 在脚本运行界面，F12 调出开发者选项，点击 console 栏查看。
如何抽象出公共参数？ 将公共参数写到 Pre-request Script(请求参数处理脚本) 内，这样也可以实现从接口响应内获取到内容作为其他请求的参数。
// Pre-request Script // 从响应内去动态获取 session_id let session_id = localStorage.getItem(&#39;session_id&#39;); context.query[&#39;session_id&#39;] = session_id; console.log(&#34;当前 session_id 为：&#34; + session_id); // 这里可以添加公共参数 context.query[&#39;os&#39;] = &#34;android&#34;; // Pre-response Script if(context.responseData[&#39;session_id&#39;] !== undefined) { let session_id = context.responseData[&#39;session_id&#39;]; console.log(&#34;获取到session_id:&#34;+session_id); localStorage.setItem(&#39;session_id&#39;, session_id); } /*else { console.log(&#34;当前响应内没有找到 session_id.&#34;); } */ 页面UI调整 body 示例参数框内容稍长就会折行展示，备注框太长，导致页面整体拉长，不美观。
打开开发者选项调试页面，定位到表格处，发现该处引用了 word-break 属性，取消勾选后查看效果，比较满意。
  word-break  ：在恰当的断字点进行换行
 找到问题就好办了，登录容器内，找到该文件，注释掉这个属性即可。
$ docker exec -it yapi sh $ find / -name *.css | grep index@dc0427a58a38aab0505d.css $ vi /yapi/vendors/static/prd/index@dc0427a58a38aab0505d.css # vi 模式内通过 /.ant-table-thead&gt;tr&gt;th{padding:16px 10px; 搜索关键字 # 注释掉 ant-table-thead 的自动换行属性 .ant-table-thead&gt;tr&gt;th{padding:16px 10px;/*word-break:break-all;*/} # 修改后刷新页面并不能直接生效 # 原因是当前目录下还存在 index@dc0427a58a38aab0505d.css.gz 压缩文件 # 修改名字作为备份 $ mv index@dc0427a58a38aab0505d.css index@dc0427a58a38aab0505d.css_bak # 刷新页面，修改生效 # 重新压缩文件 -v 显示命令执行过程 -k 保留原文件 $ gzip -vk index@dc0427a58a38aab0505d.css References [1] yapi 安全漏洞详解:  https://blog.csdn.net/meifannao789456/article/details/119551053   [2] word-break:  https://www.w3school.com.cn/cssref/pr_word-break.asp  
]]></content></entry><entry><title>Docker - 关于Docker的问题答疑</title><url>/tech/docker/docker-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[关于 docker 的一些问题。
问题汇总 问题 1：在 selenium grid 中，多个 node 是在同一机器上，依然是在单机上执行自动化测试，如何将这些 node 分布到不同的机器上？ $ docker exec -it chrome bash $ env | grep HUB HUB_PORT_4444_TCP_ADDR=172.17.0.3 HUB_PORT_4444_TCP_PORT=4444 --link hub 的原理是将目标容器的 HUB 信息以环境变量的形式注入到容器内，如果两个容器不在同一机器上无法使用 &ndash;link 参数。
那么，在其他机器上启动容器的时候，可以通过 -e 参数，填写上面获取的 IP 地址和端口，以设置环境变量的方式传递给容器信息，即可实现多机器运行 node 节点。
问题 2：在 docker selenium 的开源镜像中，为什么不支持 IE 浏览器的镜像？ 因为容器并不虚拟化自己的内核，一台机器上所有的容器都使用宿主机的内核。
而 docker 只能安装在 linux 系统上，因为容器的底层逻辑需要 linux 内核的能力，而 IE 浏览器是使用 windows 内核驱动的，所以无法制作 IE 浏览器的镜像。
容器都是使用宿主机的内核，如果运行的软件挑内核或者内核版本，那么尽量不要用容器来运行。
windows 上之所以能运行 docker，是因为先安装了 linux 系统，然后再安装的 docker，微软已经在开发自己的 docker，但是目前还没有太多人使用。
问题 3：需要测试 toB 产品兼容不同的操作系统，比如不同版本的 centos、redhat、ubantu 等等，通过在宿主机下载这些镜像去安装软件，软件都安装成功，能不能认为测试通过？ 不能；因为容器使用的内核是宿主机的内核，比如在 ubantu 上安装 centos 镜像，运行内核依然是 ubantu，centos 镜像只是安装了一些 centos 的软件供用户使用而已，所以在容器安装成功，不能真的代表在 centos 操作系统上运行成功。
所以总结下来任何对内核有要求的场景尽量不要使用容器测试。
问题 4：现在需要排查一个容器中的网络问题，但是容器没有安装任何的网络排查工具，也无法通过网络下载工具，这个时候要怎么做？ 可以启动一个带有网络排查工具的容器，然后通过 container 网络模式将新创建的容器挂载到要排查的容器上。这样两个容器的网络就是互通的，就可以抓取到目标容器的网络流量。
还有一种方法就是不用启动新的容器，而是直接让宿主机切换到容器网络的名称空间
$ docker inspect jenkins # 查找容器 PID -&gt; 24171 # 进入该 pid 对应的地址 $ cd /proc/24171 # ns = namespace 名称空间 $ cd ns # 在宿主机上切换到容器的名称空间 # -n 代表切换 network namespace $ nsenter --help $ nsenter -t 24171 -n # 查看只有两个网络设备，代表成功切换到容器网络 $ ifconfig # 退出网络名称空间，可以看到宿主机是有多个网络设备的 $ exit 问题 5: 解释一下容器网络的运行原理（三种连接方式） 桥接模式（创建虚拟网卡） host 模式（不创建虚拟网卡，直接使用宿主机网络） 容器网络模式（打破容器间的界限，应用场景较多，很关键。） 通过 container 模式进行 mock server 原理图
通过 container 模式进行多服务日志收集上传原理图
通过 container 模式，进程共享，可以进行故障注入
sandbox 连接到容器 A 的进程内，A 进程运行的同时，sandbox 进行一些故障注入。
问题 6：dockerfile RUN 指令，执行多个命令时，下面那种方式更好一些？ ### 方式一 ###FROMcentos:7RUN yum install -y wegt vim gitRUN yum install -y wgetRUN yum install -y git### 方式二 ###FROMcentos:7RUN yum install -y wegt vim git \  &amp;&amp; yum install -y wget \  &amp;&amp; yum install -y git用两种方式分别构建镜像，查看 dockerfile 的执行过程
使用方式一构建镜像 $ docker build -t tmp . # . 代表存放 dockerfile 的目录，开始构建时，先将当前目录下的所有文件打包发送给 docker 进程 # 所以 dockerfile 独立保存在一个目录下而且该目录下不要放无关的文件 Sending build context to Docker daemon 4.608kB # 每执行安装一个命令都会重新新建一个临时容器，安装完成后会移除该中间容器 Step 3/3: yum install -y git ---&gt; Running in xxxxxx Removing intermediate container xxxxxx # 再次进行构建，会自动使用缓存，如果修改 dockerfile，哪行被修改重新执行哪行，其他行依然会使用缓存。 # 优点： # 拆分步骤后，可以复用缓存，提高效率 # 缺点： # 镜像是分层的，一个 RUN 指令就是一层，每多一层就会有一层的io性能开销，如果多个 RUN 指令会影响性能。 为什么会提升性能开销？ 解释：当前 X 目录下有 A 文件，Y 目录下有 B 文件，如果管理员需要分别对 AB 两个文件操作的话，需要切换目录，但是如果文件多的话，切换目录是非常麻烦的，所以，docker 底层是文件共享系统 overlay2，通过 docker info 可以查看；
共享文件系统 Z 里面会有 AB 两个文件，对 A 文件添加字符串 hello 后，X 目录下的 A 文件也会同步修改，就不用切换目录；
对 Z 目录的 B 文件添加字符串 world 后，Y 目录下的 B 文件不会同步修改，而是在 A 目录下面新建一个文件，记录 B 文件的修改；
这是因为 docker 文件系统只会对第一个文件开发读写权限，其他文件全部仅可读，视图文件层 Z 目录的 B 文件，其实是通过 Y 目录的 B 文件读内容 merge X 目录 B 文件的更改，展示到 Z 目录下。
那么，文件过多的话，merge 操作会增加，所以会增加系统读写开销，拖慢性能。
使用方式二再次构建镜像 # 缺点：# 使用方式二，修改 RUN 指令内的任意一个东西，都会整条命令全部重新执行，没有使用缓存。# 优点：# 节省性能开销总结： 开发 dockerfile 过程中，可以使用多个 RUN 指令的方式，这样便于调试，提高效率；
如果 dockerfile 已经开发完成，需要将 RUN 指令合并，减少层数，减少 IO 性能开销。
问题 7: 自动化测试环境搭建及使用，一种简单的模式 在 dockerfile 内定义安装 python 环境，设置启动脚本，即容器启动就会运行 entrypoint.sh 脚本
容器启动即去拉取最新代码，然后运行测试程序。
]]></content></entry><entry><title>Docker - 搭建Selenium测试环境</title><url>/tech/docker/%E6%90%AD%E5%BB%BAselenium%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[docker 实战演练，搭建测试平台。
搭建分布式 UI 自动化测试环境 自动化测试发展从刚开始的单机单线程到单机多线程再到多机分布式操作。
UI 自动化测试通过 Grid hub 分发用例到不同的节点，执行用例。
grid 负载均衡是通过查看不同节点启动的浏览器数量，如果数量多证明繁忙，会优先分发到浏览器数量少的node上
github 搜索 docker- selenium
standalone 镜像内包含 hub 和 node，一般来做调试用，不能做分布式。
启动 hub $ docker run --name=hub -p 5001:4444 -e GRID_TIMEOUT=0 -e GRID_THROW_ON_CAPABILITY_NOT_PRESENT=true -e GRID_NEW_SESSION_WAIT_TIMEOUT=-1 -e GRID_BROWSER_TIMEOUT=15000 -e GRID_TIMEOUT=30000 -e GRID_CLEAN_UP_CYCLE=30000 -d selenium/hub:3.7.1-beryllium 访问：http://localhost:5001/，得到下图中的页面。
启动 node $ docker run --name=chrome -p 5902:5900 -e NODE_MAX_INSTANCES=6 -e NODE_MAX_SESSION=6 -e NODE_REGISTER_CYCLE=5000 -e DBUS_SESSION_BUS_ADDRESS=/dev/null -v /dev/shm:/dev/shm --link hub -d selenium/node-chrome-debug:3.7.1-beryllium 由于 node 节点运行的是远程浏览器，selenium/node-chrome-debug 镜像，提供远程 debug 的功能，通过 VNC 远程桌面服务来进行查看浏览器的运行状态，所以 node 也需要映射一个端口来与 VNC 进行通信。VNC 密码是 secret。
NODE_MAX_INSTANCES、NODE_MAX_SESSION 这两个参数决定该 node 节点启动浏览器的上限，启动浏览器是非常消耗 CPU 的，如果启动过多，可能会压垮机器，需要设置上限进行保护。
-v /dev/shm:/dev/shm：这个参数是优化内存使用的，如果没有会因为内存问题容易崩溃。
&ndash;link hub：把 hub 的网络信息发送给 node 节点，将 hub 链接到容器上
访问：http://localhost:5001/，点击 console，跳转到下图页面。
通过该命令可以启动多个 node，注意更换下名称和端口号即可，刷新当前页面，会看到有多个节点。
node 也可以启动不同的浏览器，用来做浏览器的兼容性测试。
演示 环境已经搭建完成了， 那么接下来通过代码来看看实际效果。
# demo.py import selenium.webdriver.remote.webdriver from selenium.webdriver.common.desired_capabilities import DesiredCapabilities from time import sleep def test_baidu_search(): driver = selenium.webdriver.remote.webdriver.WebDriver( command_executor=&#34;http://127.0.0.1:5001/wd/hub&#34;, desired_capabilities=DesiredCapabilities.CHROME ) driver.get(&#34;http://www.baidu.com&#34;) driver.find_element_by_id(&#34;kw&#34;).send_keys(&#34;python&#34;) driver.find_element_by_id(&#34;su&#34;).click() sleep(2) driver.quit() 通过 remote 将远程地址修改为 hub 的地址，由于是本地服务，所以只需要修改一下端口即可。
运行测试用例，发现执行通过，由于是运行在容器内，本地是看不到浏览器窗口的，还需要通过 VNC Viewer 来查看远程浏览器。
 VNC Viewer
官网下载：https://www.realvnc.com/en/connect/download/viewer/
打开应用后，command + N 新建远程链接，填写远程 IP 和端口，名称随意。
 server 处输入 {本机IP}:5902，连接上面的 node-chrome-debug，密码为 secret；
链接成功后，执行测试用例，即可看到浏览器被拉起，搜索关键词 python 后点击搜索。
搭建镜像仓库 $ docker pull registry:2 $ docker run -d -p 5000:5000 -v /usr/local/registry:/var/lib/registry --restart=always --name registry registry:2 # --restart=always 代表容器万一挂掉，docker 会永远重启容器 # DEMO # 先下载一个小镜像 $ docker pull busybox # 上传镜像前需要更新名字，命名规范 ==&gt; IP地址:端口号/名称:版本号； # 上面 pull busybox，其实应该是 library/busybox:latest # library 是docker默认仓库地址，版本号不写默认是latest，代表最新版本 $ docker tag busybox localhost:5000/busybox:v1.0 $ docker push localhost:5000/busybox:v1.0 # 通过命令查看镜像仓库 $ curl http://localhost:5000/v2/_catalog # 从一个运行的容器制作镜像 $ docker commit registry localhost:5000/myimage:v1.0 $ docker images | grep myimage $ docker push localhost:5000/myimage:v1.0 $ curl http://localhost:5000/v2/_catalog # 这种方法不推荐，别人拿到这个镜像，如果要做一些扩展，不知道安装了什么软件、设置权限、配置等等 # 为了解决上面的问题，推荐使用 dockerfile # 将制作镜像的过程脚本化 ]]></content></entry><entry><title>Selenium - 分布式执行Seleniumgrid</title><url>/tech/selenium/%E5%88%86%E5%B8%83%E5%BC%8F%E6%89%A7%E8%A1%8Cseleniumgrid/</url><categories><category>Selenium</category></categories><tags><tag>Selenium</tag></tags><content type="html"><![CDATA[  Selenium Grid  : 将客户端发送的命令转发到远程浏览器上执行 WebDriver 脚本。
 简介 Selenium Grid 是由一个 hub 服务和若干个 node 代理节点组成。
Hub 调度服务，管理各个代理节点的注册信息和状态信息，并且接收来自客户端代码的调用请求，把请求的命令转发给代理节点执行。
Node 代理节点，相当于一台可以运行浏览器自动化测试的机器，根据 hub 的命令执行脚本。
 支持在多台机器上并行测试 支持在不同的浏览器版本上进行测试 支持跨平台测试  执行流程
 运行代码初始化 driver 时，配置远程浏览器为 hub 服务 + 端口； 服务端收到代码请求后转为执行命令，分发给不同的 node（浏览器）； node 根据收到的命令执行测试； 测试完成后返回结果给 hub； hub 收集结果返回给客户端。  搭建 整套环境搭建可以通过两种方式：
 *.jar（太麻烦且不易维护） docker（官方镜像支持，即插即用）  Docker 简单好用，由于要启动多个服务，这里使用工具 docker-compose 进行部署。
编写配置文件 新建目录下创建配置文件 compose.yml，用来定义初始化容器的配置。
# ref: https://github.com/SeleniumHQ/docker-selenium version: &#34;3&#34; services: chrome: image: selenium/node-chrome:4.6.0-20221104 shm_size: 2gb  # 设置共享内存，官方建议值，避免浏览器引起容器崩溃 depends_on: # 设置依赖关系 - selenium-hub environment: - SE_EVENT_BUS_HOST=selenium-hub - SE_EVENT_BUS_PUBLISH_PORT=4442 - SE_EVENT_BUS_SUBSCRIBE_PORT=4443 firefox: image: selenium/node-firefox:4.6.0-20221104 shm_size: 2gb depends_on: - selenium-hub environment: - SE_EVENT_BUS_HOST=selenium-hub - SE_EVENT_BUS_PUBLISH_PORT=4442 - SE_EVENT_BUS_SUBSCRIBE_PORT=4443 selenium-hub: image: selenium/hub:4.6.0-20221104 container_name: selenium-hub ports: - &#34;4442:4442&#34; - &#34;4443:4443&#34; - &#34;4444:4444&#34; 启动服务 # 进入配置文件所在的目录下 # 该目录下尽量别放其他东西，影响启动性能 $ cd seleniumgrid # -d 后台启动 $ docker-compose up -d Creating network &#34;seleniumgrid-compose_default&#34; with the default driver Creating selenium-hub ... done Creating seleniumgrid-compose_firefox_1 ... done Creating seleniumgrid-compose_chrome_1 ... done 根据日志可以看到，首先创建桥接网络，每个容器都会自动加入该网络中，便于服务间互相通信；然后再启动 Hub 容器，根据依赖关系，继续启动节点容器。
同一服务配置，支持启动多个容器节点。注意：如果要启动多节点的话，配置文件内不要定义容器端口号，避免冲突。
# 启动多节点 $ docker-compose up -d --scale chrome=2 --scale firefox=2 Creating selenium-hub ... done Creating seleniumgrid-compose_firefox_1 ... done Creating seleniumgrid-compose_firefox_2 ... done Creating seleniumgrid-compose_chrome_1 ... done Creating seleniumgrid-compose_chrome_2 ... done # 停止并删除容器&amp;网络 # stop 指令仅停止不删除 $ docker-compose down 验证 访问服务端： http://localhost:4444  ，可以看到启动的节点信息，即为成功。
运行 编写测试脚本，在远程节点上运行。
import pytest from time import sleep from selenium import webdriver &#34;&#34;&#34; 初始化 chrome | firefox driver &#34;&#34;&#34; @pytest.fixture(scope=&#39;session&#39;) def driver(): options = webdriver.ChromeOptions() driver = webdriver.Remote( command_executor=&#39;http://localhost:4444/wd/hub&#39;, options=options ) yield driver driver.quit() @pytest.fixture(scope=&#39;session&#39;) def firefox_driver(): firefox_options = webdriver.FirefoxOptions() driver = webdriver.Remote( command_executor=&#39;http://localhost:4444/wd/hub&#39;, options=firefox_options ) yield driver driver.quit() &#34;&#34;&#34; 测试执行：2 条用谷歌浏览器，2 条用火狐浏览器 测试用例：访问百度首页，在页面停止一秒。 &#34;&#34;&#34; URL = &#34;https://baidu.com&#34; TITLE = &#34;百度一下，你就知道&#34; def test_chrome(driver): driver.get(URL) sleep(1) assert driver.title == TITLE def test_chrome2(driver): driver.get(URL) sleep(1) assert driver.title == TITLE def test_firefox(firefox_driver): firefox_driver.get(URL) sleep(1) assert firefox_driver.title == TITLE def test_firefox2(firefox_driver): firefox_driver.get(URL) sleep(1) assert firefox_driver.title == TITLE 用例运行完成后，观察 hub 界面展示，会看到节点运行状态与 session 信息。 由于是单线程运行，所以会有两个闲置节点。
单线程运行测试用例 hello.py::test_chrome hello.py::test_chrome2 hello.py::test_firefox hello.py::test_firefox2 ===== 4 passed in 143.25s ===== 并发执行测试用例 # 两节点并发 $ pytest hello.py -n 2 -vs ... [gw1] PASSED hello.py::test_chrome2 [gw0] PASSED hello.py::test_chrome [gw1] PASSED hello.py::test_firefox2 [gw0] PASSED hello.py::test_firefox ===== 4 passed in 42.20s ===== # 四节点并发 $ pytest hello.py -n 4 -vs ... [gw1] PASSED hello.py::test_chrome2 [gw0] PASSED hello.py::test_chrome [gw3] PASSED hello.py::test_firefox2 [gw2] PASSED hello.py::test_firefox ===== 4 passed in 27.21s ===== 根据运行时间，可以看到，并发测试会明显缩短耗时。实际项目中，需注意规避用例间的依赖问题。
Debugging 浏览器运行在容器内，本地看不到用例执行过程。为方便调试，代理节点允许用户查看容器内浏览器的执行过程。
实现此功能需要将浏览器端口暴露出来，注意主机端口号不要重复，可以按序增加。
比如：
 Chrome : port=7900 Firefox: port=7901  在 compose.yml 内增加端口号，修改后重新启动服务。
# VNC Viewer version: &#34;2&#34; services: chrome: image: selenium/node-chrome:4.6.0-20221104 shm_size: 2gb  # 设置共享内存，官方建议值，避免浏览器引起容器崩溃 depends_on: # 设置依赖关系 - selenium-hub environment: - SE_EVENT_BUS_HOST=selenium-hub - SE_EVENT_BUS_PUBLISH_PORT=4442 - SE_EVENT_BUS_SUBSCRIBE_PORT=4443 - SE_VNC_NO_PASSWORD=1  # 取消 VNC 密码，默认密码 secret ports: - &#34;5900:5900&#34; # VNC Server - &#34;7900:7900&#34; # noVNC Web  firefox: image: selenium/node-firefox:4.6.0-20221104 shm_size: 2gb depends_on: - selenium-hub environment: - SE_EVENT_BUS_HOST=selenium-hub - SE_EVENT_BUS_PUBLISH_PORT=4442 - SE_EVENT_BUS_SUBSCRIBE_PORT=4443 ports: - &#34;5901:5900&#34; - &#34;7901:7900&#34; selenium-hub: image: selenium/hub:4.6.0-20221104 container_name: selenium-hub ports: - &#34;4442:4442&#34; - &#34;4443:4443&#34; - &#34;4444:4444&#34; 方式一：VNC Viewer Client 该项目使用 x11vnc   作为 VNC 服务器，通过 VNC Viewer   客户端建立连接后，可实时查看容器内运行情况。
 新建连接 Command+N VNC Server: IP/Host:Port Name: 自定义  如果未添加无需密码的配置项，则需要输入默认密码 secret 后建立连接。
方式二：noVNC Web 基于 noVNC   可以直接在本机浏览器上查看容器内的运行情况，无需安装客户端。
访问配置的端口服务即可：
 Chrome: http://localhost:7900   Firefox: http://localhost:7901    ]]></content></entry><entry><title>Docker - Docker基础</title><url>/tech/docker/docker-%E5%9F%BA%E7%A1%80%E7%AC%94%E8%AE%B0/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[ Docker 是一个开源的应用容器引擎，基于 GO 语言开发，可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的系统，也可以实现虚拟化。
容器是完全使用沙箱机制,相互之间不会有任何接口。
推荐不错的教程地址: https://yeasy.gitbook.io/docker_practice/  
 介绍 组成部分  Docker Client：客户端，命令行 Docker Daemon：服务端守护进程，接受并处理来自客户端的消息 Docker Image：镜像，相当于面向对象编程 类 的概念 Docker Container：容器，相当于面向对象编程 对象 的概念  镜像（Docker Images）
一个只读层被称为镜像，一个镜像是永久不会变的。因为 Docker 使用统一文件系统，Docker 进程认为整个文件系统是以读写方式挂载的，由于所有的变更都发生在顶层的可写层，所以下层的原始的只读镜像文件并未发生变化。
每一个镜像都可能依赖一个或者由多个下层镜像组成的另一个镜像（AUFS 文件系统）。
容器（Docker Containers）
镜像运行后的进程。因为 Docker 的容器实在太轻量级了，很多时候用户都是随用随建，用完即删。
仓库（Docker Registry）
集中存放镜像的地方。官方提供公共仓库，也支持搭建私有镜像仓库。
优点  快速交付应用。加快打包时间，加快测试，加快发布，缩短开发及运行代码之间的周期； 复杂环境管理，应用隔离。不同软件运行环境兼容依赖问题，开发环境、测试环境、线上环境一致； 轻量级。对于系统内核来说，一个 docker 只是一个进程，一个系统可以运行上千个容器。  与虚拟机的区别  容器与容器之间只是进程隔离，而虚拟机是完全的资源隔离； 虚拟机的启动需要分钟级别，Docker 启动是秒级或者更短； 容器共享宿主操作系统的内核，减少内核的开销；而虚拟机使用完全独立的内核。  安装与配置 官网下载 Desktop：https://www.docker.com/products/docker-desktop
 查看服务器发行版本  $ cat /etc/centos-release CentOS Linux release 7.9.2009 (Core) 查看服务器内核版本  # Docker 要求 CentOS 内核版本高于 3.10 $ uname -a 3.10.0-1160.el7.x86_64 下载对应依赖包  # -y 不询问直接安装 $ yum install -y yum-utils device-mapper-persistent-data lvm2 ... Complete! yum-utils 包提供yum-config-manager命令，该命令是对资源库（/etc/yum.repos.d/）进行增删改查，用于设置下载源。系统默认没有安装。
Device Mapper 是一个基于内核的框架，它支持 Linux 上的许多高级卷管理技术。Docker 的 devicemapper   存储驱动程序利用此框架的精简配置和快照功能来进行映像和容器管理。
 devicemapper requires the lvm2 and device-mapper-persistent-data packages to be installed.
 设置 docker 下载源  $ yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo ... repo saved to /etc/yum.repos.d/docker-ce.repo 下载安装 docker  $ yum -y install docker-ce docker-ce.x86_64 3:20.10.12-3.el7 ... Complete! 验证 docker 安装成功  # 查看版本信息 $ docker version Client: Docker Engine - Community ... Server: Docker Engine - Community ... # 查看系统信息 $ dcoker info ... 设置开机自启动  # centOS $ systemctl start docker $ systemctl enable docker  ubantu 自动启动，无需设置 MacOS 和 Windows 通过桌面版启动  配置镜像仓库国内源  # 阿里云需要自己去申请，xxx 为申请的 key # https://account.aliyun.com # 将源地址写入配置文件 $ tee /etc/docker/daemon.json &lt;&lt;-&#39;EOF&#39; { &#34;registry-mirrors&#34;:[ &#34;https://xxx.mirror.aliyuncs.com&#34;, &#34;https://registry.docker-cn.com&#34;, &#34;http://hub-mirror.c.163.com&#34; ] } EOF # 重启生效 $ systemctl daemon-reload $ systemctl restart docker # 验证源 $ docker info ... Registry Mirrors: https://xxx.mirror.aliyuncs.com/ https://registry.docker-cn.com/ http://hub-mirror.c.163.com/ 命令 # CentOS 启动 docker 服务 $ systemctl start docker $ systemctl restart docker $ ststemctl enable docker # 开机自启动 # ubantu 自动启动 # MacOS 和 Windows 通过桌面版启动 基本命令 # 查看版本信息 $ docker version # 查看系统信息 $ dcoker info 镜像管理 # 查看所有镜像 $ docker images # 搜索镜像 $ docker search jenkins # 拉取镜像，默认最新版本，可以指定版本 $ docker pull jenkins:latest # 导出镜像 $ docker save jenkins:latest &gt; jenkins.tar # 导出镜像 $ docker load &lt; jenkins.tar # 删除镜像 $ docker rmi jenkins:latest # 修改镜像标签名 $ docker tag jenkins:latest jenkins:test # 查看镜像创建层信息 $ docker history jenkins # 查看镜像占用磁盘空间 $ docker system df -v # SIZE 镜像所有层加起来占用的空间 # SHARE SIZE 与其他镜像共享的镜像层占用空间大小 # UNIQUE SIZE 镜像独占层的空间大小 # 所以，理论上 Share size 越大越好，unique size 越小越好；复用才最好 容器管理 # 运行容器；-d 在后台运行 $ docker run -d --name=mysql:latest # 查看运行中的容器 $ docker ps $ docker ps -a # 查看容器中运行的进程 $ docker top mysql # 查看资源占用 $ docker stats mysql # 容器操作 $ docker start mysql $ docker restart mysql $ docker stop mysql $ docker kill mysql # 暂停/恢复容器 $ docker pause mysql $ docker unpause mysql # 删除容器 $ docker rm mysql # 运行状态的容器会删除失败 $ docker rm -f mysql # 强制删除容器 # 查看容器运行日志 $ docker logs -f {CONTAINER_ID} # 执行命令(-i 交互式 -t 终端方式) $ docker exec -it mysql bash # 复制文件 $ docker cp mysql:/var/tmp . $ docker cp a.txt mysql:/tmp # 查看容器/镜像元信息；包含 PID、IP 等等 $ docker insepct mysql # 格式化输出提取创建时间 $ docker inspect -f &#39;{{.Created}}&#39; mysql # 查看挂载目录 $ docker inspect --format &#34;{{.Config.Volumes}}&#34; # 查看运行状态 $ docker inspect --format &#39;{{.Name}} {{.State.Running}}&#39; mysql # 查看 IP 地址  $ docker inspect --format=&#39;{{.NetworkSettings.IPAddress}}&#39; mysql # 查看容器内文件结构变化 $ docker diff mysql 在服务器上查看当前 docker 容器，会折行展示，看着很乱；网上没找到相关的美化命令行工具，通过格式化输出信息实现。
# 办法一：通过 less 命令实现 # -e：文件内容显示完毕后，按任意键退出 # -S：在单行显示较长的内容，而不换行显示 # -N：每一行行首显示行号 $ docker ps | less -SNe # 办法二：通过 docker format 实现 # 1. 将以下函数 写入环境变量 $ vim /etc/profile docker-ps(){ docker ps $1 --format &#34;table {{.ID}}\t{{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}&#34; } # 2. 重新登录该用户或者 `source` 环境变量即可。 $ source ~/.bash_profile # 3. 按指定字段展示信息，这里的 docker-ps 是自定义的 shell 函数 $ docker-ps CONTAINER ID NAMES IMAGE STATUS PORTS 容器网络 # https://docs.docker.com/network # 创建网桥  $ docker network create --driver bridge mynet # 查看网桥列表 $ docker network ls # 查看网桥信息 $ docker network inspect mynet # 查看容器网络信息 $ docker inspect --format=&#39;{{json .NetworkSettings.Networks}}&#39; my_container 容器启动参数解释 端口映射（-p） docker 会在虚拟的容器网络内启动容器，容器网络内的容器之间可以互相通信，外部无法与容器进行通信，我们希望将宿主机（启动容器的机器）作为跳板，这样，用户可以将网络请求发送给宿主机，宿主机再转发请求到容器实现通信，所以需要端口映射。
$ docker run --name=hub -p 5001:4444 用户将请求发送到宿主机的 5001 端口，宿主机再转发请求到容器的 4444 端口。
使用宿主机网络（&ndash;net host） 通过 &ndash;net 指定 host 就可以不用容器网络，直接使用宿主机的网络。
容器间网络互通（&ndash;net container:容器名） 容器 A 使用容器 B 的网络；容器 ABCD 使用容器 E 的网络
环境变量（-e） 启动容器时，通过设置环境变量，来控制容器行为。容器内部的程序会读取环境变量，相当于传参。
比如，通过 mysql 镜像启动容器，不知道用户想设置什么账号密码，那么就通过环境变量来进行设置。
后台执行（-d） 如果非后台执行的话，关闭当前窗口或者 ctrl+c 结束命令后，该容器就会停止运行，服务停掉。
搭建 Web 服务器 Nginx Nginx 简介 Nginx（发音同 engine x）是一个异步的 Web 服务器，主要提供 Web 服务、反向代理、负载均衡和 HTTP 缓存功能。由 Igor Sysoev 创建于 2004 年，使用 C 语言开发。
反向代理：服务器将收到的请求分发到其他服务器
负载均衡：流量均匀的分布到后端的服务器上
HTTP缓存：缓存服务器，提高用户访问速度
运行 Nginx 容器 # 拉取 $ docker pull nginx:1.17.9 # 运行 # 将容器的 80 端口映射到本机的 80 端口，浏览器访问本机 IP 即可看到 nginx 欢迎页 # 退出后就不能访问了 $ docker run -p 80:80 nginx:1.17.9 # -d 在后台运行 $ docker run -d --name nginx -p 80:80 nginx 6438442df9b325e8bfc5a8c5ff95dc21e599c0e885a7dbf5687d91c1f44045db # -v 挂载目录，在本地的html目录下添加文件，访问服务的 8080 端口就可以看到了 $ docker run -d --name nginx -p 8080:80 -v ${PWD}/nginx/html:/usr/share/nginx/html nginx:1.17.9 891e09a6bbb5e131f99cd3fe60dfb2687b0939c28ad614d017408ce74478b1a1 $ cd nginx/html $ vi index.html &lt;h1&gt;Everythin will be ok.&lt;/h1&gt; # 保存后，访问本地服务的8080端口，即可看到页面展示 搭建测试用例管理平台 Testlink Testlink 简介 Testlink 基于 WEB 的测试用例管理系统，主要功能是测试项目管理、产品需求管理、测试用例管理、测试计划管理、测试用例的创建、管理和执行，并且还提供了统计功能。
部署数据库 # 创建一个名为 testlink 的容器网络 $ docker network create testlink # 查看当前存在的容器网络 $ docker network ls NETWORK ID NAME DRIVER SCOPE 备注（自己加的） 4deb334c55f6 bridge bridge local 桥接网络 cf4fbaac0160 host host local 主机网络 50027393c74d none null local 6ac9853f1eab testlink bridge local 刚才新建的网络 # 运行数据库，如果本地没有该镜像的话会自动去下载 $ docker run -d --name mariadb -e MARIADB_ROOT_PASSWORD=mariadb -e MARIADB_USER=bn_testlink -e MARIADB_PASSWORD=bn_testlink -e MARIADB_DATABASE=bitnami_testlink --net testlink -v ${PWD}/mariadb:/bitnami bitnami/mariadb:10.3.22 Unable to find image &#39;bitnami/mariadb:10.3.22&#39; locally 10.3.22: Pulling from bitnami/mariadb ... 74dbf92d3ddca4d241f2b9022890445820f7e26e5324c352c90983515379bd65 部署 Testlink # 运行 testlink $ docker run -d -p 80:8080 -p 443:8443 --name testlink -e TESTLINK_DATABASE_USER=bn_testlink -e TESTLINK_DATABASE_PASSWORD=bn_testlink -e TESTLINK_DATABASE_NAME=bitnami_testlink --net testlink -v ${PWD}/testlink:/bitnami bitnami/testlink:1.9.20 Unable to find image &#39;bitnami/testlink:1.9.20&#39; locally 1.9.20: Pulling from bitnami/testlink ... 5e766b7f386db5c0bdb3adcb14c1daea6f5f9517f56dfc9af556fbcb4c6e1bc9 在浏览器访问本地 IP 地址，即可正常浏览网页。
默认用户名：user；默认密码：bitnami。
搭建持续集成平台 Jenkins 简介 Jenkins 是开源的 CI&amp;CD 软件领导者，提供持续集成和持续交付服务，有超过 1000 个插件来支持构建、部署、自动化，满足任何项目的需要。
部署 Jenkins # 运行 $ docker run -d --name jenkins -p 8080:8080 jenkins/jenkins Unable to find image &#39;jenkins/jenkins:latest&#39; locally latest: Pulling from jenkins/jenkins ... 0f2b01bf74d566fe6ea90790307ccd1de317f1095b1d3056a3986c0eaee8c856 # 首次启动需要管理员密码，通过日志可以查看 $ docker logs -f jenkins ... ************************************************************* Jenkins initial setup is required. An admin user has been created and a password generated. Please use the following password to proceed to installation: 207e5af52d004e058e48e66c751b5086 This may also be found at: /var/jenkins_home/secrets/initialAdminPassword ************************************************************* # 也可以去文件内查看默认密码 $ docker exec -it jenkins cat /var/jenkins_home/secrets/initialAdminPassword 207e5af52d004e058e48e66c751b5086 # 挂载目录，由于容器名称不能重复，需要删除之前的容器或者更换名字 $ docker run -d --name jenkins -p 8080:8080 -p 50000:50000 -v ${PWD}/jenkins:/var/jenkins_home jenkins/jenkins # 如果启动失败，添加下权限后重启即可 $ chmod 777 jenkins $ docker restart jenkins Dcoekr-compose 简介 Docker-compose 是用于定义和运行多容器的 Docker 应用程序的工具。通过 compose，可以使用 yaml 文件来配置应用程序的服务。compose 的使用一般分为三步：
 使用 Dockerfile 定义应用程序的环境，以便可以在任何地方复制它； 在 docker-compose.yml 中定义组成应用程序的服务，以便他们可以在隔离的环境中一起运行； 运行 docker-compose up，然后 compose 启动并运行您的整个应用程序。  安装 macOS、windwos 上的 Desktop 版本，默认已经安装
# 验证 $ docker-compose version docker-compose version 1.23.2, build 1110ad01 docker-py version: 3.6.0 CPython version: 3.6.6 OpenSSL version: OpenSSL 1.1.0h 27 Mar 2018 常用命令 # 查看配置 $ docker-compose config # 后台启动 $ docker-compose up -d # 构建镜像 $ docker-compose build # 下载镜像 $ docker-compose pull # 正在运行 $ docker-compose ps # 进程 $ docker-compose top # 启动 $ docker-compose start # 停止 $ docker-compose stop 演示 通过一个 Python web 小实例来演示 Docker-compose 的功能。
# docker-compose.yml # 指定 docker-compose API 版本 # 在当前目录下运行 docker-compose config 可以验证变量具体的值 version: &#39;3&#39; services: web: build: context: . depends_on: - redis ports: - &#34;5000:5000&#34; redis: image: ${REDIS_VERSION} restart: always # .env REDIS_VERSION=redis:alpine # Dockerfile FROM python:3.7-alpine LABEL maintainer=&#34;test&#34; # 工作路径设定为 /code WORKDIR /code # 创建环境变量给 Flask 使用 ENV FLASK_APP app.py ENV FLASK_RUN_HOST 0.0.0.0 # 复制 app.py 到容器内的 /code 目录 COPY app.py /code # 安装 gcc 工具、python 依赖 RUN pip install flask &amp;&amp; pip install redis # 映射端口 EXPOSE 5000 STOPSIGNAL SIGTERM # 为容器设置默认启动命令 CMD [&#34;flask&#34;, &#34;run&#34;] # app.py # 实现统计访问次数 import time import redis from flask import Flask app = Flask(__name__) cache = redis.Redis(host=&#39;redis&#39;, port=6379) def get_hit_count(): retries = 5 while True: try: return cache.incr(&#34;hits&#34;) except redis.exceptions.ConnectionError as e: if retries == 0: raise e retries -= 1 time.sleep(0.5) @app.route(&#39;/&#39;) def hello(): count = get_hit_count() return f&#34;Hello World! I have been seen {count}times.\n&#34; 启动 $ docker-compoes up -d Docker registry 简介 Docker Registry 是存储 Dcoker Image 的仓库，运行 push、pull、search 时，是通过 Docker daemon 与 docker registry 通信。有时候使用 Docker Hub 这样的公共仓库可能不方便，我们可以通过 registry 创建一个本地仓库。
运行 # 搭建仓库的主机运行 $ docker run -d -p 5000:5000 -v ${PWD}/registry:/var/lib/registry --restart always --name registry registry:2.7.1 # 其他机配置下镜像仓库 $ vim /etc/docker/daemon.json { &#34;insecure-registries&#34;:[&#34;{仓库主机的IP地址和端口号}&#34;] } $ systemctl restart docker # 重启下docker 演示 # 搭建仓库的主机：先从 docker hub 上随便下载一个镜像 $ docker pull nginx:1.18.0 # 打上带主机 IP 地址的标签 $ docker tag nginx:1.18.0 {仓库地址}/nginx:1.18.0 # 推送到内网仓库下 $ docker push {仓库IP:port}/nginx:1.18.0 # 其他机器 $ docker pull {仓库IP:port}/nginx:1.18.0 # 查看下载的镜像，就是本地仓库的镜像 $ docker image # 构建镜像并推送到本地仓库上 $ docker build -t {仓库IP:port}/flask-web:1.0 . 通过搭建本地仓库，下载镜像后 push 到本地仓库，其他内网机器 pull 的话速度会有所提升。
一般公司业务不方便放到 docker hub 上，可以通过内网仓库提高隐私性。
dockerfile 简介 Dockerfile 是由一系列指令和参数构成的脚本，一个 Dockerfile 里面包含了构建整个镜像的完整命令。
通过 docker build 执行 Dockerfile 中的一系列指令自动构建镜像。
常用指令 FROM：基础镜像，FROM 命令必须是 dockerfile 的首个命令LABEL：为镜像生成元数据标签信息，作者、版本信息等USER：指定运行容器时的用户名或 UID，默认管理员用户，后续 RUN 也会使用指定用户RUN：是 dockerfile 执行命令的核心部分，接受命令作为参数并用于创建镜像。每条 run 命令在当前基础镜像上执行，并且会提交一个新的镜像层WORKDIR：设置 CMD 命令的运行目录，为后续的 RUN、CMD、ENTRYPOINT、ADD 指令配置工作目录ENV：容器启动的环境变量ARG：构建环境的环境变量，仅供 dockerfile 赋值使用COPY：复制文件CMD：容器运行时执行的默认命令ENTRYPOINT：执行容器的入口HEALTHCHECK：容器健康状态检查演示 使用 dockerfile 构建 nginx 容器，添加容器健康检查
# Dockerfile# 导入基础镜像FROMnginx:1.17.9# 指定信息LABEL maintainer=&#34;Ultraman_Tiga&#34;# 设置环境变量ENV NGINX_VERSION 1.17.9ARG work_pwd=/data/html# 切换用户USERroot# 执行命令# 安装 curl，设置软链把 nginx 服务的日志显示到终端输出RUN apt-get -yq update &amp;&amp; apt-get install -y curl &amp;&amp; \ ln -sf /dev/stdout /var/log/nginx/access.log &amp;&amp; \ ln -sf /dev/stderr /var/log/nginx/error.log# 挂载卷VOLUME [&#34;/data&#34;]# 设置工作目录WORKDIR$work_pwd# 复制 index.html 文件到 workdir 目录下COPY index.html .# 映射 80 端口EXPOSE80# 此处 CMD 作为 ENTRYPOINT 的参数CMD [&#34;nginx&#34;, &#34;-g&#34;, &#34;daemon off;&#34;]# 使用 docker stop 指令停止容器时，发出 sigrtmax 指令停止容器STOPSIGNALSIGRTMAX# 检查容器健康，通过访问 Nginx 服务 80 端口，来判断容器是否正常运行HEALTHCHECK --interval=5s --timeout=3s \ CMD curl -fs http://localhost/ || exit 1构建 # -t 指定标签；. 代表当前路径 $ docker build -t nginx:1 . # 启动 $ docker run -d nginx:1 # 新建一个窗口，进入容器内 $ docker exec -it {container_id} bash root@*****:/data/html$ env # 用户名为指定的 root 用户 # 执行env命令后会出现dockerfile设置的环境变量 # 当前目录就是设置的workdir # 当前目录下存在 index.html root@*****:/data/html$ df -h # 挂载卷为设置的VOLUME /dev/sda1 ... /data 镜像构建 简介 工作中，常常需要制作自己的项目镜像，便于分发给其他同学使用。一般通过以下两种方式制作镜像：
 docker commit dockerfile  docker commit 一般用做从一个运行状态的容器来创建一个新的镜像，定制镜像应该使用 dockerfile 来完成，默认 commit 镜像，对外不可解释，别人不知道该容器的构建环境，不方便排查问题，可维护性差。
$ docker commit {容器名} {新镜像名}:tag docker build # 忽略文件，构建时不会被打包到镜像内 # 创建一个 .dockerignore 文件，里面写入 Dockerfile* # 指定文件 $ docker build -f # 添加标签 $ docker build -t # 不使用缓存 $ docker build --no-chche # 构建时变量 $ docker build --build-arg 这个帖子不错，留在这里备忘：https://blog.csdn.net/lb245557472/article/details/91966770
]]></content></entry><entry><title>Mac - Svn 安装及使用命令</title><url>/tech/mac/svn-%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">记录下 Mac 上的 SVN 命令行使用，脑子不好总是忘记。
安装 $ brew install svn Error: homebrew-core is a shallow clone. homebrew-cask is a shallow clone. To `brew update`, first run: git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core fetch --unshallow git -C /usr/local/Homebrew/Library/Taps/homebrew/homebrew-cask fetch --unshallow 出现报错，按照提示 git 合并下分支
$ brew install svn Error: python@3.9: wrong number of arguments (given 1, expected 0) 出现报错，手动更新下。
$ brew update Already up-to-date. 再次安装
$ brew install svn ... 常用命令 下载仓库代码（checkout）
$ svn co {project_link}</content></entry><entry><title>安全测试 - Burpsuite基本使用</title><url>/tech/%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95/burpsuite%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url><categories><category>安全测试</category></categories><tags><tag>安全测试</tag></tags><content type="html">扫盲贴，简单了解一下。
相对开放、定制性强、黑客工具、测试工具
重要特性：
代理工具（Proxy） 爬虫（Spider）：对网站进行爬取 暴力破解（Intruder）：对接口的参数进行数据注入 漏洞扫描（Scanner 付费） 重放请求（Repeater） 附属工具（decode comparer）：编译 解码 工具 扩展定制（Exetnder） 应用场景：
服务端攻击：篡改请求 客户端攻击：篡改响应 使用步骤：
谷歌浏览器设置好代理，访问请求，可以在 burpsuite 内看到，抓到网站请求后，可以右键爬取网站的资源的内容，还有很多其他功能。没理解。</content></entry><entry><title>安全测试 - 了解安全测试</title><url>/tech/%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95/%E4%BA%86%E8%A7%A3%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95/</url><categories><category>安全测试</category></categories><tags><tag>安全测试</tag></tags><content type="html">接口安全测试基础知识
演练地址 https://dvwa.ceshiren.com | admin | password
常见安全工具 OWASP ZAP（开源、全能；推荐） WVS（商业） AppScan（商业） BuipSuite（商业） Sqlmap（开源） 安全测试关注维度 传输 敏感信息传递加密 链路加密 接口 访问控制 参数 注入：sql 注入、命令注入、文件注入 越权：越过更高权限、越过同级权限 业务安全常见的 checklist 业务数据传输链路分析 http 是否传输敏感信息 tcp 等协议是否可被解密 资产安全分析 api 清单收集：明确敏感信息分级，可访问性验证 API 参数收集：明确参数分类并针对分析 token 可遍历 文件上传 身份参数的有效性验证 建立安全测试流程 白盒代码分析：自动化 sonar、findbugs 等 黑盒扫描机制：自动化 zap、wvs、burpsuite、appscan、sqlmap 业务流程安全探索：人工检测 burpsuite、zap</content></entry><entry><title>安全测试 - Dvwa漏洞介绍及案例</title><url>/tech/%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95/dvwa%E6%BC%8F%E6%B4%9E%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%A1%88%E4%BE%8B/</url><categories><category>安全测试</category></categories><tags><tag>安全测试</tag></tags><content type="html"><![CDATA[接口安全测试，常见漏洞了解和案例演示。
命令注入漏洞 原理 命令注入是一种攻击，其目标是通过易受攻击的应用程序在主机操作系统上执行任意命令。
当应用程序将用户提供的不安全数据（表格、cookie、http 标头等）传递到 shell 时，可能会发生命令注入攻击。在这种攻击中，通常由易受攻击的应用程序以特权执行由攻击者提供的操作系统命令。由于没有足够的输入验证，因此可能会发生命令注入攻击。
案例 演示地址：https://dvwa.ceshiren.com/vulnerabilities/exec
在地址框内输入一个正常的测试地址，会执行 ping 命令，然后打印该地址的一些信息，这是一个正常的流程。
点击 submit 后，底层的执行逻辑代码，是通过字符串拼接的方式，执行 shell 命令。
上面的 target 用户可以自定义，而 shell 本身是有一些特殊字符代表特殊含义的，那么输入下面的内容，再次执行一下试试。
会发现打印出当前目录下的其他文件名称，如果输入 rm -rf * 之类的命令，或者获取用户密码、数据库数据等等，会造成比较严重的后果；这就是恶意命令注入漏洞。
常用漏洞利用 payload   多语句分号：;
  条件执行：&amp;&amp; ||
  管道符号：｜
  需要通过工具，来扫描验证屏蔽这些符号。
SQL 注入漏洞 原理 是发生于应用程序与数据库层的安全漏洞。简而言之，是在输入的字符串之中注入 SQL 指令，在设计不良的程序当中忽略了字符检查，那么这些注入进去的恶意指令就会被数据库服务误认为是正常的 SQL 指令而运行，因此遭到破坏或是入侵。
案例 案例一： 案例二： 当在输入框内输入 ID 时，会返回当前 ID 所对应的用户名信息；通过恶意输入 sql 命令来完成一次注入漏洞
# 1 是搜索条件 # 一个单引号来完成字符串拼接引号的闭合 # 执行查询整表的命令 # --- 注释掉后面所有的内容 $ 1 &#39; union select * from users; --- 执行效果如下，通过该漏洞达到执行任意 sql 命令的目的；获取到了所有用户的信息，导致数据泄露。
危害与预防 危害：可以无限制的使用 SQL，造成数据泄露甚至远程命令执行
预防：使用参数化查询避免数据被混在指令中
XSS 漏洞 原理  跨站脚本（简称为 XSS）是一种网站应用程序的安全漏洞攻击，是代码注入的一种。 XSS 攻击通常指的是利用网页开发时的漏洞，通过巧妙的方法注恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。这些恶意网页程序通常是 JavaScript，但实际上也可以包括 Java、VBScript、ActiceX、Flash 或者普通的 HTML。攻击成功后，攻击者可能得到更高的权限（如执行一些操作）、私密网页内容、会话和 cookie 等各种内容。  案例 在输入框，输入用户名，点击提交后，会打印出一个带有用户名的字符串
通过代码片段可以看到，输出命令是通过字符串拼接来实现的，容易被恶意指令攻击。
# 通过语句闭合输入恶意指令 $ myname &lt;script&gt;alert(&#34;myname&#34;)&lt;/script&gt; 通过这种方法来执行 JavaScript 脚本，显示出我的名称；同样，可以通过伪造请求获取到用户 cookie 打印出来；如果将该网页发送给其他用户，点击后，
常见的攻击 payload 危害与防范  危害：危害网站上的其他用户，导致别动执行非预期网页脚本 预防：输入输出过滤，利用浏览器安全机制等 检测：可自动化发现  CSFR 漏洞 原理  跨站请求伪造，是一种挟制用户在当前已登录的 Web 应用程序上执行非本意的操作的攻击方法。与跨网站脚本（XSS）相比，XSS 利用的是用户对指定网站的信任，CSFR 利用的是网站对用户网页浏览器的信任。 跨站请求攻击，简单的说，是攻击中通过一些技术手段欺骗用户的浏览器去访问一个自己曾将认证过的网站，并运行一些操作（发邮件，发消息，甚至是转账和购买商品等财产操作）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去运行。这利用了 web 中用户身份验证的一个漏洞：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求是用户自愿发出的。  案例 修改密码的功能页面
设置新密码后，点击 change 即可修改，问题在于使用的 get 方法进行请求。
如果将该链接发送给用户，且用户正好已经是登录状态，那么密码就会直接被重置为新密码。
常见的攻击 payload  利用 url 利用图片请求 利用伪造表单  危害与检测 危害：导致用户执行非本意的网站请求
预防：增加 token 校验（提交过程中检验是否是第三方伪造）、检查 referer
]]></content></entry><entry><title>Blog - Typora 图床</title><url>/tech/blog/typora-%E5%9B%BE%E5%BA%8A/</url><categories><category>Blog</category></categories><tags><tag>Blog</tag></tags><content type="html">这篇文章记录如何给 Typora 配置 gitee 免费图床。
编写文本时，经常会插入图片，Typora 默认会把图片存储在本地，如果发布到 CSDN 或者其他在线渠道，图片就会加载失败，非常的困扰，接下来就来解决这个问题吧！
gitee 国内的代码管理远程仓库，考虑到速度问题，选它，重要的是免费；
如果没有，注册一个。
创建仓库，选择公开，初始化 README 文件。
PicGo 下载安装：https://github.com/Molunerfinn/PicGo/releases
选择跟系统对应的安装包，我这里选择的是 dmg 2.3.0 beta7 版本，傻瓜式安装。
1⃣️ 安装 gitee-uploader 插件 打开后在上面菜单栏会出现一个图标，右键图标，打开详细窗口，安装插件
2⃣️ 设置图床 生成令牌时，取消全选，除默认 user_info 外，勾选 projects 即可。
设置为默认图床。
3. Typora 偏好设置 - 图像
配置好后，验证图片是否上传成功；如果未成功，查看日志会有错误信息。</content></entry><entry><title>Python - Pycharm 插件汇总</title><url>/tech/python/pycharm-%E6%8F%92%E4%BB%B6%E6%B1%87%E6%80%BB/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html">插件汇总 Json Parser JSON Parser是一个用于验证和格式化 JSON 字符串的轻量级插件。
Tabnine（强烈推荐） 该插件主要在于可以帮助我们自动填充代码，由于是在人工智能技术的驱动之下，因此每次都可以精准的预测我们将要填充的究竟是什么代码。
Rainbow Brackets（推荐） 该插件的作用在于能够将括号以不同的颜色标注出来，这样就能够在括号很多的时候，清楚辨别哪个括号是一对，支持多种语言。
Indent Rainbow（推荐） 该插件的作用在于能够对于不同层级缩进的空格标注不同的颜色
CodeGlance（推荐） 该插件的主要作用表现为会在 IDE 的最右侧生成一条工具栏，这样可以更加便捷的跳转至所要寻找的代码位置
ignore ignore 包含了各种各样语言、框架、应用程序的排除文件模板，可以在项目中排除某些无用文件，在版本控制软件中很有用。比如用 git 管理的 Python 项目， 项目上右键选 new， 就会有个 .ignore file 的选项，选择 git， 进入下一页面选择 Python 生成就可以了。
BashSupport bash-support 是一个高度定制化的 vim 插件，它允许你插入：文件头、补全语句、注释、函数、以及代码块。它也使你可以进行语法检查、使脚本可执行、一键启动调试器；而完成所有的这些而不需要关闭编辑器。
SonarLint（必备推荐） SonarLint是一个免费的IDE扩展，可让在编写代码时修复错误和漏洞！ 像拼写检查器一样，SonarLint可以即时突出显示编码问题，并提供清晰的修复指导，因此可以在提交代码之前对其进行修复。 在各类IDE（Eclipse，IntelliJ，Visual Studio，VS Code）和编程语言中，SonarLint能够帮助所有开发人员编写更好、更安全的代码！
pycharm自动补全代码插件：TabNine的插件 statistic 统计代码行数
Translation 翻译插件，快捷键：cmd+ctl+u；
https://yiiguxing.gitee.io/translation-plugin/start.html
PlantUML 插件 PlantUML 是画程序时序图的，Pycharm 有插件，可以创建 *.puml 文件，非常方便。
官方网站： http://plantuml.com/sequence-diagram
在线使用： https://plantuml.ceshiren.com/uml/SyfFKj2rKt3CoKnELR1Io4ZDoSa70000
插件下载 直接在 Pycharm 的 插件商店内没有搜索到，需要在网页点击下载。
插件下载地址： https://plugins.jetbrains.com/plugin/7017-plantuml-integration
插件安装步骤 进入插件页面后，选择当前编译器版本；
点击后网页右下角出现提示：
这时回到 Pycharm 内，会出现插件安装弹框，点击 OK 下载成功后，会出现提示，重启 Pycharm 生效，点击 restart 即可。
验证 在插件的安装栏内就会出现该插件
项目内新建文件，也会出现 puml 类型的文件</content></entry><entry><title>随笔 - 摩托车从入门到放弃</title><url>/tech/%E9%9A%8F%E7%AC%94/%E6%91%A9%E6%89%98%E8%BD%A6%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/</url><categories><category>随笔</category></categories><tags><tag>随笔</tag></tags><content type="html">有天早上，媳妇跟我说晚上做梦，梦里特别需要摩托车驾照，然后鼓励我成为一名骑士；
正合我意，开帖记录摩托车考驾照。
驾照 报名（2021.5.9） 驾校：京都府（朋友推荐，离住处距离近，有班车，昌平）
费用
培训：周末班 ¥ 1590；加上体检照相费用共 ¥ 1643； 考试：考试费用单独交，共计 160 沙河站附近有报名中心，我是现场去报的，报名中心的老师服务态度很好，细节基本都会说到。
科目一 报名完成后，开始学习科目一，下载「学车不」APP，刷题练习；
等待预约考试的电话即可。
拿证 后面就练两次车，就准备考试了。
有惊无险，拿到驾照，接下来开始选车。
摩托车选购 一直想买一个非常酷的摩托车，但是那种摩托车后面坐起来就不舒服，而且不能放东西。考虑到这点需求，基本上是放弃了~
哎~ 最终向生活低下了 🐶
问了问周围同事的下踏板：
勇哥座驾：豪爵 usr125，2020年购入，下来 1.1 万，说现在降价，8k+ 宝哥座驾：雅马哈 福喜125，2020年购入，下来 9k+ 刚哥座驾：铃木 uu125，不详 最后买了个 UY125，一万2落地，方便很多，生活半径扩展了 3 公里，哈哈。
记录 骑行 1 万公里左右，在一个湿滑的十字路口，摔车了，飞出去 3 米远，好在速度慢。
媳妇跟孩子都轻微擦伤，太心疼了。
骑车千万注意安全！！！注意安全！！！安全第一！！！
占用公交车道被拍了，罚款 100 上班进入四环被拍了，就在公司门口，新装了个摄像头。罚款 100 扣 1 分 以后上下班公交通勤 😄 2023/07/01
摩托车胎磨得比较薄了，漏了三次，也容易打滑。修车店建议更换轮胎。
网上下单买了倍耐力天使，顺便换了润滑油。</content></entry><entry><title>Mac - 解决Jetbrains全家桶无法打开</title><url>/tech/mac/%E8%A7%A3%E5%86%B3jetbrains%E5%85%A8%E5%AE%B6%E6%A1%B6%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">点击程序坞上面的应用程序，跳动两下就没有然后了，无法打开程序；附上解决办法。
前几天改了电脑的用户名称，导致一部分软件都没办法启动；原因是软件的配置文件依然保存原用户名的路径，启动时未获取到目录地址，所以报错了。
以 Pycharm 为例
找到命令行执行程序：「应用程序」- 右键「显示包内容」- Contents - MacOS - pycharm；
/Applications/PyCharm.app/Contents/MacOS/pycharm ; exit; # lan @ tester in ~ [14:58:15] $ /Applications/PyCharm.app/Contents/MacOS/pycharm ; exit; 2021-04-07 14:58:15.785 pycharm[55629:2464832] allVms required 1.8*,1.8+ 2021-04-07 14:58:15.787 pycharm[55629:2464835] Current Directory: /Users/lan 2021-04-07 14:58:15.787 pycharm[55629:2464835] Value of PYCHARM_VM_OPTIONS is (null) 2021-04-07 14:58:15.787 pycharm[55629:2464835] Processing VMOptions file at /Users/lan/Library/Application Support/JetBrains/PyCharm2020.1/pycharm.vmoptions 2021-04-07 14:58:15.788 pycharm[55629:2464835] Done Error: could not find libjava.dylib Failed to GetJREPath() OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. Error opening zip file or JAR manifest missing : /Users/lanzy/.jetbrains/jetbrains-agent-v3.2.1.4255.9c8 Error occurred during initialization of VM agent library failed to init: instrument [进程已完成] 日志显示获取 jre 环境失败，关键信息就是这句，这个路径是老用户名，需要修改为最新：
Error opening zip file or JAR manifest missing : /Users/lanzy/.jetbrains/jetbrains-agent-v3.2.1.4255.9c8
$ cd /Users/lan/Library/Application Support/JetBrains/PyCharm2020.1/ $ subl pycharm.vmoptions # 将 `javaagent` 这一项改为新用户名即可 ... -javaagent:/Users/lan/.jetbrains/jetbrains-agent-v3.2.1.4255.9c8=51aaea47 再次启动 Pycharm，正常使用～
idea 也是同样的问题，修改 idea.vmoptions 文件下的 javaagent 配置即可。</content></entry><entry><title>Ios - 快捷指令实现自动提醒打卡</title><url>/tech/ios/%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%8F%90%E9%86%92%E6%89%93%E5%8D%A1/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html">下班自动提醒的快捷指令工具 🕙
iOS 快捷指令使用记录
公司弹性打卡，规则是这样：早上九点半之前到公司，那么下午六点半到七点之间，根据打卡时间弹性下班；早上晚于9点半到公司，需要多加半小时上班时间。
公司采用古老的手指打卡机系统，不提供查询打卡时间，经常忘记啥时候该下班，是否需要多加半小时；于是购买了「小日常」APP，作为习惯每天记录自己的上班时间；快到下班时间打开 APP 查看打卡记录，再计算，操作路径较长，懒。
于是想到了快捷指令，官方概述：该 App 可让您合并多个 App 间的多个步骤，以创建功能强大的任务自动化。
花 15 分钟在 b 站看了几个教程视频后，有了点想法，这东西可以搞。
需求实现逻辑梳理：
当到达指定地点-公司； 自动记录打卡时间； 根据当前打卡时间推算出下班时间； 设置提醒事项，提醒时间为下班前 5 分钟 实现 step 1
新建快捷指令中添加，搜索位置 ==&amp;gt; 获取当前位置；
等等，我们是手指打卡，到达位置后的时间不一定是我手指触碰打卡机的时间，到楼下还得扫健康码、等电梯，时间获取不精确，下班早了是要扣钱的&amp;hellip;
step 1 手指打卡后，点击启动手机上的快捷指令； 创建快捷指令，「详细信息」内点击「添加到主屏幕」，自定义图标和名称，放到手可以轻松触碰的位置，打完卡后点击触发。
step 2 打卡逻辑梳理，满足以下条件即可
上班 下班 9:00 6:30 9:30 7:00 9:31 7:31 10:00 8:00 根据所需判断条件在快捷指令内搜索就行，非常方便。
### 整体实现如下 获取当前日期 格式化日期 格式化后的日期 - 930（9点半的时间节点） 如果 计算结果 小于或等于 0 将 日期 加上 34200 秒钟 否则 如果 计算结果 小于或等于 70 将 日期 加上 36000 秒钟 否则 文本 8:00（迟到） 结束条件 结束条件 显示预览 打卡时间；下班时间（出现提示框） 从 所有提醒事项 中查找 如果 存在之前设置的下班提醒 移除该提醒事项 否则 结束条件 计算 下班时间 减去 5分钟 将 下班啦 添加到提醒事项 设置 提醒时间 为下班前 5 分钟 over.
同时开启 iOS 和 Mac 的提醒事项同步；那么效果就很 Nice 😄
到点了，验证下结果；</content></entry><entry><title>Ios - 快捷指令打卡</title><url>/tech/ios/%E5%BF%AB%E6%8D%B7%E6%8C%87%E4%BB%A4%E6%89%93%E5%8D%A1/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html"> 下班自动提醒的快捷指令工具 🕙
iOS 快捷指令使用记录
公司弹性打卡，规则是这样：早上九点半之前到公司，那么下午六点半到七点之间，根据打卡时间弹性下班；早上晚于9点半到公司，需要多加半小时上班时间。
公司采用古老的手指打卡机系统，不提供查询打卡时间，经常忘记啥时候该下班，是否需要多加半小时；于是购买了「小日常」APP，作为习惯每天记录自己的上班时间；快到下班时间打开 APP 查看打卡记录，再计算，操作路径较长，懒。
于是想到了快捷指令，官方概述：该 App 可让您合并多个 App 间的多个步骤，以创建功能强大的任务自动化。
花 15 分钟在 b 站看了几个教程视频后，有了点想法，这东西可以搞。
需求实现逻辑梳理：
当到达指定地点-公司； 自动记录打卡时间； 根据当前打卡时间推算出下班时间； 设置提醒事项，提醒时间为下班前 5 分钟 实现 step 1
新建快捷指令中添加，搜索位置 ==&amp;gt; 获取当前位置；
等等，我们是手指打卡，到达位置后的时间不一定是我手指触碰打卡机的时间，到楼下还得扫健康码、等电梯，时间获取不精确，下班早了是要扣钱的&amp;hellip;
step 1 手指打卡后，点击启动手机上的快捷指令； 创建快捷指令，「详细信息」内点击「添加到主屏幕」，自定义图标和名称，放到手可以轻松触碰的位置，打完卡后点击触发。
step 2 打卡逻辑梳理，满足以下条件即可
上班 下班 9:00 6:30 9:30 7:00 9:31 7:31 10:00 8:00 根据所需判断条件在快捷指令内搜索就行，非常方便。
### 整体实现如下 获取当前日期 格式化日期 格式化后的日期 - 930（9点半的时间节点） 如果 计算结果 小于或等于 0 将 日期 加上 34200 秒钟 否则 如果 计算结果 小于或等于 70 将 日期 加上 36000 秒钟 否则 文本 8:00（迟到） 结束条件 结束条件 显示预览 打卡时间；下班时间（出现提示框） 从 所有提醒事项 中查找 如果 存在之前设置的下班提醒 移除该提醒事项 否则 结束条件 计算 下班时间 减去 5分钟 将 下班啦 添加到提醒事项 设置 提醒时间 为下班前 5 分钟 over.
同时开启 iOS 和 Mac 的提醒事项同步；那么效果就很 Nice 😄
到点了，验证下结果；</content></entry><entry><title>Linux - 命令-rz和sz</title><url>/tech/linux/%E5%91%BD%E4%BB%A4-rz%E5%92%8Csz/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[rz &amp; sz 命令使用 🔧
 操作系统：macOS Catalina 10.15.7
软件版本：secureCRT Version 8.7.3 (build 2279)
 rz: Receive Zmodem
sz: Send Zmodem
rz 和 sz 都是使用 Zmodem 文件传输协议  
sz 从服务器传输文件到电脑，对于服务器来说，是发送（send），所以 sz
# 单个文件 $ sz {filename} # 多个文件 $ sz {filename1} {filename2} # 目录下文件 $ sz {dirname}/* 文件下载默认路径：~/Document
设置自定义路径：secureCRT --&gt; Preferences --&gt; General --&gt; Default Session --&gt; Edit Default Settings --&gt; X/Y/Zmodem
rz 从电脑上传文件到服务器，对于服务器来说，是接收（receive），所以 rz
# -be 解决文件乱码  $ rz -be # 弹框内选择要上传的文件 ]]></content></entry><entry><title>Mac - 终端Ohmyzsh设置主题</title><url>/tech/mac/%E7%BB%88%E7%AB%AFohmyzsh%E8%AE%BE%E7%BD%AE%E4%B8%BB%E9%A2%98/</url><categories><category>Mac</category></categories><tags><tag>Mac</tag></tags><content type="html">为 ohmyzsh 设置新的主题样式 🎉 点击跳转官方主题展示
$ vi ~/.zshrc # 找到这一行，修改为自己喜欢的主题名称 ZSH_THEME=&amp;#34;ys&amp;#34; # 修改保存后，使配置生效 $ source ~/.zshrc</content></entry><entry><title>Ios - 编译Wda问题记录</title><url>/tech/ios/%E7%BC%96%E8%AF%91wda%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html"><![CDATA[编译 webDriverAgent 遇到的问题记录&hellip;
获取 UDID 报错 方法一
打开 xcode --&gt; Window --&gt; Divices and Simulators --&gt; identifier，复制即可
方法二
打开 fidder --&gt; 位置 --&gt; xxx的iPhone --&gt; 信任设备，点击设备下方可以切换信息，复制 UDID 即可
xcode：Could not locate device support files.
⚠️ 上面方法一获取设备 UDID 的时候，遇到该提示
Could not locate device support files. This iPhone XR is running iOS 13.5.1 (17F80), which may not be supported by this version of Xcode. 原因是 Xcode 版本过低，不支持调试 13.5.1 的设备，查看当前 xcode 支持版本
$ cd /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/DeviceSupport $ ls 10.0 10.2 11.0 ... 可以 下载   手机对应的 DeviceSupport 版本，放到该目录下，重启 xcode，再次查看
⚠️ 再次遇到提示
dyld_shared_cache_extract_dylibs failed 参考 解决办法  
⚠️ 再次遇到提示
An error was encountered while enabling development on this device. Please try rebooting and reconnecting the device. (0xE8000076) 网上查了一下，说是因为 xcode 版本过低，手机版本过高，还是得升级 Xcode，郁闷&hellip; 先继续往下推进看看。
编译 WebDriverAgent 报错 问题：Messaging unqualified id
报错信息如下
/WebDriverAgent/WebDriverAgentLib/Categories/XCUIElement+FBPickerWheel.m: Messaging unqualified id /WebDriverAgent/WebDriverAgentLib/Categories/XCUIElement+FBTyping.m: Messaging unqualified id 解决
# 进入到项目路径下 $ cd ../WebDriverAgent/ $ xcodebuild -project WebDriverAgent.xcodeproj -scheme WebDriverAgentRunner -destination id={device_udid} GCC_TREAT_WARNINGS_AS_ERRORS=0 test # 13.5.1 手机版本过高，编译失败 xcodebuild -project WebDriverAgent.xcodeproj -scheme WebDriverAgentRunner -destination id=00008020-001A08D11A7A002E GCC_TREAT_WARNINGS_AS_ERRORS=0 test # 12.4.8 成功 xcodebuild -project WebDriverAgent.xcodeproj -scheme WebDriverAgentRunner -destination id=7017c3493f7a50f2c90a8ec56f1556b92089732c GCC_TREAT_WARNINGS_AS_ERRORS=0 test 出现图标即为成功了
]]></content></entry><entry><title>Ios - Tidevice命令汇总</title><url>/tech/ios/tidevice%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</url><categories><category>Ios</category></categories><tags><tag>Ios</tag></tags><content type="html"><![CDATA[让 iOS 拥有像安卓 adb 一样的命令行工具。
需求 IOS 手机也能像安卓一样，做一个桌面工具，支持：
 截图 获取手机信息 App 安装，启动，停止，查看 获取应用信息 指定应用性能采集（类似 PerfDog） 其他  最重要的是支持 Windows、Linux、Mac 跨平台使用。
工具确定  tidevice  感谢 codebluesky 发帖   &amp; taobao-iphone-device  
环境准备  电脑（先用 Mac 测试） Python 3.7 +（3.7.3 测试） 确保手机上安装有 WebDriverAgent   应用  安装 1. 安装 tidevice $ pip3 install -U tidevice ... Successfully installed colored-1.4.2 simple-tornado-0.2.0 tidevice-0.1.11 2. 安装 WebDriverAgent  教程  
编译相关问题参考 &raquo;&gt; 桌面文档 - WebDriverAgent编译遇到的问题.md
tidevice 命令行使用 查看版本号
$ tidevice version tidevice version 0.1.11 列出连接设备
$ tidevice list List of apple devices attached # json 格式列出设备信息(uid&amp;name) $ tidevice list --json 应用管理
# 安装应用 $ tidevice install example.ipa # 指定设备安装 $ tidevice --udid $UDID install https://example.org/example.ipa # 卸载应用 $ tidevice uninstall com.example.demo # 启动应用 $ tidevice launch com.example.demo # 停止应用 $ tidevice kill com.example.demo # 查看已安装应用 $ tidevice applist ]]></content></entry><entry><title>Andorid - 安装包加固后闪退</title><url>/tech/andorid/%E5%AE%89%E8%A3%85%E5%8C%85%E5%8A%A0%E5%9B%BA%E5%90%8E%E9%97%AA%E9%80%80/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"><![CDATA[这版本测试时，出现装包后启动 CRASH 的情况（仅在部分机型上面出现），出现该问题后，APP 一直无法正常启动，重新安装后，启动正常；尝试定位问题。
闪退日志：
java.lang.UnsatisfiedLinkError:dlopenfailed: library &#34;/data/data/cn.wejuan.reader/.jiagu/libjiagu.so&#34; not found 问题排查：
  看日志应该是加固的问题， 启动时文件创建失败导致未找到；
  没有任何 APP 相关的报错信息；
  非必现。
  BUG 复现步骤：
 手动重复安装卸载；未复现 通过命令快速重复安装后卸载；尝试 20 次左右复现了  闪退日志与之前一样，依然无法具体定位问题
贴上快速安装卸载脚本，待问题解决，验 BUG 用。
#!/bin/zsh # 该脚本为了复现 BUG：某些机型启动出现 CRASH，报错日志为加固问题 # 在小米6上复现方法：快速安装启动 # 循环 # 1. 安装 apk； # 2. 启动 APP； # 3. 点击弹框内确定进入APP；【注释该行：经测试，与是否进入APP，关系不大】 # 4. 卸载 APP echo &#34;Usage : ./resart.sh {apk_path} {loop_count}&#34; echo &#34;Package Name: $1&#34;echo &#34;Loop Count : $2&#34; count=$2 # 循环次数 # 协议弹窗确定按钮 x y 坐标 agreement_box_x=727 agreement_box_y=1303 # 系统权限弹窗 x y 坐标 box_x=800 box_y=1800 for ((i=1; i&lt;=count; i++)) do adb install $1 adb shell am start -n &#34;cn.wejuan.reader/com.esbook.reader.activity.ActLoading&#34; sleep 2 # adb shell input tap $agreement_box_x $agreement_box_y # sleep 0.5 # adb shell input tap $box_x $box_y # sleep 0.5 # adb shell input tap $box_x $box_y # sleep 3 adb uninstall cn.wejuan.reader echo &#34;========= Loop count &gt;&gt;&gt; $i============&#34; done ]]></content></entry><entry><title>Andorid - 闪退日志提取</title><url>/tech/andorid/adb-%E5%91%BD%E4%BB%A4%E9%97%AA%E9%80%80%E6%97%A5%E5%BF%97%E6%8F%90%E5%8F%96python/</url><categories><category>Andorid</category></categories><tags><tag>Andorid</tag></tags><content type="html"><![CDATA[安卓手机测试过程中，遇到应用闪退，通常需要在 BUG 信息上附加崩溃日志，便于开发同学快速定位问题。
存储日志命令为：adb logcat -v time &gt; crash_log.log
这个方法抓到的日志过多，很多都是无用的系统日志或级别过低的打印日志，所以需要做一次过滤，logcat 可以根据日志等级过滤。将日志级别设置为 ERROR，就可以过滤掉一大部分无用信息。
命令修改为：adb logcat -v time *:E &gt; crash_log.log
 备注：
 星号 * 代表日志任意 tag 都只输出 Error 级别以上日志； MacOS 命令行直接使用 *:E 会报错 no matches found: *:E，所以需要添加双引号或转义符来解决：&quot;*:E&quot; 或 \*:E   获取到日志后，会发现，还是存在一部分系统的错误日志，如何再次过滤呢？
目标：仅需要某个闪退的全部堆栈信息
思路：
 通过命令行做第一次过滤，获取到 ERROR 级别的原始日志； 逐行读取日志，如果查找到关键字 FATAL EXCEPTION: main 则代表出现一次闪退，记录该进程 PID 存储到列表内； 判断当 PID 列表非空时，创建日志文件，将该 PID 的所有日志写入到新文件内。  这样就能满足需求了，接下来代码实现，验证效果。
获取日志 人工操作步骤为：命令行输入命令，获取日志后，Ctrl+C 关闭日志
代码也一样，实现方法：
 模拟命令行：subprocess模块 等待日志获取：安卓日志缓冲区一般为64KB，可以通过 time.sleep() 暂停程序 5 秒（可以自定义时间，我是感觉够用了）； Ctrl+C：通过命令杀死 adb logcat 进程  def log_cat(file_path, device=&#34;&#34;): &#34;&#34;&#34;获取 adb 日志 &#34;&#34;&#34; command = rf&#34;adb {device}logcat -v time \*:E &gt; {file_path}&#34; subprocess.Popen(command, shell=True) time.sleep(5) try: if platform.system() == &#34;Darwin&#34; or &#34;Linux&#34;: subprocess.call( &#34;kill -9 $(ps -ef | grep &#39;adb logcat&#39; | sed -n 1p | awk &#39;{print $2}&#39;)&#34;, shell=True ) else: # Windows 不知道能否生效，网上查的这个方法，没有机器测试 subprocess.Popen(&#34;taskkill /F /IM adb.exe&#34;) except Exception as e: logging.warning(f&#34;Kill「adb logcat」called Exception，message：{e}&#34;) 统计出现闪退次数 关键字：闪退日志每次出现都会带一行关键字 FATAL EXCEPTION: main，FATAL 是日志级别，比 ERROR 更高一级，类似 Python 中的 critical，无法使用的状态，所以当遇到这一行日志时，我就认为出现闪退了；
第二步的实现思路为：逐行读取保存的日志文件，出现关键字就获取当前进程号，并添加到列表中，最后统计列表长度即可。
def get_crash_pid_list(file_path): &#34;&#34;&#34;读取日志，获取出现关键字（crash）的次数 &#34;&#34;&#34; keyword = &#34;FATAL EXCEPTION: main&#34; crash_pid = [] with open(file_path, encoding=&#34;utf-8&#34;) as f: for line in f.readlines(): if keyword in line: # 提取出日志行内所有数字（日期 + PID） data = re.findall(r&#34;\d+&#34;, line) pid = data[-1] crash_pid.append(pid) logging.info(f&#34;Crash PID list &gt;&gt;&gt; {crash_pid}&#34;) return crash_pid 转储闪退日志 这里需要进行一次判断：
 如果不存在闪退，直接给出提示，退出程序 如果存在，创建新的日志文件，写入设备信息，根据进程号提取日志  获取设备信息 日志提交后，被开发同学问过几次机型和系统，索性就直接加到日志里面吧
def get_device_info(device=&#34;&#34;): &#34;&#34;&#34;获取设备信息 &#34;&#34;&#34; model = os.popen(f&#34;adb {device}shell getprop ro.product.model&#34;).read().strip() manufacturer = os.popen(f&#34;adb {device}shell getprop ro.product.manufacturer&#34;).read().strip() version = os.popen(f&#34;adb {device}shell getprop ro.build.version.release&#34;).read().strip() sdk_version = os.popen(f&#34;adb {device}shell getprop ro.build.version.sdk&#34;).read().strip() output = f&#34;DeviceInfo: {manufacturer}{model}| Android {version}(API {sdk_version})&#34; return output 转存日志 逐行读取，匹配进程号，写入到新的日志文件内，如果不填，则走默认路径
def dump_crash_log(file_path=&#34;&#34;, dump_path=&#34;&#34;, device=&#34;&#34;): &#34;&#34;&#34;转储带有 crash pid 的日志 &#34;&#34;&#34; # 设置默认转储路径 if not file_path: file_path = &#34;logcat.log&#34; if not dump_path: dump_path = &#34;logcat_crash.log&#34; if device: device = f&#34;-s {device}&#34; log_cat(file_path, device) device_info = get_device_info(device) pid_list = get_crash_pid_list(file_path) if pid_list: # 创建转储日志并写入 with open(dump_path, &#34;w+&#34;, encoding=&#34;utf-8&#34;) as f: f.write(f&#34;{&#39;-&#39; * 50}\n&#34;) f.write(f&#34;{device_info}\n共出现 {len(pid_list)}次闪退\n&#34;) f.write(f&#34;{&#39;-&#39; * 50}\n&#34;) # 读取原始日志 with open(file_path, encoding=&#34;utf-8&#34;) as f1: for line in f1.readlines(): for pid in pid_list: if pid in line: if &#34;FATAL&#34; in line: f.write(&#34;\n# begging of crash --- &gt;&gt;&gt;\n&#34;) f.write(line) logging.info(f&#34;Crash log path: {dump_path}&#34;) else: logging.info(f&#34;Not found &#39;FATAL EXCEPTION: main&#39; in {file_path}&#34;) if __name__ == &#39;__main__&#39;: dump_crash_log() 最后执行效果如下：
控制台输出
[ I 201231 13:57:05 dump_crash_log:44 ] PID LIST &gt;&gt;&gt; [&#39;26997&#39;, &#39;28084&#39;, &#39;6964&#39;] [ I 201231 13:57:05 dump_crash_log:88 ] Crash log path: logcat_crash.log 目录结构
 dump_crash_log.py logcat.log logcat_crash.log  日志内容
DeviceInfo: HUAWEI ELE-AL00 | Android 10 (API 29) 共出现 3 次闪退 # begging of crash --- &gt;&gt;&gt; 11-02 17:39:58.802 E/AndroidRuntime(26997): FATAL EXCEPTION: main 11-02 17:39:58.802 E/AndroidRuntime(26997): Process: com.esbook.reader, PID: 26997 11-02 17:39:58.802 E/AndroidRuntime(26997): java.lang.IllegalArgumentException: 这是异常信息 11-02 17:39:58.802 E/AndroidRuntime(26997): at 这是堆栈信息 11-02 17:39:58.802 E/AndroidRuntime(26997): at 这是堆栈信息 ... # begging of crash --- &gt;&gt;&gt; 11-02 17:55:39.306 E/AndroidRuntime(28084): FATAL EXCEPTION: main 11-02 17:55:39.306 E/AndroidRuntime(28084): Process: com.esbook.reader, PID: 28084 11-02 17:55:39.306 E/AndroidRuntime(28084): java.lang.NullPointerException: 这是异常信息 11-02 17:55:39.306 E/AndroidRuntime(28084): at 这是堆栈信息 11-02 17:55:39.306 E/AndroidRuntime(28084): at 这是堆栈信息 ... # begging of crash --- &gt;&gt;&gt; 11-02 18:15:37.625 E/AndroidRuntime( 6964): FATAL EXCEPTION: main 11-02 18:15:37.625 E/AndroidRuntime( 6964): Process: com.esbook.reader, PID: 6964 11-02 18:15:37.625 E/AndroidRuntime( 6964): at 这是堆栈信息 11-02 18:15:37.625 E/AndroidRuntime( 6964): at 这是堆栈信息 ...  大功告成，这样提取日志就会方便许多啦！😄
]]></content></entry><entry><title>Python - Else语法总结</title><url>/tech/python/else%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[记录一个小知识…
问题 阅读别人代码，有点疑惑，精简后如下：
def code_example(arg=None): for i in range(5): if arg: break else: print(&#39;else branch&#39;) 循环语句后面直接跟了 else 语句，未报错，程序正常运行。一般 else 都是配合判断语句用，那么这里的 else 是什么作用呢？
尝试
for i in range(2): print(i) else: print(&#34;else branch&#34;) &gt;&gt;&gt; 0 1 else branch test01：根据打印信息发现，for 循环正常执行完成后执行了 else 分支；
for i in range(2): continue else: print(&#34;else branch&#34;) &gt;&gt;&gt; else branch test02：循环体内增加 continue 跳出，执行完成循环后，正常执行 else 分支；
for i in range(2): break else: print(&#34;else branch&#34;) &gt;&gt;&gt; test03：如果 break 掉循环，打断循环，没有任何输出，也就是不走 else 分支；
def test(): for i in range(2): return else: print(&#34;else branch&#34;) &gt;&gt;&gt; test04：尝试 return 语句，打断循环，也是不走 else 分支。
结论 for … else …
 仅当循环体全部执行完成，才执行 else 分支； 当循环过程被打断，则不执行 else 分支。  扩展 Python 支持 else 语句汇总：
 for … else … while … else … try … except … else … if … elif … else …  while 与 for 循环相同步骤测试，结论一样
try
 当 try 内无异常执行完成后，执行 else 分支； 当 try 内出现异常，执行到 except，不再执行 else 分支。  def test_01(): try: print(&#34;try&#34;) except: print(&#34;except&#34;) else: print(&#34;else&#34;) &gt;&gt;&gt; try else def test02(): try: 5 / 0 except: print(&#34;except&#34;) else: print(&#34;else&#34;) &gt;&gt;&gt; except 总结  for、while 循环 当循环语句全部正常执行完成(包括 continue)，会继续执行 else 分支；当循环语句被打断(break\return)，不再执行 else 分支 try 异常处理 当 try 语句无异常执行完成时，会继续执行 else 分支；当抛出异常后，不再执行 else 分支 if 条件判断 不符合 if 或者 elif，才执行 else 分支  ]]></content></entry><entry><title>Python - 递归学习与练习</title><url>/tech/python/%E9%80%92%E5%BD%92%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%83%E4%B9%A0/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[递归学习，通过汉诺塔游戏加强理解！
递归 在一个函数内部调用自身本身，就是递归函数。
阶乘
5 的阶乘为：5*4*3*2*1
n 的阶乘为：1*2*3*…*(n-1)
所以其实就是n*(n-1)的循环，只有当n=1时，需要特殊处理。
# 递归实现，暂不考虑负数和零 def fact(n): if n == 1: return 1 return n * (fact(n-1)) &gt;&gt;&gt; fact(5) 120 当计算fact(5)时，函数运算过程如下：
&gt;&gt;&gt; fact(5) ===&gt; 5 * fact(4) ===&gt; 5 * (4 * fact(3)) ===&gt; 5 * (4 * (3 * fact(2))) ===&gt; 5 * (4 * (3 * (2 * fact(1)))) ===&gt; 5 * (4 * (3 * (2 * 1))) ===&gt; 5 * (4 * (3 * 2)) ===&gt; 5 * (4 * 6) ===&gt; 5 * 24 ===&gt; 120 递归函数的优点是定义简单，逻辑清晰。理论上，所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰。
使用递归函数需要注意防止栈溢出。在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。
Python 3.7 的最大递归深度为 998，如果超出就会报错，如：
&gt;&gt;&gt; fact(999) Traceback (most recent call last): File &#34;test.py&#34;, line 28, in fact if n == 1: RecursionError: maximum recursion depth exceeded in comparison 当然这个递归深度可以修改，998 只是一个默认值
import sys sys.setrecursionlimit(1000) # 设置最大递归深度 1000 # 源码解释 sys.py def setrecursionlimit(n): # real signature unknown; restored from __doc__ &#34;&#34;&#34; setrecursionlimit(n) Set the maximum depth of the Python interpreter stack to n. This limit prevents infinite recursion from causing an overflow of the C stack and crashing Python. The highest possible limit is platform- dependent. &#34;&#34;&#34; pass 练习 汉诺塔（http://www.hannuota.cn）
游戏介绍 源于印度一个古老传说的益智玩具，大梵天创造世界的时候做了三根金刚石柱子，在一根柱子上从下往上按照大小顺序摞着 64 片黄金圆盘，并且预言当僧侣将 64 片圆盘从 A 柱移动到 C 柱时，世界就会在一声霹雳中毁灭。
大概就是这个样子
游戏规则
 全部圆环从 A 柱移动到 C 柱视为完成 每次只能移动一个圆环，必须在三个柱子间移动 在小圆环上不能放大圆环，小圆环在上，大圆环在下  游戏原理 当看到这个游戏规则时，可能会产生疑惑，这个跟递归有什么关系呢？先别着急，慢慢往下分析。
当圆环数为 1 时，完成步骤：
A &ndash;&gt; C
非常简单，直接把圆环从 A 放到 C 就可以完成。
增加难度，当圆环数为 2 时，完成步骤：
A &ndash;&gt; B A &ndash;&gt; C
为方便描述，P 代表圆盘，P2 &gt; P1
当我们想把第 P2 移动到 C 柱时，由于每次只能移动一个圆环，所以先要把 P1 移动到 B 柱上，P2 才可以移动到 C 柱。
继续增加难度，当圆环数为 3 时，目标是 P3 移动到 C 柱，反推一下：只有当 P3 上面没有其他圆盘时，才可以移动，所以 P2 和 P1 需要移动到 B 柱。
 P1 移动到 C 柱（保证 P2 可以移动，先移开） P2 移动到 B 柱 P1 再次移动到 B（C 柱就空出来了） P3 移动到 C 柱（变成了 P2 移动到 C 柱的问题） P1 移动到 A 柱（变成了 P1 移动到 C 柱的问题） P2 移动到 C 柱  完成步骤如下：
A &ndash;&gt; C A &ndash;&gt; B C &ndash;&gt; B A &ndash;&gt; C B &ndash;&gt; A B &ndash;&gt; C A &ndash;&gt; C
图示：
再次梳理一下 3 个圆盘的移动规则，为满足将全部圆盘移动到 C 柱：
 前两个圆盘移动到 B 柱； 第三个圆盘移动到 C 柱； 两个圆盘移到 C 柱；  所以如果为 n 个圆盘的话，那么：
 n-1 个圆盘移动到 B 柱； n 移动到 C 柱； n-1 个圆盘从 B 柱移动到 C 柱子  所以，这是一个递归的问题，代码实现
def hanoi(n, a, b, c): if n == 1: print(f&#34;{a} --&gt; {c}&#34;) return hanoi(n-1, a, c, b) hanoi(1, a, b, c) hanoi(n-1, b, a, c) &gt;&gt;&gt; hanoi(3, &#34;A&#34;, &#34;B&#34;, &#34;C&#34;) 题外话
梵天说当僧侣完成 64 层汉诺塔时，世界就会毁灭，那么完成它到底需要多长时间呢？
根据上面的规律可得：
f(n) = f(n-1) + 1 + f(n-1)` `f(n) = 2f(n-1) + 1 移动 1 个圆盘： f(1) = 1 = 2^1-1
移动 2 个圆盘： f(2) = 3 = 2^2-1
移动 3 个圆盘： f(3) = 7 = 2^3-1 … f(64) = 2^{64}-1
&gt;&gt;&gt; (2**64 - 1) / (60*60*24*365) 584942417355.072 得出结果 5800 亿年，宇宙形成到现在经过了 138 亿年，所以这么久远的未来是想象不到的&hellip; 不过人家梵天的数字底子是真不赖。
结语 递归学习是跟随廖雪峰老师的教程走的，后续理解是看 B 站李永乐老师的讲解明白的，感谢。我的文字水平有限，如果表述不清楚，就看下方视频 + 多玩游戏，肯定能弄明白的。
 视频地址  
 游戏地址  
 教程地址  
当理解原理之后，玩汉诺塔很自然的就用最少步骤完成，知识就是力量，感谢阅读。
]]></content></entry><entry><title>Git - 遇到的报错记录</title><url>/tech/git/%E9%81%87%E5%88%B0%E7%9A%84%E6%8A%A5%E9%94%99%E8%AE%B0%E5%BD%95/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[ 使用过程中遇到的报错信息记录。
 Operation timed out 问题：下载仓库时报错 443
$ git clone xxx Cloning into &#39;xxx&#39;... fatal: unable to access &#39;xxx&#39;: Failed to connect to github.com port 443: Operation timed out 取消全局代理，问题解决。
$ git config --global --unset http.proxy $ git config --global --unset https.proxy Mac 在无线设置中，代理项内手动关闭也行。
not a git repository 问题：fatal: not a git repository (or any of the parent directories)
原因：命令必须在 git 仓库目录内执行（git init除外），在仓库目录外执行是没有意义的
$ git add readme.md fatal: not a git repository (or any of the parent directories) fatal: pathspec &#39;readme.md&#39; did not match any files 添加某个文件时，该文件必须在当前目录下存在，用 ls 或者 dir 命令查看当前目录的文件：
 文件是否存在 是否写错了文件名  failed to push some refs to xxx 问题：error: failed to push some refs to xxx
原因：远程仓库有本地未同步的文件
$ git push origin main error: failed to push some refs to &#39;https://github.com/abeelan/abeelan.github.io.git&#39; # 重新提交即可 $ git pull --rebase origin main $ git push origin main unable to access（403） remote: You are not allowed to push code to this project. fatal: unable to access &#39;https://gitlab.joyame.com/test/sixdu_u2.git/&#39;: The requested URL returned error: 403 gitlab 提交一直提示权限不够，更新权限到主程序员即可。
Device not configured 问题：fatal: could not read Username for &lsquo; https://github.com  &rsquo;: Device not configured
Changes not staged for commit On branch master Changes not staged for commit: 推送不到远程仓库，提示该信息。
解决：git commit -am &quot;message&quot;，添加一个 -a 参数，表示新增。
命令行中文乱码 问题：使用命令行提交时，中文乱码。
$ git commit -m &#34;selenium cookies api&#34; [main 2cc063e] selenium cookies api 2 files changed, 448 insertions(+) create mode 100644 &#34;16.\351\235\242\350\257\225/\346\265\213\350\257\225\350\267\257\347\272\277\345\217\202\350\200\203.md&#34; create mode 100644 &#34;5.selenium/\344\275\277\347\224\250cookies.md&#34; 解决
$ git config --global core.quotepath false ]]></content></entry><entry><title>Git - Git命令速查</title><url>/tech/git/%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5%E7%AC%94%E8%AE%B0/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[常用命令记录，速查速记&hellip;
$ brew install git $ git --version # 默认安装路径 /usr/local/bin/git  初始化仓库提示命令 创建新版本库 git clone https://gitlab.xxx.com/test/xxx.git touch README.md git add README.md git commit -m &#34;add README&#34; 本地项目已存在但是未添加版本管理 cd existing_folder git init git remote add origin https://gitlab.xxx.com/test/xxx.git git add . git commit -m &#34;Initial commit&#34; 本地项目已存在，更换远程仓库地址 cd existing_repo git remote rename origin old-origin git remote add origin https://gitlab.joyame.com/test/sixdu_u2.git 提交本地仓库后撤销 # 查看提交记录 $ git log # 回退到指定版本 $ git reset --hard &lt;commit-id&gt; 全局配置 # 查看本机 git 配置 $ git config --list # 全局配置 $ git config --list --global # 当前仓库配置 $ git config --list --local # --global 参数：表示机器上所有的仓库都会使用这个配置 # 如果不加，则只对当前仓库起作用 # 设置全局用户名和邮箱 后续本机器的提交都展示此信息 $ git config --global user.name &#34;Your Name&#34; $ git config --global user.email &#34;emai@example.com&#34; # 设置 git 命令行颜色 $ git config --global color.ui true # 设置 git 默认分支名为 main git config --global init.defaultBranch main # 配置别名 简写 co表示checkout，ci表示commit，br表示branch # https://www.liaoxuefeng.com/wiki/896043488029600/898732837407424 $ git config --global alias.co checkout $ git config --global alias.ci commit $ git config --global alias.br branch # 通过 git last 查看最后一次提交记录 $ git config --global alias.last &#39;log -1&#39; # 通过 git lg 查看分支合并情况 $ git config --global alias.lg &#34;log --color --graph --pretty=format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&#34; # 忽略特殊文件 # https://www.liaoxuefeng.com/wiki/896043488029600/900004590234208 # 在线生成 https://gitignore.itranswarp.com/ 本地仓库 创建本地仓库 # 创建本地目录 $ mkdir git_notes $ cd git_notes # 初始化目录 # 该目录下会自动创建 .git 隐藏目录 $ git init $ ls -al .git 提交文件到本地仓库 # 新建文件 $ cd git_notes $ echo &#34;git notes&#34; &gt; readme.md # 1. 提交暂存区 # 添加单个文件到本地仓库 $ git add readme.md # 添加目录下所有文件到本地仓库 $ git add . # 2. 提交到分支 # 将暂存区的所有文件提交到当前分支 $ git commit -m &#34;first commit&#34; 其他命令 # 查看状态比如当前目录下文件是否添加仓库，是否提交等等 $ git status # 查看文件最新修改的内容与之前版本的不同 $ git diff readme.md # 查看所有提交记录 # 显示版本号、分支、提交的备注信息、提交人、日期 $ git log # 仅显示版本号、分支、提交的备注信息 $ git log --pretty=oneline # log 页面，按 q 返回到命令行 # 查看历史命令，通常用来查看未来版本号 $ git reflog 撤销修改 # 将文件恢复到最近一次 add 或 commit 的状态 # -- 代表当前分支 $ git checkout -- readme.md 删除文件 $ git rm readme.md $ git commit -m &#34;remove readme.md&#34; 回退版本 # 回退上一版本 $ git reset --hard HEAD^ # 回退上上个版本 $ git reset --hard HEAD^^ # 回退到前 100 个版本 $ git reset --hard HEAD~100 # 回退到指定版本，commit_version 通过 git log 查看 # 版本号不写全也可以，多写几位保证唯一 $ git reset --hard {commit_version} 远程仓库 配置通过 ssh 连接远程仓库（使用 https 可以忽略） ssh 速度快，https 速度慢且需要输入口令
 创建 ssh 密钥对，信息一般为是邮箱  $ cd ~/.ssh $ ssh-keygen -t rsa -C &#34;emai@example.com&#34; # 一路回车，得到公钥和私钥 # 名称别改，用 git 命令的时候，会默认找 id_rsa $ ll id_rsa # 私钥 id_rsa.pub # 公钥 将公钥信息配置到 github   Github 主页 -&gt; 点击头像 -&gt; Settings -&gt; 左侧边栏 SSH and GPG keys -&gt; SSH keys -&gt; New SSH key Title：自定义 Key：填写公钥，把 id_rsa.pub 内复制粘贴过来 点击 Add SSH key  修改远程仓库 URL 为 SSH  $ git remote set-url origin git@github.com:username/repository.git $ git pull 克隆仓库 $ git clone git@github.com:lanyangbi/lanyangbi.github.io.git 关联远程仓库 # orgin 代表的是远程仓库，这是默认叫法 $ git remote add origin git@github.com:lanyangbi/lanyangbi.github.io.git # 查看远程仓库 $ git remote origin # 查看详细信息 $ git remote -v origin	https://github.com/lanyangbi/lanyangbi.blog.git (fetch) origin	https://github.com/lanyangbi/lanyangbi.blog.git (push) # 取消关联 $ git remote rm origin 提交内容到远程仓库 # 修改分支名称为 main 与远程分支相同 # 解决报错：error: src refspec main does not match any $ git branch -m master main # 首次提交时加上 -u 代表关联分支，后续就可以不用了 $ git push -u origin main $ git push orgin main 查看当前分支 # * 代表当前分支 $ git branch * dev master # 查看全部分支，q 退出 $ git branch -a 创建并切换分支 # 创建分支后切换 $ git branch dev $ git checkout dev # 也可以使用一条命令 -b 表示创建并切换到新分支 $ git checkout -b dev 合并指定分支到当前分支 # 当在 dev 有文件修改后 # 需要先切换到 master 分支然后合并 $ git checkout master $ git merge dev 删除分支 # 当分支合并到 master 后，分支就可以删除啦 $ git branch -d dev 冲突解决  文件冲突  
 多人协作：分支冲突  
保存工作区 $ git stash Saved working directory and index state WIP on dev: f52c633 add merge # 查看保存的工作区 $ git stash list # 恢复工作区 $ git stash apply # 恢复后，需要手动删除该工作区 $ git stash drop # 恢复的同时，删除工作区 $ git stash pop # 可以保存多个 stash，恢复指定 stash $ git stash apply stash@{0} 复制特定提交到当前分支 # 可以将修改 bug 后提交的修改复制到当前开发分支，避免重复劳动 $ git cherry-pick {commit_version} 强制删除未合并过的分支 $ git branch -D dev 创建标签 # 创建标签 $ git tag v1.0 # 对指定 commit 打标签 $ git tag v1.1 f52c633 # 创建带有说明的标签 $ git tag -a v1.2 -m &#34;version 1.2 released&#34; 1094adb 查看标签 # 查看标签 $ git tag # 查看标签信息 $ git show v1.0 推送标签到远程仓库 #推送指定标签 $ git push orgin v1.0 # 推送全部标签 $ git push orgin --tags 删除标签 # 删除本地标签 $ git tag -d v1.0 # 删除远程仓库标签 $ git push orgin :refs/tags/v1.0 子仓库 # 当前仓库下拉取子仓库 $ git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod # 更新子仓库 $ git submodule update --init 参考    廖雪峰 Git 教程  
   Git 实战通关  
  ]]></content></entry><entry><title>Blog - Hugo 搭建博客（V1）</title><url>/tech/blog/hugo-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2v1/</url><categories><category>Blog</category></categories><tags><tag>Blog</tag></tags><content type="html"><![CDATA[Hugo 是使用 Go 语言编写的 静态网站生成器  ，页面编译速度快，支持跨平台、皮肤自定义，方便部署。
 Hugo is a fast and modern static site generator written in Go, and designed to make website creation fun again.
  搭建教程  ，官方教程写的非常详细，下文是我自己的搭建记录 👀
安装 使用 Mac Homebrew 进行安装
# 跳过 brew 检查更新（可以忽略） $ export HOMEBREW_NO_AUTO_UPDATE=true # 开始安装 $ brew install hugo # 出现下面内容就是安装完成了 ==&gt; Summary 🍺 /usr/local/Cellar/hugo/0.55.0: 31 files, 40.6MB 建站 创建一个自定义路径，执行命令
$ hugo new site $YourBlogName 这样就建立了自己的站点，目录接口如下：
. ├── archetypes # 存放生成博客的模版 ├── assets # 存放被 Hugo Pipes 处理的文件 ├── config # 配置文件；支持 JSON YAML TOML 三种格式配置文件 ├── content # 存放博客 markdown 文件 ├── data # 存放 Hugo 处理的数据 ├── layouts # 存放布局文件 ├── static # 存放静态文件 图片 CSS JS文件 └── themes # 存放主题 目前无法使用，还需要设置网站主题。
添加主题  主题库   可供挑选，以 Sam 为例，下载方法：
$ cd $YourBlogName $ git init $ git clone https://github.com/victoriadrake/hugo-theme-sam.git themes/sam # 选好主题后注意查看最低支持的 hugo 版本 配置站点
将 exampleSite/config.toml 复制替换 $YourBlogName/config.toml 即可，在 config.toml 文件内进行基础设置， Sam 主题，可以在配置内添加主页的主题背景图/视频/背景色。
视频/图片存放路径：themes/sam/static/
[[params.videoBackground.sources]] source = &#34;sample_video.mp4&#34; type = &#34;video/mp4&#34; poster = &#34;background.png&#34; [params.videoBackground] overlay = &#34;rgba(0, 0, 0, 0.4)&#34; # 这是背景色+透明度 # 设置分类及链接 [[params.mainMenu]] link = &#34;test_summary&#34; text = &#34;Test Summary&#34; [[params.mainMenu]] link = &#34;python&#34; text = &#34;Python&#34; [[params.mainMenu]] link = &#34;essay&#34; text = &#34;Essay&#34; [[params.mainMenu]] link = &#34;about/about/&#34; text = &#34;Who am I ?&#34; 访问 命令行启动
$ hugo sever -D 在浏览器中访问 localhost:1313  ，刷新页面可以实时预览。
写博客 创建文章
$ hugo new about/about.md 该命令就是在 /content/ 目录下创建了 about 目录，该目录内包含一个 about.md 的文件，这个文件就是第一篇博客的名称。可以通过 http://localhost:1313/about/about/ 访问。
其实这个 about 目录就是上面我配置文件内最后一个菜单的关联目录，通过点击主页的 Who am I ? 也可以实现跳转。
同理，可以在 content 目录下根据自己的喜好，建立不同的分类，来进行文章管理。
选择其他主题也大同小异&hellip;
博客静态页面搭建完成后，接下来就需要对外发布展示。但是还没有自己的服务器和注册域名，如何发布呢？
这里要感谢 github 提供的 github.io，可以做到这一点，并且免费。
创建 github.io 首先 注册   创建账号；登录 github 个人页面，新建仓库
这里新建两个仓库：
  blog
这个仓库用于存在 Hugo 博客的内容文件，如果本地存储的话，不创建也是可以的
  用户名.github.io
对外发布的仓库，这是 github 免费提供的可访问域名，仓库名格式必须为 用户名.github.io，用户名可以通过点击头像查看
创建完成后，进入该仓库的设置页面内，设置一下页面模版，不然会展示不出来网页样式
![image-20210121141839306](/Users/lan/Library/Application Support/typora-user-images/image-20210121141839306.png)
  关联远程仓库   blog 关联远程仓库
进入博客目录，关联远程仓库
$ cd $blogPath $ git remote add orgin https://github.com/$blogProject   用户名 .github.io 关联远程仓库
将 hugo 内容转为静态网页文件，会在当前目录生成 public 目录
$ hugo --theme=sam --buildDrafts --baseUrl=&#34;https://name.github.io/&#34; $ cd public $ git remote add origin git@github.com:$name/$name.github.io.git $ git add -A $ git commit -m &#34;first commit&#34; $ git push -u origin master   遇到的报错 $ hugo --theme=sam --buildDrafts --baseUrl=&#34;https://name.github.io/&#34; ERROR 2021/01/20 22:38:04 error: failed to transform resource: POSTCSS: failed to transform &#34;css/main.css&#34; (text/css): PostCSS not found; install with &#34;npm install postcss-cli&#34;. See https://gohugo.io/hugo-pipes/postcss/ 按照提示 npm install postcss-cli 进行下载：
$ npm install postcss-cli 下载完成后，再次执行，依然报错：
$ hugo --theme=sam --buildDrafts --baseUrl=&#34;https://name.github.io/&#34; Building sites … /Users/lanyangbi.blog/node_modules/fs-extra/lib/mkdirs/make-dir.js:85 } catch { ^ SyntaxError: Unexpected token { at createScript (vm.js:80:10) at Object.runInThisContext (vm.js:139:10) at Module._compile (module.js:617:28) at Object.Module._extensions..js (module.js:664:10) at Module.load (module.js:566:32) at tryModuleLoad (module.js:506:12) at Function.Module._load (module.js:498:3) at Module.require (module.js:597:17) at require (internal/module.js:11:18) at Object.&lt;anonymous&gt; (/Users/lanyangbi.blog/node_modules/fs-extra/lib/mkdirs/index.js:3:44) ERROR 2021/01/21 14:16:51 error: failed to transform resource: exit status 1 Total in 231 ms Error: Error building site: logged 1 error(s) 该问题原因是 node 版本过低，进行升级：
# 查看 node 版本号 $ node -v v8.14.1 # 查看 node 发布版本 $ nvm list-remote # 安装最新版，通过淘宝镜像下载更快 $ export NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node $ nvm install v15.6.0 # 切换 node 版本，第二行是将该版本设置为默认版本 $ nvm use v15.6.0 $ nvm alias default v15.6.0 升级 node 版本后，依然报错
$ hugo --theme=sam --buildDrafts --baseUrl=&#34;https://name.github.io/&#34; Building sites … node:internal/modules/cjs/loader:928 throw err; ^ Error: Cannot find module &#39;postcss&#39; Require stack: - /Users/name.blog/node_modules/postcss-cli/index.js - /Users/lanyangbi.blog/node_modules/postcss-cli/bin/postcss at Function.Module._resolveFilename (node:internal/modules/cjs/loader:925:15) at Function.Module._load (node:internal/modules/cjs/loader:769:27) at Module.require (node:internal/modules/cjs/loader:997:19) at require (node:internal/modules/cjs/helpers:92:18) at Object.&lt;anonymous&gt; (/Users/lanyangbi.blog/node_modules/postcss-cli/index.js:14:17) at Module._compile (node:internal/modules/cjs/loader:1108:14) at Object.Module._extensions..js (node:internal/modules/cjs/loader:1137:10) at Module.load (node:internal/modules/cjs/loader:973:32) at Function.Module._load (node:internal/modules/cjs/loader:813:14) at Module.require (node:internal/modules/cjs/loader:997:19) { code: &#39;MODULE_NOT_FOUND&#39;, requireStack: [ &#39;/Users/name.blog/node_modules/postcss-cli/index.js&#39;, &#39;/Users/name.blog/node_modules/postcss-cli/bin/postcss&#39; ] } ERROR 2021/01/21 14:43:13 error: failed to transform resource: exit status 1 Total in 247 ms Error: Error building site: logged 1 error(s) 找不到模块，继续安装：
# 使用淘宝镜像安装 $ npm config set registry https://registry.npm.taobao.org $ npm install postcss 安装后再次执行，还是报错：
$ hugo --theme=sam --buildDrafts --baseUrl=&#34;https://name.github.io/&#34; Building sites … Plugin Error: Cannot find module &#39;autoprefixer&#39; Require stack: - /Users/name.blog/node_modules/postcss-cli/index.js - /Users/name.blog/node_modules/postcss-cli/bin/postcss&#39; ERROR 2021/01/21 14:52:28 error: failed to transform resource: exit status 1 Total in 247 ms Error: Error building site: logged 1 error(s) 继续安装：
$ npm install autoprefixer 泪目，终于成功了～ 🥱
| EN +------------------+----+ Pages | 17 Paginator pages | 0 Non-page files | 0 Static files | 13 Processed images | 0 Aliases | 0 Sitemaps | 1 Cleaned | 0 Total in 767 ms 通过 sh 脚本完成一键构建，更新博客。
创建帖子 $ hugo new posts/blog-自动构建.md 重新构建 hugo 页面 编辑完成帖子后，更新网站。
#!/bin/sh # deploy.sh hugo --theme=dream --buildDrafts --baseUrl=&#34;https://abeelan.github.io/&#34; echo &#34;\033[0;32mDeploying updates to GitHub...\033[0m&#34; # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=&#34;rebuilding site `date`&#34; if [ $# -eq 1 ] then msg=&#34;$1&#34; fi git commit -m &#34;$msg&#34; # Push source and build repos. git push origin main # Come Back up to the Project Root cd .. 在项目目录下执行上面脚本，记得添加一下可执行权限。
$ ./deploy.sh ]]></content></entry></search>